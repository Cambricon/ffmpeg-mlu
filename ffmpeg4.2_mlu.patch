From 82ae960adb5187d85b108d56bbf49b7d87084c3a Mon Sep 17 00:00:00 2001
From: solution-sdk <solution-sdk@cambricon.com>
Date: Thu, 26 Aug 2021 11:48:47 +0800
Subject: [PATCH] gen new patch

---
 configure                            |   18 +
 doc/examples/Makefile                |    2 +
 doc/examples/hw_decode_mlu.c         |  256 ++++
 doc/examples/mlumpp_transcode.c      |  396 ++++++
 fftools/Makefile                     |    1 +
 fftools/ffmpeg.h                     |    2 +
 fftools/ffmpeg_mlu.c                 |   74 ++
 fftools/ffmpeg_opt.c                 |    3 +
 libavcodec/Makefile                  |    8 +
 libavcodec/allcodecs.c               |    8 +
 libavcodec/hwaccel.h                 |    2 +
 libavcodec/mlumpp_dec.c              | 1690 ++++++++++++++++++++++++++
 libavcodec/mlumpp_enc_h264.c         |  175 +++
 libavcodec/mlumpp_enc_hevc.c         |  172 +++
 libavcodec/mlumpp_enc_jpeg.c         | 1084 +++++++++++++++++
 libavcodec/mlumpp_mluop.c            |  122 ++
 libavcodec/mlumpp_mluop.h            |   33 +
 libavcodec/mlumpp_vid_enc.c          | 1301 ++++++++++++++++++++
 libavcodec/mlumpp_vid_enc.h          |  147 +++
 libavfilter/Makefile                 |   10 +
 libavfilter/allfilters.c             |   10 +
 libavfilter/vf_cvt_rgbx2yuv_mlu.c    |  547 +++++++++
 libavfilter/vf_cvt_yuv2rgbx_mlu.c    |  541 +++++++++
 libavfilter/vf_hwdownload_mlu.c      |  209 ++++
 libavfilter/vf_hwupload_mlu.c        |  200 +++
 libavfilter/vf_scale_rgbx2rgbx_mlu.c |  495 ++++++++
 libavfilter/vf_scale_yuv2yuv_mlu.c   |  502 ++++++++
 libavfilter/vf_sr_mlu.c              |  271 +++++
 libavutil/Makefile                   |    3 +
 libavutil/hwcontext.c                |    5 +
 libavutil/hwcontext.h                |    1 +
 libavutil/hwcontext_internal.h       |    1 +
 libavutil/hwcontext_mlu.c            |  433 +++++++
 libavutil/hwcontext_mlu.h            |   62 +
 libavutil/pixdesc.c                  |    4 +
 libavutil/pixfmt.h                   |    6 +
 36 files changed, 8794 insertions(+)
 create mode 100644 doc/examples/hw_decode_mlu.c
 create mode 100755 doc/examples/mlumpp_transcode.c
 create mode 100644 fftools/ffmpeg_mlu.c
 mode change 100644 => 100755 libavcodec/Makefile
 mode change 100644 => 100755 libavcodec/allcodecs.c
 create mode 100755 libavcodec/mlumpp_dec.c
 create mode 100755 libavcodec/mlumpp_enc_h264.c
 create mode 100755 libavcodec/mlumpp_enc_hevc.c
 create mode 100755 libavcodec/mlumpp_enc_jpeg.c
 create mode 100755 libavcodec/mlumpp_mluop.c
 create mode 100755 libavcodec/mlumpp_mluop.h
 create mode 100755 libavcodec/mlumpp_vid_enc.c
 create mode 100755 libavcodec/mlumpp_vid_enc.h
 create mode 100644 libavfilter/vf_cvt_rgbx2yuv_mlu.c
 create mode 100644 libavfilter/vf_cvt_yuv2rgbx_mlu.c
 create mode 100644 libavfilter/vf_hwdownload_mlu.c
 create mode 100644 libavfilter/vf_hwupload_mlu.c
 create mode 100644 libavfilter/vf_scale_rgbx2rgbx_mlu.c
 create mode 100644 libavfilter/vf_scale_yuv2yuv_mlu.c
 create mode 100644 libavfilter/vf_sr_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.h

diff --git a/configure b/configure
index 34c2adb4a4..bb2c2833f7 100755
--- a/configure
+++ b/configure
@@ -340,6 +340,7 @@ External library support:
   --disable-vaapi          disable Video Acceleration API (mainly Unix/Intel) code [autodetect]
   --disable-vdpau          disable Nvidia Video Decode and Presentation API for Unix code [autodetect]
   --disable-videotoolbox   disable VideoToolbox code [autodetect]
+  --enable-mlumpp          enable Cambricon MLU Media Process Platform code (mlumpp) [no]
 
 Toolchain options:
   --arch=ARCH              select architecture [$arch]
@@ -1685,6 +1686,8 @@ EXAMPLE_LIST="
     transcoding_example
     vaapi_encode_example
     vaapi_transcode_example
+    mlumpp_transcode_example
+    hw_decode_mlu_example
 "
 
 EXTERNAL_AUTODETECT_LIBRARY_LIST="
@@ -1738,6 +1741,7 @@ EXTERNAL_LIBRARY_VERSION3_LIST="
     libvo_amrwbenc
     mbedtls
     rkmpp
+    mlumpp
 "
 
 EXTERNAL_LIBRARY_GPLV3_LIST="
@@ -1831,6 +1835,7 @@ HWACCEL_AUTODETECT_LIBRARY_LIST="
     videotoolbox
     v4l2_m2m
     xvmc
+    mlu
 "
 
 # catchall list of things that require external libs to link
@@ -3014,11 +3019,14 @@ h264_mediacodec_decoder_deps="mediacodec"
 h264_mediacodec_decoder_select="h264_mp4toannexb_bsf h264_parser"
 h264_mmal_decoder_deps="mmal"
 h264_nvenc_encoder_deps="nvenc"
+h264_mlumpp_encoder_deps="mlumpp"
 h264_omx_encoder_deps="omx"
 h264_qsv_decoder_select="h264_mp4toannexb_bsf h264_parser qsvdec"
 h264_qsv_encoder_select="qsvenc"
 h264_rkmpp_decoder_deps="rkmpp"
 h264_rkmpp_decoder_select="h264_mp4toannexb_bsf"
+h264_mlumpp_decoder_deps="mlumpp"
+h264_mlumpp_decoder_select="h264_mp4toannexb_bsf"
 h264_vaapi_encoder_select="cbs_h264 vaapi_encode"
 h264_v4l2m2m_decoder_deps="v4l2_m2m h264_v4l2_m2m"
 h264_v4l2m2m_decoder_select="h264_mp4toannexb_bsf"
@@ -3029,16 +3037,21 @@ hevc_cuvid_decoder_select="hevc_mp4toannexb_bsf"
 hevc_mediacodec_decoder_deps="mediacodec"
 hevc_mediacodec_decoder_select="hevc_mp4toannexb_bsf hevc_parser"
 hevc_nvenc_encoder_deps="nvenc"
+hevc_mlumpp_encoder_deps="mlumpp"
 hevc_qsv_decoder_select="hevc_mp4toannexb_bsf hevc_parser qsvdec"
 hevc_qsv_encoder_select="hevcparse qsvenc"
 hevc_rkmpp_decoder_deps="rkmpp"
 hevc_rkmpp_decoder_select="hevc_mp4toannexb_bsf"
+hevc_mlumpp_decoder_deps="mlumpp"
+hevc_mlumpp_decoder_select="hevc_mp4toannexb_bsf"
 hevc_vaapi_encoder_deps="VAEncPictureParameterBufferHEVC"
 hevc_vaapi_encoder_select="cbs_h265 vaapi_encode"
 hevc_v4l2m2m_decoder_deps="v4l2_m2m hevc_v4l2_m2m"
 hevc_v4l2m2m_decoder_select="hevc_mp4toannexb_bsf"
 hevc_v4l2m2m_encoder_deps="v4l2_m2m hevc_v4l2_m2m"
 mjpeg_cuvid_decoder_deps="cuvid"
+mjpeg_mlumpp_decoder_deps="mlumpp"
+mjpeg_mlumpp_encoder_deps="mlumpp"
 mjpeg_qsv_encoder_deps="libmfx"
 mjpeg_qsv_encoder_select="qsvenc"
 mjpeg_vaapi_encoder_deps="VAEncPictureParameterBufferJPEG"
@@ -3069,6 +3082,7 @@ vc1_mmal_decoder_deps="mmal"
 vc1_qsv_decoder_select="qsvdec vc1_parser"
 vc1_v4l2m2m_decoder_deps="v4l2_m2m vc1_v4l2_m2m"
 vp8_cuvid_decoder_deps="cuvid"
+vp8_mlumpp_decoder_deps="mlumpp"
 vp8_mediacodec_decoder_deps="mediacodec"
 vp8_qsv_decoder_select="qsvdec vp8_parser"
 vp8_rkmpp_decoder_deps="rkmpp"
@@ -3077,6 +3091,7 @@ vp8_vaapi_encoder_select="vaapi_encode"
 vp8_v4l2m2m_decoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp8_v4l2m2m_encoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp9_cuvid_decoder_deps="cuvid"
+vp9_mlumpp_decoder_deps="mlumpp"
 vp9_mediacodec_decoder_deps="mediacodec"
 vp9_rkmpp_decoder_deps="rkmpp"
 vp9_vaapi_encoder_deps="VAEncPictureParameterBufferVP9"
@@ -6367,6 +6382,9 @@ enabled rkmpp             && { require_pkg_config rkmpp rockchip_mpp  rockchip/r
                              }
 enabled vapoursynth       && require_pkg_config vapoursynth "vapoursynth-script >= 42" VSScript.h vsscript_init
 
+if enabled mlumpp; then
+    require_headers  cn_video_dec.h && require_headers  cn_video_enc.h || die "ERROR: mlumpp requires proper neuware environment";
+fi
 
 if enabled gcrypt; then
     GCRYPT_CONFIG="${cross_prefix}libgcrypt-config"
diff --git a/doc/examples/Makefile b/doc/examples/Makefile
index 2935424e54..ff4041cfc9 100644
--- a/doc/examples/Makefile
+++ b/doc/examples/Makefile
@@ -21,6 +21,8 @@ EXAMPLES-$(CONFIG_TRANSCODE_AAC_EXAMPLE)     += transcode_aac
 EXAMPLES-$(CONFIG_TRANSCODING_EXAMPLE)       += transcoding
 EXAMPLES-$(CONFIG_VAAPI_ENCODE_EXAMPLE)      += vaapi_encode
 EXAMPLES-$(CONFIG_VAAPI_TRANSCODE_EXAMPLE)   += vaapi_transcode
+EXAMPLES-$(CONFIG_MLUMPP_TRANSCODE_EXAMPLE)  += mlumpp_transcode
+EXAMPLES-$(CONFIG_HW_DECODE_MLU_EXAMPLE)     += hw_decode_mlu
 
 EXAMPLES       := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)$(EXESUF))
 EXAMPLES_G     := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)_g$(EXESUF))
diff --git a/doc/examples/hw_decode_mlu.c b/doc/examples/hw_decode_mlu.c
new file mode 100644
index 0000000000..6c6c983544
--- /dev/null
+++ b/doc/examples/hw_decode_mlu.c
@@ -0,0 +1,256 @@
+/*
+ * MLU MPP Video Acceleration API (video transcoding) transcode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated decoding example.
+ *
+ * @example hw_decode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated decoding with output
+ * frames from the HW video surfaces.
+ * Usage: hw_decode_mlu mlu input.mp4 output.yuv
+ */
+
+#include <stdio.h>
+
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+#include <libavutil/pixdesc.h>
+#include <libavutil/hwcontext.h>
+#include <libavutil/opt.h>
+#include <libavutil/avassert.h>
+#include <libavutil/imgutils.h>
+
+static AVBufferRef *hw_device_ctx = NULL;
+static enum AVPixelFormat hw_pix_fmt;
+static FILE *output_file = NULL;
+
+static int hw_decoder_init(AVCodecContext *ctx, const enum AVHWDeviceType type)
+{
+    int err = 0;
+
+    if ((err = av_hwdevice_ctx_create(&hw_device_ctx, type,
+                                      NULL, NULL, 0)) < 0) {
+        fprintf(stderr, "Failed to create specified HW device.\n");
+        return err;
+    }
+    ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);
+
+    return err;
+}
+
+static enum AVPixelFormat get_hw_format(AVCodecContext *ctx,
+                                        const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+
+    for (p = pix_fmts; *p != -1; p++) {
+        if (*p == hw_pix_fmt)
+            return *p;
+    }
+
+    fprintf(stderr, "Failed to get HW surface format.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int decode_write(AVCodecContext *avctx, AVPacket *packet)
+{
+    AVFrame *frame = NULL, *sw_frame = NULL;
+    AVFrame *tmp_frame = NULL;
+    uint8_t *buffer = NULL;
+    int size;
+    int ret = 0;
+
+    ret = avcodec_send_packet(avctx, packet);
+    if (ret < 0) {
+        fprintf(stderr, "Error during decoding\n");
+        return ret;
+    }
+
+    while (1) {
+        if (!(frame = av_frame_alloc()) || !(sw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Can not alloc frame\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        ret = avcodec_receive_frame(avctx, frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            av_frame_free(&frame);
+            av_frame_free(&sw_frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding\n");
+            goto fail;
+        }
+
+        if (frame->format == hw_pix_fmt) {
+            /* retrieve data from MLU to CPU */
+            if ((ret = av_hwframe_transfer_data(sw_frame, frame, 0)) < 0) {
+                fprintf(stderr, "Error transferring the data to system memory\n");
+                goto fail;
+            }
+            tmp_frame = sw_frame;
+        } else
+            tmp_frame = frame;
+
+        size = av_image_get_buffer_size(tmp_frame->format, tmp_frame->width,
+                                        tmp_frame->height, 1);
+        buffer = av_malloc(size);
+        if (!buffer) {
+            fprintf(stderr, "Can not alloc buffer\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        ret = av_image_copy_to_buffer(buffer, size,
+                                      (const uint8_t * const *)tmp_frame->data,
+                                      (const int *)tmp_frame->linesize, tmp_frame->format,
+                                      tmp_frame->width, tmp_frame->height, 1);
+        if (ret < 0) {
+            fprintf(stderr, "Can not copy image to buffer\n");
+            goto fail;
+        }
+
+        if ((ret = fwrite(buffer, 1, size, output_file)) < 0) {
+            fprintf(stderr, "Failed to dump raw data.\n");
+            goto fail;
+        }
+
+    fail:
+        av_frame_free(&frame);
+        av_frame_free(&sw_frame);
+        av_freep(&buffer);
+        if (ret < 0)
+            return ret;
+    }
+}
+
+int main(int argc, char *argv[])
+{
+    AVFormatContext *input_ctx = NULL;
+    int video_stream, ret;
+    AVStream *video = NULL;
+    AVCodecContext *decoder_ctx = NULL;
+    AVCodec *decoder = NULL;
+    AVPacket packet;
+    enum AVHWDeviceType type;
+    int i;
+
+    if (argc < 4) {
+        fprintf(stderr, "Usage: %s <device type> <input file> <output file>\n", argv[0]);
+        return -1;
+    }
+
+    type = av_hwdevice_find_type_by_name(argv[1]);
+    if (type == AV_HWDEVICE_TYPE_NONE) {
+        fprintf(stderr, "Device type %s is not supported.\n", argv[1]);
+        fprintf(stderr, "Available device types:");
+        while((type = av_hwdevice_iterate_types(type)) != AV_HWDEVICE_TYPE_NONE)
+            fprintf(stderr, " %s", av_hwdevice_get_type_name(type));
+        fprintf(stderr, "\n");
+        return -1;
+    }
+
+    /* open the input file */
+    if (avformat_open_input(&input_ctx, argv[2], NULL, NULL) != 0) {
+        fprintf(stderr, "Cannot open input file '%s'\n", argv[2]);
+        return -1;
+    }
+
+    if (avformat_find_stream_info(input_ctx, NULL) < 0) {
+        fprintf(stderr, "Cannot find input stream information.\n");
+        return -1;
+    }
+
+    decoder = avcodec_find_decoder_by_name("h264_mludec");
+    if (!decoder) {
+        fprintf(stderr, "The MLU decoder is not present in libavcodec\n");
+        return -1;
+    }
+
+    // find video stream
+    for (size_t i = 0; i < input_ctx->nb_streams; i++) {
+        if (input_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            video_stream = i;
+        }
+    }
+
+    for (i = 0;; i++) {
+        const AVCodecHWConfig *config = avcodec_get_hw_config(decoder, i);
+        if (!config) {
+            fprintf(stderr, "Decoder %s does not support device type %s.\n",
+                    decoder->name, av_hwdevice_get_type_name(type));
+            return -1;
+        }
+        if (config->methods & AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &&
+            config->device_type == type) {
+            hw_pix_fmt = config->pix_fmt;
+            break;
+        }
+    }
+
+    if (!(decoder_ctx = avcodec_alloc_context3(decoder)))
+        return AVERROR(ENOMEM);
+
+    video = input_ctx->streams[video_stream];
+    if (avcodec_parameters_to_context(decoder_ctx, video->codecpar) < 0)
+        return -1;
+
+    decoder_ctx->get_format  = get_hw_format;
+
+    if (hw_decoder_init(decoder_ctx, type) < 0)
+        return -1;
+
+    if ((ret = avcodec_open2(decoder_ctx, decoder, NULL)) < 0) {
+        fprintf(stderr, "Failed to open codec for stream #%u\n", video_stream);
+        return -1;
+    }
+
+    /* open the file to dump raw data */
+    output_file = fopen(argv[3], "w+");
+
+    /* actual decoding and dump the raw data */
+    while (ret >= 0) {
+        if ((ret = av_read_frame(input_ctx, &packet)) < 0)
+            break;
+
+        if (video_stream == packet.stream_index)
+            ret = decode_write(decoder_ctx, &packet);
+
+        av_packet_unref(&packet);
+    }
+
+    /* flush the decoder */
+    packet.data = NULL;
+    packet.size = 0;
+    ret = decode_write(decoder_ctx, &packet);
+    av_packet_unref(&packet);
+
+    if (output_file)
+        fclose(output_file);
+    avcodec_free_context(&decoder_ctx);
+    avformat_close_input(&input_ctx);
+    av_buffer_unref(&hw_device_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/mlumpp_transcode.c b/doc/examples/mlumpp_transcode.c
new file mode 100755
index 0000000000..8aca30a7c4
--- /dev/null
+++ b/doc/examples/mlumpp_transcode.c
@@ -0,0 +1,396 @@
+/*
+ * MLU MPP Video Acceleration API (video transcoding) transcode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-accelerated transcoding example.
+ *
+ * @example mlumpp_transcode.c
+ * This example shows how to do mlumpp-accelerated transcoding with multi-threads supports.
+ * Usage: mlu_transcode codec input_stream codec output_path file extension
+ * e.g: - mlu_transcode h264_mludec input.mp4 hevc_mluenc ./ mp4
+ *      - mlu_transcode hevc_mludec input.mp4 h264_mluenc ./ mp4
+ */
+
+#include <stdio.h>
+#include <errno.h>
+#include <unistd.h>
+#include <pthread.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+#include <libavutil/avstring.h>
+#include <libavutil/time.h>
+typedef struct{
+    AVFormatContext *ifmt_ctx;
+    AVFormatContext *ofmt_ctx;
+    AVCodecContext *decoder_ctx;
+    AVCodecContext *encoder_ctx;
+    int video_stream;
+    AVStream *ost;
+    int initialized;
+    uint64_t transcoding_frames_count;
+    uint64_t decoder_time_st;
+    uint64_t seconds_elapsed;
+}mlu_transcode_context_t;
+
+#define DOWNSCALE
+// #define PERF_PRINT
+static int open_input_file(const char *filename,AVCodec *decoder,mlu_transcode_context_t *ctx)
+{
+    int ret;
+    AVStream *video = NULL;
+    AVDictionary *decoder_opts = NULL;
+#ifdef DOWNSCALE
+    char resize_str[10];
+#endif
+    if ((ret = avformat_open_input(&ctx->ifmt_ctx, filename, NULL, NULL)) < 0) {
+        fprintf(stderr, "Cannot open input file '%s', Error code: %s\n",
+                filename, av_err2str(ret));
+        return ret;
+    }
+
+    if ((ret = avformat_find_stream_info(ctx->ifmt_ctx, NULL)) < 0) {
+        fprintf(stderr, "Cannot find input stream information. Error code: %s\n",
+                av_err2str(ret));
+        return ret;
+    }
+
+    ret = av_find_best_stream(ctx->ifmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);
+    if (ret < 0) {
+        fprintf(stderr, "Cannot find a video stream in the input file. "
+                "Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+    ctx->video_stream = ret;
+
+    if (!(ctx->decoder_ctx = avcodec_alloc_context3(decoder)))
+        return AVERROR(ENOMEM);
+
+    video = ctx->ifmt_ctx->streams[ctx->video_stream];
+    if ((ret = avcodec_parameters_to_context(ctx->decoder_ctx, video->codecpar)) < 0) {
+        fprintf(stderr, "avcodec_parameters_to_context error. Error code: %s\n",
+                av_err2str(ret));
+        return ret;
+    }
+    if (av_stristr(decoder->name,"mludec")) {
+#ifdef DOWNSCALE
+        snprintf(resize_str,10,"%dx%d", ctx->decoder_ctx->width>>2,ctx->decoder_ctx->height>>2);
+        av_dict_set(&decoder_opts, "resize", resize_str, 0);
+#endif
+        ctx->decoder_ctx->flags |= AV_CODEC_FLAG_LOW_DELAY;
+        //av_dict_set_int(&decoder_opts, "trace", 1, 0);
+        av_dict_set_int(&decoder_opts, "device_id", 0, 0);
+    }
+    if ((ret = avcodec_open2(ctx->decoder_ctx, decoder, &decoder_opts)) < 0)
+        fprintf(stderr, "Failed to open codec for decoding. Error code: %s\n",
+                av_err2str(ret));
+
+    if (decoder_opts) {
+        av_dict_free(&decoder_opts);
+        decoder_opts = NULL;
+    }
+    return ret;
+}
+
+static int encode_write(AVFrame *frame,mlu_transcode_context_t *ctx)
+{
+    int ret = 0;
+    AVPacket enc_pkt;
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+    if ((ret = avcodec_send_frame(ctx->encoder_ctx, frame)) < 0) {
+        fprintf(stderr, "Error during encoding. Error code: %s\n", av_err2str(ret));
+        goto end;
+    }
+
+    while (1) {
+        ret = avcodec_receive_packet(ctx->encoder_ctx, &enc_pkt);
+        if (ret)
+            break;
+#ifndef PERF_PRINT
+        enc_pkt.stream_index = 0;
+        av_packet_rescale_ts(&enc_pkt, ctx->ifmt_ctx->streams[ctx->video_stream]->time_base,
+                             ctx->ofmt_ctx->streams[0]->time_base);
+        ret = av_interleaved_write_frame(ctx->ofmt_ctx, &enc_pkt);
+        if (ret < 0) {
+            fprintf(stderr, "Error during writing data to output file. "
+                    "Error code: %s\n", av_err2str(ret));
+            return -1;
+        }
+#else
+        ctx->transcoding_frames_count ++;
+#endif
+    }
+end:
+    if (ret == AVERROR_EOF)
+        return 0;
+    ret = ((ret == AVERROR(EAGAIN)) ? 0:-1);
+    return ret;
+}
+#define DEFAULT_BPS 0x100000
+#define DEFAULT_GOP 50
+#define DEFAULT_QMIN 26
+#define DEFAULT_QMAX 51
+#define DEFAULT_B_NUM 1
+static int dec_enc(AVPacket *pkt, AVCodec *dec_codec,AVCodec *enc_codec,mlu_transcode_context_t *ctx)
+{
+    AVFrame *frame;
+    int ret = 0;
+    AVDictionary *encoder_opts = NULL;
+
+    ret = avcodec_send_packet(ctx->decoder_ctx, pkt);
+    if (ret < 0) {
+        if (ret != AVERROR_EOF)
+            fprintf(stderr, "Error during decoding. Error code: %s\n", av_err2str(ret));
+        return ret;
+    }
+    while (ret >= 0) {
+        if (!(frame = av_frame_alloc()))
+            return AVERROR(ENOMEM);
+
+        ret = avcodec_receive_frame(ctx->decoder_ctx, frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            av_frame_free(&frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding. Error code: %s\n", av_err2str(ret));
+            goto fail;
+        }
+
+        if (!ctx->initialized) {
+            /* set AVCodecContext Parameters for encoder, here we keep them stay
+             * the same as decoder.
+             * xxx: now the sample can't handle resolution change case.
+             */
+            ctx->encoder_ctx->time_base = (AVRational){1, 25};
+            /* take first format from list of supported formats */
+            if (enc_codec->pix_fmts)
+                ctx->encoder_ctx->pix_fmt = enc_codec->pix_fmts[0];
+            else
+                ctx->encoder_ctx->pix_fmt = ctx->decoder_ctx->pix_fmt;
+            ctx->encoder_ctx->width     = ctx->decoder_ctx->width;
+            ctx->encoder_ctx->height    = ctx->decoder_ctx->height;
+            ctx->encoder_ctx->bit_rate = DEFAULT_BPS;
+            ctx->encoder_ctx->gop_size = DEFAULT_GOP;
+            ctx->encoder_ctx->sample_aspect_ratio = ctx->decoder_ctx->sample_aspect_ratio;
+            ctx->encoder_ctx->framerate =  (AVRational){25, 1};
+            ctx->encoder_ctx->max_b_frames = DEFAULT_B_NUM;
+            ctx->encoder_ctx->qmin = DEFAULT_QMIN;
+            ctx->encoder_ctx->qmax = DEFAULT_QMAX;
+            if (av_stristr(enc_codec->name,"mluenc")) {
+                //av_dict_set_int(&encoder_opts, "trace", 1, 0);
+                av_dict_set_int(&encoder_opts, "device_id", 0, 0);
+            }
+            if ((ret = avcodec_open2(ctx->encoder_ctx, enc_codec, &encoder_opts)) < 0) {
+                fprintf(stderr, "Failed to open encode codec. Error code: %s\n",
+                        av_err2str(ret));
+                goto fail;
+            }
+            if (encoder_opts) {
+                av_dict_free(&encoder_opts);
+                encoder_opts = NULL;
+            }
+            if (!(ctx->ost = avformat_new_stream(ctx->ofmt_ctx, enc_codec))) {
+                fprintf(stderr, "Failed to allocate stream for output format.\n");
+                ret = AVERROR(ENOMEM);
+                goto fail;
+            }
+
+            ctx->ost->time_base = ctx->encoder_ctx->time_base;
+            ret = avcodec_parameters_from_context(ctx->ost->codecpar, ctx->encoder_ctx);
+            if (ret < 0) {
+                fprintf(stderr, "Failed to copy the stream parameters. "
+                        "Error code: %s\n", av_err2str(ret));
+                goto fail;
+            }
+
+            /* write the stream header */
+            if ((ret = avformat_write_header(ctx->ofmt_ctx, NULL)) < 0) {
+                fprintf(stderr, "Error while writing stream header. "
+                        "Error code: %s\n", av_err2str(ret));
+                goto fail;
+            }
+            ctx->decoder_time_st = av_gettime_relative();
+            ctx->initialized = 1;
+        }
+
+        if ((ret = encode_write(frame,ctx)) < 0)
+            fprintf(stderr, "Error during encoding and writing.\n");
+fail:
+        av_frame_free(&frame);
+        if (ret < 0)
+            return ret;
+    }
+    return 0;
+}
+
+int transcode_cmd(int argc, char **argv);
+#define FILE_NAME_MAX 1024
+int transcode_cmd(int argc, char **argv)
+{
+    int ret = 0;
+    AVPacket dec_pkt;
+    AVCodec *enc_codec;
+    AVCodec *dec_codec;
+    char output_file[FILE_NAME_MAX];
+    pthread_t tid;
+    mlu_transcode_context_t ctx;
+    uint64_t time_st,time_end;
+    memset((void*)&ctx,0,sizeof(mlu_transcode_context_t));
+    ctx.video_stream = -1;
+    ctx.initialized = 0;
+    av_log_set_flags(AV_LOG_SKIP_REPEATED);
+    av_log_set_level(AV_LOG_INFO);
+    tid = pthread_self();
+    memset(output_file,0,FILE_NAME_MAX);
+    snprintf(output_file,FILE_NAME_MAX,"%s/%lu.%s",argv[4],(long unsigned)tid,argv[5]);
+    if (!(dec_codec = avcodec_find_decoder_by_name(argv[1]))) {
+        fprintf(stderr, "Could not find decoder '%s'\n", argv[1]);
+        ret = -1;
+        goto end;
+    }
+
+    if ((ret = open_input_file(argv[2],dec_codec,&ctx) < 0))
+        goto end;
+
+    if (!(enc_codec = avcodec_find_encoder_by_name(argv[3]))) {
+        fprintf(stderr, "Could not find encoder '%s'\n", argv[3]);
+        ret = -1;
+        goto end;
+    }
+
+    if ((ret = (avformat_alloc_output_context2(&(ctx.ofmt_ctx), NULL, NULL, output_file))) < 0) {
+        fprintf(stderr, "Failed to deduce output format from file extension. Error code: "
+                "%s\n", av_err2str(ret));
+        goto end;
+    }
+
+    if (!(ctx.encoder_ctx = avcodec_alloc_context3(enc_codec))) {
+        ret = AVERROR(ENOMEM);
+        goto end;
+    }
+
+    ret = avio_open(&(ctx.ofmt_ctx->pb), output_file, AVIO_FLAG_WRITE);
+    if (ret < 0) {
+        fprintf(stderr, "Cannot open output file. "
+                "Error code: %s\n", av_err2str(ret));
+        goto end;
+    }
+
+    /* read all packets and only transcoding video */
+    while (ret >= 0) {
+        if ((ret = av_read_frame(ctx.ifmt_ctx, &dec_pkt)) < 0)
+            break;
+
+        if (ctx.video_stream == dec_pkt.stream_index){
+            ret = dec_enc(&dec_pkt, dec_codec,enc_codec,&ctx);
+        }
+        av_packet_unref(&dec_pkt);
+    }
+
+    /* flush decoder */
+    {
+        dec_pkt.data = NULL;
+        dec_pkt.size = 0;
+        ret = dec_enc(&dec_pkt, dec_codec,enc_codec,&ctx);
+        av_packet_unref(&dec_pkt);
+    }
+
+    /* flush encoder */
+    ret = encode_write(NULL,&ctx);
+#ifndef PERF_PRINT
+    /* write the trailer for output stream */
+    av_write_trailer(ctx.ofmt_ctx);
+#endif
+
+end:
+    time_st = ctx.decoder_time_st;
+    time_end = av_gettime_relative();
+    ctx.seconds_elapsed = (time_end - time_st) / 1000000;
+#ifdef PERF_PRINT
+    fprintf(stderr, "Total transcoding frames couts: %lu,"
+    "elapsed seconds: %lu,transcoding perf: %.2f \n",
+    ctx.transcoding_frames_count,ctx.seconds_elapsed,(float)ctx.transcoding_frames_count/(float)ctx.seconds_elapsed);
+#endif
+    avformat_close_input(&ctx.ifmt_ctx);
+    avformat_close_input(&ctx.ofmt_ctx);
+    avcodec_free_context(&ctx.decoder_ctx);
+    avcodec_free_context(&ctx.encoder_ctx);
+    return ret;
+}
+
+typedef struct {
+    int argc;
+    char** argv;
+}cmd_set_t;
+
+void* transocde_task(void* args);
+void* transocde_task(void* args)
+{
+    cmd_set_t * cmd = (cmd_set_t*)args;
+    transcode_cmd(cmd->argc,cmd->argv);
+    return NULL;
+}
+#define NUM_THREADS 60
+int main(int argc, char** argv)
+{
+    pthread_t tids[NUM_THREADS];
+    pthread_attr_t attr;
+    cmd_set_t cmd[NUM_THREADS];
+    int ret = 0;
+    int thread_num = NUM_THREADS;
+    if (argc != 7) {
+        fprintf(stderr, "Usage: %s <decode codec> <input file> <encode codec> <output path> <file extension> <task num>\n"
+        "The output format is guessed according to the file extension.\n"
+        "\n", argv[0]);
+        return -1;
+    }
+    thread_num = atoi(argv[6]);
+    if (thread_num < 0 || thread_num > NUM_THREADS) {
+        thread_num = NUM_THREADS;
+    }
+    pthread_attr_init( &attr);
+    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);
+    for (int i = 0;i < thread_num; i++) {
+        cmd[i].argc = argc;
+        cmd[i].argv = argv;
+        ret = pthread_create( &tids[i], &attr, transocde_task, (void*)&cmd[i]);
+        if(ret != 0) {
+            fprintf(stderr, "pthread_create error:error_code= %d\n",ret);
+        }
+    }
+    pthread_attr_destroy(&attr);
+    for(int i = 0; i < thread_num; i++){
+        void *status = NULL;
+        ret = pthread_join( tids[i], &status);
+        if (ret != 0){
+            fprintf(stderr, "pthread_join error(thread id :%lu): error_code=%d\n",(long unsigned)tids[i],ret);
+        } else {
+#ifndef PERF_PRINT
+            fprintf(stderr, "pthread_join(thread id :%lu): get status:=%ld\n",(long unsigned)tids[i],(long)status);
+#endif
+        }
+    }
+    return 0;
+}
diff --git a/fftools/Makefile b/fftools/Makefile
index 6cec666dd9..ea35e26a4c 100644
--- a/fftools/Makefile
+++ b/fftools/Makefile
@@ -12,6 +12,7 @@ ALLAVPROGS_G = $(AVBASENAMES:%=%$(PROGSSUF)_g$(EXESUF))
 OBJS-ffmpeg                        += fftools/ffmpeg_opt.o fftools/ffmpeg_filter.o fftools/ffmpeg_hw.o
 OBJS-ffmpeg-$(CONFIG_CUVID)        += fftools/ffmpeg_cuvid.o
 OBJS-ffmpeg-$(CONFIG_LIBMFX)       += fftools/ffmpeg_qsv.o
+OBJS-ffmpeg-$(CONFIG_MLU)          += fftools/ffmpeg_mlu.o
 ifndef CONFIG_VIDEOTOOLBOX
 OBJS-ffmpeg-$(CONFIG_VDA)          += fftools/ffmpeg_videotoolbox.o
 endif
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 7b6f802082..210ebbe01b 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -62,6 +62,7 @@ enum HWAccelID {
     HWACCEL_VIDEOTOOLBOX,
     HWACCEL_QSV,
     HWACCEL_CUVID,
+    HWACCEL_MLU,
 };
 
 typedef struct HWAccel {
@@ -655,6 +656,7 @@ int ffmpeg_parse_options(int argc, char **argv);
 int videotoolbox_init(AVCodecContext *s);
 int qsv_init(AVCodecContext *s);
 int cuvid_init(AVCodecContext *s);
+int mlu_init(AVCodecContext *s);
 
 HWDevice *hw_device_get_by_name(const char *name);
 int hw_device_init_from_string(const char *arg, HWDevice **dev);
diff --git a/fftools/ffmpeg_mlu.c b/fftools/ffmpeg_mlu.c
new file mode 100644
index 0000000000..546b9ef707
--- /dev/null
+++ b/fftools/ffmpeg_mlu.c
@@ -0,0 +1,74 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/pixdesc.h"
+
+#include "ffmpeg.h"
+
+static void mlu_uninit(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    av_buffer_unref(&ist->hw_frames_ctx);
+}
+
+int mlu_init(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    AVHWFramesContext *frames_ctx;
+    int ret;
+
+    av_log(avctx, AV_LOG_VERBOSE, "Initializing mlu hwaccel\n");
+
+    if (!hw_device_ctx) {
+        ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_MLU,
+                                     ist->hwaccel_device, NULL, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Error creating a MLU device\n");
+            return ret;
+        }
+    }
+
+    av_buffer_unref(&ist->hw_frames_ctx);
+    ist->hw_frames_ctx = av_hwframe_ctx_alloc(hw_device_ctx);
+    if (!ist->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR, "Error creating a MLU frames context\n");
+        return AVERROR(ENOMEM);
+    }
+
+    frames_ctx = (AVHWFramesContext*)ist->hw_frames_ctx->data;
+
+    frames_ctx->format = AV_PIX_FMT_MLU;
+    frames_ctx->sw_format = avctx->sw_pix_fmt;
+    frames_ctx->width  = avctx->width;
+    frames_ctx->height = avctx->height;
+
+    av_log(avctx, AV_LOG_DEBUG, "Initializing MLU frames context: sw_format = %s, width = %d, height = %d\n",
+           av_get_pix_fmt_name(frames_ctx->sw_format), frames_ctx->width, frames_ctx->height);
+
+    ret = av_hwframe_ctx_init(ist->hw_frames_ctx);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error initializing a MLU frame pool\n");
+        return ret;
+    }
+
+    ist->hwaccel_uninit = mlu_uninit;
+
+    return 0;
+}
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index f5ca18aa64..47b83a7c4f 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -74,6 +74,9 @@ const HWAccel hwaccels[] = {
 #endif
 #if CONFIG_CUVID
     { "cuvid", cuvid_init, HWACCEL_CUVID, AV_PIX_FMT_CUDA },
+#endif
+#if CONFIG_MLU
+    { "mlu", mlu_init, HWACCEL_MLU, AV_PIX_FMT_MLU },
 #endif
     { 0 },
 };
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
old mode 100644
new mode 100755
index 3cd73fbcc6..f47f3adde4
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -347,6 +347,8 @@ OBJS-$(CONFIG_H264_DECODER)            += h264dec.o h264_cabac.o h264_cavlc.o \
                                           h264_mb.o h264_picture.o \
                                           h264_refs.o h264_sei.o \
                                           h264_slice.o h264data.o
+OBJS-$(CONFIG_H264_MLUMPP_DECODER)     += mlumpp_dec.o mlumpp_mluop.o
+OBJS-$(CONFIG_H264_MLUMPP_ENCODER)     += mlumpp_vid_enc.o mlumpp_enc_h264.o
 OBJS-$(CONFIG_H264_AMF_ENCODER)        += amfenc_h264.o
 OBJS-$(CONFIG_H264_CUVID_DECODER)      += cuviddec.o
 OBJS-$(CONFIG_H264_MEDIACODEC_DECODER) += mediacodecdec.o
@@ -368,6 +370,8 @@ OBJS-$(CONFIG_HCOM_DECODER)            += hcom.o
 OBJS-$(CONFIG_HEVC_DECODER)            += hevcdec.o hevc_mvs.o \
                                           hevc_cabac.o hevc_refs.o hevcpred.o    \
                                           hevcdsp.o hevc_filter.o hevc_data.o
+OBJS-$(CONFIG_HEVC_MLUMPP_DECODER)     += mlumpp_dec.o
+OBJS-$(CONFIG_HEVC_MLUMPP_ENCODER)     += mlumpp_vid_enc.o mlumpp_enc_hevc.o
 OBJS-$(CONFIG_HEVC_AMF_ENCODER)        += amfenc_hevc.o
 OBJS-$(CONFIG_HEVC_CUVID_DECODER)      += cuviddec.o
 OBJS-$(CONFIG_HEVC_MEDIACODEC_DECODER) += mediacodecdec.o
@@ -427,6 +431,8 @@ OBJS-$(CONFIG_MIMIC_DECODER)           += mimic.o
 OBJS-$(CONFIG_MJPEG_DECODER)           += mjpegdec.o
 OBJS-$(CONFIG_MJPEG_ENCODER)           += mjpegenc.o mjpegenc_common.o \
                                           mjpegenc_huffman.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_DECODER)    += mlumpp_dec.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_ENCODER)    += mlumpp_enc_jpeg.o
 OBJS-$(CONFIG_MJPEGB_DECODER)          += mjpegbdec.o
 OBJS-$(CONFIG_MJPEG_CUVID_DECODER)     += cuviddec.o
 OBJS-$(CONFIG_MJPEG_QSV_ENCODER)       += qsvenc_jpeg.o
@@ -666,6 +672,7 @@ OBJS-$(CONFIG_VP3_DECODER)             += vp3.o
 OBJS-$(CONFIG_VP5_DECODER)             += vp5.o vp56.o vp56data.o vp56rac.o
 OBJS-$(CONFIG_VP6_DECODER)             += vp6.o vp56.o vp56data.o \
                                           vp6dsp.o vp56rac.o
+OBJS-$(CONFIG_VP8_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VP7_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_CUVID_DECODER)       += cuviddec.o
@@ -678,6 +685,7 @@ OBJS-$(CONFIG_VP8_V4L2M2M_ENCODER)     += v4l2_m2m_enc.o
 OBJS-$(CONFIG_VP9_DECODER)             += vp9.o vp9data.o vp9dsp.o vp9lpf.o vp9recon.o \
                                           vp9block.o vp9prob.o vp9mvs.o vp56rac.o \
                                           vp9dsp_8bpp.o vp9dsp_10bpp.o vp9dsp_12bpp.o
+OBJS-$(CONFIG_VP9_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VP9_CUVID_DECODER)       += cuviddec.o
 OBJS-$(CONFIG_VP9_MEDIACODEC_DECODER)  += mediacodecdec.o
 OBJS-$(CONFIG_VP9_RKMPP_DECODER)       += rkmppdec.o
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
old mode 100644
new mode 100755
index d2f9a39ce5..311ca7a05b
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -143,11 +143,14 @@ extern AVCodec ff_h264_mediacodec_decoder;
 extern AVCodec ff_h264_mmal_decoder;
 extern AVCodec ff_h264_qsv_decoder;
 extern AVCodec ff_h264_rkmpp_decoder;
+extern AVCodec ff_h264_mlumpp_decoder;
+extern AVCodec ff_h264_mlumpp_encoder;
 extern AVCodec ff_hap_encoder;
 extern AVCodec ff_hap_decoder;
 extern AVCodec ff_hevc_decoder;
 extern AVCodec ff_hevc_qsv_decoder;
 extern AVCodec ff_hevc_rkmpp_decoder;
+extern AVCodec ff_hevc_mlumpp_decoder;
 extern AVCodec ff_hevc_v4l2m2m_decoder;
 extern AVCodec ff_hnm4_video_decoder;
 extern AVCodec ff_hq_hqa_decoder;
@@ -754,6 +757,7 @@ extern AVCodec ff_nvenc_hevc_encoder;
 #endif
 extern AVCodec ff_hevc_amf_encoder;
 extern AVCodec ff_hevc_cuvid_decoder;
+extern AVCodec ff_hevc_mlumpp_encoder;
 extern AVCodec ff_hevc_mediacodec_decoder;
 extern AVCodec ff_hevc_nvenc_encoder;
 extern AVCodec ff_hevc_qsv_encoder;
@@ -762,6 +766,8 @@ extern AVCodec ff_hevc_vaapi_encoder;
 extern AVCodec ff_hevc_videotoolbox_encoder;
 extern AVCodec ff_libkvazaar_encoder;
 extern AVCodec ff_mjpeg_cuvid_decoder;
+extern AVCodec ff_mjpeg_mlumpp_decoder;
+extern AVCodec ff_mjpeg_mlumpp_encoder;
 extern AVCodec ff_mjpeg_qsv_encoder;
 extern AVCodec ff_mjpeg_vaapi_encoder;
 extern AVCodec ff_mpeg1_cuvid_decoder;
@@ -773,11 +779,13 @@ extern AVCodec ff_mpeg4_mediacodec_decoder;
 extern AVCodec ff_mpeg4_v4l2m2m_encoder;
 extern AVCodec ff_vc1_cuvid_decoder;
 extern AVCodec ff_vp8_cuvid_decoder;
+extern AVCodec ff_vp8_mlumpp_decoder;
 extern AVCodec ff_vp8_mediacodec_decoder;
 extern AVCodec ff_vp8_qsv_decoder;
 extern AVCodec ff_vp8_v4l2m2m_encoder;
 extern AVCodec ff_vp8_vaapi_encoder;
 extern AVCodec ff_vp9_cuvid_decoder;
+extern AVCodec ff_vp9_mlumpp_decoder;
 extern AVCodec ff_vp9_mediacodec_decoder;
 extern AVCodec ff_vp9_vaapi_encoder;
 
diff --git a/libavcodec/hwaccel.h b/libavcodec/hwaccel.h
index 3aaa92571c..6a0ea9f6f9 100644
--- a/libavcodec/hwaccel.h
+++ b/libavcodec/hwaccel.h
@@ -70,6 +70,8 @@ typedef struct AVCodecHWConfigInternal {
     HW_CONFIG_HWACCEL(1, 1, 0, D3D11,        D3D11VA,      ff_ ## codec ## _d3d11va2_hwaccel)
 #define HWACCEL_NVDEC(codec) \
     HW_CONFIG_HWACCEL(1, 1, 0, CUDA,         CUDA,         ff_ ## codec ## _nvdec_hwaccel)
+#define HWACCEL_MLUDEC(codec) \
+    HW_CONFIG_HWACCEL(1, 1, 0, MLU,          MLU,         ff_ ## codec ## _mludec_hwaccel)
 #define HWACCEL_VAAPI(codec) \
     HW_CONFIG_HWACCEL(1, 1, 1, VAAPI,        VAAPI,        ff_ ## codec ## _vaapi_hwaccel)
 #define HWACCEL_VDPAU(codec) \
diff --git a/libavcodec/mlumpp_dec.c b/libavcodec/mlumpp_dec.c
new file mode 100755
index 0000000000..6d3c06c780
--- /dev/null
+++ b/libavcodec/mlumpp_dec.c
@@ -0,0 +1,1690 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <stdint.h>
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <semaphore.h>
+#include "config.h"
+#include <stdatomic.h>
+#include "libavutil/buffer.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/fifo.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+#include "libavutil/time.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/thread.h"
+#include "libavutil/version.h"
+#include "libavutil/pixfmt.h"
+#include "avcodec.h"
+#include "decode.h"
+#include "hwaccel.h"
+#include "internal.h"
+#include "cn_video_dec.h"
+#include "cn_jpeg_dec.h"
+#include "cn_codec_common.h"
+#include "mlumpp_mluop.h"
+
+#define CN_VFRAME_ALIGNMENT 1
+#define CN_JFRAME_ALIGNMENT_W 64
+#define CN_JFRAME_ALIGNMENT_H 16
+// common defines
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return ret;                                                                         \
+    }
+#define CNCODEC_ERROR_CHECK(avctx, ret)                                                     \
+    if (ret != CNCODEC_SUCCESS) {                                                           \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__); \
+        return ret;                                                                          \
+    }
+
+#ifdef CNCODEC_MAJOR_VERSION
+#define CNCODEC_VERSION_INT AV_VERSION_INT(CNCODEC_MAJOR_VERSION, \
+                                           CNCODEC_MINOR_VERSION, \
+                                           CNCODEC_PATCH_VERSION)
+#endif
+#define FF_MLU_MAJPR_VERSION 1
+#define FF_MLU_MINOR_VERSION 5
+#define FF_MLU_PATCH_VERSION 1
+
+static av_cold void mlumpp_empty_frame_queue(AVCodecContext *avctx);
+typedef struct MLUMPPContext
+{
+    AVClass *avclass;
+    int device_id;
+    int instance_id;
+    int num_input_buffers;
+    int num_output_buffers;
+    char *crop_str;
+    char *resize_str;
+    int trace_flag;
+    int cnrt_init_flag;
+    int async_queue_depth;
+    char *output_pixfmt;
+    struct
+    {
+        int left;
+        int top;
+        int right;
+        int bottom;
+    } crop;
+    struct
+    {
+        int width;
+        int height;
+        void *in_y_ptr;
+        void *in_uv_ptr;
+        void *out_y_ptr;
+        void *out_uv_ptr;
+    } resize;
+    int progressive;
+    void *handle;
+
+    AVBufferRef *hwdevice;
+    AVBufferRef *hwframe;
+    AVBufferRef *resize_hwframe;
+    AVCodecContext *avctx;
+
+    sem_t eos_sema;
+    AVBSFContext *bsf;
+    AVFifoBuffer *frame_queue;
+
+    MluContext *mlu_ctx;
+    cncodecType codec_type;
+    volatile int eos_sended;
+    cnvideoDecCreateInfo vdec_params;
+    cnvideoDecSequenceInfo codec_info;
+    AVMLUDeviceContext *dev_hwctx;
+    AVHWFramesContext  *hwframes_ctx;
+
+    AVMutex queue_mutex;
+    volatile int eos_received;
+    volatile int decoder_flushing;
+    int64_t last_send_pkt_time;
+
+    int stride_align;
+    int first_packet;
+    volatile int codec_abort_flag;
+    volatile int decoder_start;
+    volatile int decoder_init_flag;
+    HANDLE_MLU_OP mluop_handle;
+
+    // AVMutex count_mutex;
+    unsigned long long total_frame_count;
+    unsigned long long total_packet_count;
+    unsigned long long total_outframe_count;
+} MLUMPPContext_t;
+
+typedef struct MLUVideoFrameInfo {
+    cnvideoDecOutput outframe;
+} MLUVideoFrameInfo_t;
+typedef struct MLUJpegFrameInfo {
+    cnjpegDecOutput outframe;
+} MLUJpegFrameInfo_t;
+
+static inline void mlumpp_get_version(void) {
+    av_log(NULL, AV_LOG_VERBOSE, "rel time: 2021/08/26 \n");
+    av_log(NULL, AV_LOG_INFO, "CNCODEC: %d.%d.%d \n",
+            CNCODEC_MAJOR_VERSION, CNCODEC_MINOR_VERSION, CNCODEC_PATCH_VERSION);
+    av_log(NULL, AV_LOG_INFO, "FFMPEG_MLU: %d.%d.%d \n",
+            FF_MLU_MAJPR_VERSION, FF_MLU_MINOR_VERSION, FF_MLU_PATCH_VERSION);
+}
+static inline int mlumpp_adapt_resolution(AVCodecContext* avctx) {
+    if (avctx->codec->id == AV_CODEC_ID_MJPEG) {
+        if (avctx->width < 64 ||  avctx->width > 8192 || avctx->height < 64 || avctx->height > 4320) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU jpeg decoder only support resolution: 64x64~8192x4320\n");
+            return -1;
+        }
+    } else {
+        if (avctx->width < 64 ||  avctx->width > 4096 || avctx->height < 64 || avctx->height > 4096) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU video decoder only support resolution: 64x64~4096x4096\n");
+            return -1;
+        }
+    }
+    return 0;
+}
+static inline  enum AVPixelFormat mlumpp_dec_map_ff_pixfmt(cncodecPixelFormat pixfmt)
+{
+    switch (pixfmt) {
+    case CNCODEC_PIX_FMT_NV12: return AV_PIX_FMT_NV12;
+    case CNCODEC_PIX_FMT_NV21: return AV_PIX_FMT_NV21;
+    case CNCODEC_PIX_FMT_I420: return AV_PIX_FMT_YUV420P;
+    case CNCODEC_PIX_FMT_P010: return AV_PIX_FMT_P010;
+    default:                   return AV_PIX_FMT_NV12;
+    }
+}
+static inline cncodecPixelFormat mlumpp_dec_map_mlu_pixfmt(enum AVPixelFormat pixfmt)
+{
+    switch (pixfmt) {
+    case AV_PIX_FMT_NV12:     return CNCODEC_PIX_FMT_NV12;
+    case AV_PIX_FMT_NV21:     return CNCODEC_PIX_FMT_NV21;
+    case AV_PIX_FMT_P010:     return CNCODEC_PIX_FMT_P010;
+    case AV_PIX_FMT_YUV420P:  return CNCODEC_PIX_FMT_I420;
+    case AV_PIX_FMT_YUVJ420P: return CNCODEC_PIX_FMT_I420;
+    default:                  return CNCODEC_PIX_FMT_NV12;
+    }
+}
+static inline cnjpegDecInstance mlumpp_dec_get_jpu_inst(int id)
+{
+    switch (id) {
+    case  0:  return CNJPEGDEC_INSTANCE_0;
+    case  1:  return CNJPEGDEC_INSTANCE_1;
+    case  2:  return CNJPEGDEC_INSTANCE_2;
+    case  3:  return CNJPEGDEC_INSTANCE_3;
+    case  4:  return CNJPEGDEC_INSTANCE_4;
+    case  5:  return CNJPEGDEC_INSTANCE_5;
+    case  6:  return CNJPEGDEC_INSTANCE_AUTO;
+    case -1:  return CNJPEGDEC_INSTANCE_AUTO;
+    default:  return CNJPEGDEC_INSTANCE_INVALID;
+    }
+}
+static inline cncodecPixelFormat mlumpp_dec_map_cn_pixfmt(char *pixfmt)
+{
+    if (!strcmp("nv12", pixfmt) || !strcmp("NV12", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV12;
+    } else if (!strcmp("nv21", pixfmt) || !strcmp("NV21", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV21;
+    } else if (!strcmp("yuv420p", pixfmt) || !strcmp("YUV420P", pixfmt)) {
+        return CNCODEC_PIX_FMT_I420;
+    } else if (!strcmp("p010", pixfmt) || !strcmp("P010", pixfmt) ||
+               !strcmp("p010le", pixfmt) || !strcmp("P010LE", pixfmt) ||
+               !strcmp("p010be", pixfmt) || !strcmp("P010BE", pixfmt)) {
+        return CNCODEC_PIX_FMT_P010;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt: %s, only suport nv12/nv21/yuv420p/p010 \n", pixfmt);
+        return -1;
+    }
+}
+
+static int mlumpp_device_binding(MLUMPPContext_t *ctx) {
+    cnrtRet_t cnrt_ret;
+    cnrtDev_t dev;
+    cnrt_ret = ctx->mlu_ctx->mluGetDeviceHandle(&dev, ctx->device_id);
+    if (cnrt_ret < 0) {
+        av_log(ctx->avctx, AV_LOG_ERROR, "Mlu device binding failed.\n");
+        return -1;
+    }
+
+    cnrt_ret = ctx->mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Mlu device binding failed \n");
+        return -1;
+    }
+    return 0;
+}
+
+static int mlumpp_is_input_available(AVCodecContext *avctx, int nonblock_flag)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    if (ctx->codec_type == CNCODEC_JPEG) {
+        return 1;
+    }
+    if (nonblock_flag) {
+        int ret = 0;
+        if (ctx->handle){
+#if CNCODEC_PATCH_VERSION < 100
+            ret = cnvideoDecQueryAvailInputBuf(ctx->handle);
+#else
+            ret = cnvideoDecQueryAvailInputBufCnt(ctx->handle);
+#endif
+        }
+        return ret;
+    } else {
+        int ret = 0;
+        int counts = 500;
+        while (!ctx->codec_abort_flag && --counts) {
+            if (ctx->handle) {
+#if CNCODEC_PATCH_VERSION < 100
+                ret = cnvideoDecQueryAvailInputBuf(ctx->handle);
+#else
+                ret = cnvideoDecQueryAvailInputBufCnt(ctx->handle);
+#endif
+            }
+            if (ret)
+                return 1;
+            av_usleep(1000);
+        }
+    }
+    return 0;
+}
+
+static int mlumpp_is_frame_queue_empty(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 1;
+    ff_mutex_lock(&ctx->queue_mutex);
+    if(ctx->frame_queue) {
+        ret = av_fifo_size(ctx->frame_queue) == 0;
+    } else {
+        ret = -1;
+        av_log(avctx, AV_LOG_WARNING, "Frame queue address is invalid \n");
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    return ret;
+}
+
+static int mlumpp_is_frame_queue_invalid(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 0;
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        ret = 0;
+    } else {
+        ret = 1;
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    return ret;
+}
+
+static int mlumpp_create_vid_frame_queue(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = -1;
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        av_log(avctx, AV_LOG_WARNING, "Received sequence info again, need flush vid frame queue firstly \n");
+        while (av_fifo_size(ctx->frame_queue) >= sizeof(MLUVideoFrameInfo_t)) {
+            MLUVideoFrameInfo_t video_frame;
+            if (ctx->trace_flag > 1) {
+                av_log(avctx, AV_LOG_INFO, "Thread id: %lu, decoded frames [%lu] are reserved in cache\n", (long unsigned)pthread_self(),
+                    av_fifo_size(ctx->frame_queue) / sizeof(MLUVideoFrameInfo_t));
+            }
+            av_fifo_generic_read(ctx->frame_queue, &video_frame, sizeof(MLUVideoFrameInfo_t), NULL);
+            if (ctx->handle)
+                cnvideoDecReleaseReference(ctx->handle, &(video_frame.outframe.frame));
+        }
+        ctx->frame_queue = NULL;
+    }
+    if (!ctx->frame_queue) {
+        ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(MLUVideoFrameInfo_t));
+        if (!ctx->frame_queue) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create vid frame queue \n");
+            return -1;
+        }
+        ret = 1;
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    return ret;
+}
+
+static av_cold void mlumpp_empty_frame_queue(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Decode frame queue valid \n");
+        }
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            while (av_fifo_size(ctx->frame_queue) >= sizeof(MLUJpegFrameInfo_t)) {
+                MLUJpegFrameInfo_t jpeg_frame;
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Thread id: %lu, decoded frames [%lu] are reserved in cache\n", (long unsigned)pthread_self(),
+                        av_fifo_size(ctx->frame_queue) / sizeof(MLUJpegFrameInfo_t));
+                }
+                av_fifo_generic_read(ctx->frame_queue, &jpeg_frame, sizeof(MLUJpegFrameInfo_t), NULL);
+                if (ctx->handle)
+                    cnjpegDecReleaseReference(ctx->handle, &(jpeg_frame.outframe.frame));
+            }
+        } else {
+            if (ctx->trace_flag > 0) {
+                av_log(avctx, AV_LOG_INFO, "Decode fqueue size: %d, sizeof(vid data): %lu \n", av_fifo_size(ctx->frame_queue), sizeof(MLUVideoFrameInfo_t));
+            }
+            while (av_fifo_size(ctx->frame_queue) >= sizeof(MLUVideoFrameInfo_t)) {
+                MLUVideoFrameInfo_t video_frame;
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Thread id: %lu, decoded frames [%lu] are reserved in cache\n", (long unsigned)pthread_self(),
+                        av_fifo_size(ctx->frame_queue) / sizeof(MLUVideoFrameInfo_t));
+                }
+                av_fifo_generic_read(ctx->frame_queue, &video_frame, sizeof(MLUVideoFrameInfo_t), NULL);
+                if (ctx->handle)
+                    cnvideoDecReleaseReference(ctx->handle, &(video_frame.outframe.frame));
+            }
+        }
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+}
+
+static av_cold void mlumpp_set_frame_queue_invalid(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    ff_mutex_lock(&ctx->queue_mutex);
+    ctx->frame_queue = NULL;
+    ff_mutex_unlock(&ctx->queue_mutex);
+}
+
+static int mlumpp_read_from_frame_queue (AVCodecContext *avctx) {
+    // MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    return 0;
+}
+
+static int mlumpp_write_in_frame_queue (AVCodecContext *avctx) {
+    // MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    return 0;
+}
+
+static int mlumpp_send_video_data(AVCodecContext *avctx,const AVPacket *avpkt, int eos)
+{
+    cnvideoDecInput input;
+    int ret = 0;
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    const int feed_timeout = 3000;
+    if (avpkt && avpkt->size) {
+        // on first packet, send extradata
+        if (ctx->first_packet) {
+            if (avctx->extradata_size) {
+                input.streamBuf = avctx->extradata;
+                input.streamLength = avctx->extradata_size;
+                input.pts = avpkt->pts;
+                input.flags = CNVIDEODEC_FLAG_TIMESTAMP;
+#ifdef CNCODEC_VERSION_INT
+                input.flags |= CNVIDEODEC_FLAG_END_OF_FRAME;
+#endif
+                if (ctx->trace_flag > 1) {
+                    av_log(avctx, AV_LOG_INFO, "first packet, write extradata to decoder: %p, length: %u, pts: (%3" PRId64 ")\n",
+                           input.streamBuf, input.streamLength, input.pts);
+                }
+                if (ctx->handle) {
+                    ret = cnvideoDecFeedData(ctx->handle, &input, feed_timeout);
+                }
+                CNCODEC_ERROR_CHECK(avctx, ret);
+            }
+            ctx->first_packet = 0;
+        }
+        // send packet
+        memset(&input, 0, sizeof(cnvideoDecInput));
+        input.streamBuf = avpkt->data;
+        input.streamLength = avpkt->size;
+        input.pts = avpkt->pts;
+        input.flags = CNVIDEODEC_FLAG_TIMESTAMP;
+#ifdef CNCODEC_VERSION_INT
+        input.flags |= CNVIDEODEC_FLAG_END_OF_FRAME;
+#endif
+        if (ctx->trace_flag > 1) {
+            av_log(avctx, AV_LOG_INFO, "[%lu]Feed stream info start\n", (long unsigned)pthread_self());
+            av_log(avctx, AV_LOG_INFO, "[%lu]data: %p, length: %u, pts: (%3" PRId64 ")\n", (long unsigned)pthread_self(),
+                   input.streamBuf, input.streamLength, input.pts);
+        }
+        if (ctx->handle) {
+            ret = cnvideoDecFeedData(ctx->handle, &input, feed_timeout);
+            CNCODEC_ERROR_CHECK(avctx,ret);
+        }
+        if (ctx->trace_flag > 1) {
+            av_log(avctx, AV_LOG_INFO, "[%lu]Feed stream info end\n", (long unsigned)pthread_self());
+        }
+        ctx->total_packet_count++;
+    }
+    if (eos) {
+        ctx->eos_sended = 1;
+        input.streamBuf = NULL;
+        input.streamLength = 0;
+        input.pts = 0;
+        input.flags |= CNVIDEODEC_FLAG_EOS;
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Decoder vid feed eos ... \n");
+        }
+        if (ctx->handle) {
+            ret = cnvideoDecFeedData(ctx->handle, &input, feed_timeout);
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Decode vid feed eos done \n");
+        }
+        CNCODEC_ERROR_CHECK(avctx,ret);
+        if (ctx->trace_flag > 1) {
+            av_log(avctx, AV_LOG_INFO, "[%lu]Feed stream info EOS, flags: %u, pts: (%3" PRId64 ")\n",
+                   (long unsigned)pthread_self(), input.flags, input.pts);
+        }
+    }
+    return ret;
+}
+static int mlumpp_send_jpeg_data(AVCodecContext *avctx,const AVPacket *avpkt, int eos)
+{
+    cnjpegDecInput input;
+    int ret = -1;
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    const int feed_timeout = 3000;
+    if (avpkt && avpkt->size) {
+        memset(&input, 0, sizeof(cnjpegDecInput));
+        input.streamBuffer =  avpkt->data;
+        input.streamLength = avpkt->size;
+        input.pts = avpkt->pts;
+        input.flags = CNJPEGDEC_FLAG_TIMESTAMP;
+        if (ctx->trace_flag > 1) {
+            av_log(avctx, AV_LOG_INFO, "Feed stream info: data: %p, length: %u, pts: (%3" PRId64 ")\n",
+                   input.streamBuffer, input.streamLength, input.pts);
+        }
+        if (ctx->handle) {
+            ret = cnjpegDecFeedData(ctx->handle, &input, feed_timeout);
+        }
+        CNCODEC_ERROR_CHECK(avctx, ret);
+        ctx->total_packet_count++;
+    }
+    if (eos) {
+        ctx->eos_sended = 1;
+        input.streamBuffer = NULL;
+        input.streamLength = 0;
+        input.pts = 0;
+        input.flags |= CNJPEGDEC_FLAG_EOS;
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "cndecoder jpeg feed eos ... \n");
+        }
+        if (ctx->handle) {
+            ret = cnjpegDecFeedData(ctx->handle, &input, feed_timeout);
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "cndecoder jpeg feed done \n");
+        }
+        CNCODEC_ERROR_CHECK(avctx,ret);
+        if (ctx->trace_flag > 1) {
+            av_log(avctx, AV_LOG_INFO, "Feed stream info: EOS, flags: %u, pts: (%3" PRId64 ")\n", input.flags, input.pts);
+        }
+    }
+    return ret;
+}
+
+// cncodec callback
+static av_cold int mlumpp_decode_end(AVCodecContext *avctx);
+static int mlumpp_dec_sequence_cb(void *pData, cnvideoDecSequenceInfo *info)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)pData;
+    AVCodecContext *avctx = ctx->avctx;
+    int ret = -1;
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_WARNING, "cndecoder received sequence cb event \n");
+        av_log(avctx, AV_LOG_INFO, "in sequence cb func, handle: %lu \n", (long unsigned)ctx->handle);
+    }
+    if (ctx->codec_info.width == info->width && ctx->codec_info.height == info->height) {
+        av_log(avctx, AV_LOG_WARNING, "sequece event happend, but video resolution dont' changed \n");
+        return 0;
+    }
+
+    // resolution changed
+    ctx->codec_info.width = info->width;
+    ctx->codec_info.height = info->height;
+    ctx->vdec_params.codec = info->codec;
+    if (ctx->resize.width > 0 && ctx->resize.height > 0) {
+        // only support WxH downscaling for vid dec
+        ctx->vdec_params.width = ctx->resize.width;
+        ctx->vdec_params.height = ctx->resize.height;
+        avctx->width  = ctx->resize.width;
+        avctx->height = ctx->resize.height;
+    } else {
+        ctx->vdec_params.width  = info->width;
+        ctx->vdec_params.height = info->height;
+        avctx->width  = ctx->vdec_params.width;
+        avctx->height = ctx->vdec_params.height;
+    }
+    avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+    avctx->coded_height = avctx->height;
+    if(0 != mlumpp_adapt_resolution(avctx)) {
+        return AVERROR(EINVAL);
+    }
+
+    // this is for synchronous invocation, need keep enough frames for decoder output buffer
+    ctx->vdec_params.outputBufNum = info->minOutputBufNum + ctx->num_output_buffers;
+    ctx->async_queue_depth = ctx->vdec_params.outputBufNum;
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Set input buffers: %u, output buffers: %u, queue depth: %u\n",
+                    ctx->vdec_params.inputBufNum, ctx->vdec_params.outputBufNum, ctx->async_queue_depth);
+    }
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_WARNING, "Received sequence info again, need flush vid frame queue firstly \n");
+            av_log(avctx, AV_LOG_INFO, "now frame queue exist, flush ... \n");
+        }
+        while (av_fifo_size(ctx->frame_queue) >= sizeof(MLUVideoFrameInfo_t)) {
+            MLUVideoFrameInfo_t video_frame;
+            if (ctx->trace_flag > 0) {
+                av_log(avctx, AV_LOG_INFO, "Thread id: %lu, decoded frames [%lu] are reserved in cache\n", (long unsigned)pthread_self(),
+                    av_fifo_size(ctx->frame_queue) / sizeof(MLUVideoFrameInfo_t));
+            }
+            av_fifo_generic_read(ctx->frame_queue, &video_frame, sizeof(MLUVideoFrameInfo_t), NULL);
+            if (ctx->handle)
+                cnvideoDecReleaseReference(ctx->handle, &(video_frame.outframe.frame));
+        }
+        ctx->frame_queue = NULL;
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "now frame queue exist, flush done \n");
+        }
+    }
+    if (!ctx->frame_queue) {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "dec frame queue don't exist, create ... \n");
+        }
+        ctx->async_queue_depth = ctx->vdec_params.outputBufNum;
+        ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(MLUVideoFrameInfo_t));
+        if (!ctx->frame_queue) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create frame queue \n");
+            return -1;
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "dec frame queue don't exist, create done \n");
+        }
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "vid decoder start ... \n");
+    }
+    ret = cnvideoDecStart(ctx->handle, &ctx->vdec_params);
+    if (ret != CNCODEC_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "cnvideoDecStart error occur, line: %d\n", __LINE__);
+        return -1;
+    }
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "vid decoder start done \n");
+    }
+
+    ctx->total_frame_count = 0;
+    ctx->decoder_start = 1;
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "out sequence cb func, handle: %lu \n", (long unsigned)ctx->handle);
+    }
+    return 0;
+}
+
+static int mlumpp_dec_newframe_cb(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    // AVCodecContext *avctx = ctx->avctx;
+    cnjpegDecOutput *jPic  = NULL;
+    cnvideoDecOutput *pPic = NULL;
+    MLUJpegFrameInfo_t jpeg_frame;
+    MLUVideoFrameInfo_t video_frame;
+    if (ctx->codec_type == CNCODEC_JPEG) {
+        jPic = (cnjpegDecOutput*)data;
+        memset(&jpeg_frame, 0, sizeof(MLUJpegFrameInfo_t));
+        jpeg_frame.outframe = *jPic;
+        ff_mutex_lock(&ctx->queue_mutex);
+        av_fifo_generic_write(ctx->frame_queue, &jpeg_frame, sizeof(MLUJpegFrameInfo_t), NULL);
+        if (ctx->handle) {
+            cnjpegDecAddReference(ctx->handle, &jPic->frame);
+        }
+        ff_mutex_unlock(&ctx->queue_mutex);
+    } else {
+        pPic = (cnvideoDecOutput*)data;
+        memset(&video_frame,0,sizeof(MLUVideoFrameInfo_t));
+        video_frame.outframe = *pPic;
+        ff_mutex_lock(&ctx->queue_mutex);
+        av_fifo_generic_write(ctx->frame_queue, &video_frame, sizeof(MLUVideoFrameInfo_t), NULL);
+        if (ctx->handle) {
+            cnvideoDecAddReference(ctx->handle,&pPic->frame);
+        }
+        ff_mutex_unlock(&ctx->queue_mutex);
+    }
+
+    ctx->total_frame_count++;
+    return 0;
+}
+static int mlumpp_dec_eos_cb(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    AVCodecContext *avctx = ctx->avctx;
+    sem_post(&ctx->eos_sema);
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Decode got eos callback pthread id: %lu\n", (long unsigned)pthread_self());
+    }
+    ctx->eos_received = 1;
+    return 0;
+}
+
+static int mlumpp_event_cb(cncodecCbEventType event_type, void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    if (ctx == NULL && data == NULL) {
+        av_log(ctx->avctx, AV_LOG_FATAL, "Decode callback error,event type: %d \n", event_type);
+        return -1;
+    }
+    if(mlumpp_device_binding(ctx) != 0) {
+        av_log(ctx->avctx, AV_LOG_ERROR, "Device binding failed\n");
+        return AVERROR(EINVAL);
+    }
+    if (ctx->trace_flag > 1) {
+        av_log(ctx->avctx, AV_LOG_INFO, "[%lu]Decode callback event type: %d \n", (long unsigned)pthread_self(), event_type);
+    }
+    switch (event_type)
+    {
+        case CNCODEC_CB_EVENT_NEW_FRAME:
+            mlumpp_dec_newframe_cb(userptr, data);
+            break;
+        case CNCODEC_CB_EVENT_SEQUENCE:
+            mlumpp_dec_sequence_cb(userptr, data);
+            break;
+        case CNCODEC_CB_EVENT_EOS:
+            mlumpp_dec_eos_cb(userptr, data);
+            break;
+        case CNCODEC_CB_EVENT_SW_RESET:
+        case CNCODEC_CB_EVENT_HW_RESET:
+            av_log(ctx->avctx, AV_LOG_FATAL, "Decode FATAL Error <Firmware crash Event>: %d \n", event_type);
+            if (!ctx->codec_abort_flag) {
+                sem_post(&ctx->eos_sema);
+                ctx->codec_abort_flag = 1;
+            }
+            break;
+        case CNCODEC_CB_EVENT_OUT_OF_MEMORY:
+            av_log(ctx->avctx, AV_LOG_FATAL, "Decode FATAL Error <Out of memory Event>: %d \n", event_type);
+            if (!ctx->codec_abort_flag) {
+                sem_post(&ctx->eos_sema);
+                ctx->codec_abort_flag = 1;
+            }
+            break;
+        case CNCODEC_CB_EVENT_ABORT_ERROR:
+            av_log(ctx->avctx, AV_LOG_FATAL, "Decode FATAL Error <Abort Event>: %d \n", event_type);
+            if (!ctx->codec_abort_flag) {
+                sem_post(&ctx->eos_sema);
+                ctx->codec_abort_flag = 1;
+            }
+            break;
+#ifdef CNCODEC_VERSION_INT
+        case CNCODEC_CB_EVENT_STREAM_CORRUPT:
+            av_log(ctx->avctx, AV_LOG_WARNING, "Decode Error <corrupt stream>: %d \n", event_type);
+            if (ctx->trace_flag > 0) {
+                cnvideoDecStreamCorruptInfo *err_info = (cnvideoDecStreamCorruptInfo*)data;
+                av_log(ctx->avctx, AV_LOG_INFO, "Decode stream error frame count: %lu, frame number: %lu \n", \
+                                    err_info->frameCount, err_info->frameNumber);
+            }
+            break;
+#endif
+        default:
+            av_log(ctx->avctx, AV_LOG_FATAL, "Decode FATAL Error <Unknow Event>: %d \n", event_type);
+            if (!ctx->codec_abort_flag) {
+                sem_post(&ctx->eos_sema);
+                ctx->codec_abort_flag = 1;
+            }
+            break;
+    }
+    return 0;
+}
+static int mlumpp_decode_packet(AVCodecContext *avctx, const AVPacket *avpkt)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVPacket filter_packet = { 0 };
+    AVPacket filtered_packet = { 0 };
+    int ret = 0;
+    if (ctx->bsf && avpkt && avpkt->size) {
+        if ((ret = av_packet_ref(&filter_packet, avpkt)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "av_packet_ref failed\n");
+            return ret;
+        }
+        if ((ret = av_bsf_send_packet(ctx->bsf, &filter_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "av_bsf_send_packet failed\n");
+            av_packet_unref(&filter_packet);
+            return ret;
+        }
+        if ((ret = av_bsf_receive_packet(ctx->bsf, &filtered_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "av_bsf_receive_packet failed\n");
+            return ret;
+        }
+        avpkt = &filtered_packet;
+    }
+    av_packet_unref(&filter_packet);
+    if (avpkt && avpkt->size) {
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            ret = mlumpp_send_jpeg_data(avctx, avpkt, 0);
+        } else {
+            ret = mlumpp_send_video_data(avctx, avpkt, 0);
+        }
+        if (ret < 0) {
+            av_packet_unref(&filtered_packet);
+            return AVERROR(EAGAIN);
+        }
+    } else if(!ctx->decoder_flushing) {
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            ret = mlumpp_send_jpeg_data(avctx, NULL, 1);
+        } else {
+            ret = mlumpp_send_video_data(avctx, NULL, 1);
+        }
+        if (ret < 0) {
+            av_packet_unref(&filtered_packet);
+            return AVERROR(EAGAIN);
+        }
+        ctx->decoder_flushing = 1;
+    }
+    av_packet_unref(&filtered_packet);
+    if (ctx->codec_type != CNCODEC_JPEG && (avctx->flags & AV_CODEC_FLAG_LOW_DELAY)) {
+        int64_t current = av_gettime_relative();
+        int guess_fps = 30;
+        if (ctx->last_send_pkt_time > 0 && (current - ctx->last_send_pkt_time)/1000 < 1000/guess_fps) {
+            int diff = 1000/(guess_fps) - (current - ctx->last_send_pkt_time)/1000;
+            while (diff-- > 0) {
+                if (ctx->frame_queue && (av_fifo_size(ctx->frame_queue) > 0)) {
+                    break;
+                }
+                av_usleep(1000);
+            }
+        }
+        ctx->last_send_pkt_time = av_gettime_relative();
+    }
+    return 0;
+}
+
+static int mlumpp_ffcopy_helper(AVCodecContext *avctx, AVFrame *avframe, cncodecFrame *cnframe)
+{
+    MLUMPPContext_t *ctx             = (MLUMPPContext_t*)avctx->priv_data;
+    AVHWDeviceContext *device_ctx    = (AVHWDeviceContext*)ctx->hwdevice->data;
+    AVMLUDeviceContext *device_hwctx = device_ctx->hwctx;
+    MluContext *mlu_ctx              = device_hwctx->mlu_ctx;
+
+    int i = 0;
+    int ret = 0;
+    int factor = 0;
+    cnrtRet_t cnrt_ret;
+    ctx->total_outframe_count++;
+
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU && (ctx->resize.width > 0 || ctx->resize.width > 0)) {
+        ret = av_hwframe_get_buffer(ctx->resize_hwframe, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode av_hwframe_get_buffer failed\n");
+            return AVERROR(ENOMEM);
+        }
+
+        ret = ff_decode_frame_props(avctx, avframe);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_decode_frame_props failed\n");
+            return AVERROR(ENOMEM);
+        }
+    } else if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        ret = av_hwframe_get_buffer(ctx->hwframe, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode av_hwframe_get_buffer failed\n");
+            return AVERROR(ENOMEM);
+        }
+
+        ret = ff_decode_frame_props(avctx, avframe);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_decode_frame_props failed\n");
+            return AVERROR(ENOMEM);
+        }
+    } else {
+        ret = ff_get_buffer(avctx, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_get_buffer failed\n");
+            return AVERROR(ENOMEM);
+        }
+    }
+
+    switch (cnframe->pixelFmt) {
+    case CNCODEC_PIX_FMT_NV21:
+    case CNCODEC_PIX_FMT_NV12:
+        for (i = 0; i < cnframe->planeNum; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->stride[i];
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void *)avframe->data[i], (void *)cnframe->plane[i].addr,
+                                    cnframe->stride[i] * cnframe->height / factor, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_ERROR, "Output frame D2D: dev %p -> dev %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height / factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to device \n");
+                    return AVERROR_EXTERNAL;
+                }
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void *)avframe->data[i], (void *)cnframe->plane[i].addr,
+                                    cnframe->stride[i] * cnframe->height / factor, CNRT_MEM_TRANS_DIR_DEV2HOST);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_INFO, "Output frame D2h: dev %p -> host %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height / factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to host \n");
+                    return AVERROR_EXTERNAL;
+                }
+            }
+        }
+        break;
+    case CNCODEC_PIX_FMT_P010:
+        for (i = 0; i < cnframe->planeNum; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->stride[i];
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)avframe->data[i],\
+                                    (void*)cnframe->plane[i].addr,\
+                                    cnframe->stride[i] * cnframe->height/factor, \
+                                    CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_INFO, "Output frame D2h: dev %p -> dev %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height/factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to device \n");
+                    return AVERROR_EXTERNAL;
+                }
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)avframe->data[i],\
+                                    (void*)cnframe->plane[i].addr,\
+                                    cnframe->stride[i] * cnframe->height/factor, \
+                                    CNRT_MEM_TRANS_DIR_DEV2HOST);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_INFO, "Output frame D2h: dev %p -> host %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height/factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to host \n");
+                    return AVERROR_EXTERNAL;
+                }
+            }
+        }
+        break;
+    case CNCODEC_PIX_FMT_I420:
+        for (i = 0; i < cnframe->planeNum; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->stride[i];
+
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)avframe->data[i],\
+                                    (void*)cnframe->plane[i].addr,\
+                                    cnframe->stride[i] * cnframe->height/factor, \
+                                    CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_INFO, "Output frame D2h: dev %p -> dev %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height/factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to device \n");
+                    return AVERROR_EXTERNAL;
+                }
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)avframe->data[i],\
+                                    (void*)cnframe->plane[i].addr,\
+                                    cnframe->stride[i] * cnframe->height/factor, \
+                                    CNRT_MEM_TRANS_DIR_DEV2HOST);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(avctx, AV_LOG_INFO, "Output frame D2h: dev %p -> host %p, size %d \n",
+                        (void *)cnframe->plane[i].addr, (void *)avframe->data[i], cnframe->stride[i] * cnframe->height/factor);
+                    av_frame_unref(avframe);
+                    av_log(avctx, AV_LOG_ERROR, "Failed to transfer data from device to host \n");
+                    return AVERROR_EXTERNAL;
+                }
+            }
+        }
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "unsupported pixfmt: %d, except NV12/NV21/YUV420P/P010 \n", cnframe->pixelFmt);
+        break;
+    }
+    return 0;
+}
+
+//ffmpeg wrapper interface
+static int mlumpp_output_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    // AVHWDeviceContext *device_ctx = (AVHWDeviceContext*)ctx->hwdevice->data;
+    // AVMLUDeviceContext *device_hwctx = device_ctx->hwctx;
+    // MluContext *mlu_ctx = device_hwctx->mlu_ctx;
+
+    int ret = 0;
+    int fifo_empty = 1;
+    MLUJpegFrameInfo_t out_jframe;
+    MLUVideoFrameInfo_t out_vframe;
+    cnjpegDecOutput *jpeg_info = NULL;
+    cnvideoDecOutput *video_info = NULL;
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        fifo_empty = (av_fifo_size(ctx->frame_queue) == 0);
+    }else{
+        fifo_empty = 1;
+    }
+    if (!fifo_empty) {
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            av_fifo_generic_read(ctx->frame_queue, &out_jframe, sizeof(MLUJpegFrameInfo_t), NULL);
+            jpeg_info = &out_jframe.outframe;
+            ret = mlumpp_ffcopy_helper(avctx,frame,&jpeg_info->frame);
+            frame->width = avctx->width;
+            frame->height = avctx->height;
+            frame->pkt_pos = -1;
+            frame->pkt_duration = 0;
+            frame->pkt_size = -1;
+            frame->interlaced_frame = ctx->progressive ? 0 : 1;
+            frame->pts = jpeg_info->pts;
+            //frame->pkt_dts = AV_NOPTS_VALUE;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+            frame->pkt_pts = frame->pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+            if (ctx->handle) {
+                cnjpegDecReleaseReference(ctx->handle,&jpeg_info->frame);
+            }
+        } else {
+            av_fifo_generic_read(ctx->frame_queue, &out_vframe, sizeof(MLUVideoFrameInfo_t), NULL);
+            video_info = &out_vframe.outframe;
+            ret = mlumpp_ffcopy_helper(avctx, frame, &video_info->frame);
+            frame->pkt_pos = -1;
+            frame->pkt_duration = 0;
+            frame->pkt_size = -1;
+            frame->interlaced_frame = ctx->progressive ? 0 : 1;
+            frame->pts = video_info->pts;
+            //frame->pkt_dts = AV_NOPTS_VALUE;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+            frame->pkt_pts = frame->pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+            frame->width = avctx->width;
+            frame->height = avctx->height;
+            if (ctx->handle) {
+                cnvideoDecReleaseReference(ctx->handle, &video_info->frame);
+            }
+        }
+    } else {
+        av_usleep(1000);
+        ret = AVERROR(EAGAIN);
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    return ret;
+}
+
+static int mlumpp_receive_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    // AVHWDeviceContext *device_ctx = (AVHWDeviceContext*)ctx->hwdevice->data;
+    // AVMLUDeviceContext *device_hwctx = device_ctx->hwctx;
+    // MluContext *mlu_ctx = device_hwctx->mlu_ctx;
+
+    int ret = 0;
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in mlumpp_receive_frame\n");
+        return AVERROR_BUG;
+    }
+    if (ctx->codec_abort_flag || !ctx->decoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Decode got abort or not init, return AVERROR_EXTERNAL \n");
+        return AVERROR_BUG;
+    }
+    if(mlumpp_device_binding(ctx) != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Device binding failed\n");
+        return AVERROR(EINVAL);
+    }
+    if (ctx->eos_received && mlumpp_is_frame_queue_empty(avctx)) {
+        if (ctx->trace_flag > 0)
+            av_log(avctx, AV_LOG_INFO, "Decode return AVERROR_EOF \n");
+        return AVERROR_EOF;
+    }
+    if (!ctx->decoder_flushing) {
+        if (mlumpp_is_input_available(avctx, 0)) {
+            AVPacket pkt = {0};
+            ret = ff_decode_get_packet(avctx, &pkt);
+            if (ret < 0 && ret != AVERROR_EOF) {
+                return ret;
+            }
+            ret = mlumpp_decode_packet(avctx, &pkt);
+            av_packet_unref(&pkt);
+            if (ret == AVERROR(EAGAIN))
+                ret = AVERROR_EXTERNAL;
+            if (ret < 0 && ret != AVERROR_EOF)
+                return ret;
+        }
+    }
+    if (!ctx->decoder_flushing) {
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            while (!ctx->codec_abort_flag) {
+                ret = mlumpp_output_frame(avctx, frame);
+                if(ret == AVERROR(EAGAIN)) {
+                    av_usleep(1000);
+                    continue;
+                }
+                return ret;
+            }
+            av_log(avctx, AV_LOG_ERROR, "Receive frame ABORT->EOF, [%lu]\n", (long unsigned)pthread_self());
+            return AVERROR_EOF;
+        }
+        ret = mlumpp_output_frame(avctx, frame);
+        return ret;
+    } else {
+        int count = 5000;
+        while (!ctx->codec_abort_flag) {
+            ret = mlumpp_output_frame(avctx, frame);
+            if( ret == AVERROR(EAGAIN)) {
+                if (ctx->eos_received && mlumpp_is_frame_queue_empty(avctx)) {
+                    if (ctx->trace_flag > 0)
+                        av_log(avctx, AV_LOG_INFO, "eos_received AVERROR_EOF \n");
+                    return AVERROR_EOF;
+                }
+                av_usleep(1000);
+                if(count-- <= 0) {
+                    av_log(avctx, AV_LOG_ERROR, "[%lu] Receive frame TIMEOUT->EOF \n",
+                          (long unsigned)pthread_self());
+                    return AVERROR_EOF;
+                }
+                continue;
+            }
+            return ret;
+        }
+        av_log(avctx, AV_LOG_ERROR, "[%lu] Receive frame ABORT->EOF \n", (long unsigned)pthread_self());
+        return AVERROR_EOF;
+    }
+}
+
+static av_cold int mlumpp_decode_end(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = NULL;
+    cnjpegDecInput jpeg_in;
+    cnvideoDecInput vid_in;
+
+    int time_flag;
+    int ret = -1;
+    int time_cnt = 0;
+    int timeout = 0;
+    struct timespec ts;
+    ctx = (MLUMPPContext_t*)avctx->priv_data;
+    if (NULL == avctx || NULL == avctx->priv_data || NULL == ctx->handle) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in mlumpp_decode_end \n");
+        return AVERROR_BUG;
+    }
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Decode closing, handle: %lu \n", (long unsigned)ctx->handle);
+    }
+    // flush cached decoded frames to release output buffers
+    if(mlumpp_device_binding(ctx) != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Device binding failed\n");
+        return AVERROR(EINVAL);
+    }
+    mlumpp_empty_frame_queue(avctx);
+    time_cnt = 1000;
+    timeout = 3000;
+    time_flag = 0;
+
+    // wait eos cb: 1s
+    while (!ctx->eos_received && time_cnt-- >= 0) {
+        if (!ctx->eos_sended) {
+            av_log(avctx, AV_LOG_WARNING, "Decode had't fed EOS data, fed in close func \n");
+            ctx->eos_sended = 1;
+            if (ctx->codec_type == CNCODEC_JPEG) {
+                memset(&jpeg_in, 0, sizeof(cnjpegDecInput));
+                jpeg_in.streamBuffer = NULL;
+                jpeg_in.flags |= CNJPEGDEC_FLAG_EOS;
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Decode feed eos in close func ... \n");
+                }
+                if (ctx->handle) {
+                    ret = cnjpegDecFeedData(ctx->handle, &jpeg_in, timeout);
+                    if (ret != 0) {
+                        av_log(avctx, AV_LOG_ERROR, "Failed to feed EOS data for jpeg dec in decode end\n");
+                    }
+                }
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Decode close func feed eos done \n");
+                }
+                ctx->decoder_flushing = 1;
+            } else {
+                memset(&vid_in, 0, sizeof(cnvideoDecInput));
+                vid_in.streamBuf = NULL;
+                vid_in.flags |= CNVIDEODEC_FLAG_EOS;
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Decode close func feed eos ... \n");
+                }
+                if (ctx->handle) {
+                    ret = cnvideoDecFeedData(ctx->handle, &vid_in, timeout);
+                    if (ret != 0) {
+                        av_log(avctx, AV_LOG_ERROR, "Failed to feed EOS data for vdec in decode end\n");
+                    }
+                }
+                if (ctx->trace_flag > 0) {
+                    av_log(avctx, AV_LOG_INFO, "Decode close func fed eos done \n");
+                }
+                ctx->decoder_flushing = 1;
+            }
+        } else {
+            if (!time_flag) {
+                av_log(avctx, AV_LOG_WARNING, "Decode had feed EOS data, waited eos call back \n");
+                time_flag = 1;
+            }
+        }
+        mlumpp_empty_frame_queue(avctx);
+        av_usleep(100);
+    }
+    if (!ctx->eos_received && ctx->codec_type != CNCODEC_JPEG) {
+        mlumpp_empty_frame_queue(avctx);
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec stop, not eos cb ... \n");
+        }
+        if (ctx->handle) {
+            cnvideoDecStop(ctx->handle);
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec stop done, not eos cb \n");
+        }
+        goto abort_exit;
+    }
+    if (!ctx->decoder_flushing && ctx->handle != NULL) {
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            if (ctx->handle) {
+                cnjpegDecAbort(ctx->handle);
+                ctx->handle = NULL;
+            }
+        } else {
+            if (ctx->handle) {
+                cnvideoDecAbort(ctx->handle);
+                ctx->handle = NULL;
+            }
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec abort, due to not dec flushing \n");
+        }
+        goto abort_exit;
+    }
+
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Decode wait eos sema post ... \n");
+    }
+    // sem_wait(&ctx->eos_sema);
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ts.tv_sec += 5;
+    mlumpp_empty_frame_queue(avctx);
+    ret = sem_timedwait(&(ctx->eos_sema), &ts);
+    if (ret == -1) {
+        int semvalue = -1;
+        sem_getvalue(&ctx->eos_sema, &semvalue);
+        av_log(avctx, AV_LOG_ERROR, "Decode sem_timewait = -1, semvalue = %d ... \n", semvalue);
+    }
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Decode wait eos sema post done \n");
+    }
+
+    // flush cached decoded frames again
+    mlumpp_empty_frame_queue(avctx);
+    if (ctx->codec_type != CNCODEC_JPEG && ctx->decoder_start) {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec stop, had eos cb ... \n");
+        }
+        if (ctx->handle) {
+            cnvideoDecStop(ctx->handle);
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec stop done, had eos cb \n");
+        }
+    }
+
+abort_exit:
+    if (ctx->codec_type != CNCODEC_JPEG) {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec destroy ... \n");
+        }
+        if (ctx->handle) {
+            cnvideoDecDestroy(ctx->handle);
+            ctx->handle = NULL;
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Vid dec destroy done \n");
+        }
+    } else {
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Jpeg dec destroy ... \n");
+        }
+        if (ctx->handle) {
+            cnjpegDecDestroy(ctx->handle);
+            ctx->handle = NULL;
+        }
+        if (ctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Jpeg dec destroy done \n");
+        }
+    }
+    sem_destroy(&ctx->eos_sema);
+    if (ctx->frame_queue) {
+        av_fifo_freep(&ctx->frame_queue);
+        ctx->frame_queue = NULL;
+    }
+    ff_mutex_destroy(&ctx->queue_mutex);
+    if (ctx->bsf) {
+        av_bsf_free(&ctx->bsf);
+        ctx->bsf = NULL;
+    }
+
+    ctx->mlu_ctx = NULL;
+    av_buffer_unref(&ctx->hwframe);
+    av_buffer_unref(&ctx->hwdevice);
+    av_buffer_unref(&ctx->resize_hwframe);
+
+    ctx->decoder_init_flag = 0;
+    if (ctx->trace_flag > 1) {
+        av_log(avctx, AV_LOG_INFO, "cndecoder status summary: \n");
+        av_log(avctx, AV_LOG_INFO, "decode thread id, %lu \n", (long unsigned)pthread_self());
+        av_log(avctx, AV_LOG_INFO, "decode flushing flag:%d \n", ctx->decoder_flushing);
+        av_log(avctx, AV_LOG_INFO, "decode D2H total pictures count:%llu\n", ctx->total_outframe_count);
+        av_log(avctx, AV_LOG_INFO, "decode received total pictures count:%llu\n", ctx->total_frame_count);
+        av_log(avctx, AV_LOG_INFO, "decode feed data count:%llu\n", ctx->total_packet_count);
+    }
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "cndecoder close done \n");
+    }
+    return 0;
+}
+
+static av_cold int mlumpp_decode_init(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVMLUDeviceContext *device_hwctx;
+    AVHWFramesContext *hwframe_ctx;
+    AVHWFramesContext *resize_frame_ctx;
+    // MluContext *mlu_ctx = NULL;
+
+    int ret = 0;
+    int old_width = 0;
+    int old_height = 0;
+    int probed_width = 0;
+    int probed_height = 0;
+    int bitstream_size = 0;
+    char device_idx[sizeof(int)];
+
+    const AVBitStreamFilter *bsf;
+    cnjpegDecCreateInfo jdec_params;
+    enum AVPixelFormat dec_pix_format = mlumpp_dec_map_ff_pixfmt(
+                                        mlumpp_dec_map_cn_pixfmt(ctx->output_pixfmt));
+    enum AVPixelFormat pix_fmts[3] = { AV_PIX_FMT_MLU, dec_pix_format,
+                                       AV_PIX_FMT_NONE };
+
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in mlumpp_decode_init func.\n");
+        return AVERROR_BUG;
+    }
+    if (ctx->decoder_init_flag == 1) {
+        av_log(avctx, AV_LOG_ERROR, "Error, cndecode double init. \n");
+        return AVERROR_BUG;
+    }
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cndecoder init ... \n");
+    }
+
+    if (ctx->resize_str && sscanf(ctx->resize_str, "%dx%d",
+                                &ctx->resize.width, &ctx->resize.height) != 2) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid resize string\n");
+        return AVERROR(EINVAL);
+    }
+    if (ctx->resize_str && avctx->codec_type == CNCODEC_JPEG) {
+        av_log(avctx, AV_LOG_ERROR, "Jpeg decode unsuported resize feature\n");
+        return AVERROR(EINVAL);
+    }
+
+    avctx->sw_pix_fmt = mlumpp_dec_map_ff_pixfmt(
+                        mlumpp_dec_map_cn_pixfmt(ctx->output_pixfmt));
+    ret = ff_get_format(avctx, pix_fmts);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error, ff_get_format failed: %d\n", ret);
+        return ret;
+    }
+    avctx->pix_fmt = ret;
+
+    ctx->avctx = avctx;
+    ctx->frame_queue = NULL;
+    old_width  = avctx->width;
+    old_height = avctx->height;
+    probed_width  = avctx->coded_width ? avctx->coded_width : 1920;
+    probed_height = avctx->coded_height ? avctx->coded_height : 1080;
+    if (avctx->codec->id == AV_CODEC_ID_MJPEG) {
+        ctx->stride_align = CN_JFRAME_ALIGNMENT_W;
+        avctx->coded_width = FFALIGN(avctx->coded_width, CN_JFRAME_ALIGNMENT_W);
+        avctx->coded_height= FFALIGN(avctx->coded_height,CN_JFRAME_ALIGNMENT_H);
+    } else {
+        ctx->stride_align = CN_VFRAME_ALIGNMENT;
+        avctx->coded_width = FFALIGN(avctx->coded_width, CN_VFRAME_ALIGNMENT);
+    }
+
+    mlumpp_get_version();
+    if(0 != mlumpp_adapt_resolution(avctx)) {
+        return AVERROR(EINVAL);
+    }
+
+    sprintf(device_idx, "%d", ctx->device_id);
+    if (avctx->hw_frames_ctx) {
+        av_buffer_unref(&ctx->hwframe);
+        ctx->hwframe = av_buffer_ref(avctx->hw_frames_ctx);
+        if (!ctx->hwframe) {
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+
+        hwframe_ctx = (AVHWFramesContext*)ctx->hwframe->data;
+        ctx->hwdevice = av_buffer_ref(hwframe_ctx->device_ref);
+        if (!ctx->hwdevice) {
+            av_log(avctx, AV_LOG_ERROR, "A hardware frames or device context is "
+                "required for hardware accelerated decoding.\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        if (avctx->codec->id == AV_CODEC_ID_MJPEG) {
+            if (hwframe_ctx->pool) {
+                av_buffer_pool_uninit(&(hwframe_ctx->pool));
+                hwframe_ctx->pool = NULL;
+            }
+            hwframe_ctx->format = AV_PIX_FMT_MLU;
+            hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            hwframe_ctx->width  = avctx->coded_width;
+            hwframe_ctx->height = avctx->height;
+            if ((ret = av_hwframe_ctx_init(ctx->hwframe)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_init failed\n");
+                return 0;
+            }
+        }
+    } else {
+        if (avctx->hw_device_ctx) {
+            ctx->hwdevice = av_buffer_ref(avctx->hw_device_ctx);
+            if (!ctx->hwdevice) {
+                ret = AVERROR(EINVAL);
+                goto error;
+            }
+        } else {
+            ret = av_hwdevice_ctx_create(&ctx->hwdevice, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+            if (ret < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Hardware device context create failed, ret(%d).\n", ret);
+                goto error;
+            }
+        }
+
+        ctx->hwframe = av_hwframe_ctx_alloc(ctx->hwdevice);
+        if (!ctx->hwframe) {
+            av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_alloc failed.\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        hwframe_ctx = (AVHWFramesContext*)ctx->hwframe->data;
+        if (!hwframe_ctx->pool) {
+            hwframe_ctx->format = AV_PIX_FMT_MLU;
+            hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            hwframe_ctx->width  = avctx->coded_width;
+            hwframe_ctx->height = avctx->height;
+            if ((ret = av_hwframe_ctx_init(ctx->hwframe)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_init failed\n");
+                return 0;
+            }
+        }
+    }
+
+    ctx->hwframes_ctx = hwframe_ctx;
+    device_hwctx      = ((AVHWDeviceContext*)ctx->hwdevice->data)->hwctx;
+    ctx->mlu_ctx      = device_hwctx->mlu_ctx;
+
+    sem_init(&(ctx->eos_sema), 0, 0);
+    ff_mutex_init(&ctx->queue_mutex, NULL);
+
+    ctx->total_frame_count = 0;
+    ctx->total_packet_count = 0;
+    ctx->total_outframe_count = 0;
+    ctx->decoder_flushing = 0;
+    ctx->eos_sended = 0;
+    ctx->eos_received = 0;
+    ctx->resize.in_y_ptr = NULL;
+    ctx->resize.in_uv_ptr = NULL;
+    ctx->resize.out_y_ptr = NULL;
+    ctx->resize.out_uv_ptr = NULL;
+    ctx->first_packet = 1;
+    ctx->codec_abort_flag = 0;
+    switch (avctx->codec->id) {
+#if CONFIG_H264_MLUMPP_DECODER
+    case AV_CODEC_ID_H264:
+        ctx->codec_type = CNCODEC_H264;
+        break;
+#endif
+#if CONFIG_HEVC_MLUMPP_DECODER
+    case AV_CODEC_ID_HEVC:
+        ctx->codec_type = CNCODEC_HEVC;
+        break;
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+    case AV_CODEC_ID_MJPEG:
+        ctx->codec_type = CNCODEC_JPEG;
+        break;
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+    case AV_CODEC_ID_VP8:
+        ctx->codec_type = CNCODEC_VP8;
+        break;
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+    case AV_CODEC_ID_VP9:
+        ctx->codec_type = CNCODEC_VP9;
+        break;
+#endif
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Invalid mlumpp codec %d\n",avctx->codec->id);
+        return AVERROR_BUG;
+    }
+
+    ctx->bsf = NULL;
+    if (avctx->codec->id == AV_CODEC_ID_H264 || avctx->codec->id == AV_CODEC_ID_HEVC) {
+        if (avctx->codec->id == AV_CODEC_ID_H264)
+            bsf = av_bsf_get_by_name("h264_mp4toannexb");
+        else
+            bsf = av_bsf_get_by_name("hevc_mp4toannexb");
+        if (!bsf) {
+            ret = AVERROR_BSF_NOT_FOUND;
+            goto error;
+        }
+        if (ret = av_bsf_alloc(bsf, &ctx->bsf)) {
+            goto error;
+        }
+        if (((ret = avcodec_parameters_from_context(ctx->bsf->par_in, avctx)) < 0) ||
+            ((ret = av_bsf_init(ctx->bsf)) < 0)) {
+            av_bsf_free(&ctx->bsf);
+            goto error;
+        }
+    }
+    /*At this moment, if the demuxer does not set this value (avctx->field_order == UNKNOWN),
+    *   the input stream will be assumed as progressive one.
+    */
+    switch(avctx->field_order){
+    case AV_FIELD_TT:
+    case AV_FIELD_BB:
+    case AV_FIELD_TB:
+    case AV_FIELD_BT:
+        ctx->progressive = 0;
+        break;
+    case AV_FIELD_PROGRESSIVE: // fall through
+    default:
+        ctx->progressive = 1;
+        break;
+    }
+
+    if (ctx->codec_type != CNCODEC_JPEG) {
+        bitstream_size = ceil((probed_width * probed_height) * 1.25);
+        memset(&(ctx->vdec_params), 0 ,sizeof(cnvideoDecCreateInfo));
+        ctx->vdec_params.codec = ctx->codec_type;
+        ctx->vdec_params.deviceId = ctx->device_id;
+        ctx->vdec_params.width = probed_width;
+        ctx->vdec_params.height = probed_height;
+        ctx->vdec_params.bitDepthMinus8 =  0;
+        ctx->vdec_params.progressive = ctx->progressive;
+        ctx->vdec_params.inputBufNum = ctx->num_input_buffers;
+        ctx->vdec_params.outputBufNum = ctx->num_output_buffers;
+        ctx->vdec_params.allocType = CNCODEC_BUF_ALLOC_LIB;
+        ctx->vdec_params.instance = ctx->instance_id;
+        ctx->vdec_params.pixelFmt = mlumpp_dec_map_mlu_pixfmt(avctx->sw_pix_fmt);
+        ctx->vdec_params.suggestedLibAllocBitStrmBufSize = FFALIGN(bitstream_size, 4096);
+        ctx->vdec_params.userContext = (void*) ctx;
+
+        ret = cnvideoDecCreate(&ctx->handle, &mlumpp_event_cb, &ctx->vdec_params);
+        if (0 != ret) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create decoder, ret:%d\n",ret);
+            ctx->handle = NULL;
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        avctx->pkt_timebase.num = 1;
+        avctx->pkt_timebase.den = 90000;
+        if (ctx->handle) {
+            ret = cnvideoDecSetAttributes(ctx->handle, CNVIDEO_DEC_ATTR_OUT_BUF_ALIGNMENT, &ctx->stride_align);
+            if (0 != ret) {
+                av_log(avctx, AV_LOG_ERROR, "Failed to set output buffer stride alignment, ret:%d\n",ret);
+                ret = AVERROR(EINVAL);
+                goto error;
+            }
+        }
+        ctx->decoder_start = 0;
+    } else {
+        bitstream_size = ceil((
+                FFALIGN(probed_width, CN_JFRAME_ALIGNMENT_W) *
+                FFALIGN(probed_height, CN_JFRAME_ALIGNMENT_H)) * 1.25);
+        jdec_params.deviceId = ctx->device_id;
+        jdec_params.width = probed_width;
+        jdec_params.height = probed_height;
+        jdec_params.bitDepthMinus8 = 0;
+        jdec_params.inputBufNum = ctx->num_input_buffers;
+        jdec_params.outputBufNum = ctx->num_output_buffers;
+        jdec_params.colorSpace = CNCODEC_COLOR_SPACE_BT_709;
+        jdec_params.allocType = CNCODEC_BUF_ALLOC_LIB;
+        jdec_params.instance = mlumpp_dec_get_jpu_inst(ctx->instance_id);
+        jdec_params.pixelFmt = mlumpp_dec_map_mlu_pixfmt(avctx->sw_pix_fmt);
+        jdec_params.suggestedLibAllocBitStrmBufSize = FFALIGN(bitstream_size, 4096);
+        jdec_params.userContext = (void *)ctx;
+
+        ctx->async_queue_depth = ctx->num_output_buffers;
+        avctx->coded_width  = FFALIGN(avctx->coded_width, CN_JFRAME_ALIGNMENT_W);
+        avctx->coded_height = FFALIGN(avctx->coded_height,CN_JFRAME_ALIGNMENT_H);
+        ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(MLUJpegFrameInfo_t));
+        if (!ctx->frame_queue) {
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        ret = cnjpegDecCreate(&ctx->handle, CNJPEGDEC_RUN_MODE_ASYNC, &mlumpp_event_cb, &jdec_params);
+        if (0 != ret) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create jpeg decoder,error code: %d \n",ret);
+            ctx->handle = NULL;
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+    }
+
+    // only vid decoder has post proc
+    if (ctx->resize.width > 0 && ctx->resize.height > 0) {
+        if ((ctx->resize.width != avctx->width / 2 || ctx->resize.height != avctx->height / 2) &&
+            (ctx->resize.width != avctx->width / 4 || ctx->resize.height != avctx->height / 4)) {
+            av_log(avctx, AV_LOG_ERROR, "Reisze params error, only supported 1/2 or 1/4 downscale\n");
+            return AVERROR(EINVAL);
+        }
+        ctx->resize_hwframe = av_hwframe_ctx_alloc(ctx->hwdevice);
+        if (!ctx->resize_hwframe) {
+            av_log(avctx, AV_LOG_ERROR, "Resize hwframe av_hwframe_ctx_alloc failed\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+
+        resize_frame_ctx = (AVHWFramesContext*)ctx->resize_hwframe->data; // HWFrameContext
+
+        if (!resize_frame_ctx->pool) {
+            resize_frame_ctx->format = AV_PIX_FMT_MLU;
+            resize_frame_ctx->sw_format = avctx->sw_pix_fmt;
+            resize_frame_ctx->width = ctx->resize.width;
+            resize_frame_ctx->height = ctx->resize.height;
+            if ((ret = av_hwframe_ctx_init(ctx->resize_hwframe)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Resize frame: av_hwframe_ctx_init failed\n");
+                return 0;
+            }
+        }
+    }
+
+    ctx->decoder_init_flag = 1;
+    if (!avctx->pkt_timebase.num || !avctx->pkt_timebase.den)
+        av_log(avctx, AV_LOG_WARNING, "Invalid pkt_timebase, passing timestamps as-is.\n");
+    if (ctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cndecoder init done, handle: %lu, thread id: %lu \n", \
+                      (long unsigned)ctx->handle, (long unsigned)pthread_self());
+    }
+    return 0;
+error:
+    sem_post(&ctx->eos_sema);
+    mlumpp_decode_end(avctx);
+    return ret;
+}
+
+static void mlumpp_flush(AVCodecContext *avctx) {
+
+}
+
+#define OFFSET(x) offsetof(MLUMPPContext_t, x)
+#define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+#define MLU2XX_COMMON_OPTS \
+    { "device_id",     "use to choose the accelerator card",     OFFSET(device_id),       AV_OPT_TYPE_INT, { .i64 = 0 },0, INT_MAX, VD },\
+    { "instance_id",   "use to choose which vpu instance",       OFFSET(instance_id),     AV_OPT_TYPE_INT, { .i64 =-1 },-1, INT_MAX, VD },\
+    { "cnrt_init_flag", "init/destory cnrt device in ffmpeg",    OFFSET(cnrt_init_flag),  AV_OPT_TYPE_INT, { .i64 = 1 },0, 1, VD },\
+    { "input_buf_num",  "Number of input buffers for decoder",   OFFSET(num_input_buffers),   AV_OPT_TYPE_INT, { .i64 = 4}, 1, 18, VD },\
+    { "output_buf_num","Number of output buffers for decoder",   OFFSET(num_output_buffers),  AV_OPT_TYPE_INT, { .i64 = 4}, 1, 18, VD },\
+    { "stride_align","stride align of output buffers for decoder",OFFSET(stride_align),   AV_OPT_TYPE_INT, { .i64 = 1 },0, 128, VD },\
+    { "output_pixfmt",        "output pix fmt",                   OFFSET(output_pixfmt),   AV_OPT_TYPE_STRING, { .str = "nv12" },0, 0, VD }, /*NV12, NV21, YUV420P, P010*/
+
+static const AVOption options[] = {
+    MLU2XX_COMMON_OPTS
+    { "crop",     "Crop (top)x(bottom)x(left)x(right)", OFFSET(crop_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "resize",   "Resize (width)x(height)", OFFSET(resize_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "trace", "Whether open trace switch or not",    OFFSET(trace_flag),  AV_OPT_TYPE_INT, { .i64 = 0 },0, 3, VD },
+    { NULL }
+};
+
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+
+#define MLUMPP_DEC_CODEC(x, X) \
+    static const AVClass x##_mlumpp_class = { \
+        .class_name = #x "_mludec", \
+        .item_name = av_default_item_name, \
+        .option = options, \
+        .version = LIBAVUTIL_VERSION_INT, \
+    }; \
+    AVCodec ff_##x##_mlumpp_decoder = { \
+        .name           = #x "_mludec", \
+        .long_name      = NULL_IF_CONFIG_SMALL("Cambricon MLUMPP " #X " decoder"), \
+        .type           = AVMEDIA_TYPE_VIDEO, \
+        .id             = AV_CODEC_ID_##X, \
+        .priv_data_size = sizeof(MLUMPPContext_t), \
+        .priv_class     = &x##_mlumpp_class, \
+        .init           = mlumpp_decode_init, \
+        .close          = mlumpp_decode_end, \
+        .receive_frame  = mlumpp_receive_frame, \
+        .flush          = mlumpp_flush,  \
+        .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_HARDWARE, \
+        .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_MLU, \
+                                                        AV_PIX_FMT_NV12, \
+                                                        AV_PIX_FMT_NV21, \
+                                                        AV_PIX_FMT_YUV420P, \
+                                                        AV_PIX_FMT_P010, \
+                                                        AV_PIX_FMT_NONE }, \
+        .hw_configs     = mlu_hw_configs, \
+        .wrapper_name   = "mludec", \
+    };
+
+#if CONFIG_HEVC_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(hevc, HEVC)
+#endif
+#if CONFIG_H264_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(h264, H264)
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(mjpeg, MJPEG)
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp8, VP8)
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp9, VP9)
+#endif
\ No newline at end of file
diff --git a/libavcodec/mlumpp_enc_h264.c b/libavcodec/mlumpp_enc_h264.c
new file mode 100755
index 0000000000..d23d6b88c6
--- /dev/null
+++ b/libavcodec/mlumpp_enc_h264.c
@@ -0,0 +1,175 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <unistd.h>
+#include <stdint.h>
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/log.h"
+#include "internal.h"
+#include "mlumpp_vid_enc.h"
+typedef struct _CNVIDH264EncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnvid;
+} CNVIDH264EncContext;
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNVIDH264EncContext *cnctx =(CNVIDH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_init(avctx, &cnctx->cnvid);
+}
+static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    CNVIDH264EncContext *cnctx = (CNVIDH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_send_frame(avctx, &cnctx->cnvid, frame);
+}
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    CNVIDH264EncContext *cnctx = (CNVIDH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_receive_packet(avctx, &cnctx->cnvid, pkt);
+}
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNVIDH264EncContext *cnctx = (CNVIDH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_close(avctx, &cnctx->cnvid);
+}
+
+static const AVCodecDefault h264_defaults[] = {
+    { "b",                "0" },
+    { "bf",               "0" },
+    { "g",                "200" },
+    { "qmin",             "-1" },
+    { "qmax",             "-1" },
+    { "refs",             "-1" },
+    { NULL },
+};
+#define OFFSET(x) offsetof(CNVIDH264EncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+#define MLU2XX_COMMON_OPTS \
+    { "device_id",      "use to choose the accelerator card",     OFFSET(cnvid.device_id),       AV_OPT_TYPE_INT, { .i64 = 0 },0, INT_MAX, VE },\
+    { "instance_id",    "use to choose which vpu instance",       OFFSET(cnvid.instance_id),     AV_OPT_TYPE_INT, { .i64 =-1 },-1, 6, VE },\
+    { "cnrt_init_flag", "init/destory cnrt device in ffmpeg",     OFFSET(cnvid.cnrt_init_flag),  AV_OPT_TYPE_INT, { .i64 = 1 },0, 1, VE },\
+    { "input_buf_num",  "number of input buffers for encoder",    OFFSET(cnvid.input_buf_num),   AV_OPT_TYPE_INT, { .i64 = 4 },1, 18, VE },\
+    { "output_buf_num", "number of output buffers for encoder",   OFFSET(cnvid.output_buf_num),  AV_OPT_TYPE_INT, { .i64 = 4 },1, 18, VE },\
+    { "stride_align",   "stride align of output buffers for encoder",OFFSET(cnvid.stride_align),   AV_OPT_TYPE_INT, { .i64 = 1 },0, 128, VE },\
+
+static const AVOption options[] = {
+    MLU2XX_COMMON_OPTS
+    { "resize",       "resize (width)x(height)",      OFFSET(cnvid.resize_str),  AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },\
+    { "sar",          "sar (width):(height)",         OFFSET(cnvid.vui_sar_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },\
+    { "trace",        "trace log switch",             OFFSET(cnvid.trace_flag),  AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 3, VE },
+    { "preset",       "Set the encoding preset",      OFFSET(cnvid.preset),      AV_OPT_TYPE_INT,   { .i64 = PRESET_MEDIUM }, PRESET_DEFAULT, PRESET_FAST, VE, "preset" },
+    { "fast",         "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_FAST },        0, 0, VE, "preset" },
+    { "medium",       "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_MEDIUM },      0, 0, VE, "preset" },
+    { "slow",         "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_SLOW },        0, 0, VE, "preset" },
+
+    { "rc",           "Override the preset rate-control",  OFFSET(cnvid.rcmode), AV_OPT_TYPE_INT, { .i64 = CNVIDEOENC_RATE_CTRL_VBR}, CNVIDEOENC_RATE_CTRL_VBR, CNVIDEOENC_RATE_CTRL_CQP, VE, "rc" },
+    { "cqp",          "",   0,       AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_CQP },        0, 0, VE, "rc" },
+    { "cbr",          "",   0,       AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_CBR },        0, 0, VE, "rc" },
+    { "vbr",          "",   0,       AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_VBR },        0, 0, VE, "rc" },
+    { "vbr_minqp",    "Variable bitrate mode with MinQP ",          OFFSET(cnvid.vbr_minqp),    AV_OPT_TYPE_INT, { .i64 = 0},   0, 51, VE},
+    { "vbr_maxqp",    "Variable bitrate mode with MaxQP ",          OFFSET(cnvid.vbr_maxqp),    AV_OPT_TYPE_INT, { .i64 = 51},  0, 51, VE},
+    { "init_qpP",     "Initial QP value for P frame",               OFFSET(cnvid.init_qp_p),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "init_qpB",     "Initial QP value for B frame",               OFFSET(cnvid.init_qp_b),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "init_qpI",     "Initial QP value for I frame",               OFFSET(cnvid.init_qp_i),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "qp",           "Constant QP rate control method",            OFFSET(cnvid.cqp),          AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "profile",      "Set the encoding profile",                   OFFSET(cnvid.profile),      AV_OPT_TYPE_INT, { .i64 = CNVIDEOENC_PROFILE_H264_HIGH }, CNVIDEOENC_PROFILE_H264_BASELINE, CNVIDEOENC_PROFILE_H264_HIGH_10, VE, "profile" },
+    { "baseline",  "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H264_BASELINE },  0, 0, VE, "profile" },
+    { "main",      "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H264_MAIN },      0, 0, VE, "profile" },
+    { "high",      "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H264_HIGH },      0, 0, VE, "profile" },
+    { "high444p",  "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H264_HIGH_10 }, 0, 0, VE, "profile" },
+    { "level",  "Set the encoding level restriction",  OFFSET(cnvid.level),  AV_OPT_TYPE_INT,   { .i64 = CNVIDEOENC_LEVEL_H264_42 }, CNVIDEOENC_LEVEL_H264_1, CNVIDEOENC_LEVEL_H264_51, VE, "level" },
+    { "auto",  "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_13 },       0, 0, VE, "level" },
+    { "1",     "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_1 },        0, 0, VE, "level" },
+    { "1.0",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_1 },        0, 0, VE, "level" },
+    { "1b",    "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_1B },       0, 0, VE, "level" },
+    { "1.0b",  "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_1B },       0, 0, VE, "level" },
+    { "1.1",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_11 },       0, 0, VE, "level" },
+    { "1.2",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_12 },       0, 0, VE, "level" },
+    { "1.3",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_13 },       0, 0, VE, "level" },
+    { "2",     "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_2 },        0, 0, VE, "level" },
+    { "2.0",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_2 },        0, 0, VE, "level" },
+    { "2.1",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_21 },       0, 0, VE, "level" },
+    { "2.2",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_22 },       0, 0, VE, "level" },
+    { "3",     "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_3 },        0, 0, VE, "level" },
+    { "3.0",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_3 },        0, 0, VE, "level" },
+    { "3.1",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_31 },       0, 0, VE, "level" },
+    { "3.2",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_32 },       0, 0, VE, "level" },
+    { "4",     "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_4 },        0, 0, VE, "level" },
+    { "4.0",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_4 },        0, 0, VE, "level" },
+    { "4.1",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_41 },       0, 0, VE, "level" },
+    { "4.2",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_42 },       0, 0, VE, "level" },
+    { "5",     "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_5 },        0, 0, VE, "level" },
+    { "5.0",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_5 },        0, 0, VE, "level" },
+    { "5.1",   "",     0,      AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H264_51 },       0, 0, VE, "level" },
+    { "coder",        "Coder type",     OFFSET(cnvid.coder),  AV_OPT_TYPE_INT,   { .i64 = CNVIDEOENC_ENTROPY_MODE_CAVLC  }, 0, 1, VE, "coder" },
+    { "cabac",        "",               0,                    AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_ENTROPY_MODE_CABAC  }, 0, 0, VE, "coder" },
+    { "cavlc",        "",               0,                    AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_ENTROPY_MODE_CAVLC  }, 0, 0, VE, "coder" },
+    { NULL },
+};
+static const AVClass class = {
+    .class_name = "h264_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_h264_mlumpp_encoder = {
+    .name = "h264_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 (Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_H264,
+    .init = mlumpp_enc_init,
+    .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    /*.encode2        = mlumpp_enc_frame,*/
+    .close = mlumpp_enc_close,
+    .priv_data_size = sizeof(CNVIDH264EncContext),
+    .priv_class = &class,
+    .defaults = h264_defaults,
+    .capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_HARDWARE,
+    .caps_internal = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_P010,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_ARGB,
+                                             AV_PIX_FMT_ABGR,
+                                             AV_PIX_FMT_BGRA,
+                                             AV_PIX_FMT_RGBA,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs     = mlu_hw_configs,
+};
\ No newline at end of file
diff --git a/libavcodec/mlumpp_enc_hevc.c b/libavcodec/mlumpp_enc_hevc.c
new file mode 100755
index 0000000000..f9e6a8c7a0
--- /dev/null
+++ b/libavcodec/mlumpp_enc_hevc.c
@@ -0,0 +1,172 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <unistd.h>
+#include <stdint.h>
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/log.h"
+#include "internal.h"
+//for cambricon
+#include "mlumpp_vid_enc.h"
+typedef struct _CNVIDHEVCEncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnvid;
+} CNVIDHEVCEncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNVIDHEVCEncContext *cnctx =(CNVIDHEVCEncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_init(avctx, &cnctx->cnvid);
+}
+static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame){
+    CNVIDHEVCEncContext *cnctx = (CNVIDHEVCEncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_send_frame(avctx, &cnctx->cnvid, frame);
+}
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt){
+    CNVIDHEVCEncContext *cnctx = (CNVIDHEVCEncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_receive_packet(avctx, &cnctx->cnvid, pkt);
+}
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNVIDHEVCEncContext *cnctx = (CNVIDHEVCEncContext*)avctx->priv_data;
+    return ff_mlumpp_vid_enc_close(avctx, &cnctx->cnvid);
+}
+
+static const AVCodecDefault hevc_defaults[] = {
+    { "b",                "0" },
+    { "bf",               "0" },
+    { "g",                "200" },
+    { "qmin",             "-1" },
+    { "qmax",             "-1" },
+    { "refs",             "0" },
+#if FF_API_CODER_TYPE
+    { "coder",            "-1" },
+#endif
+    { NULL },
+};
+#define OFFSET(x) offsetof(CNVIDHEVCEncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+#define MLU2XX_COMMON_OPTS \
+    { "device_id",      "use to choose the accelerator card",     OFFSET(cnvid.device_id),       AV_OPT_TYPE_INT, { .i64 = 0 },0, INT_MAX, VE },\
+    { "instance_id",    "use to choose which vpu instance",       OFFSET(cnvid.instance_id),     AV_OPT_TYPE_INT, { .i64 =-1 },-1, 6, VE },\
+    { "cnrt_init_flag", "init/destory cnrt device in ffmpeg",     OFFSET(cnvid.cnrt_init_flag),  AV_OPT_TYPE_INT, { .i64 = 1 },0, 1, VE },\
+    { "input_buf_num",  "Number of input buffers for encoder",    OFFSET(cnvid.input_buf_num),   AV_OPT_TYPE_INT, { .i64 = 4 },1, 18, VE },\
+    { "output_buf_num","Number of output buffers for encoder",    OFFSET(cnvid.output_buf_num),  AV_OPT_TYPE_INT, { .i64 = 4 },1, 18, VE },\
+    { "stride_align","stride align of output buffers for encoder",OFFSET(cnvid.stride_align),   AV_OPT_TYPE_INT, { .i64 = 1 },0, 128, VE },\
+
+static const AVOption options[] = {
+    MLU2XX_COMMON_OPTS
+    { "resize",       "resize (width)x(height)",      OFFSET(cnvid.resize_str),  AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },\
+    { "sar",          "sar (width):(height)",         OFFSET(cnvid.vui_sar_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VE },\
+    { "trace",        "trace log switch",             OFFSET(cnvid.trace_flag),  AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 3, VE },
+    { "preset",       "Set the encoding preset",      OFFSET(cnvid.preset),      AV_OPT_TYPE_INT,   { .i64 = PRESET_MEDIUM }, PRESET_DEFAULT, PRESET_FAST, VE, "preset" },
+    { "fast",         "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_FAST },        0, 0, VE, "preset" },
+    { "medium",       "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_MEDIUM },      0, 0, VE, "preset" },
+    { "slow",         "",   0,       AV_OPT_TYPE_CONST, { .i64 = PRESET_SLOW },        0, 0, VE, "preset" },
+
+    { "rc",  "Override the preset rate-control",   OFFSET(cnvid.rcmode), AV_OPT_TYPE_INT,   { .i64 = CNVIDEOENC_RATE_CTRL_VBR}, CNVIDEOENC_RATE_CTRL_VBR, CNVIDEOENC_RATE_CTRL_CQP, VE, "rc" },
+    { "cqp",          "",  0,    AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_CQP },        0, 0, VE, "rc" },
+    { "cbr",          "",  0,    AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_CBR },        0, 0, VE, "rc" },
+    { "vbr",          "",  0,    AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_RATE_CTRL_VBR },        0, 0, VE, "rc" },
+    { "vbr_minqp",    "Variable bitrate mode with MinQP ",          OFFSET(cnvid.vbr_minqp),    AV_OPT_TYPE_CONST, { .i64 = 0},   0, INT_MAX, VE },
+    { "vbr_maxqp",    "Variable bitrate mode with MinQP ",          OFFSET(cnvid.vbr_maxqp),    AV_OPT_TYPE_CONST, { .i64 = 0},   0, INT_MAX, VE },
+    { "init_qpP",     "Initial QP value for P frame",               OFFSET(cnvid.init_qp_p),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "init_qpB",     "Initial QP value for B frame",               OFFSET(cnvid.init_qp_b),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "init_qpI",     "Initial QP value for I frame",               OFFSET(cnvid.init_qp_i),    AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "qp",           "Constant QP rate control method",            OFFSET(cnvid.cqp),          AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 51, VE },
+    { "profile",      "Set the encoding profile",                   OFFSET(cnvid.profile),      AV_OPT_TYPE_INT,   { .i64 = CNVIDEOENC_PROFILE_H265_MAIN }, CNVIDEOENC_PROFILE_H265_MAIN, CNVIDEOENC_PROFILE_H265_MAIN_10, VE, "profile" },
+    { "main",       "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H265_MAIN },       0, 0, VE, "profile" },
+    { "main_still", "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H265_MAIN_STILL }, 0, 0, VE, "profile" },
+    { "main_intra", "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H265_MAIN_INTRA }, 0, 0, VE, "profile" },
+    { "main10",     "", 0, AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_PROFILE_H265_MAIN_10 },    0, 0, VE, "profile" },
+    { "level","Set the encoding level restriction", OFFSET(cnvid.level),        AV_OPT_TYPE_INT,   { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_1 }, CNVIDEOENC_LEVEL_H265_MAIN_1, CNVIDEOENC_LEVEL_H265_HIGH_62, VE, "level" },
+    { "auto",  "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_5 },        0, 0, VE, "level" },
+    { "1",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_1 },        0, 0, VE, "level" },
+    { "1.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_1 },        0, 0, VE, "level" },
+    { "2",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_2 },        0, 0, VE, "level" },
+    { "2.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_2 },        0, 0, VE, "level" },
+    { "2.1",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_21 },       0, 0, VE, "level" },
+    { "3",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_3 },        0, 0, VE, "level" },
+    { "3.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_3 },        0, 0, VE, "level" },
+    { "3.1",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_31 },       0, 0, VE, "level" },
+    { "4",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_4 },        0, 0, VE, "level" },
+    { "4.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_4 },        0, 0, VE, "level" },
+    { "4.1",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_41 },       0, 0, VE, "level" },
+    { "5",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_5 },        0, 0, VE, "level" },
+    { "5.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_5 },        0, 0, VE, "level" },
+    { "5.1",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_51 },       0, 0, VE, "level" },
+    { "5.2",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_52 },       0, 0, VE, "level" },
+    { "6",     "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_6 },        0, 0, VE, "level" },
+    { "6.0",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_6 },        0, 0, VE, "level" },
+    { "6.1",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_MAIN_61 },       0, 0, VE, "level" },
+    { "6.2",   "",   0,   AV_OPT_TYPE_CONST, { .i64 = CNVIDEOENC_LEVEL_H265_HIGH_62 },       0, 0, VE, "level" },
+    { NULL },
+};
+static const AVClass class = {
+    .class_name = "hevc_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_hevc_mlumpp_encoder = {
+    .name = "hevc_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("HEVC ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_HEVC,
+    .init = mlumpp_enc_init,
+    .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    /*.encode2 = mlumpp_enc_frame,*/
+    .close = mlumpp_enc_close,
+    .priv_data_size = sizeof(CNVIDHEVCEncContext),
+    .priv_class = &class,
+    .defaults = hevc_defaults,
+    .capabilities = AV_CODEC_CAP_DELAY,
+    .caps_internal = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_P010,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_ARGB,
+                                             AV_PIX_FMT_ABGR,
+                                             AV_PIX_FMT_BGRA,
+                                             AV_PIX_FMT_RGBA,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs     = mlu_hw_configs,
+};
\ No newline at end of file
diff --git a/libavcodec/mlumpp_enc_jpeg.c b/libavcodec/mlumpp_enc_jpeg.c
new file mode 100755
index 0000000000..9302525d0e
--- /dev/null
+++ b/libavcodec/mlumpp_enc_jpeg.c
@@ -0,0 +1,1084 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <stdio.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <stdint.h>
+#include <string.h>
+#include <stdbool.h>
+#include <pthread.h>
+#include <fcntl.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/time.h"
+#include "libavutil/log.h"
+#include "internal.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "hwaccel.h"
+#include "internal.h"
+
+#include "cn_codec_common.h"
+#include "cn_jpeg_enc.h"
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return -1;                                                                         \
+    }
+#define CNCODEC_ERROR_CHECK(avctx, ret)                                                     \
+    if (ret != CNCODEC_SUCCESS) {                                                           \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__); \
+        return -1;                                                                          \
+    }
+#define OUTPUT_BUFFER_SIZE_FOR_ENCODE (1024 * 4096) // must be 4k align
+
+typedef struct CNJpegEncContext{
+    AVClass                             *class;
+    AVCodecContext                      *avctx;
+    int                                 width;
+    int                                 height;
+    int                                 frame_size;
+    int                                 jpeg_quality;
+    int                                 device_id;
+    int                                 instance_id;
+    int                                 input_buf_num;
+    int                                 output_buf_num;
+    int                                 trace_flag;
+    int                                 codec_abort_flag;
+    volatile int                        encoder_init_flag;
+    int                                 coded_width;
+    int                                 coded_height;
+
+    cnjpegEncInput                      input_buf;
+    cnjpegEncOutput                     output_buf;
+    cnjpegEncParameters                 enFrameParam;
+
+    cnjpegEncoder                       handle;
+    cncodecPixelFormat                  pixelFmt;
+    cncodecColorSpace                   color_space;
+    cncodecBufAllocType                 allocType;
+    cnjpegEncCreateInfo                 *enc_create_params;
+
+    AVBufferRef                         *hw_frame_ref;
+    AVBufferRef                         *hw_device_ref;
+
+    MluContext                          *mlu_ctx;
+    AVMLUDeviceContext                  *hw_device_ctx;
+    AVHWFramesContext                   *hw_frame_ctx;
+    enum AVPixelFormat                  in_sw_pixfmt;
+
+    // the below only for debug
+    unsigned long long                  total_frame_count;
+    unsigned long long                  total_packet_count;
+    unsigned long long                  total_outframe_count;
+}CNJpegEncContext_t;
+
+static int _jpeg_enc_abort_handler(CNJpegEncContext_t *cnctx)
+{
+    int ret;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Jpeg_enc_abort_handler start\n");
+    }
+    ret = cnjpegEncAbort(cnctx->handle);
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Call cnjpegDecAbort failed, ret(%d)\n", ret);
+        return -1;
+    }
+    cnctx->codec_abort_flag = 1;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Jpeg_enc_abort_handler end\n");
+    }
+    return 0;
+}
+
+static inline int mlumpp_adapt_resolution(AVCodecContext* avctx) {
+    if (avctx->width < 64 ||  avctx->width > 8192 || avctx->height < 64 || avctx->height > 4320) {
+        av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+        av_log(avctx, AV_LOG_ERROR, "MLU jpeg encoder only support resolution: 64x64~8192x4320\n");
+        return -1;
+    }
+    return 0;
+}
+
+static int _jpeg_cnframe_addr_check(cncodecFrame *cnframe) {
+    switch (cnframe->pixelFmt) {
+    case CNCODEC_PIX_FMT_YUYV:
+    case CNCODEC_PIX_FMT_UYVY:
+        return 0;
+        break;
+    case CNCODEC_PIX_FMT_NV12:
+    case CNCODEC_PIX_FMT_NV21:
+    {
+        uint64_t start_addr1 = (cnframe->plane[0].addr)>>32;
+        uint64_t end_addr1 = (cnframe->plane[0].addr + cnframe->plane[0].size)>>32;
+        uint64_t start_addr2 = (cnframe->plane[1].addr)>>32;
+        uint64_t end_addr2 = (cnframe->plane[1].addr + cnframe->plane[1].size)>>32;
+        //av_log(NULL, AV_LOG_WARNING, "start_addr1 and addr2:%ld, %ld ; end_addr1 and addr2:%ld, %ld\n", start_addr1,start_addr2,end_addr1,end_addr2);
+        return (start_addr1 == start_addr2) && (end_addr1 == end_addr2) ? 0 : -1 ;
+        break;
+    }
+    default:
+        return -1;
+        break;
+    }
+    return 0;
+}
+
+static inline unsigned int get_plane_height(CNJpegEncContext_t *cnctx, unsigned int height,
+                                            int plane)
+{
+    if (cnctx->pixelFmt == CNCODEC_PIX_FMT_NV12 ||
+        cnctx->pixelFmt == CNCODEC_PIX_FMT_NV21) {
+        return plane == 0 ? FFALIGN(height, 16) : FFALIGN(height / 2, 16);
+    }
+    return FFALIGN(height, 16);
+}
+static inline unsigned int get_plane_width(CNJpegEncContext_t *cnctx, unsigned int width,
+                                           int plane)
+{
+    unsigned int planWidth = 0;
+    switch (cnctx->pixelFmt) {
+    case CNCODEC_PIX_FMT_NV12:
+    case CNCODEC_PIX_FMT_NV21:
+        planWidth = width;
+        break;
+    case CNCODEC_PIX_FMT_YUYV:
+    case CNCODEC_PIX_FMT_UYVY:
+        planWidth = width * 2;
+        break;
+    default:
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Unknown fmt(%d)\n", cnctx->pixelFmt);
+        break;
+    }
+    return planWidth;
+}
+
+static int jpeg_enc_input_frame(CNJpegEncContext_t *cnctx, cncodecFrame *tempInput,
+                                const AVFrame *frame)
+{
+    int ret = -1;
+    cnrtRet_t cnrt_ret;
+    unsigned int fake_height = 0;
+    unsigned int fake_width = 0;
+    void *host_ptr = NULL;
+    void *devi_ptr = NULL;
+    char *tmpData;
+    if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        switch (cnctx->pixelFmt) {
+        case CNCODEC_PIX_FMT_YUYV:
+        case CNCODEC_PIX_FMT_UYVY:
+            fake_height = cnctx->height;
+            fake_width = 2 * cnctx->width;
+            if (fake_width == tempInput->stride[0]) {
+                if (NULL == (void *)tempInput->plane[0].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr,
+                            (void *)frame->data[0], cnctx->width * cnctx->height * 2,
+                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnctx->trace_flag) {
+                    av_log(cnctx->avctx, AV_LOG_INFO, "Yuv h2d plane: host %p -> devi %lu, size %u \n",
+                           frame->data[0], tempInput->plane[0].addr, tempInput->plane[0].size);
+                }
+                CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+            } else {
+                host_ptr = NULL;
+                devi_ptr = NULL;
+                for (int i = 0; i < fake_height; i++) {
+                    host_ptr = (void *)(frame->data[0] + i * fake_width);
+                    devi_ptr = (void *)(tempInput->plane[0].addr + i * tempInput->stride[0]);
+                    if (NULL == host_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR,
+                            "Jpeg encoder input buffer address(CPU) is NULL \n");
+                        return -1;
+                    }
+                    if (NULL == devi_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR,
+                                "Jpeg encoder input data address(MLU) is NULL \n");
+                        return -1;
+                    }
+                    cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2D(devi_ptr,
+                                                            host_ptr, fake_width,
+                                                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                    if (cnctx->trace_flag) {
+                        av_log(cnctx->avctx, AV_LOG_INFO,
+                             "Yuv h2d plane: host(dev) %p -> devi %p, size %u \n",
+                             host_ptr, devi_ptr, fake_width);
+                    }
+                    CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+                }
+            }
+            break;
+        case CNCODEC_PIX_FMT_NV12:
+        case CNCODEC_PIX_FMT_NV21:
+            if (cnctx->width == tempInput->stride[0]) {
+                if (NULL == (void *)tempInput->plane[0].addr ||
+                    NULL == (void *)tempInput->plane[1].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR,
+                           "Jpeg encoder input buffer address(MLU) is NULL \n");
+                    return -1;
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR,
+                           "Jpeg encoder input data address(CPU) is NULL \n");
+                    return -1;
+                }
+                cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr,
+                            (void *)frame->data[0], frame->width * frame->height,
+                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+                cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[1].addr,
+                            (void *)frame->data[1], frame->width * frame->height / 2,
+                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+            } else {
+                host_ptr = NULL;
+                devi_ptr = NULL;
+                for (int i = 0; i < cnctx->height; i++) {
+                    host_ptr = (void *)(frame->data[0] + i * cnctx->width);
+                    devi_ptr = (void *)(tempInput->plane[0].addr + i * tempInput->stride[0]);
+                    if (NULL == host_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR,
+                                            "Encoder input buffer address(MLU) is NULL \n");
+                        return -1;
+                    }
+                    if (NULL == devi_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(MLU) is NULL \n");
+                        return -1;
+                    }
+                    cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2D(devi_ptr, host_ptr, cnctx->width,
+                                                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                    if (cnctx->trace_flag) {
+                        av_log(cnctx->avctx, AV_LOG_INFO,
+                               "Yuv h2h plane: host(dev) %p -> devi %p, size(host) %d \n",
+                                host_ptr, devi_ptr, cnctx->width);
+                    }
+                    CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+                }
+                host_ptr = NULL;
+                devi_ptr = NULL;
+                for (int i = 0; i < cnctx->height / 2; i++) {
+                    host_ptr = (void *)(frame->data[1] + i * cnctx->width);
+                    devi_ptr = (void *)(tempInput->plane[1].addr + i * tempInput->stride[1]);
+                    if (NULL == host_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR,
+                               "Encoder input buffer address(MLU) is NULL \n");
+                        return -1;
+                    }
+                    if (NULL == devi_ptr) {
+                        av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(MLU) is NULL \n");
+                        return -1;
+                    }
+                    cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2D(devi_ptr, host_ptr, cnctx->width,
+                                                            CNRT_MEM_TRANS_DIR_DEV2DEV);
+                    if (cnctx->trace_flag) {
+                        av_log(cnctx->avctx, AV_LOG_INFO,
+                            "Yuv h2h plane: host %p -> devi %p, size(host) %d \n",
+                            host_ptr, devi_ptr, cnctx->width);
+                    }
+                    CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+                }
+            }
+            break;
+        default:
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Unsupported format:%d\n", cnctx->pixelFmt);
+            break;
+        }
+        ret = 0;
+        return ret;
+    }
+
+    switch (cnctx->pixelFmt) {
+    case CNCODEC_PIX_FMT_YUYV:
+    case CNCODEC_PIX_FMT_UYVY:
+        fake_height = cnctx->height;
+        fake_width = 2 * cnctx->width;
+        if (fake_width == tempInput->stride[0]) {
+            if (NULL == (void *)tempInput->plane[0].addr) {
+                av_log(cnctx->avctx, AV_LOG_ERROR,
+                       "Jpeg encoder input buffer address(MLU) is NULL \n");
+                return -1;
+            }
+            if (NULL == frame->data[0]) {
+                av_log(cnctx->avctx, AV_LOG_ERROR,
+                       "Jpeg encoder input data address(CPU) is NULL \n");
+                return -1;
+            }
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr,
+                                                    (void *)frame->data[0],
+                                                    frame->height * fake_width,
+                                                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            if (cnctx->trace_flag) {
+                av_log(cnctx->avctx, AV_LOG_INFO, "Yuv h2d plane: host %p -> devi %lu, size %u \n",
+                       frame->data[0], tempInput->plane[0].addr, tempInput->plane[0].size);
+            }
+            CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+        } else {
+            host_ptr = NULL;
+            devi_ptr = NULL;
+            for (int i = 0; i < fake_height; i++) {
+                host_ptr = (void *)(frame->data[0] + i * fake_width);
+                devi_ptr = (void *)(tempInput->plane[0].addr + i * tempInput->stride[0]);
+                if (NULL == host_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR,
+                         "Jpeg encoder input buffer address(CPU) is NULL \n");
+                  return -1;
+                }
+                if (NULL == devi_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR,
+                         "Jpeg encoder input data address(MLU) is NULL \n");
+                  return -1;
+                }
+                cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D(devi_ptr, host_ptr,
+                                                        fake_width,
+                                                        CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnctx->trace_flag) {
+                  av_log(cnctx->avctx, AV_LOG_INFO,
+                         "Yuv h2d plane: host %p -> devi %p, size %u \n",
+                         host_ptr, devi_ptr, fake_width);
+                }
+                CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+            }
+        }
+        break;
+    case CNCODEC_PIX_FMT_NV12:
+    case CNCODEC_PIX_FMT_NV21:
+        if (cnctx->width == tempInput->stride[0]) {
+            if (NULL == (void *)tempInput->plane[0].addr ||
+                NULL == (void *)tempInput->plane[1].addr) {
+                av_log(cnctx->avctx, AV_LOG_ERROR,
+                       "Jpeg encoder input buffer address(MLU) is NULL \n");
+                return -1;
+            }
+            if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                av_log(cnctx->avctx, AV_LOG_ERROR,
+                       "Jpeg encoder input data address(CPU) is NULL \n");
+                return -1;
+            }
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr,
+                                                    (void *)frame->data[0],
+                                                    frame->width * frame->height,
+                                                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            if (cnctx->trace_flag) {
+                av_log(cnctx->avctx, AV_LOG_INFO, "palne[0].size: %u  width * height: %d\n",
+                      tempInput->plane[0].size, cnctx->width * cnctx->height);
+                av_log(cnctx->avctx, AV_LOG_INFO, "yuv h2d plane[0]: src %p -> dst %lu, size: %u\n",
+                      frame->data[0], tempInput->plane[0].addr, tempInput->plane[0].size);
+            }
+            CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[1].addr,
+                                                    (void *)frame->data[1],
+                                                    frame->width * frame->height / 2,
+                                                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            if (cnctx->trace_flag) {
+                av_log(cnctx->avctx, AV_LOG_INFO, "palne[1].size: %u  width * height / 2: %d\n",
+                       tempInput->plane[1].size, cnctx->width * cnctx->height / 2);
+                av_log(cnctx->avctx, AV_LOG_INFO, "yuv h2d plane[1]: src %p -> dst %lu, size: %u\n",
+                       frame->data[1], tempInput->plane[1].addr, tempInput->plane[1].size);
+            }
+            CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+        } else {
+            tmpData = malloc(tempInput->plane[0].size);
+            memset(tmpData, 0, tempInput->plane[0].size);
+            host_ptr = NULL;
+            devi_ptr = NULL;
+            for (int i = 0; i < cnctx->height; i++) {
+                host_ptr = (void *)(frame->data[0] + i * cnctx->width);
+                devi_ptr = (void *)(tmpData + i * tempInput->stride[0]);
+                if (NULL == host_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(CPU) is NULL \n");
+                  return -1;
+                }
+                if (NULL == devi_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(MLU) is NULL \n");
+                  return -1;
+                }
+                memcpy(devi_ptr, host_ptr, cnctx->width);
+            }
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr,
+                                                    (void *)tmpData,
+                                                    tempInput->plane[0].size,
+                                                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            host_ptr = NULL;
+            devi_ptr = NULL;
+            free(tmpData);
+            tmpData = NULL;
+            CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+
+            tmpData = malloc(tempInput->plane[1].size);
+            memset(tmpData, 0, tempInput->plane[1].size);
+            for (int i = 0; i < cnctx->height / 2; i++) {
+                host_ptr = (void *)(frame->data[1] + i * cnctx->width);
+                devi_ptr = (void *)(tmpData + i * tempInput->stride[1]);
+                if (NULL == host_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR,
+                         "Encoder input buffer address(CPU) is NULL \n");
+                  return -1;
+                }
+                if (NULL == devi_ptr) {
+                  av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(MLU) is NULL \n");
+                  return -1;
+                }
+                memcpy(devi_ptr, host_ptr, cnctx->width);
+            }
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[1].addr,
+                                                    (void *)tmpData,
+                                                    tempInput->plane[1].size,
+                                                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            host_ptr = NULL;
+            devi_ptr = NULL;
+            free(tmpData);
+            tmpData = NULL;
+            CNRT_ERROR_CHECK(cnctx->avctx, cnrt_ret);
+        }
+        break;
+    default:
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Not supported format:%d\n", ret);
+        break;
+    }
+    ret = 0;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Jpeg_enc_input_frame end\n");
+    }
+    return ret;
+}
+
+static int jpeg_enc_output_packet(CNJpegEncContext_t *cnctx, AVPacket *pkt, int *got_packet)
+{
+    int ret = 0;
+    cnrtRet_t rtRet;
+    void *validDataAddr = NULL;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Jpeg_enc_output_packet start\n");
+    }
+
+    if (cnctx->output_buf.flags & CNJPEGENC_FLAG_EOS) {
+        // EOS got.
+        *got_packet = 0;
+        return AVERROR_EOF;
+    }
+    ret = pkt->data ? ff_alloc_packet2(cnctx->avctx, pkt, cnctx->output_buf.streamLength,
+          cnctx->output_buf.streamLength) : av_new_packet(pkt, cnctx->output_buf.streamLength);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Failed to allocate pkt memory\n");
+        *got_packet = 0;
+        return AVERROR(EINVAL);
+    }
+
+    validDataAddr = (void *)(cnctx->output_buf.streamBuffer.addr + cnctx->output_buf.dataOffset);
+    rtRet  = cnrtMemcpy((void *)pkt->data, (void *)validDataAddr, cnctx->output_buf.streamLength,
+                        CNRT_MEM_TRANS_DIR_DEV2HOST);
+    if(rtRet != CNRT_RET_SUCCESS) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "CNRTmemcpy d2h: src %p -> dst %p size: %d \n",
+               validDataAddr, pkt->data, cnctx->output_buf.streamLength);
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Output packet: cnrtMemcpy error ...\n");
+        return -1;
+    }
+
+    *got_packet = 1;
+    cnctx->total_outframe_count++;
+    pkt->pts = cnctx->output_buf.pts;
+    pkt->size = cnctx->output_buf.streamLength;
+
+    pkt->dts = pkt->pts;
+    pkt->pts = av_rescale_q_rnd(pkt->pts, (AVRational){1, 90000}, cnctx->avctx->time_base,
+                                (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
+    pkt->dts = av_rescale_q_rnd(pkt->dts, (AVRational){1, 90000}, cnctx->avctx->time_base,
+                                (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
+    pkt->duration = av_rescale_q(pkt->duration, (AVRational){1, 90000}, cnctx->avctx->time_base);
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Jpeg_enc_output_packet end\n");
+    }
+    return ret;
+}
+
+static int allocateEncCodecFrameBuffer(CNJpegEncContext_t *cnctx)
+{
+    unsigned int j = 0;
+    unsigned int try_time = 50;
+    unsigned int size;
+    unsigned int width;
+    unsigned int height;
+    cnrtRet_t  rtRet;
+    uint32_t planes_num;
+    cnrtChannelType_t channel;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "AllocateEncCodecFrameBuffer start\n");
+    }
+
+    if (!(&cnctx->input_buf.frame)) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Error: cnctx->input_buf.frame address is null...\n");
+        return -1;
+    }
+    if (cnctx->pixelFmt == CNCODEC_PIX_FMT_NV12 || cnctx->pixelFmt == CNCODEC_PIX_FMT_NV21) {
+        planes_num = 2;
+    }
+    else if (cnctx->pixelFmt == CNCODEC_PIX_FMT_I420 || cnctx->pixelFmt == CNCODEC_PIX_FMT_YV12)
+    {
+        planes_num = 3;
+    } else {
+        planes_num = 1;
+    }
+    width = cnctx->width > 0 ? cnctx->width : 1920;
+    height = cnctx->height > 0 ? cnctx->height : 1080;
+    memset(&cnctx->input_buf.frame, 0, sizeof(cncodecFrame));
+    rtRet = cnrtGetCurrentChannel(&channel);
+    CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+    cnctx->input_buf.frame.channel = (int)channel;
+    cnctx->input_buf.frame.width    = width;//FFALIGN(width, 64);
+    cnctx->input_buf.frame.height   = FFALIGN(height, 16);
+    cnctx->input_buf.frame.planeNum = planes_num;
+    cnctx->input_buf.frame.pixelFmt = cnctx->pixelFmt;
+    cnctx->input_buf.frame.deviceId = cnctx->device_id;
+
+    for(try_time = 50; try_time > 0; --try_time) {
+        for (j = 0; j < planes_num; j++) {
+            unsigned int planeW = get_plane_width(cnctx, width, j);
+            unsigned int stride = FFALIGN(planeW, 64);
+            size  = stride * get_plane_height(cnctx, height, j);
+            rtRet = cnrtMallocFrameBuffer((void **)(&cnctx->input_buf.frame.plane[j].addr), size);
+            if (rtRet != CNRT_RET_SUCCESS) {
+                av_log(cnctx->avctx, AV_LOG_ERROR, "%s() call cnrtMallocFrameBuffer failed\n",
+                    __FUNCTION__);
+                goto alloc_failed;
+            }
+            cnctx->input_buf.frame.plane[j].size = size;
+            cnctx->input_buf.frame.stride[j]     = stride;
+        }
+        if (_jpeg_cnframe_addr_check(&cnctx->input_buf.frame) < 0) {
+            for (j = 0; j < planes_num; ++j) {
+                if (cnctx->input_buf.frame.plane[j].addr != 0) {
+                    rtRet = cnrtFree((void *)cnctx->input_buf.frame.plane[j].addr);
+                    CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+                }
+            }
+        } else {
+            break;
+        }
+    }
+    if (try_time <= 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR,
+            "AllocateEncCodecFrameBuffer failed, cannot get aligned addr buffer \n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "AllocateEncCodecFrameBuffer end\n");
+    }
+    return 0;
+
+alloc_failed:
+    for (j = 0; j < planes_num; ++j) {
+        if (cnctx->input_buf.frame.plane[j].addr != 0) {
+            rtRet = cnrtFree((void *)cnctx->input_buf.frame.plane[j].addr);
+            CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+        }
+    }
+    return -1;
+}
+static int releaseEncodeCodecFrameBuffer(CNJpegEncContext_t *cnctx)
+{
+    cnrtRet_t rtRet;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "ReleaseEncodeCodecFrameBuffer start\n");
+    }
+    if (!(&cnctx->input_buf.frame)) {
+        return -1;
+    }
+    for (unsigned j = 0; j < cnctx->input_buf.frame.planeNum; j++) {
+        rtRet = cnrtFree((void *)(cnctx->input_buf.frame.plane[j].addr));
+        if (rtRet != CNRT_RET_SUCCESS) {
+            av_log(cnctx->avctx, AV_LOG_INFO, "Release input buffer faile ...\n");
+        }
+        CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+    }
+    CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "ReleaseEncodeCodecFrameBuffer end\n");
+    }
+    return 0;
+}
+static int allocateEncodeDevMemBuf(CNJpegEncContext_t *cnctx)
+{
+    cnrtRet_t  rtRet;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "AllocateEncodeDevMemBuf start\n");
+    }
+    if (!(&cnctx->output_buf.streamBuffer)) {
+        av_log(cnctx->avctx, AV_LOG_ERROR,
+               "Error: cnctx->output_buf.streamBuffer address is null...\n");
+        return -1;
+    }
+    memset(&cnctx->output_buf.streamBuffer, 0, sizeof(cncodecDevMemory));
+    rtRet = cnrtMallocFrameBuffer((void **)(&cnctx->output_buf.streamBuffer.addr),
+                                  OUTPUT_BUFFER_SIZE_FOR_ENCODE);
+    if (rtRet != CNRT_RET_SUCCESS) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "%s() call cnrtMallocFrameBuffer failed\n",
+               __FUNCTION__);
+        return -1;
+    }
+    cnctx->output_buf.streamBuffer.size = OUTPUT_BUFFER_SIZE_FOR_ENCODE;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "AllocateEncodeDevMemBuf end\n");
+    }
+    return 0;
+}
+static int releaseEncodeDevMemBuf(CNJpegEncContext_t *cnctx)
+{
+    cnrtRet_t rtRet;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "ReleaseEncodeDevMemBuf start\n");
+    }
+    if (!(&cnctx->output_buf.streamBuffer)) {
+        return -1;
+    }
+    if (cnctx->output_buf.streamBuffer.addr != 0) {
+        rtRet = cnrtFree((void *)cnctx->output_buf.streamBuffer.addr);
+        CNRT_ERROR_CHECK(cnctx->avctx, rtRet);
+    }
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "ReleaseEncodeDevMemBuf end\n");
+    }
+    return 0;
+}
+
+static int alloc_syncencode_in_and_out_buffer(CNJpegEncContext_t *cnctx)
+{
+    int ret;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Alloc_syncencode_in_and_out_buffer start\n");
+    }
+    ret = allocateEncCodecFrameBuffer(cnctx);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "AllocateEncCodecFrameBuffer failed! \n");
+        return -1;
+    }
+    ret = allocateEncodeDevMemBuf(cnctx);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "AllocateEncodeDevMemBuf failed! \n");
+        return -1;
+    }
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Alloc_syncencode_in_and_out_buffer end\n");
+    }
+    return 0;
+}
+static int release_syncencode_in_and_out_buffer(CNJpegEncContext_t *cnctx)
+{
+    int ret;
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Release_syncencode_in_and_out_buffer start\n");
+    }
+    ret = releaseEncodeCodecFrameBuffer(cnctx);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "ReleaseEncodeCodecFrameBuffer failed!\n");
+        return -1;
+    }
+    ret = releaseEncodeDevMemBuf(cnctx);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "releaseEncodeDevMemBuf failed!\n");
+        return -1;
+    }
+    if (cnctx->trace_flag) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Release_syncencode_in_and_out_buffer end\n");
+    }
+    return 0;
+}
+
+// main functions
+static int ff_mlumpp_jpeg_enc_frame(AVCodecContext *avctx, AVPacket *pkt,
+                                    const AVFrame *frame, int *got_packet) {
+    int ret = -1;
+    CNJpegEncContext_t *cnctx;
+    cnjpegEncInput *input;
+    cnjpegEncOutput *output;
+
+    cnctx = (CNJpegEncContext_t *)avctx->priv_data;
+    input = &cnctx->input_buf;
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Start ff_mlumpp_jpeg_enc_frame\n");
+    }
+    if (NULL == avctx || NULL == cnctx || !cnctx->encoder_init_flag) {
+        // Sanity checks... these are all serious usage bugs.
+        av_log(avctx, AV_LOG_ERROR, "Early error in \"ff_mlumpp_jpeg_enc_frame\" \n");
+        return -1;
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_ERROR,
+               "Jpeg encoder got abort flag before sending frame, return AVERROR_EXTERNAL\n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Send frame: %ux%u (%" PRId64 "),frame tpe:%d\n",\
+               frame->width, frame->height, frame->pts, frame->pict_type);
+    }
+    input->frame = cnctx->input_buf.frame;
+    input->pts = av_rescale_q(frame->pts, avctx->time_base, (AVRational){1, 90000});
+    ret = jpeg_enc_input_frame(cnctx, &(input->frame), frame);
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "Input frame to input buffer failed! \n");
+        return AVERROR_EXTERNAL;
+    }
+
+    output = &cnctx->output_buf;
+    if (cnctx->handle) {
+        int timeout = 3000;
+        if (cnctx->trace_flag) {
+            av_log(avctx, AV_LOG_INFO, "cCnjpegEncSyncEncode before ...\n");
+            av_log(avctx, AV_LOG_INFO, "EnFrameParam: %u  %u  %lu \n", cnctx->enFrameParam.quality,\
+               cnctx->enFrameParam.restartInterval, cnctx->enFrameParam.metaData);
+        }
+        ret = cnjpegEncSyncEncode(cnctx->handle, output, input, &cnctx->enFrameParam, timeout);
+        if (cnctx->trace_flag) {
+            av_log(avctx, AV_LOG_INFO, "Input frame width: %d height: %d planeNum: %d\n",
+                   input->frame.width, input->frame.height, input->frame.planeNum);
+            av_log(avctx, AV_LOG_INFO, "Output length: %d  size: %d\n",
+                   output->streamLength, output->streamBuffer.size);
+            av_log(avctx, AV_LOG_INFO, "CnjpegEncSyncEncode after ...\n");
+        }
+        if (ret == CNCODEC_SUCCESS) {
+            if (cnctx->trace_flag) {
+                av_log(avctx, AV_LOG_INFO, "CnjpegEncSyncEncode success ...\n");
+            }
+            cnctx->total_frame_count++;
+            if (output->result == 0) {
+                if (cnctx->trace_flag) {
+                    av_log(avctx, AV_LOG_INFO, "Jpeg encoded yuv data is succeeed\n");
+                }
+                ret = jpeg_enc_output_packet(cnctx, pkt, got_packet);
+                if (ret < 0) {
+                  av_log(avctx, AV_LOG_WARNING, "Jpeg enc output packet failed ...\n");
+                }
+            } else {
+                av_log(avctx, AV_LOG_WARNING,
+                       "Jpeg encoded yuv data is failed, skip this frame ...\n");
+            }
+        } else if (ret == CNCODEC_JPU_ENC_FAIL | ret == CNCODEC_TIMEOUT) {
+            av_log(avctx, AV_LOG_INFO, "CnjpegEncSyncEncode faile or timeout ...\n");
+            ret = _jpeg_enc_abort_handler(cnctx);
+        }
+        CNCODEC_ERROR_CHECK(avctx, ret);
+    } else {
+        av_log(avctx, AV_LOG_WARNING, "Jpeg encoder handle is NULL, skip cnjpegEncSyncEncode\n");
+    }
+    return ret;
+}
+
+static int ff_mlumpp_jpeg_enc_init(AVCodecContext *avctx)
+{
+    CNJpegEncContext_t *cnctx = (CNJpegEncContext_t *)avctx->priv_data;
+    AVMLUDeviceContext *device_hwctx;
+    AVHWFramesContext *hwframe_ctx;
+    cnjpegEncCreateInfo enc_params;
+
+    int ret = -1;
+    char device_idx[sizeof(int)];
+    int bitstream_buf_size = 0;
+
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Start ff mlumpp jpeg enc init\n");
+    }
+
+    cnctx->enc_create_params = &enc_params;
+    if (NULL == avctx || NULL == cnctx || 1 == cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in \"ff_mlumpp_jpeg_enc_init\" \n");
+        return AVERROR_BUG;
+    }
+    if(0 != mlumpp_adapt_resolution(avctx)) {
+        return AVERROR(EINVAL);
+    }
+    // set device
+    sprintf(device_idx, "%d", cnctx->device_id);
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        if (avctx->hw_frames_ctx) {
+            av_buffer_unref(&cnctx->hw_frame_ref);
+            cnctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+            if (!cnctx->hw_frame_ref) {
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            cnctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+
+            device_hwctx = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+            if (!cnctx->hw_device_ref) {
+                return AVERROR(EINVAL);
+            }
+        } else {
+            if (avctx->hw_device_ctx) {
+                cnctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+                if (!cnctx->hw_device_ref) {
+                    return AVERROR(EINVAL);
+                }
+            } else {
+                ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref,
+                                             AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+                if (ret < 0)
+                    return AVERROR(EINVAL);
+            }
+
+            cnctx->hw_frame_ref = av_hwframe_ctx_alloc(cnctx->hw_device_ref);
+            if (!cnctx->hw_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_alloc\n");
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data; // HWFrameContext
+            device_hwctx = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+
+            if (!hwframe_ctx->pool) {
+                hwframe_ctx->format = AV_PIX_FMT_MLU;
+                hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+                hwframe_ctx->width = FFALIGN(avctx->width, 64);
+                hwframe_ctx->height = FFALIGN(avctx->height, 16);
+                if ((ret = av_hwframe_ctx_init(cnctx->hw_frame_ref)) < 0) {
+                    av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_init\n");
+                    return 0;
+                }
+            }
+        }
+        cnctx->in_sw_pixfmt = avctx->sw_pix_fmt;
+    } else {
+        av_buffer_unref(&cnctx->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref,
+                                     AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            return AVERROR(EINVAL);
+        }
+        cnctx->hw_device_ctx = ((AVHWDeviceContext*)cnctx->hw_device_ref->data)->hwctx;
+        cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+
+        cnctx->in_sw_pixfmt = avctx->pix_fmt;
+    }
+
+    cnctx->width = avctx->width;
+    cnctx->height = avctx->height;
+    avctx->coded_width = FFALIGN(avctx->width, 64);
+    avctx->coded_height = cnctx->height;
+    cnctx->coded_width = avctx->coded_width;
+    cnctx->coded_height = avctx->coded_height;
+    bitstream_buf_size = FFALIGN(cnctx->width, 64) * FFALIGN(cnctx->height, 16);
+    switch (cnctx->in_sw_pixfmt) {
+    case AV_PIX_FMT_NV12:
+        if (cnctx->trace_flag) av_log(avctx, AV_LOG_INFO, "Get pix fmtAV_PIX_FMT_NV12\n");
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV12;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_NV21:
+        if (cnctx->trace_flag) av_log(avctx, AV_LOG_INFO, "Get pix fmt: AV_PIX_FMT_NV21\n");
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV21;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_YUYV422:
+        if (cnctx->trace_flag) av_log(avctx, AV_LOG_INFO, "Get pix fmt: AV_PIX_FMT_YUYV422\n");
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_YUYV;
+        bitstream_buf_size = (bitstream_buf_size << 1);
+        break;
+    case AV_PIX_FMT_UYVY422:
+        if (cnctx->trace_flag) av_log(avctx, AV_LOG_INFO, "Get pix fmt: AV_PIX_FMT_UYUV422\n");
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_UYVY;
+        bitstream_buf_size = (bitstream_buf_size << 1);
+        break;
+    default:
+        av_log(avctx, AV_LOG_WARNING, "Default: pix fmt: AV_PIX_FMT_NV12\n");
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV12;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    }
+
+    cnctx->total_frame_count = 0;
+    cnctx->total_packet_count = 0;
+    cnctx->total_outframe_count = 0;
+    cnctx->codec_abort_flag = 0;
+
+    enc_params.width = cnctx->width;
+    enc_params.height = cnctx->height;
+    enc_params.pixelFmt = cnctx->pixelFmt;
+    enc_params.deviceId = cnctx->device_id;
+    enc_params.allocType = CNCODEC_BUF_ALLOC_APP;
+    enc_params.inputBufNum = 1;
+    enc_params.outputBufNum = 1;
+    enc_params.instance = cnctx->instance_id;
+    enc_params.userContext = (void *)cnctx;
+    if ( FFALIGN(bitstream_buf_size, 4096) < OUTPUT_BUFFER_SIZE_FOR_ENCODE) {
+        enc_params.suggestedLibAllocBitStrmBufSize = FFALIGN(bitstream_buf_size, 4096);
+    } else {
+        enc_params.suggestedLibAllocBitStrmBufSize = OUTPUT_BUFFER_SIZE_FOR_ENCODE;
+    }
+
+    cnctx->avctx = avctx;
+    cnctx->total_frame_count = 0;
+    cnctx->total_packet_count = 0;
+    cnctx->total_outframe_count = 0;
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Sync encode in out buffer before ...\n");
+    }
+    alloc_syncencode_in_and_out_buffer(cnctx);
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Sync encode in out buffer after ...\n");
+    }
+    enc_params.inputBuf = &cnctx->input_buf.frame;
+    enc_params.outputBuf = &cnctx->output_buf.streamBuffer;
+
+    ret = cnjpegEncCreate(&cnctx->handle, CNJPEGENC_RUN_MODE_SYNC, NULL, &enc_params);
+    if (ret != CNCODEC_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create jpeg encoder, ret(%d)\n", ret);
+        cnctx->handle = NULL;
+        return AVERROR_EXTERNAL; //  notice user
+    }
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Create JPEG encoder succeeded\n");
+    }
+
+    memset(&cnctx->enFrameParam, 1, sizeof(cnjpegEncParameters));
+    cnctx->enFrameParam.quality = cnctx->jpeg_quality; // jpeg_quality
+    cnctx->enFrameParam.restartInterval = 0;
+    cnctx->enFrameParam.metaData = 0;
+    cnctx->encoder_init_flag = 1;
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "End ff mlumpp jpeg enc init\n");
+    }
+    return 0;
+}
+
+static int ff_mlumpp_jpeg_enc_close(AVCodecContext *avctx)
+{
+    int ret = -1;
+    CNJpegEncContext_t *cnctx;
+    cnctx = (CNJpegEncContext_t *)avctx->priv_data;
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "Start ff mlumpp jpeg enc close\n");
+    }
+    if (NULL == avctx || NULL == cnctx) { // Sanity checks... these are all serious usage bugs.
+        av_log(avctx, AV_LOG_ERROR, "Early error in \"ff_mlumpp_jpeg_enc_close\" \n");
+        return -1;
+    }
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "User start to release encoder device\n");
+    }
+    if (cnctx->handle) {
+        release_syncencode_in_and_out_buffer(cnctx);
+        ret = cnjpegEncDestroy(cnctx->handle);
+        if (ret != CNCODEC_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "Call CN_Encode_Desroy failed, ret(%u)\n", ret);
+            return -1;
+        }
+        cnctx->handle = NULL;
+    }
+    CNCODEC_ERROR_CHECK(avctx, ret);
+    // cnrtDestroy();
+    if (cnctx->hw_frame_ref) {
+        av_buffer_unref(&cnctx->hw_frame_ref);
+    }
+    if (cnctx->hw_device_ref) {
+        av_buffer_unref(&cnctx->hw_device_ref);
+    }
+    cnctx->encoder_init_flag = 0;
+    if (cnctx->trace_flag) {
+        av_log(avctx, AV_LOG_INFO, "MLU MPP Jpeg encoder status summary\n");
+        av_log(avctx, AV_LOG_INFO, "Encode thread id, %lu \n", (long unsigned)pthread_self());
+        av_log(avctx, AV_LOG_INFO,
+               "Encode D2H total packet count:%llu\n", cnctx->total_outframe_count);
+        av_log(avctx, AV_LOG_INFO, "Received total packet count:%llu\n",
+               cnctx->total_packet_count);
+        av_log(avctx, AV_LOG_INFO, "Encode feed data count:%llu\n", cnctx->total_frame_count);
+        av_log(avctx, AV_LOG_INFO, "End ff mlumpp jpeg enc close\n");
+    }
+    return 0;
+}
+
+#define OFFSET(x) offsetof(CNJpegEncContext_t, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+static const AVOption options[] = {
+    { "device_id",     "use to choose the accelerator card",       OFFSET(device_id),
+                        AV_OPT_TYPE_INT,    { .i64 = 0 },   0,  INT_MAX,    VE },
+    { "instance_id",   "use to choose which vpu instance",         OFFSET(instance_id),
+                        AV_OPT_TYPE_INT,    { .i64 = 6 },   0,  6,    VE },
+    { "input_buf_num",  "Number of input buffers for encoder",     OFFSET(input_buf_num),
+                        AV_OPT_TYPE_INT,    { .i64 = 1 },   1,  18,         VE },
+    { "output_buf_num","Number of output buffers for encoder",     OFFSET(output_buf_num),
+                        AV_OPT_TYPE_INT,    { .i64 = 1 },   1,  18,         VE },
+    { "trace", "Whether open trace switch or not",                 OFFSET(trace_flag),
+                        AV_OPT_TYPE_INT,    { .i64 = 0 },   0,  1,          VE },
+    { "quality", "Encode quality",                                 OFFSET(jpeg_quality),
+                        AV_OPT_TYPE_INT,    { .i64 = 80 },  0,  100,        VE },
+    { NULL },
+};
+static const AVClass mjpeg_mluenc_class = {
+    .class_name = "mjpeg_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_mjpeg_mlumpp_encoder = {
+    .name = "mjpeg_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("Jpeg (Cambricon Jpeg acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_MJPEG,
+    .init = ff_mlumpp_jpeg_enc_init,
+    //.send_frame = ff_mlumpp_jpeg_enc_send_frame,
+    //.receive_packet = ff_mlumpp_jpeg_enc_receive_packet,
+    .encode2 = ff_mlumpp_jpeg_enc_frame,
+    .close = ff_mlumpp_jpeg_enc_close,
+    .priv_data_size = sizeof(CNJpegEncContext_t),
+    .priv_class = &mjpeg_mluenc_class,
+    .capabilities = AV_CODEC_CAP_FRAME_THREADS | AV_CODEC_CAP_INTRA_ONLY | AV_CODEC_CAP_HARDWARE,
+    .caps_internal = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
\ No newline at end of file
diff --git a/libavcodec/mlumpp_mluop.c b/libavcodec/mlumpp_mluop.c
new file mode 100755
index 0000000000..1c04a416d3
--- /dev/null
+++ b/libavcodec/mlumpp_mluop.c
@@ -0,0 +1,122 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_mluop.h"
+#include "libavutil/avstring.h"
+#include "libavutil/log.h"
+#include "cnrt.h"
+#include <dlfcn.h>
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return -1;                                                                         \
+    }
+typedef struct mlumpp_mluop_ctx {
+    void *lib;
+    HANDLE_MLU_OP mlu_handle;
+    void *logctx;
+    int (*ptr_resize_yuv_init)(void **, int, int, int, int, int, int,int);
+    int (*ptr_resize_yuv_exec)(void *, void *, void *, void *, void *);
+    int (*ptr_resize_yuv_destroy)(void *);
+} mlumpp_mluop_ctx_t;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+int mlumpp_mluop_load(HANDLE_MLU_OP *h, const char *libname, void *logctx) {
+    mlumpp_mluop_ctx_t *mluop_ctx;
+    mluop_ctx = av_mallocz(sizeof(*mluop_ctx));
+    if (mluop_ctx == NULL) {
+        return AVERROR(ENOMEM);
+    }
+    if (libname) {
+        mluop_ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!mluop_ctx->lib) {
+            // av_log(logctx, AV_LOG_WARNING, "%s not found\n", libname);
+            av_free(mluop_ctx);
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "%s found\n", libname);
+        }
+    }
+    mluop_ctx->ptr_resize_yuv_init =
+        dlsym_prefixed(mluop_ctx->lib, "resize_yuv_invoke_init", "mluop");
+    mluop_ctx->ptr_resize_yuv_exec =
+        dlsym_prefixed(mluop_ctx->lib, "resize_yuv_invoke_exec", "mluop");
+    mluop_ctx->ptr_resize_yuv_destroy =
+        dlsym_prefixed(mluop_ctx->lib, "resize_yuv_invoke_destroy", "mluop");
+    if (!mluop_ctx->ptr_resize_yuv_init || !mluop_ctx->ptr_resize_yuv_exec ||
+        !mluop_ctx->ptr_resize_yuv_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(mluop_ctx->lib);
+        mluop_ctx->lib = NULL;
+        av_free(mluop_ctx);
+        return AVERROR_EXTERNAL;
+    }
+    mluop_ctx->logctx = logctx;
+    *h = (void *)mluop_ctx;
+    return 0;
+}
+int mlumpp_mluop_resize_yuv_init(HANDLE_MLU_OP h, int src_w, int src_h, int dst_w,
+                                 int dst_h, int dev_id) {
+    // cnrtRet_t cnrt_ret;
+    mlumpp_mluop_ctx_t *mluop_ctx = (mlumpp_mluop_ctx_t *)h;
+    if (!mluop_ctx->lib || !mluop_ctx->ptr_resize_yuv_init) {
+        return AVERROR_EXTERNAL;
+    }
+    return mluop_ctx->ptr_resize_yuv_init(&mluop_ctx->mlu_handle, src_w, src_h,
+                                          -1, dst_w, dst_h, -1, dev_id);
+}
+int mlumpp_mluop_resize_yuv_exec(HANDLE_MLU_OP h, void *src_y, void *src_uv,
+                                 void *dst_y, void *dst_uv) {
+
+    mlumpp_mluop_ctx_t *mluop_ctx = (mlumpp_mluop_ctx_t *)h;
+    if (!mluop_ctx || !mluop_ctx->lib || !mluop_ctx->ptr_resize_yuv_exec) {
+        return AVERROR_EXTERNAL;
+    }
+    return mluop_ctx->ptr_resize_yuv_exec(mluop_ctx->mlu_handle, src_y, src_uv, dst_y, dst_uv);
+}
+int mlumpp_mluop_resize_yuv_destroy(HANDLE_MLU_OP h) {
+    mlumpp_mluop_ctx_t *mluop_ctx = (mlumpp_mluop_ctx_t *)h;
+    if (!mluop_ctx || !mluop_ctx->lib || !mluop_ctx->ptr_resize_yuv_destroy) {
+        return AVERROR_EXTERNAL;
+    }
+    return mluop_ctx->ptr_resize_yuv_destroy(mluop_ctx->mlu_handle);
+}
+
+int mlumpp_mluop_unload(HANDLE_MLU_OP h) {
+    // cnrtRet_t cnrt_ret;
+    mlumpp_mluop_ctx_t *mluop_ctx = (mlumpp_mluop_ctx_t *)h;
+    if (!mluop_ctx) {
+        return -1;
+    }
+    if (mluop_ctx->lib) {
+        dlclose(mluop_ctx->lib);
+        mluop_ctx->lib = NULL;
+    }
+    av_free(mluop_ctx);
+    mluop_ctx = NULL;
+    return 0;
+}
diff --git a/libavcodec/mlumpp_mluop.h b/libavcodec/mlumpp_mluop.h
new file mode 100755
index 0000000000..45dc55ad4a
--- /dev/null
+++ b/libavcodec/mlumpp_mluop.h
@@ -0,0 +1,33 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef AVCODEC_MLUMPP_MLUOP_H
+#define AVCODEC_MLUMPP_MLUOP_H
+
+typedef void *HANDLE_MLU_OP;
+int mlumpp_mluop_load(HANDLE_MLU_OP *h, const char *path, void *logctx);
+int mlumpp_mluop_resize_yuv_init(HANDLE_MLU_OP h, int src_w, int src_h, int dst_w,
+                                 int dst_h, int dev_id);
+int mlumpp_mluop_resize_yuv_exec(HANDLE_MLU_OP h, void *src_y, void *src_uv,
+                                 void *dst_y, void *dst_uv);
+int mlumpp_mluop_resize_yuv_destroy(HANDLE_MLU_OP h);
+int mlumpp_mluop_unload(HANDLE_MLU_OP h);
+
+#endif /* AVCODEC_MLUMPP_MLUOP_H */
diff --git a/libavcodec/mlumpp_vid_enc.c b/libavcodec/mlumpp_vid_enc.c
new file mode 100755
index 0000000000..36068ff0f4
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.c
@@ -0,0 +1,1301 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <unistd.h>
+#include <stdint.h>
+
+#include <fcntl.h>
+#include <time.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/time.h"
+#include "libavutil/log.h"
+#include "internal.h"
+#include"mlumpp_vid_enc.h"
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"Error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return -1;                                                                         \
+    }
+#define CNCODEC_ERROR_CHECK(avctx, ret)                                                     \
+    if (ret != CNCODEC_SUCCESS) {                                                           \
+        av_log(avctx,AV_LOG_ERROR,"Error occur, func: %s, line: %d\n", __func__, __LINE__); \
+        return -1;                                                                          \
+    }
+
+#define CN_VENC_FRAME_ALIGNMENT 1
+#define OUTPUT_BUFFER_SIZE_FOR_ENCODE (1024 * 4096) // must be 4k align
+
+typedef struct MLUVideoFrameInfo {
+    cnvideoEncOutput info;
+    unsigned char* buf;
+} MLUVideoFrameInfo_t;
+
+static inline int mlumpp_adapt_resolution(AVCodecContext* avctx) {
+    if (avctx->width < 64 ||  avctx->width > 4096 || avctx->height < 64 || avctx->height > 4096) {
+        av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+        av_log(avctx, AV_LOG_ERROR, "MLU video encoder only support resolution: 64x64~4096x4096\n");
+        return -1;
+    }
+    return 0;
+}
+
+static inline int mlumpp_check_stride_align(AVCodecContext* avctx, MLUMPPEncContext_t *cnctx) {
+    int tmp = 0;
+    int align = cnctx->stride_align;
+    if (align & (align - 1)) {
+        av_log(avctx, AV_LOG_ERROR,
+              "Parames error, stride align must be a power of 2, now is %d\n", cnctx->stride_align);
+        return -1;
+    }
+    while (align > 1) {
+        align >>= 1;
+        tmp++;
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Stride align is the %d power of 2.\n", tmp);
+    }
+    return 0;
+}
+
+static int process_sps_pps(void *pData, cnvideoEncOutput *pStream)
+{
+    cnrtRet_t cnrt_ret;
+    MLUMPPEncContext_t* cnctx = (MLUMPPEncContext_t*)pData;
+    if (cnctx->trace_flag > 0) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "First frame, will process sps/pps header data \n");
+    }
+    if (cnctx->trace_flag > 1) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Bitstream info: streamLength:%d, dataOffset:%u\n", pStream->streamLength, pStream->dataOffset);
+    }
+    if (pStream->streamLength > 0 && NULL == cnctx->avctx->extradata) { // check pps/sps
+        cnctx->pkt_sps_pps_len = pStream->streamLength;
+        cnctx->avctx->extradata_size = cnctx->pkt_sps_pps_len;
+        cnctx->avctx->extradata = av_mallocz(cnctx->avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+        memset(cnctx->avctx->extradata, 0, cnctx->avctx->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
+        if (NULL == (void *)pStream->streamBuffer.addr) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "encoder output buffer address(MLU) is NULL \n");
+            return -1;
+        }
+        if (NULL == cnctx->avctx->extradata) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "malloc sps/pps pkt buff(CPU) failed\n");
+            return -1;
+        }
+        ff_mutex_lock(&cnctx->queue_mutex);
+        cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2H((void *)cnctx->avctx->extradata,
+                (void *)(pStream->streamBuffer.addr + pStream->dataOffset), cnctx->avctx->extradata_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+        ff_mutex_unlock(&cnctx->queue_mutex);
+        if(cnrt_ret != CNRT_RET_SUCCESS){
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Can't get SPS/PPS, D2H failed, ret(%d)\n", cnrt_ret);
+            return AVERROR(EINVAL);
+        }
+
+        return 0;
+    } else {
+        return -1;
+    }
+}
+
+static int newframe_callback(void *pData, cnvideoEncOutput *pStream)
+{
+    MLUMPPEncContext_t* cnctx = (MLUMPPEncContext_t*)pData;
+
+    cnrtRet_t cnrt_ret;
+    int extra_len_tmp = 0;
+    MLUVideoFrameInfo_t encoded_frame;
+    if (pData && pStream) {
+        /*  sps/pps generated by the encode as first newframe,
+         *  will be saved and inserted before IDR frame. */
+        if ((pStream->sliceType == CNCODEC_SLICE_H264_SPS_PPS || pStream->sliceType  == CNCODEC_SLICE_NALU_VPS ||
+            pStream->sliceType  == CNCODEC_SLICE_NALU_SPS || pStream->sliceType == CNCODEC_SLICE_HEVC_VPS_SPS_PPS)) {
+            if(process_sps_pps(pData, pStream) != 0) {
+                av_log(cnctx->avctx, AV_LOG_WARNING, "Process sps/pps failed \n");
+            }
+            if (!cnctx->spspps_post_flag) {
+                sem_post(&(cnctx->spspps_sema));
+                cnctx->spspps_post_flag = 1;
+            }
+            return 0;
+        }
+        if (NULL == (void *)(pStream->streamBuffer.addr + pStream->dataOffset)) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Call back frame data buffer address is null \n");
+            return -1;
+        }
+
+        ff_mutex_lock(&cnctx->queue_mutex);
+        if (pStream->streamLength > 0) {
+            memcpy((void *)&encoded_frame.info, pStream, sizeof(cnvideoEncOutput));
+            if (CNCODEC_SLICE_NALU_IDR == encoded_frame.info.sliceType && !cnctx->is_spspps_packet_flag) {
+                extra_len_tmp = cnctx->avctx->extradata_size;
+                encoded_frame.info.streamLength += extra_len_tmp;
+            }
+            encoded_frame.buf = av_malloc(encoded_frame.info.streamLength);
+            if (NULL == encoded_frame.buf) {
+                av_log(cnctx->avctx, AV_LOG_ERROR, "Failed to allocate cpu buffer for cnvideoEncOutput\n");
+                av_free(encoded_frame.buf);
+                encoded_frame.buf = NULL;
+                ff_mutex_unlock(&cnctx->queue_mutex);
+                return AVERROR(EINVAL);
+            }
+            if (extra_len_tmp) {
+                memcpy((void *)encoded_frame.buf, cnctx->avctx->extradata, extra_len_tmp);
+            }
+            cnrt_ret = cnctx->mlu_ctx->mluMemcpyD2H((void *)(encoded_frame.buf + extra_len_tmp),
+                        (void *)(encoded_frame.info.streamBuffer.addr + encoded_frame.info.dataOffset),
+                        encoded_frame.info.streamLength - extra_len_tmp, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            if (cnrt_ret != CNRT_RET_SUCCESS) {
+                av_log(cnctx->avctx, AV_LOG_WARNING, "Enc d2h error, ret(%d), func: %s, line: %d\n", cnrt_ret, __func__, __LINE__);
+                ff_mutex_unlock(&cnctx->queue_mutex);
+                return AVERROR(EINVAL);
+            }
+            if (!cnctx->insert_spspps_idr) {
+                cnctx->is_spspps_packet_flag = 1;
+            }
+            cnctx->total_packet_count ++;
+        }
+
+        av_fifo_generic_write(cnctx->frame_queue, &encoded_frame, sizeof(MLUVideoFrameInfo_t), NULL);
+        ff_mutex_unlock(&cnctx->queue_mutex);
+        if (cnctx->trace_flag > 1) {
+            av_log(cnctx->avctx, AV_LOG_INFO, "Channel:%d,frame offset:%u,flags:%u,encoded frames counts: %llu,pts:(%" PRId64 "), frame size: %u\n",
+                   cnctx->instance_id, pStream->dataOffset, pStream->flags, cnctx->total_packet_count, pStream->pts, pStream->streamLength);
+        }
+    }
+    return 0;
+}
+
+static int mlumpp_enc_event_cb(cncodecCbEventType eventType, void *pUserData, void *cbInfo)
+{
+    MLUMPPEncContext_t *cnctx = (MLUMPPEncContext_t *)pUserData;
+
+    switch (eventType) {
+        case CNCODEC_CB_EVENT_NEW_FRAME:
+            newframe_callback(pUserData, (cnvideoEncOutput *)cbInfo);
+            break;
+        case CNCODEC_CB_EVENT_EOS:
+            if (!cnctx->eos_post_flag) {
+                sem_post(&(cnctx->eos_sema));
+                cnctx->eos_post_flag = 1;
+            }
+            if (cnctx->trace_flag > 0) {
+                av_log(cnctx->avctx, AV_LOG_INFO, "Enc get eos callback, %lu \n",
+                    (long unsigned)pthread_self());
+            }
+            cnctx->eos_reached = 1;
+            break;
+        case CNCODEC_CB_EVENT_SW_RESET:
+        case CNCODEC_CB_EVENT_HW_RESET:
+            av_log(cnctx->avctx, AV_LOG_FATAL, "Encoder fatal error, Firmware crash Event(%d) \n", eventType);
+            if (!cnctx->codec_abort_flag) {
+                sem_post(&cnctx->eos_sema);
+                cnctx->codec_abort_flag = 1;
+            }
+            break;
+        case CNCODEC_CB_EVENT_OUT_OF_MEMORY:
+            av_log(cnctx->avctx, AV_LOG_FATAL, "Encoder fatal error, out of memory Event(%d) \n", eventType);
+            if (!cnctx->codec_abort_flag) {
+                sem_post(&cnctx->eos_sema);
+                cnctx->codec_abort_flag = 1;
+            }
+            break;
+        case CNCODEC_CB_EVENT_ABORT_ERROR:
+            av_log(cnctx->avctx, AV_LOG_FATAL, "Encoder fatal error, abort Event(%d) \n", eventType);
+            if (!cnctx->codec_abort_flag) {
+                sem_post(&cnctx->eos_sema);
+                cnctx->codec_abort_flag = 1;
+            }
+            break;
+        default:
+            av_log(cnctx->avctx, AV_LOG_FATAL, "Encoder fatal error, Unknow Event(%d) \n", eventType);
+            if (!cnctx->codec_abort_flag) {
+                sem_post(&cnctx->eos_sema);
+                cnctx->codec_abort_flag = 1;
+            }
+            break;
+    }
+    return 0;
+}
+
+static inline unsigned int cnvid_fifo_item_size(void)
+{
+    return sizeof(MLUVideoFrameInfo_t);
+}
+
+static inline unsigned int cnvid_fifo_size(const AVFifoBuffer *fifo)
+{
+    return av_fifo_size(fifo) / cnvid_fifo_item_size();
+}
+
+static int get_sps_pps_header (MLUMPPEncContext_t *cnctx) {
+    int ret = -1;
+    int timeout = 3000;
+    struct timespec ts;
+    cnvideoEncInput input_probe;
+    // for H264/H265, fill extradata
+    cnctx->insert_spspps_to_extradata = 1;
+    memset(&input_probe, 0, sizeof(cnvideoEncInput));
+    if (cnctx->trace_flag > 0) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Enc get sps/pps ..., in init func \n");
+    }
+    if (!cnctx->handle) {
+       av_log(cnctx->avctx, AV_LOG_ERROR, "Encode handle is NULL, Error\n");
+       return AVERROR(EINVAL);
+    }
+    ret = cnvideoEncWaitAvailInputBuf(cnctx->handle, &input_probe.frame, timeout);
+    CNCODEC_ERROR_CHECK(cnctx->avctx, ret);
+
+    ret = cnvideoEncFeedFrame(cnctx->handle, &input_probe, timeout);
+    CNCODEC_ERROR_CHECK(cnctx->avctx, ret);
+
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ts.tv_sec += 3; // 5s
+    ret = sem_timedwait(&(cnctx->spspps_sema), &ts);
+    if (ret != 0) {
+        int semvalue = -1;
+        sem_getvalue(&cnctx->spspps_sema, &semvalue);
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Enc sem_timewait error \n");
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Enc sem_timewait = -1, semvalue = %d ... \n", semvalue);
+    }
+    // sem_wait(&(cnctx->spspps_sema));
+    sem_destroy(&(cnctx->spspps_sema));
+    if (cnctx->trace_flag > 0) {
+        av_log(cnctx->avctx, AV_LOG_INFO, "Enc get sps/pps done, in init func \n");
+    }
+    return ret;
+}
+
+static int is_cnvid_fifo_empty(MLUMPPEncContext_t *cnctx) {
+    int is_fifo_empty = 0;
+    ff_mutex_lock(&cnctx->queue_mutex);
+    is_fifo_empty = (cnvid_fifo_size(cnctx->frame_queue) == 0);
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    return is_fifo_empty;
+}
+
+static void empty_fifo_queue(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx) {
+    MLUVideoFrameInfo_t pkt;
+    ff_mutex_lock(&cnctx->queue_mutex);
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnenc empty fifo ... \n");
+    }
+    while (cnctx->frame_queue && cnvid_fifo_size(cnctx->frame_queue) > 0) {
+        if (cnctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Thread id: %lu, encoded frames [%u] are reserved in cache\n",
+                    (long unsigned)pthread_self(), cnvid_fifo_size(cnctx->frame_queue));
+        }
+        av_fifo_generic_read(cnctx->frame_queue, &pkt, sizeof(pkt), NULL);
+        if (!(pkt.info.flags & CNVIDEOENC_FLAG_EOS) && NULL != pkt.buf) {
+            av_free(pkt.buf);
+            pkt.buf = NULL;
+        }
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnenc empty fifo done\n");
+    }
+    ff_mutex_unlock(&cnctx->queue_mutex);
+}
+
+static int cnvid_enc_build_std_buffer(MLUMPPEncContext_t *cnctx, cncodecFrame *tempInput, const AVFrame *frame)
+{
+    int ret = -1;
+    cnrtRet_t cnrt_ret;
+    int time_out_ = 5000;
+
+    ret = cnvideoEncWaitAvailInputBuf(cnctx->handle, tempInput, time_out_);
+    if (ret == CNCODEC_SUCCESS) {
+        if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+            switch (cnctx->pixelFmt) {
+            case CNCODEC_PIX_FMT_YUYV:
+            case CNCODEC_PIX_FMT_UYVY:
+                if (NULL == (void *)tempInput->plane[0].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr,
+                        (void *)frame->data[0], cnctx->coded_width*cnctx->height*2, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"enc: d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_ARGB:
+            case CNCODEC_PIX_FMT_ABGR:
+            case CNCODEC_PIX_FMT_BGRA:
+            case CNCODEC_PIX_FMT_RGBA:
+                if (NULL == (void *)tempInput->plane[0].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr,
+                        (void *)frame->data[0], cnctx->coded_width*cnctx->height*4, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_NV12:
+            case CNCODEC_PIX_FMT_NV21:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * cnctx->height, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * cnctx->height / 2, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_P010:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * 2 * cnctx->height, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"enc: d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * 2 * cnctx->height / 2, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_I420:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr
+                    || NULL == (void *)tempInput->plane[2].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1] || NULL == frame->data[2]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * cnctx->height, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * cnctx->height / 4, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyD2D((void *)tempInput->plane[2].addr, (void *)frame->data[2],
+                        cnctx->coded_width * cnctx->height / 4, CNRT_MEM_TRANS_DIR_DEV2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc d2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            default:
+                av_log(cnctx->avctx, AV_LOG_ERROR, "Unsupported format:%d\n", cnctx->pixelFmt);
+                break;
+            }
+        } else {
+            switch (cnctx->pixelFmt) {
+            case CNCODEC_PIX_FMT_YUYV:
+            case CNCODEC_PIX_FMT_UYVY:
+                if (NULL == (void *)tempInput->plane[0].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * 2 * cnctx->height, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_ARGB:
+            case CNCODEC_PIX_FMT_ABGR:
+            case CNCODEC_PIX_FMT_BGRA:
+            case CNCODEC_PIX_FMT_RGBA:
+                if (NULL == (void *)tempInput->plane[0].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * cnctx->height * 4, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc: h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_NV12:
+            case CNCODEC_PIX_FMT_NV21:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * cnctx->height, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * cnctx->height / 2, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_P010:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * 2 * cnctx->height, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * 2 * cnctx->height / 2, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            case CNCODEC_PIX_FMT_I420:
+                if (NULL == (void *)tempInput->plane[0].addr || NULL == (void *)tempInput->plane[1].addr ||
+                    NULL == (void *)tempInput->plane[2].addr) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input buffer address(MLU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                if (NULL == frame->data[0] || NULL == frame->data[1] || NULL == frame->data[2]) {
+                    av_log(cnctx->avctx, AV_LOG_ERROR, "Encoder input data address(CPU) is NULL \n");
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[0].addr, (void *)frame->data[0],
+                        cnctx->coded_width * cnctx->height, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[1].addr, (void *)frame->data[1],
+                        cnctx->coded_width * cnctx->height / 4, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                cnrt_ret =  cnctx->mlu_ctx->mluMemcpyH2D((void *)tempInput->plane[2].addr, (void *)frame->data[2],
+                        cnctx->coded_width * cnctx->height / 4, CNRT_MEM_TRANS_DIR_HOST2DEV);
+                if (cnrt_ret != CNRT_RET_SUCCESS) {
+                    av_log(cnctx->avctx, AV_LOG_WARNING,"Enc h2d warning, ret(%d), func: %s, line: %d\n",
+                            cnrt_ret, __func__, __LINE__);
+                    return AVERROR(EINVAL);
+                }
+                break;
+            default:
+                av_log(cnctx->avctx, AV_LOG_ERROR, "Unsupported format:%d\n", cnctx->pixelFmt);
+                break;
+            }
+        }
+    } else {
+        if (cnctx->trace_flag > 0) {
+            av_log(cnctx->avctx, AV_LOG_INFO, "Enc wait input buf failed, ret(%d) \n", ret);
+        }
+    }
+    return ret;
+}
+
+static int cnvid_output_packet(MLUMPPEncContext_t *cnctx, AVPacket *pkt, int *got_packet)
+{
+    int ret = 0;
+    int is_fifo_empty = 1;
+    MLUVideoFrameInfo_t encodedframe;
+    enum AVPictureType pict_type = AV_PICTURE_TYPE_NONE;
+    is_fifo_empty = is_cnvid_fifo_empty(cnctx);
+    if (!is_fifo_empty) {
+        ff_mutex_lock(&cnctx->queue_mutex);
+        av_fifo_generic_read(cnctx->frame_queue, &encodedframe, sizeof(MLUVideoFrameInfo_t), NULL);
+        ff_mutex_unlock(&cnctx->queue_mutex);
+        if (encodedframe.info.flags & CNVIDEOENC_FLAG_EOS) { // EOS got
+          ret = AVERROR_EOF;
+        }
+
+        ret = pkt->data ? ff_alloc_packet2(cnctx->avctx, pkt, encodedframe.info.streamLength,
+              encodedframe.info.streamLength) : av_new_packet(pkt, encodedframe.info.streamLength);
+        if (ret < 0) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Failed to allocate pkt memory\n");
+            *got_packet = 0;
+            return AVERROR(EINVAL);
+        }
+        if (NULL != encodedframe.buf && encodedframe.info.streamLength > 0) {
+            memcpy((void *)pkt->data, (void *)encodedframe.buf, encodedframe.info.streamLength);
+            av_free(encodedframe.buf);
+            encodedframe.buf = NULL;
+        }
+
+        *got_packet = 1;
+        cnctx->total_outframe_count++;
+        pkt->pts  = encodedframe.info.pts;
+        pkt->size = encodedframe.info.streamLength;
+        pkt->dts = pkt->pts; // For CNVIDEOENC_GOP_TYPE_LOW_DELAY, dts equals to pts.
+        pkt->pts = av_rescale_q_rnd(pkt->pts, (AVRational){1, 90000},
+                                    cnctx->avctx->time_base, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
+        pkt->dts = av_rescale_q_rnd(pkt->dts, (AVRational){1, 90000},
+                                    cnctx->avctx->time_base, (AV_ROUND_NEAR_INF | AV_ROUND_PASS_MINMAX));
+        pkt->duration = av_rescale_q(pkt->duration, (AVRational){1, 90000}, cnctx->avctx->time_base);
+
+        switch (encodedframe.info.sliceType) {
+        case CNCODEC_SLICE_NALU_IDR:
+            pkt->flags |= AV_PKT_FLAG_KEY;
+        case CNCODEC_SLICE_NALU_I:
+            pict_type = AV_PICTURE_TYPE_I;
+            break;
+        case CNCODEC_SLICE_NALU_P:
+            pict_type = AV_PICTURE_TYPE_P;
+            break;
+        case CNCODEC_SLICE_NALU_B:
+            pict_type = AV_PICTURE_TYPE_B;
+            break;
+        case CNCODEC_SLICE_NALU_BI:
+            pict_type = AV_PICTURE_TYPE_BI;
+            break;
+        case CNCODEC_SLICE_UNKNOWN_TYPE:
+        default:
+            pict_type = AV_PICTURE_TYPE_NONE;
+            ret = AVERROR_EXTERNAL;
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Unknown pic type encountered \n");
+            break;
+        }
+#if FF_API_CODED_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+        cnctx->avctx->coded_frame->pict_type = pict_type;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    } else {
+        *got_packet = 0;
+        ret = AVERROR(EAGAIN);
+    }
+    return ret;
+}
+
+int ff_mlumpp_vid_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame)
+{
+    int timeout;
+    int ret = -1;
+    cnvideoEncInput enc_params;
+    timeout = 3000;
+
+    if (NULL == avctx || NULL == cnctx || !cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_vid_enc_send_frame \n");
+        return AVERROR(EINVAL);
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Encoder got abort before sending frame. \n");
+        return AVERROR(EINVAL);
+    }
+    if (frame && !cnctx->encoder_flushing) {
+        memset(&enc_params, 0, sizeof(cnvideoEncInput));
+        ret = cnvid_enc_build_std_buffer(cnctx, &enc_params.frame, frame);
+        if (ret < 0) {
+            // av_usleep(1000);
+            av_log(avctx, AV_LOG_WARNING, "Got cnencode build buffer failed, ret(%d)\n", ret);
+            return AVERROR(EAGAIN);
+        }
+        enc_params.pts = av_rescale_q(frame->pts, avctx->time_base, (AVRational){1, 90000});
+
+        ret = cnvideoEncFeedFrame(cnctx->handle, &enc_params, timeout);
+        if (ret != CNCODEC_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "Enc feed frame failed, ret(%d), func: %s, line: %d\n",
+                ret, __func__, __LINE__);
+            return AVERROR(EINVAL);
+        } else {
+            cnctx->total_frame_count++;
+        }
+    } else if(cnctx->encoder_flushing) {
+        if (cnctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_ERROR, "Send frame end, return eof\n");
+        }
+        return AVERROR_EOF;
+    } else {
+        memset(&enc_params, 0, sizeof(cnvideoEncInput));
+        ret = cnvideoEncWaitAvailInputBuf(cnctx->handle, &enc_params.frame, timeout);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_WARNING, "Wait input buf failed, ret(%d), func: %s, line: %d\n",
+                ret, __func__, __LINE__);
+            // av_usleep(1000);
+            return AVERROR(EAGAIN);
+        }
+        if (cnctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Cnenc feed eos, flush ... \n");
+        }
+
+        enc_params.flags |= (CNVIDEOENC_FLAG_EOS | CNVIDEOENC_FLAG_INVALID_FRAME);
+        ret = cnvideoEncFeedFrame(cnctx->handle, &enc_params, timeout);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Cnenc feed eos failed, ret(%d), func: %s, line: %d\n",
+                ret, __func__, __LINE__);
+            return AVERROR(EINVAL);
+        }
+        if (cnctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Cnenc feed eos, flush done \n");
+        }
+
+        cnctx->encoder_flushing = 1;
+    }
+
+    return ret;
+}
+
+int ff_mlumpp_vid_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt)
+{
+    int ret = -1;
+    int got_packet = 0;
+    if (NULL == avctx || NULL == cnctx || NULL == pkt || !cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_vid_enc_receive_packet \n");
+        return AVERROR(EINVAL);
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Encode got abort before receiving packet \n");
+        return AVERROR(EINVAL);
+    }
+    if (!cnctx->encoder_flushing) {
+        if (cnctx->preset == PRESET_SLOW) {
+            av_usleep(500);
+        }
+        ret = cnvid_output_packet(cnctx, pkt, &got_packet);
+    } else {
+        int count = 1000;
+        while (1) {
+            ret = cnvid_output_packet(cnctx, pkt, &got_packet);
+            if (!ret)
+                return ret;
+            if (ret == AVERROR(EAGAIN)) {
+                av_usleep(100);
+                if (count-- <= 0 || (cnctx->eos_post_flag && is_cnvid_fifo_empty(cnctx))) {
+                    if (!cnctx->eos_post_flag)
+                        av_log(cnctx->avctx, AV_LOG_ERROR, "Receive packet timeout, %lu\n", (long unsigned)pthread_self());
+                    return AVERROR_EOF;
+                }
+                continue;
+            }
+            return ret;
+        }
+    }
+    return ret;
+}
+
+int ff_mlumpp_vid_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    AVMLUDeviceContext *device_hwctx;
+    AVHWFramesContext *hwframe_ctx;
+
+    int ret = -1;
+    cnvideoEncCreateInfo enc_params;
+    int bitstream_buf_size = 0;
+    char device_idx[sizeof(int)];
+    if (NULL == avctx || NULL == cnctx || 1 == cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_vid_enc_init.\n");
+        return AVERROR_BUG;
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode init ... \n");
+    }
+    // cnctx->stride_align = CN_VENC_FRAME_ALIGNMENT;
+    ret = mlumpp_check_stride_align(avctx, cnctx);
+    if (ret != 0) {
+        return AVERROR(EINVAL);
+    }
+    cnctx->width = avctx->width;
+    cnctx->height = avctx->height;
+    avctx->coded_width = FFALIGN(avctx->width, cnctx->stride_align);
+    avctx->coded_height = avctx->coded_height;
+    cnctx->coded_width = avctx->coded_width;
+    cnctx->coded_height = avctx->coded_height;
+    if(0 != mlumpp_adapt_resolution(avctx)) {
+        return AVERROR(EINVAL);
+    }
+
+    sprintf(device_idx, "%d", cnctx->device_id);
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        if (avctx->hw_frames_ctx) {
+            av_buffer_unref(&cnctx->hw_frame_ref);
+            cnctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+            if (!cnctx->hw_frame_ref) {
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            cnctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+
+            device_hwctx = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+            if (!cnctx->hw_device_ref) {
+                return AVERROR(EINVAL);
+            }
+        } else {
+            if (avctx->hw_device_ctx) {
+                cnctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+                if (!cnctx->hw_device_ref) {
+                    return AVERROR(EINVAL);
+                }
+            } else {
+                ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+                if (ret < 0)
+                    return AVERROR(EINVAL);
+            }
+
+            cnctx->hw_frame_ref = av_hwframe_ctx_alloc(cnctx->hw_device_ref);
+            if (!cnctx->hw_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_alloc\n");
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data; // HWFrameContext
+            device_hwctx = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+
+            if (!hwframe_ctx->pool) {
+                hwframe_ctx->format = AV_PIX_FMT_MLU;
+                hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+                hwframe_ctx->width = avctx->coded_width;
+                hwframe_ctx->height = avctx->coded_height;
+                if ((ret = av_hwframe_ctx_init(cnctx->hw_frame_ref)) < 0) {
+                    av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_init\n");
+                    return 0;
+                }
+            }
+        }
+        cnctx->in_sw_pixfmt = avctx->sw_pix_fmt;
+    } else {
+        av_buffer_unref(&cnctx->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            return AVERROR(EINVAL);
+        }
+        cnctx->hw_device_ctx = ((AVHWDeviceContext*)cnctx->hw_device_ref->data)->hwctx;
+        cnctx->mlu_ctx = cnctx->hw_device_ctx->mlu_ctx;
+
+        cnctx->in_sw_pixfmt = avctx->pix_fmt;
+    }
+
+    cnctx->insert_spspps_idr = (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;
+    // bitstream_buf_size = cnctx->width * cnctx->height;
+    bitstream_buf_size = cnctx->coded_width * cnctx->coded_height;
+    switch (cnctx->in_sw_pixfmt) {
+    case AV_PIX_FMT_NV12:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV12;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_NV21:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV21;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_YUV420P:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_I420;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_P010:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_P010;
+        bitstream_buf_size += (bitstream_buf_size << 1);
+        break;
+    case AV_PIX_FMT_YUYV422:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_YUYV;
+        bitstream_buf_size = (bitstream_buf_size << 1);
+        break;
+    case AV_PIX_FMT_UYVY422:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_UYVY;
+        bitstream_buf_size = (bitstream_buf_size << 1);
+        break;
+    case AV_PIX_FMT_ARGB:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_ARGB;
+        bitstream_buf_size = (bitstream_buf_size << 2);
+        break;
+    case AV_PIX_FMT_ABGR:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_ABGR;
+        bitstream_buf_size = (bitstream_buf_size << 2);
+        break;
+    case AV_PIX_FMT_BGRA:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_BGRA;
+        bitstream_buf_size = (bitstream_buf_size << 2);
+        break;
+    case AV_PIX_FMT_RGBA:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_RGBA;
+        bitstream_buf_size = (bitstream_buf_size << 2);
+        break;
+    default:
+        cnctx->pixelFmt = CNCODEC_PIX_FMT_NV12;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    }
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_H264:
+        cnctx->codec_type = CNCODEC_H264;
+        break;
+    case AV_CODEC_ID_HEVC:
+        cnctx->codec_type = CNCODEC_HEVC;
+        break;
+    default:
+        cnctx->codec_type = CNCODEC_H264;
+        break;
+    }
+    switch (avctx->colorspace) {
+    case AVCOL_SPC_BT709:
+        cnctx->color_space = CNCODEC_COLOR_SPACE_BT_709;
+        break;
+    case AVCOL_SPC_BT2020_CL:
+        cnctx->color_space = CNCODEC_COLOR_SPACE_BT_2020;
+        break;
+    default:
+        cnctx->color_space = CNCODEC_COLOR_SPACE_BT_2020;
+        break;
+    }
+
+    cnctx->bitrate = avctx->bit_rate; // average bitrate
+    cnctx->gop_size = avctx->gop_size;
+    cnctx->max_b_frames = avctx->max_b_frames;
+
+    if (cnctx->preset == PRESET_FAST) {
+        cnctx->gop_size = 31;
+        cnctx->max_b_frames = 0;
+
+        cnctx->level = 0;
+        cnctx->profile = cnctx->codec_type == CNCODEC_H264?
+                        CNVIDEOENC_PROFILE_H264_MAIN : CNVIDEOENC_PROFILE_H265_MAIN;
+
+        avctx->qmin = 0;
+        avctx->qmax = 40;
+        cnctx->rcmode = 0;
+        cnctx->vbr_minqp = 0;
+        cnctx->vbr_maxqp = 40;
+        cnctx->vertical_range = 16;
+        cnctx->horizontal_range = 16;
+
+        cnctx->input_buf_num = 16;
+        cnctx->output_buf_num = 16;
+    } else if (cnctx->preset == PRESET_SLOW) {
+        cnctx->gop_size = 31;
+        cnctx->max_b_frames = 4;
+
+        cnctx->level = 0;
+        cnctx->profile = cnctx->codec_type == CNCODEC_H264?
+                        CNVIDEOENC_PROFILE_H264_MAIN : CNVIDEOENC_PROFILE_H265_MAIN;
+
+        avctx->qmin = 0;
+        avctx->qmax = 20;
+        cnctx->rcmode = 0;
+        cnctx->vbr_minqp = 0;
+        cnctx->vbr_maxqp = 20;
+        cnctx->vertical_range = 64;
+        cnctx->horizontal_range = 128;
+
+        cnctx->input_buf_num = 2;
+        cnctx->output_buf_num = 4;
+    }
+
+    memset(&enc_params, 0, sizeof(enc_params));
+    enc_params.width = cnctx->width;
+    enc_params.height = cnctx->height;
+    enc_params.codec = cnctx->codec_type;
+    if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {
+        enc_params.fpsNumerator = avctx->framerate.num;
+        enc_params.fpsDenominator = avctx->framerate.den;
+    } else {
+        enc_params.fpsNumerator = avctx->time_base.den;
+        enc_params.fpsDenominator = avctx->time_base.num * avctx->ticks_per_frame;
+        av_log(avctx, AV_LOG_WARNING, "Can't get valid framerate[%d]&framerateDen[%d],use default:[%d][%d]\n",
+               avctx->framerate.num, avctx->framerate.den, enc_params.fpsNumerator, enc_params.fpsDenominator);
+    }
+    cnctx->fps_num = enc_params.fpsNumerator;
+    cnctx->fps_den = enc_params.fpsDenominator;
+    // enc_params.allocType = CNCODEC_BUF_ALLOC_LIB;
+    enc_params.allocType = CNCODEC_BUF_ALLOC_LIB_USER_SPECIFY_BUF_ALIGNMENT;
+    enc_params.pixelFmt = cnctx->pixelFmt;
+    enc_params.inputBufNum = cnctx->input_buf_num;
+    enc_params.outputBufNum = cnctx->output_buf_num;
+
+    if ( FFALIGN(bitstream_buf_size, 4096) < OUTPUT_BUFFER_SIZE_FOR_ENCODE) {
+        enc_params.suggestedLibAllocBitStrmBufSize = FFALIGN(bitstream_buf_size, 4096);
+    } else {
+        enc_params.suggestedLibAllocBitStrmBufSize = OUTPUT_BUFFER_SIZE_FOR_ENCODE;
+    }
+    enc_params.deviceId = cnctx->device_id;
+    enc_params.instance = cnctx->instance_id;
+    enc_params.rateCtrl.targetBitrate = cnctx->bitrate;
+    if (avctx->rc_max_rate > 0) {
+        enc_params.rateCtrl.peakBitrate = avctx->rc_max_rate;
+    }
+    enc_params.colorSpace = cnctx->color_space;
+    if (cnctx->rcmode == 0) { // VBR
+        if (avctx->qmin >= 0 && avctx->qmax >= 0) {
+            enc_params.rateCtrl.maxIQP = avctx->qmax;
+            enc_params.rateCtrl.maxPQP = avctx->qmax;
+            enc_params.rateCtrl.maxBQP = avctx->qmax;
+            enc_params.rateCtrl.minIQP = avctx->qmin;
+            enc_params.rateCtrl.minPQP = avctx->qmin;
+            enc_params.rateCtrl.minBQP = avctx->qmin;
+        } else {
+            if (cnctx->vbr_maxqp > 0) {
+                enc_params.rateCtrl.maxIQP = cnctx->vbr_maxqp;
+                enc_params.rateCtrl.maxPQP = cnctx->vbr_maxqp;
+                enc_params.rateCtrl.maxBQP = cnctx->vbr_maxqp;
+            }
+            if (cnctx->vbr_minqp > 0) {
+                enc_params.rateCtrl.minIQP = cnctx->vbr_minqp;
+                enc_params.rateCtrl.minPQP = cnctx->vbr_minqp;
+                enc_params.rateCtrl.minBQP = cnctx->vbr_minqp;
+            }
+        }
+        enc_params.rateCtrl.rcMode = CNVIDEOENC_RATE_CTRL_VBR;
+    } else if (cnctx->rcmode == 1) { // CBR
+        enc_params.rateCtrl.maxIQP = avctx->qmax;
+        enc_params.rateCtrl.maxPQP = avctx->qmax;
+        enc_params.rateCtrl.maxBQP = avctx->qmax;
+        enc_params.rateCtrl.minIQP = avctx->qmin;
+        enc_params.rateCtrl.minPQP = avctx->qmin;
+        enc_params.rateCtrl.minBQP = avctx->qmin;
+        enc_params.rateCtrl.rcMode = CNVIDEOENC_RATE_CTRL_CBR;
+    } else if (cnctx->rcmode == 2) { // CQP
+        if (cnctx->init_qp_i > 0) {
+            enc_params.rateCtrl.constIQP = cnctx->init_qp_i;
+            enc_params.rateCtrl.constPQP = cnctx->init_qp_p;
+            enc_params.rateCtrl.constBQP = cnctx->init_qp_b;
+            avctx->qmin = -1;
+            avctx->qmax = -1;
+        } else if (cnctx->cqp > 0) {
+            enc_params.rateCtrl.constIQP = cnctx->cqp;
+            enc_params.rateCtrl.constPQP = cnctx->cqp;
+            enc_params.rateCtrl.constBQP = cnctx->cqp;
+            avctx->qmin = -1;
+            avctx->qmax = -1;
+        } else {// default cqp value
+            enc_params.rateCtrl.constIQP = (cnctx->codec_type == CNCODEC_H264) ? 27 : 26;
+            enc_params.rateCtrl.constPQP = (cnctx->codec_type == CNCODEC_H264) ? 27 : 26;
+            enc_params.rateCtrl.constBQP = (cnctx->codec_type == CNCODEC_H264) ? 27 : 26;
+            avctx->qmin = -1;
+            avctx->qmax = -1;
+        }
+        enc_params.rateCtrl.rcMode = CNVIDEOENC_RATE_CTRL_CQP;
+    }
+
+    enc_params.rateCtrl.gopLength = cnctx->gop_size;
+
+    switch (enc_params.codec) {
+    case CNCODEC_H264:
+        enc_params.uCfg.h264.profile = cnctx->profile;
+        enc_params.uCfg.h264.level = cnctx->level;
+        if (cnctx->max_b_frames > 0) {
+            enc_params.uCfg.h264.BFramesNum = cnctx->max_b_frames;
+        }
+        enc_params.uCfg.h264.gopType = CNVIDEOENC_GOP_TYPE_LOW_DELAY;
+        if (avctx->refs > 0) {
+            enc_params.uCfg.h264.maxRefFramesNum = avctx->refs;
+        }
+        // enc_params.uCfg.h264.insertSpsPpsWhenIDR = cnctx->insert_spspps_idr;
+        if (cnctx->pixelFmt == CNCODEC_PIX_FMT_P010) { // 10bit
+            enc_params.uCfg.h264.bitDepth = 2;
+        }
+        if (cnctx->horizontal_range > 0 || cnctx->vertical_range > 0) {
+            enc_params.uCfg.h264.verticalRange = cnctx->vertical_range;
+            enc_params.uCfg.h264.horizontalRange = cnctx->horizontal_range;
+        }
+#if FF_API_CODER_TYPE
+FF_DISABLE_DEPRECATION_WARNINGS
+        if (avctx->coder_type >= 0)
+            enc_params.uCfg.h264.entropyMode = avctx->coder_type == FF_CODER_TYPE_VLC ?
+                            CNVIDEOENC_ENTROPY_MODE_CAVLC : CNVIDEOENC_ENTROPY_MODE_CABAC;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+        if (cnctx->coder >=0) {
+            enc_params.uCfg.h264.entropyMode = cnctx->coder;
+        }
+        break;
+    case CNCODEC_HEVC:
+        enc_params.uCfg.h265.profile = cnctx->profile;
+        enc_params.uCfg.h265.level = cnctx->level;
+        if (cnctx->max_b_frames > 0) {
+            enc_params.uCfg.h265.BFramesNum = cnctx->max_b_frames;
+        }
+        enc_params.uCfg.h265.gopType = CNVIDEOENC_GOP_TYPE_LOW_DELAY;
+        if (avctx->refs > 0) {
+            enc_params.uCfg.h265.maxRefFramesNum = avctx->refs;
+        }
+        // enc_params.uCfg.h265.insertSpsPpsWhenIDR = cnctx->insert_spspps_idr;
+        if (cnctx->pixelFmt == CNCODEC_PIX_FMT_P010) { // 10bit
+            enc_params.uCfg.h265.bitDepth = 2;
+        }
+        if (cnctx->horizontal_range > 0 || cnctx->vertical_range > 0) {
+            enc_params.uCfg.h265.verticalRange = cnctx->vertical_range;
+            enc_params.uCfg.h265.horizontalRange = cnctx->horizontal_range;
+        }
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Can't support this type: %d\n", enc_params.codec);
+        break;
+    }
+    enc_params.extCfg.bufCfg.frameBufAlignment = cnctx->stride_align;
+    enc_params.userContext = (void *)cnctx;
+    sem_init(&(cnctx->eos_sema), 0, 0);
+    sem_init(&(cnctx->spspps_sema), 0, 0);
+    cnctx->async_queue_depth = cnctx->output_buf_num * 4;
+    cnctx->frame_queue = av_fifo_alloc(cnctx->async_queue_depth * cnvid_fifo_item_size());
+    if (!cnctx->frame_queue) {
+        sem_post(&(cnctx->eos_sema));
+        av_log(avctx, AV_LOG_FATAL, "Failed to alloc memory for async fifo\n");
+        return AVERROR(EINVAL);
+    }
+    ff_mutex_init(&cnctx->queue_mutex, NULL);
+    cnctx->insert_spspps_to_extradata = 0;
+    cnctx->pkt_sps_pps = NULL;
+    cnctx->is_spspps_packet_flag = 0;
+    cnctx->avctx = avctx;
+
+    cnctx->vuisar.sar_h = 0;
+    cnctx->vuisar.sar_w = 0;
+    if (cnctx->vui_sar_str && sscanf(cnctx->vui_sar_str, "%d:%d",
+                                   &cnctx->vuisar.sar_w, &cnctx->vuisar.sar_h) != 2) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid vui sar string\n");
+        ret = AVERROR(EINVAL);
+        return ret;
+    }
+
+    if (cnctx->pkt_sps_pps) {
+        free(cnctx->pkt_sps_pps);
+        cnctx->pkt_sps_pps = NULL;
+    }
+
+    cnctx->eos_reached = 0;
+    cnctx->eos_post_flag = 0;
+    cnctx->spspps_post_flag = 0;
+    cnctx->codec_abort_flag = 0;
+    cnctx->encoder_flushing = 0;
+    cnctx->total_add_ref_num = 0;
+    cnctx->total_frame_count = 0;
+    cnctx->total_packet_count = 0;
+    cnctx->total_outframe_count = 0;
+
+    ret = cnvideoEncCreate(&cnctx->handle, mlumpp_enc_event_cb, &enc_params);
+    if (ret != CNCODEC_SUCCESS) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create cnencode \n");
+        cnctx->handle = NULL;
+        sem_post(&(cnctx->eos_sema));
+        return AVERROR_EXTERNAL;
+    }
+
+#if CNCODEC_PATCH_VERSION < 100
+    cnvideoEncVUISar vui_sar;
+    memset(&vui_sar, 0, sizeof(vui_sar));
+    if (cnctx->vuisar.sar_w > 0 || cnctx->vuisar.sar_h > 0) {
+        vui_sar.sarWidth = cnctx->vuisar.sar_w;
+        vui_sar.sarHeight = cnctx->vuisar.sar_h;
+    } else {
+        vui_sar.sarWidth = avctx->sample_aspect_ratio.num;
+        vui_sar.sarHeight = avctx->sample_aspect_ratio.den;
+    }
+
+    cnvideoEncSetAttributes(cnctx->handle, CNVIDEO_ENC_ATTR_VUI_SAR, &vui_sar);
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Dst w: %d, h: %d \n", avctx->width, avctx->height);
+        av_log(avctx, AV_LOG_INFO, "Sar w: %d, sar h: %d \n",
+                        vui_sar.sarWidth,  vui_sar.sarHeight);
+    }
+#endif
+
+    // get spspps data
+    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {
+        ret = get_sps_pps_header(cnctx);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Got head info failed, in init func \n");
+        }
+    }
+
+    cnctx->encoder_init_flag = 1;
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode init done, handle: %p \n", cnctx->handle);
+    }
+    return 0;
+}
+
+int ff_mlumpp_vid_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    int ret = -1;
+    int timeout = 0;
+    struct timespec ts;
+    cnvideoEncInput enc_params;
+    if (NULL == avctx || NULL == cnctx || NULL == cnctx->handle) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_vid_enc_close \n");
+        return AVERROR(EINVAL);
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode close ... \n");
+    }
+    if (!cnctx->eos_reached && !cnctx->codec_abort_flag) {
+        timeout = 3000;
+        if (cnctx->trace_flag > 0) {
+            av_log(avctx, AV_LOG_INFO, "Enc eos not received, sent manual. \n");
+        }
+        empty_fifo_queue(avctx, cnctx);
+        memset(&enc_params, 0, sizeof(cnvideoEncInput));
+        if (cnctx->handle) {
+            ret = cnvideoEncWaitAvailInputBuf(cnctx->handle, &enc_params.frame, timeout);
+            if (ret != 0) {
+                av_log(avctx, AV_LOG_ERROR, "Enc wait avail input buf failed, in close func \n");
+                goto go_exit;
+            }
+        }
+        enc_params.flags |= (CNVIDEOENC_FLAG_EOS | CNVIDEOENC_FLAG_INVALID_FRAME);
+        if (cnctx->handle) {
+            ret = cnvideoEncFeedFrame(cnctx->handle, &enc_params, timeout);
+            if (ret != 0) {
+                av_log(avctx, AV_LOG_ERROR, "Fed frame failed, in closr func \n");
+                goto go_exit;
+            }
+        }
+        cnctx->encoder_flushing = 1;
+    }
+
+go_exit:
+    //empty_fifo_queue(avctx, cnctx);
+    // sem_wait(&(cnctx->eos_sema));
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode sema wait ... \n");
+    }
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ts.tv_sec += 3; // 5s
+    empty_fifo_queue(avctx, cnctx);
+    ret = sem_timedwait(&(cnctx->eos_sema), &ts);
+    if (ret == -1) {
+        int semvalue = -1;
+        sem_getvalue(&cnctx->eos_sema, &semvalue);
+        av_log(avctx, AV_LOG_ERROR, "Enc sem_timewait = -1, semvalue = %d ... \n", semvalue);
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode sema wait done \n");
+    }
+
+    empty_fifo_queue(avctx, cnctx);
+    av_fifo_free(cnctx->frame_queue);
+    cnctx->frame_queue = NULL;
+    ff_mutex_destroy(&cnctx->queue_mutex);
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode destroy ... \n");
+    }
+    if (cnctx->handle) {
+        ret = cnvideoEncDestroy(cnctx->handle);
+        cnctx->handle = NULL;
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencoder destroy done \n");
+    }
+    CNCODEC_ERROR_CHECK(avctx, ret);
+    if (cnctx->pkt_sps_pps) {
+        free(cnctx->pkt_sps_pps);
+        cnctx->pkt_sps_pps = NULL;
+    }
+    if (avctx->extradata) {
+        av_free(avctx->extradata);
+        avctx->extradata = NULL;
+    }
+    sem_destroy(&(cnctx->eos_sema));
+    if (cnctx->hw_frame_ref) {
+        av_buffer_unref(&cnctx->hw_frame_ref);
+    }
+    if (cnctx->hw_device_ref) {
+        av_buffer_unref(&cnctx->hw_device_ref);
+    }
+
+    cnctx->encoder_init_flag = 0;
+    if (cnctx->trace_flag > 1) {
+        av_log(avctx, AV_LOG_INFO, "Encoder status summary: \n");
+        av_log(avctx, AV_LOG_INFO, "Encode thread id, %lu \n", (long unsigned)pthread_self());
+        av_log(avctx, AV_LOG_INFO, "Encode flushing flag:%d \n", cnctx->encoder_flushing);
+        av_log(avctx, AV_LOG_INFO, "Encode D2H total packet count:%llu\n", cnctx->total_outframe_count);
+        av_log(avctx, AV_LOG_INFO, "Encode received total packet count:%llu\n", cnctx->total_packet_count);
+        av_log(avctx, AV_LOG_INFO, "Encode feed data count:%llu\n", cnctx->total_frame_count);
+    }
+    if (cnctx->trace_flag > 0) {
+        av_log(avctx, AV_LOG_INFO, "Cnencode close done \n");
+    }
+    return 0;
+}
diff --git a/libavcodec/mlumpp_vid_enc.h b/libavcodec/mlumpp_vid_enc.h
new file mode 100755
index 0000000000..5b68f09fe3
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.h
@@ -0,0 +1,147 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef AVCODEC_MLUMPP_VID_ENC_H
+#define AVCODEC_MLUMPP_VID_ENC_H
+#include <semaphore.h>
+#include "libavutil/pixfmt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "hwaccel.h"
+#include "internal.h"
+#include "libavutil/fifo.h"
+#include "libavutil/thread.h"
+// Cambricon decoder header file
+#include "cn_video_enc.h"
+#include "cn_codec_common.h"
+// Cambricon runtime header file
+#include "cnrt.h"
+#include "mlumpp_mluop.h"
+typedef struct MLUMPPEncContext{
+    int                                 device_id;
+    int                                 instance_id;
+    int                                 cnrt_init_flag;
+    int                                 input_buf_num;
+    int                                 output_buf_num;
+    int                                 preset;
+    int                                 rcmode;
+    int                                 vbr_maxqp;
+    int                                 vbr_minqp;
+    unsigned int                        global_quality;
+    unsigned int                        profile;
+    unsigned int                        level;
+    unsigned int                        vertical_range;
+    unsigned int                        horizontal_range;
+
+    int                                 async_queue_depth;
+    int                                 trace_flag;
+    int                                 stride_align;
+    int                                 bitrate;
+    int                                 gop_size;
+    int                                 gop_type;
+    int                                 max_b_frames;
+    unsigned int                        fps_num;
+    unsigned int                        fps_den;
+    int                                 init_qp_p;
+    int                                 init_qp_i;
+    int                                 init_qp_b;
+    int                                 cqp;
+    cnvideoEncEntropyMode               coder;
+    AVCodecContext                      *avctx;
+    cnvideoEncoder                      handle;
+    cncodecPixelFormat                  pixelFmt;
+    cncodecType                         codec_type;
+    cncodecColorSpace                   color_space;
+
+    // hw-ctx
+    AVBufferRef                         *hw_frame_ref;
+    AVBufferRef                         *hw_device_ref;
+
+    MluContext                          *mlu_ctx;
+    AVMLUDeviceContext                  *hw_device_ctx;
+    AVHWFramesContext                   *hw_frame_ctx;
+    enum AVPixelFormat                  in_sw_pixfmt;
+
+    int                                 width;
+    int                                 height;
+    int                                 coded_width;
+    int                                 coded_height;
+    // for add mluop
+    struct {
+        int                             left;
+        int                             top;
+        int                             right;
+        int                             bottom;
+    } crop;
+    struct {
+        int                             width;  // out w
+        int                             height; // out h
+        void                            *in_y_ptr;
+        void                            *in_uv_ptr;
+        void                            *out_y_ptr;
+        void                            *out_uv_ptr;
+    } resize;
+    struct {
+        int                             sar_w;
+        int                             sar_h;
+    } vuisar;
+
+    char                                *vui_sar_str;
+    char                                *resize_str;
+    //
+    int                                 encoder_flushing;
+    volatile int                        eos_reached;
+    sem_t                               eos_sema;
+    sem_t                               spspps_sema;
+    int                                 eos_post_flag;
+    int                                 spspps_post_flag;
+    int                                 insert_spspps_idr;
+    int                                 is_spspps_packet_flag;
+    int                                 insert_spspps_to_extradata;
+    uint8_t                             *pkt_sps_pps;
+    int                                 pkt_sps_pps_len;
+    AVFifoBuffer                        *frame_queue;
+    AVMutex                             queue_mutex;
+    int64_t                             last_send_frame_time;
+    int                                 codec_abort_flag;
+    volatile int                        encode_state; // 0--get encode-headers, 1--normal encoding
+    volatile int                        encoder_init_flag;
+
+    //the below only for debug
+    long long                           total_add_ref_num;
+    unsigned long long                  total_frame_count;
+    unsigned long long                  total_packet_count;
+    unsigned long long                  total_outframe_count;
+}MLUMPPEncContext_t;
+
+enum {
+    PRESET_DEFAULT = 0,
+    PRESET_SLOW,
+    PRESET_MEDIUM,
+    PRESET_FAST,
+};
+
+// main functions
+int ff_mlumpp_vid_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t* cnctx);
+int ff_mlumpp_vid_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame);
+int ff_mlumpp_vid_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt);
+int ff_mlumpp_vid_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx);
+#endif /* AVCODEC_MLUMPP_VID_ENC_H */
\ No newline at end of file
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 455c809b15..f608eed808 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -196,6 +196,9 @@ OBJS-$(CONFIG_CROP_FILTER)                   += vf_crop.o
 OBJS-$(CONFIG_CROPDETECT_FILTER)             += vf_cropdetect.o
 OBJS-$(CONFIG_CUE_FILTER)                    += f_cue.o
 OBJS-$(CONFIG_CURVES_FILTER)                 += vf_curves.o
+OBJS-$(CONFIG_CVT_RGBX2YUV_MLU_FILTER)       += vf_cvt_rgbx2yuv_mlu.o
+OBJS-$(CONFIG_CVT_YUV2RGBX_MLU_FILTER)       += vf_cvt_yuv2rgbx_mlu.o
+OBJS-$(CONFIG_CVT_RGBX2YUV_MLU_FILTER)       += vf_cvt_rgbx2yuv_mlu.o
 OBJS-$(CONFIG_DATASCOPE_FILTER)              += vf_datascope.o
 OBJS-$(CONFIG_DCTDNOIZ_FILTER)               += vf_dctdnoiz.o
 OBJS-$(CONFIG_DEBAND_FILTER)                 += vf_deband.o
@@ -263,8 +266,10 @@ OBJS-$(CONFIG_HQX_FILTER)                    += vf_hqx.o
 OBJS-$(CONFIG_HSTACK_FILTER)                 += vf_stack.o framesync.o
 OBJS-$(CONFIG_HUE_FILTER)                    += vf_hue.o
 OBJS-$(CONFIG_HWDOWNLOAD_FILTER)             += vf_hwdownload.o
+OBJS-$(CONFIG_HWDOWNLOAD_MLU_FILTER)         += vf_hwdownload_mlu.o
 OBJS-$(CONFIG_HWMAP_FILTER)                  += vf_hwmap.o
 OBJS-$(CONFIG_HWUPLOAD_CUDA_FILTER)          += vf_hwupload_cuda.o
+OBJS-$(CONFIG_HWUPLOAD_MLU_FILTER)           += vf_hwupload_mlu.o
 OBJS-$(CONFIG_HWUPLOAD_FILTER)               += vf_hwupload.o
 OBJS-$(CONFIG_HYSTERESIS_FILTER)             += vf_hysteresis.o framesync.o
 OBJS-$(CONFIG_IDET_FILTER)                   += vf_idet.o
@@ -350,8 +355,12 @@ OBJS-$(CONFIG_ROTATE_FILTER)                 += vf_rotate.o
 OBJS-$(CONFIG_SAB_FILTER)                    += vf_sab.o
 OBJS-$(CONFIG_SCALE_FILTER)                  += vf_scale.o scale.o
 OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o vf_scale_cuda.ptx.o
+OBJS-$(CONFIG_SCALE_YUV2YUV_MLU_FILTER)      += vf_scale_yuv2yuv_mlu.o
+OBJS-$(CONFIG_SCALE_RGBX2RGBX_MLU_FILTER)    += vf_scale_rgbx2rgbx_mlu.o
 OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale.o
 OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
+OBJS-$(CONFIG_SCALE_YUV2YUV_MLU_FILTER)      += vf_scale_yuv2yuv_mlu.o scale.o
+OBJS-$(CONFIG_SCALE_RGBX2RGBX_MLU_FILTER)    += vf_scale_rgbx2rgbx_mlu.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale.o vaapi_vpp.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale.o
 OBJS-$(CONFIG_SELECT_FILTER)                 += f_select.o
@@ -380,6 +389,7 @@ OBJS-$(CONFIG_SOBEL_OPENCL_FILTER)           += vf_convolution_opencl.o opencl.o
 OBJS-$(CONFIG_SPLIT_FILTER)                  += split.o
 OBJS-$(CONFIG_SPP_FILTER)                    += vf_spp.o
 OBJS-$(CONFIG_SR_FILTER)                     += vf_sr.o
+OBJS-$(CONFIG_SR_MLU_FILTER)                 += vf_sr_mlu.o
 OBJS-$(CONFIG_SSIM_FILTER)                   += vf_ssim.o framesync.o
 OBJS-$(CONFIG_STEREO3D_FILTER)               += vf_stereo3d.o
 OBJS-$(CONFIG_STREAMSELECT_FILTER)           += f_streamselect.o framesync.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 04a3df7d56..c7076cda52 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -183,6 +183,9 @@ extern AVFilter ff_vf_crop;
 extern AVFilter ff_vf_cropdetect;
 extern AVFilter ff_vf_cue;
 extern AVFilter ff_vf_curves;
+extern AVFilter ff_vf_cvt_rgbx2yuv_mlu;
+extern AVFilter ff_vf_cvt_yuv2rgbx_mlu;
+extern AVFilter ff_vf_cvt_rgbx2yuv_mlu;
 extern AVFilter ff_vf_datascope;
 extern AVFilter ff_vf_dctdnoiz;
 extern AVFilter ff_vf_deband;
@@ -248,8 +251,10 @@ extern AVFilter ff_vf_hqx;
 extern AVFilter ff_vf_hstack;
 extern AVFilter ff_vf_hue;
 extern AVFilter ff_vf_hwdownload;
+extern AVFilter ff_vf_hwdownload_mlu;
 extern AVFilter ff_vf_hwmap;
 extern AVFilter ff_vf_hwupload;
+extern AVFilter ff_vf_hwupload_mlu;
 extern AVFilter ff_vf_hwupload_cuda;
 extern AVFilter ff_vf_hysteresis;
 extern AVFilter ff_vf_idet;
@@ -332,8 +337,12 @@ extern AVFilter ff_vf_rotate;
 extern AVFilter ff_vf_sab;
 extern AVFilter ff_vf_scale;
 extern AVFilter ff_vf_scale_cuda;
+extern AVFilter ff_vf_scale_yuv2yuv_mlu;
+extern AVFilter ff_vf_scale_rgbx2rgbx_mlu;
 extern AVFilter ff_vf_scale_npp;
 extern AVFilter ff_vf_scale_qsv;
+extern AVFilter ff_vf_scale_yuv2yuv_mlu;
+extern AVFilter ff_vf_scale_rgbx2rgbx_mlu;
 extern AVFilter ff_vf_scale_vaapi;
 extern AVFilter ff_vf_scale2ref;
 extern AVFilter ff_vf_select;
@@ -361,6 +370,7 @@ extern AVFilter ff_vf_sobel_opencl;
 extern AVFilter ff_vf_split;
 extern AVFilter ff_vf_spp;
 extern AVFilter ff_vf_sr;
+extern AVFilter ff_vf_sr_mlu;
 extern AVFilter ff_vf_ssim;
 extern AVFilter ff_vf_stereo3d;
 extern AVFilter ff_vf_streamselect;
diff --git a/libavfilter/vf_cvt_rgbx2yuv_mlu.c b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
new file mode 100644
index 0000000000..c6a98af9e0
--- /dev/null
+++ b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
@@ -0,0 +1,547 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTRGBX2YUVContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    void *input_mlu_rgbx;
+    void *output_mlu_y;
+    void *output_mlu_uv;
+
+    int output_mlu_y_size;
+    int output_mlu_uv_size;
+    int input_mlu_rgbx_size;
+
+    int (*ptr_convert_rgbx2yuv_init)(void **, int, int, const char *, const char *, const char *);
+    int (*ptr_convert_rgbx2yuv_exec)(void *, void *, void *, void *);
+    int (*ptr_convert_rgbx2yuv_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluCVTRGBX2YUVContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluCVTRGBX2YUVContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_convert_rgbx2yuv_init =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_init", "mluop");
+    ctx->ptr_convert_rgbx2yuv_exec =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_exec", "mluop");
+    ctx->ptr_convert_rgbx2yuv_destroy =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_destroy", "mluop");
+    if (!ctx->ptr_convert_rgbx2yuv_init || !ctx->ptr_convert_rgbx2yuv_exec ||
+        !ctx->ptr_convert_rgbx2yuv_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluCVTRGBX2YUVContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluCVTRGBX2YUVContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";  break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";  break;
+    case AV_PIX_FMT_RGB24:
+        ctx->pic_pixfmt = "rgb24"; break;
+    case AV_PIX_FMT_BGR24:
+        ctx->pic_pixfmt = "bgr24"; break;
+    case AV_PIX_FMT_ARGB:
+        ctx->pic_pixfmt = "argb";  break;
+    case AV_PIX_FMT_ABGR:
+        ctx->pic_pixfmt = "abgr";  break;
+    case AV_PIX_FMT_BGRA:
+        ctx->pic_pixfmt = "bgra";  break;
+    case AV_PIX_FMT_RGBA:
+        ctx->pic_pixfmt = "rgba";  break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow"; break;
+    }
+}
+
+static int mlurgbx2yuv_query_formats(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbx2yuv_init(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mlurgbx2yuv_uninit(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_convert_rgbx2yuv_destroy(s->op_handle);
+    }
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbx2yuv_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTRGBX2YUVContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char device_idx[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->output_mlu_y_size   = outlink->w * outlink->h;
+    s->output_mlu_uv_size  = outlink->w * outlink->h / 2;
+    s->input_mlu_rgbx_size = inlink->w * inlink->h * get_pixfmt_channel_num(s->in_fmt);
+
+    // checkout infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mlu op
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_convert_rgbx2yuv_init(&s->op_handle, inlink->w, inlink->h,
+                                     s->pic_pixfmt, s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_rgbx_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), sizeof(char) * s->output_mlu_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), sizeof(char) * s->output_mlu_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbx2yuv_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx     = link->dst;
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    AVFilterLink *outlink    = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+    out->linesize[1] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_y = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                             s->input_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_convert_rgbx2yuv_exec(s->op_handle, s->input_mlu_rgbx,
+                                           s->output_mlu_y, s->output_mlu_uv);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2yuv with mlu\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->output_mlu_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->output_mlu_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTRGBX2YUVContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixfmt", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS },
+    { "n",     "device index",  OFFSET(n_expr),        AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbx2yuv_class = {
+    .class_name = "mlurgbx2yuv",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbx2yuv_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbx2yuv_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbx2yuv_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbx2yuv_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_rgbx2yuv_mlu = {
+    .name      = "cvt_rgbx2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mlurgbx2yuv_init,
+    .uninit        = mlurgbx2yuv_uninit,
+    .query_formats = mlurgbx2yuv_query_formats,
+
+    .priv_size = sizeof(MluCVTRGBX2YUVContext),
+    .priv_class = &mlurgbx2yuv_class,
+
+    .inputs    = mlurgbx2yuv_inputs,
+    .outputs   = mlurgbx2yuv_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_cvt_yuv2rgbx_mlu.c b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
new file mode 100644
index 0000000000..cbefa1620e
--- /dev/null
+++ b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
@@ -0,0 +1,541 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12,
+    AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,
+    AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR,
+    AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTYUV2RGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    int in_y_size;
+    int in_uv_size;
+    int out_mlu_size;
+
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_rgbx;
+
+    int (*ptr_convert_yuv2rgbx_init)(void **, int, int, const char *, const char *, const char *);
+    int (*ptr_convert_yuv2rgbx_exec)(void *, void *, void *, void *);
+    int (*ptr_convert_yuv2rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluCVTYUV2RGBXContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluCVTYUV2RGBXContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_convert_yuv2rgbx_init =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_init", "mluop");
+    ctx->ptr_convert_yuv2rgbx_exec =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_exec", "mluop");
+    ctx->ptr_convert_yuv2rgbx_destroy =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_destroy", "mluop");
+    if (!ctx->ptr_convert_yuv2rgbx_init || !ctx->ptr_convert_yuv2rgbx_exec ||
+        !ctx->ptr_convert_yuv2rgbx_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluCVTYUV2RGBXContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static int get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluCVTYUV2RGBXContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";
+        break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";
+        break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow";
+        break;
+    }
+}
+
+static int mluyuv2rgbx_query_formats(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+   int ret;
+   out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluyuv2rgbx_init(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_rgbx = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mluyuv2rgbx_uninit(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_convert_yuv2rgbx_destroy(s->op_handle);
+    }
+    mluop_unload(s);
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluyuv2rgbx_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTYUV2RGBXContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char device_idx[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    s->in_y_size    = inlink->w * inlink->h;
+    s->in_uv_size   = inlink->w * inlink->h / 2;
+    s->out_mlu_size = outlink->w * outlink->h *
+                    get_pixfmt_channel_num(get_av_pixfmt_from_idx(s->enter_out_fmt));
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mlu
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_convert_yuv2rgbx_init(&s->op_handle, inlink->w, inlink->h, s->pic_pixfmt,
+                                    s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), sizeof(char) * s->in_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), sizeof(char) * s->in_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->out_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluyuv2rgbx_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext*ctx      = link->dst;
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    AVFilterLink*outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y = in->data[0];
+            s->input_mlu_uv = in->data[1];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                                  s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                                  s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_convert_yuv2rgbx_exec(s->op_handle, s->input_mlu_y,
+                                        s->input_mlu_uv, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2rgbx filter with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->out_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTYUV2RGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixfmt", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS},
+    { "n",     "device index",  OFFSET(n_expr),        AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mluyuv2rgbx_class = {
+    .class_name = "mluyuv2rgbx",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluyuv2rgbx_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluyuv2rgbx_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluyuv2rgbx_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluyuv2rgbx_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_yuv2rgbx_mlu = {
+    .name      = "cvt_yuv2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mluyuv2rgbx_init,
+    .uninit        = mluyuv2rgbx_uninit,
+    .query_formats = mluyuv2rgbx_query_formats,
+
+    .priv_size = sizeof(MluCVTYUV2RGBXContext),
+    .priv_class = &mluyuv2rgbx_class,
+
+    .inputs    = mluyuv2rgbx_inputs,
+    .outputs   = mluyuv2rgbx_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwdownload_mlu.c b/libavfilter/vf_hwdownload_mlu.c
new file mode 100644
index 0000000000..ece971be34
--- /dev/null
+++ b/libavfilter/vf_hwdownload_mlu.c
@@ -0,0 +1,209 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MLUDownloadContext {
+    const AVClass *class;
+    int device_idx;
+
+    AVBufferRef   *hwframes_ref;
+    AVHWFramesContext *hwframes;
+} MLUDownloadContext;
+
+static int hwdownload_query_formats(AVFilterContext *avctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_RGB24,  AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR,   AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA,   AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_NV12,   AV_PIX_FMT_NV21,
+        AV_PIX_FMT_YUV420P,AV_PIX_FMT_P010,
+        AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &avctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &avctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+    return 0;
+}
+
+static int hwdownload_config_input(AVFilterLink *inlink)
+{
+    AVFilterContext *avctx = inlink->dst;
+    MLUDownloadContext *ctx = avctx->priv;
+
+    if (!inlink->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "The input must have a hardware frame reference.\n");
+        return AVERROR(EINVAL);
+    }
+    av_buffer_unref(&ctx->hwframes_ref);
+    ctx->hwframes_ref = av_buffer_ref(inlink->hw_frames_ctx);
+    if (!ctx->hwframes_ref)
+        return AVERROR(ENOMEM);
+
+    ctx->hwframes = (AVHWFramesContext*)ctx->hwframes_ref->data;
+
+    return 0;
+}
+
+static int hwdownload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *avctx  = outlink->src;
+    AVFilterLink *inlink    = avctx->inputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+
+    int err;
+    enum AVPixelFormat *formats;
+
+    if (!ctx->hwframes_ref)
+        return AVERROR(EINVAL);
+
+    err = av_hwframe_transfer_get_formats(ctx->hwframes_ref,
+                                          AV_HWFRAME_TRANSFER_DIRECTION_FROM,
+                                          &formats, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Hwframe transfer get formats failed \n");
+        return err;
+    }
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    outlink->format = formats[0];
+
+    av_freep(&formats);
+    return 0;
+}
+
+static int hwdownload_filter_frame(AVFilterLink *link, AVFrame *input) // input on mlu
+{
+    AVFilterContext *avctx  = link->dst;
+    AVFilterLink  *outlink  = avctx->outputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+
+    int err;
+    AVFrame *output = NULL;
+    if (!ctx->hwframes_ref || !input->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+    if ((void*)ctx->hwframes != input->hw_frames_ctx->data) {
+        av_log(ctx, AV_LOG_ERROR, "Input frame is not the in the configured hwframe context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    output = ff_get_video_buffer(outlink, ctx->hwframes->width,
+                                 ctx->hwframes->height);
+    if (!output) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    output->width  = outlink->w;
+    output->height = outlink->h;
+    for (int i = 0; i < FF_ARRAY_ELEMS(input->data) && input->data[i]; i++) {
+        output->linesize[i] = input->linesize[i];
+    }
+
+    err = av_hwframe_transfer_data(output, input, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to download frame: %d.\n", err);
+        goto fail;
+    }
+
+    err = av_frame_copy_props(output, input);
+    if (err < 0) {
+        goto fail;
+    }
+
+    av_frame_free(&input);
+    return ff_filter_frame(avctx->outputs[0], output);
+
+fail:
+    av_frame_free(&input);
+    av_frame_free(&output);
+    return err;
+}
+
+static av_cold void hwdownload_uninit(AVFilterContext *avctx)
+{
+    MLUDownloadContext *ctx = avctx->priv;
+    av_buffer_unref(&ctx->hwframes_ref);
+}
+
+static const AVClass hwdownload_class = {
+    .class_name = "hwdownload_mlu",
+    .item_name  = av_default_item_name,
+    .option     = NULL,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad hwdownload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_input,
+        .filter_frame = hwdownload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad hwdownload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwdownload_mlu = {
+    .name          = "hwdownload_mlu",
+    .description   = NULL_IF_CONFIG_SMALL("Download a hardware frame to a normal frame"),
+    .uninit        = hwdownload_uninit,
+    .query_formats = hwdownload_query_formats,
+    .priv_size     = sizeof(MLUDownloadContext),
+    .priv_class    = &hwdownload_class,
+    .inputs        = hwdownload_inputs,
+    .outputs       = hwdownload_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwupload_mlu.c b/libavfilter/vf_hwupload_mlu.c
new file mode 100644
index 0000000000..c0e8b0807d
--- /dev/null
+++ b/libavfilter/vf_hwupload_mlu.c
@@ -0,0 +1,200 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MluUploadContext {
+    const AVClass *class;
+    int device_idx;
+
+    AVBufferRef *hwdevice;
+    AVBufferRef *hwframe;
+} MluUploadContext;
+
+static av_cold int mlu_upload_init(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+    char buf[64] = { 0 };
+
+    snprintf(buf, sizeof(buf), "%d", s->device_idx);
+
+    // here depend on hwcontext
+    return av_hwdevice_ctx_create(&s->hwdevice, AV_HWDEVICE_TYPE_MLU, buf, NULL, 0);
+}
+
+static av_cold void mlu_upload_uninit(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+
+    av_buffer_unref(&s->hwframe);
+    av_buffer_unref(&s->hwdevice);
+}
+
+static int mlu_upload_query_formats(AVFilterContext *ctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_P010, AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int mlu_upload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluUploadContext *s = ctx->priv;
+
+    int ret;
+    AVHWFramesContext *hwframe_ctx;
+
+    av_buffer_unref(&s->hwframe);
+    s->hwframe = av_hwframe_ctx_alloc(s->hwdevice);
+    if (!s->hwframe)
+        return AVERROR(ENOMEM);
+
+    hwframe_ctx            = (AVHWFramesContext*)s->hwframe->data;
+    hwframe_ctx->format    = AV_PIX_FMT_MLU;
+    hwframe_ctx->sw_format = inlink->format;
+    hwframe_ctx->width     = inlink->w;
+    hwframe_ctx->height    = inlink->h;
+
+    ret = av_hwframe_ctx_init(s->hwframe);
+    if (ret < 0)
+        return ret;
+
+    outlink->hw_frames_ctx = av_buffer_ref(s->hwframe);
+    if (!outlink->hw_frames_ctx)
+        return AVERROR(ENOMEM);
+
+    return 0;
+}
+
+static int mlu_upload_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext   *ctx = link->dst;
+    AVFilterLink  *outlink = ctx->outputs[0];
+    MluUploadContext *s = ctx->priv;
+    AVHWFramesContext *hwframe_ctx;
+
+    AVFrame *out = NULL;
+    int ret;
+
+    hwframe_ctx = (AVHWFramesContext*)s->hwframe->data;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    for (int i = 0; i < FF_ARRAY_ELEMS(in->data) && in->data[i]; i++) {
+        out->linesize[i] = in->linesize[i];
+    }
+
+    ret = av_hwframe_transfer_data(out, in, 0); // H2D
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Error transferring data to the MLU\n");
+        goto fail;
+    }
+
+    ret = av_frame_copy_props(out, in); // props copy
+    if (ret < 0)
+        goto fail;
+
+    av_frame_free(&in);
+
+    return ff_filter_frame(ctx->outputs[0], out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluUploadContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption mlu_upload_options[] = {
+    { "device", "use to choose the accelerator card", OFFSET(device_idx), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { NULL },
+};
+
+AVFILTER_DEFINE_CLASS(mlu_upload);
+
+static const AVFilterPad mlu_upload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlu_upload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlu_upload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlu_upload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwupload_mlu = {
+    .name        = "hwupload_mlu",
+    .description = NULL_IF_CONFIG_SMALL("Upload a system memory frame to a mlu device."),
+
+    .init      = mlu_upload_init,
+    .uninit    = mlu_upload_uninit,
+
+    .query_formats = mlu_upload_query_formats,
+
+    .priv_size  = sizeof(MluUploadContext),
+    .priv_class = &mlu_upload_class,
+
+    .inputs    = mlu_upload_inputs,
+    .outputs   = mlu_upload_outputs,
+
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_rgbx2rgbx_mlu.c b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
new file mode 100644
index 0000000000..f7a7c369d4
--- /dev/null
+++ b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
@@ -0,0 +1,495 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluScaleRGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame     *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; // Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *w_expr;
+    char *h_expr;
+    char *n_expr;
+    char *depth;
+    const char *pic_pixfmt;
+
+    // buffers and mlu-resize func-ptrs
+    int input_mlu_size;
+    int output_mlu_size;
+    void *input_mlu_rgbx;
+    void *output_mlu_rgbx;
+
+    int (*ptr_resize_rgbx_init)(void **, int, int, int, int, const char *, const char *);
+    int (*ptr_resize_rgbx_exec)(void *, void *, void *);
+    int (*ptr_resize_rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluScaleRGBXContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluScaleRGBXContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_resize_rgbx_init =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_init", "mluop");
+    ctx->ptr_resize_rgbx_exec =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_exec", "mluop");
+    ctx->ptr_resize_rgbx_destroy =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_destroy", "mluop");
+    if (!ctx->ptr_resize_rgbx_init || !ctx->ptr_resize_rgbx_exec ||
+        !ctx->ptr_resize_rgbx_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluScaleRGBXContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+  if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+    return 1;
+  } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+    return 3;
+  } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+             pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+    return 4;
+  } else {
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(pixfmt));
+    return 0;
+  }
+}
+
+static void convert_av_pixfmt_to_idx(MluScaleRGBXContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";  break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";  break;
+    case AV_PIX_FMT_RGB24:
+        ctx->pic_pixfmt = "rgb24"; break;
+    case AV_PIX_FMT_BGR24:
+        ctx->pic_pixfmt = "bgr24"; break;
+    case AV_PIX_FMT_ARGB:
+        ctx->pic_pixfmt = "argb";  break;
+    case AV_PIX_FMT_ABGR:
+        ctx->pic_pixfmt = "abgr";  break;
+    case AV_PIX_FMT_RGBA:
+        ctx->pic_pixfmt = "rgba";  break;
+    case AV_PIX_FMT_BGRA:
+        ctx->pic_pixfmt = "bgra";  break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow"; break;
+    }
+}
+
+static int mlurgbxscale_query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    int ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->inputs[0]->out_formats)) < 0)
+        return ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->outputs[0]->in_formats)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbxscale_init(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mlurgbxscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_resize_rgbx_destroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbxscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx    = outlink->src;
+    AVFilterLink *inlink    = ctx->inputs[0];
+    MluScaleRGBXContext *s  = ctx->priv;
+    MluContext *mlu_ctx     = NULL;
+
+    AVHWFramesContext *in_frames_ctx;
+
+    int w, h, ret;
+    char device_idx[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx  = NULL;
+
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "the input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->input_mlu_size  = inlink->w * inlink->h * get_pixfmt_channel_num(s->in_fmt);
+    s->output_mlu_size = outlink->w * outlink->h * get_pixfmt_channel_num(s->out_fmt);
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mluop
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_resize_rgbx_init(&s->op_handle, inlink->w, inlink->h, outlink->w, outlink->h,
+                                s->pic_pixfmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = cnrtMalloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = cnrtMalloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->output_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h * inlink->w,
+                                                             outlink->w * inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbxscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx   = link->dst;
+    MluScaleRGBXContext *s = ctx->priv;
+    AVFilterLink *outlink  = ctx->outputs[0];
+    MluContext *mlu_ctx    = s->hw_dev_ctx->mlu_ctx;
+
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                              s->input_mlu_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_resize_rgbx_exec(s->op_handle,
+                    s->input_mlu_rgbx, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2rgbx scale with mluop \n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->output_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleRGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "Output video width",  OFFSET(w_expr), AV_OPT_TYPE_STRING, {.str = "iw"}, .flags = FLAGS },
+    { "h", "Output video height", OFFSET(h_expr), AV_OPT_TYPE_STRING, {.str = "ih"}, .flags = FLAGS },
+    { "n", "device index",        OFFSET(n_expr), AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbxscale_class = {
+    .class_name = "mlurgbxscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbxscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbxscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbxscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbxscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_rgbx2rgbx_mlu = {
+    .name      = "scale_rgbx2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer for rgbx only support 8U"),
+
+    .init          = mlurgbxscale_init,
+    .uninit        = mlurgbxscale_uninit,
+    .query_formats = mlurgbxscale_query_formats,
+
+    .priv_size = sizeof(MluScaleRGBXContext),
+    .priv_class = &mlurgbxscale_class,
+
+    .inputs    = mlurgbxscale_inputs,
+    .outputs   = mlurgbxscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_yuv2yuv_mlu.c b/libavfilter/vf_scale_yuv2yuv_mlu.c
new file mode 100644
index 0000000000..996c58d3e4
--- /dev/null
+++ b/libavfilter/vf_scale_yuv2yuv_mlu.c
@@ -0,0 +1,502 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include <dlfcn.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+
+#define CNFILTER_FRAME_ALIGNMENT 1
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12,
+    AV_PIX_FMT_NV21,
+};
+
+typedef struct MluScaleContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[4], planes_out[4];
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int stride_align;
+    int passthrough;
+    enum AVPixelFormat format; // Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *w_expr;
+    char *h_expr;
+    char *n_expr;
+    char *depth;
+    const char *pic_pixfmt;
+
+    // buffers and mlu-resize func-ptrs
+    int in_y_size;
+    int in_uv_size;
+    int out_y_size;
+    int out_uv_size;
+
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_y;
+    void *output_mlu_uv;
+
+    int (*ptr_resize_yuv_init)(void **, int, int, int, int, const char *, const char *);
+    int (*ptr_resize_yuv_exec)(void *, void *, void *, void *, void *);
+    int (*ptr_resize_yuv_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluScaleContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluScaleContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_resize_yuv_init =
+        dlsym_prefixed(ctx->lib, "resize_yuv_init", "mluop");
+    ctx->ptr_resize_yuv_exec =
+        dlsym_prefixed(ctx->lib, "resize_yuv_exec", "mluop");
+    ctx->ptr_resize_yuv_destroy =
+        dlsym_prefixed(ctx->lib, "resize_yuv_destroy", "mluop");
+    if (!ctx->ptr_resize_yuv_init || !ctx->ptr_resize_yuv_exec ||
+        !ctx->ptr_resize_yuv_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluScaleContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "Unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluScaleContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12"; break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21"; break;
+    default:
+        av_log(ctx, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unkown"; break;
+    }
+}
+
+static int mluscale_query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    AVFilterFormats *pix_fmts = ff_make_format_list(pixel_formats);
+
+    int ret;
+    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluscale_init(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+
+    static const char *const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->format = AV_PIX_FMT_NONE; // for no conversion.
+
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mluscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_resize_yuv_destroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluScaleContext *s   = ctx->priv;
+    MluContext *mlu_ctx  = NULL;
+
+    int w, h, ret;
+    char device_idx[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx    = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        s->stride_align = CNFILTER_FRAME_ALIGNMENT;
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(EINVAL);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format    = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width     = FFALIGN(outlink->w, s->stride_align);
+            out_hw_frames_ctx->height    = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx) {
+            return AVERROR(EINVAL);
+        }
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+        s->stride_align = 1;
+    }
+
+    s->in_y_size   = FFALIGN(inlink->w,  s->stride_align) * inlink->h;
+    s->in_uv_size  = FFALIGN(inlink->w,  s->stride_align) * inlink->h / 2;
+    s->out_y_size  = FFALIGN(outlink->w, s->stride_align) * outlink->h;
+    s->out_uv_size = FFALIGN(outlink->w, s->stride_align) * outlink->h / 2;
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mluop
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_resize_yuv_init(&s->op_handle,
+                            FFALIGN(inlink->w, s->stride_align), inlink->h,
+                            FFALIGN(outlink->w, s->stride_align), outlink->h,
+                            s->depth, s->pic_pixfmt);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), s->in_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), s->in_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), s->out_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), s->out_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w, outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext  *ctx = link->dst;
+    MluScaleContext    *s = ctx->priv;
+    AVFilterLink *outlink = ctx->outputs[0];
+    MluContext *mlu_ctx   = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+    out->linesize[1] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y   = in->data[0];
+            s->input_mlu_uv  = in->data[1];
+            s->output_mlu_y  = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                            s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                            s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+
+        ret = s->ptr_resize_yuv_exec(s->op_handle, s->input_mlu_y,
+                        s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2yuv scale with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->out_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->out_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "Output video width",  OFFSET(w_expr), AV_OPT_TYPE_STRING, {.str = "iw"}, .flags = FLAGS },
+    { "h", "Output video height", OFFSET(h_expr), AV_OPT_TYPE_STRING, {.str = "ih"}, .flags = FLAGS },
+    { "n", "device index",        OFFSET(n_expr), AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mluscale_class = {
+    .class_name = "mluscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_yuv2yuv_mlu = {
+    .name      = "scale_yuv2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer"),
+
+    .init          = mluscale_init,
+    .uninit        = mluscale_uninit,
+    .query_formats = mluscale_query_formats,
+
+    .priv_size = sizeof(MluScaleContext),
+    .priv_class = &mluscale_class,
+
+    .inputs    = mluscale_inputs,
+    .outputs   = mluscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_sr_mlu.c b/libavfilter/vf_sr_mlu.c
new file mode 100644
index 0000000000..0c074d001b
--- /dev/null
+++ b/libavfilter/vf_sr_mlu.c
@@ -0,0 +1,271 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright notice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+//#include "libavutil/hwcontext.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+// #include "cnrt.h"
+#include <dlfcn.h>
+#include <unistd.h>
+#include <sys/time.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                        \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24,
+};
+
+typedef struct MLUSRContext {
+  const AVClass *class;
+  enum AVPixelFormat in_fmt;
+  enum AVPixelFormat out_fmt;
+
+  struct {
+      int width;
+      int height;
+  } planes_in[3], planes_out[3];
+
+  AVFrame     *frame;
+
+  /**
+   * Output sw format. AV_PIX_FMT_NONE for no conversion.
+   */
+  enum AVPixelFormat format;
+
+  char* dev_id;               ///< device_id expression string
+  char* channel_id;
+  char* model_path;
+  int   trace_flag;
+
+  // buffers and mlu-sr func-ptrs
+  void *input_mlu_data;
+  void *output_mlu_data;
+  void *lib;
+  void (*ptr_sr_model_init)(void**, const char*, int, int);
+  void (*ptr_sr_model_exec)(void*, void*, uint32_t, uint32_t, void*);
+  void (*ptr_sr_model_destroy)(void*);
+
+  struct timeval start;
+  struct timeval end;
+
+  void* handle;
+} MLUSRContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int sr_lib_load(MLUSRContext *ctx, const char *lib_dir, void *logctx)
+{
+  if (lib_dir) {
+    ctx->lib = dlopen(lib_dir, RTLD_NOW | RTLD_GLOBAL);
+    if (!ctx->lib) {
+      av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", lib_dir, dlerror());
+      return AVERROR_EXTERNAL;
+    } else {
+      av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", lib_dir);
+    }
+  }
+  ctx->ptr_sr_model_init = dlsym_prefixed(ctx->lib, "infer_sr_init", "mluop");
+  ctx->ptr_sr_model_exec = dlsym_prefixed(ctx->lib, "infer_sr_exec", "mluop");
+  ctx->ptr_sr_model_destroy = dlsym_prefixed(ctx->lib, "infer_sr_destroy", "mluop");
+  if (!ctx->ptr_sr_model_init || !ctx->ptr_sr_model_exec || !ctx->ptr_sr_model_destroy) {
+    av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n", lib_dir);
+    dlclose(ctx->lib);
+    ctx->lib = NULL;
+    return AVERROR_EXTERNAL;
+  }
+  return 0;
+}
+
+static int sr_lib_unload(MLUSRContext *ctx) {
+  if (ctx->lib) {
+    dlclose(ctx->lib);
+    ctx->lib = NULL;
+  }
+  return 0;
+}
+
+static av_cold int mlu_sr_init(AVFilterContext *ctx) {
+  MLUSRContext *s = ctx->priv;
+  static const char * const mluop_libname = "/usr/local/neuware/lib64/libeasyOP.so";
+  int ret = sr_lib_load(s, mluop_libname, ctx);
+  if (ret < 0) {
+    av_log(ctx, AV_LOG_WARNING, "SR Load lib error! Error id : %d\n", ret);
+    return ret;
+  }
+
+  s->frame = av_frame_alloc();
+  if (!s->frame) {
+    sr_lib_unload(s);
+    av_log(ctx, AV_LOG_WARNING, "SR Alloc frame error! Error id : %d\n", AVERROR(ENOMEM));
+    return AVERROR(ENOMEM);
+  }
+  return 0;
+}
+
+static av_cold void mlu_sr_uninit(AVFilterContext *ctx) {
+  MLUSRContext *s = ctx->priv;
+  s->ptr_sr_model_destroy(s->handle);
+  sr_lib_unload(s);
+  if (!s->frame) {
+    av_log(ctx, AV_LOG_WARNING, "frame error! Error id : %d\n", AVERROR(ENOMEM));
+  } else {
+      av_frame_free(&s->frame);
+  }
+}
+
+static int mlu_sr_query_formats(AVFilterContext *ctx) {
+    static const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_RGB24, AV_PIX_FMT_NONE,
+    };
+    AVFilterFormats *pix_fmts = ff_make_format_list(pixel_formats);
+    return ff_set_common_formats(ctx, pix_fmts);
+}
+
+static int mlu_filter_frame(AVFilterLink *link, AVFrame *in) {
+  AVFilterContext *ctx = link->dst;
+  MLUSRContext *s = ctx->priv;
+  AVFilterLink *outlink = ctx->outputs[0];
+
+  AVFrame *out = NULL;
+  out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+  if (!out) {
+      av_log(ctx, AV_LOG_WARNING, "get video buffer error! Error id : %d\n", AVERROR(ENOMEM));
+      av_frame_free(&in);
+      return AVERROR(ENOMEM);
+  }
+
+  av_frame_copy_props(out, in);
+  out->width  = outlink->w;
+  out->height = outlink->h;
+  if (s->trace_flag) {
+    gettimeofday(&s->start,NULL);
+  }
+  s->ptr_sr_model_exec(s->handle, (void *)in->data[0], in->linesize[0] , out->linesize[0], (void*)out->data[0]);
+  if (s->trace_flag) {
+    gettimeofday(&s->end,NULL);
+    float time_use=(s->end.tv_sec-s->start.tv_sec)*1000000+(s->end.tv_usec-s->start.tv_usec);
+    av_log(ctx, AV_LOG_INFO, "Inference fps: %3f \n", 1000000 / time_use);
+  }
+  av_frame_free(&in);
+  return ff_filter_frame(outlink, out);
+}
+
+static av_cold int mlu_config_props(AVFilterLink *outlink) {
+  AVFilterContext *ctx = outlink->src;
+  AVFilterLink *inlink = outlink->src->inputs[0];
+  MLUSRContext *s = ctx->priv;
+  FILE *model;
+  outlink->w = 2 * inlink->w;
+  outlink->h = 2 * inlink->h;
+  outlink->format = AV_PIX_FMT_RGB24;
+  av_log(ctx, AV_LOG_VERBOSE, "w:%d h:%d -> w:%d h:%d\n", inlink->w, inlink->h, outlink->w, outlink->h);
+  if(s->lib) {
+    if (strlen(s->model_path) > 1) {
+      // av_log(ctx, AV_LOG_INFO, "model_path: %s\n", s->model_path);
+      s->ptr_sr_model_init(&s->handle, s->model_path, atoi(s->dev_id), atoi(s->channel_id));
+    } else {
+      char model_path[256];
+      if (readlink("/proc/self/exe", model_path, 256) < 0) {
+          av_log(ctx, AV_LOG_ERROR, "Failed to find ffmpeg\n");
+      }
+      char *tail = strrchr(model_path, '/');
+      *tail = '\0';
+      sprintf(model_path, "%s/libmlu/%dx%d.cambricon", model_path, inlink->w, inlink->h);
+      // av_log(ctx, AV_LOG_INFO, "model_path: %s\n", model_path);
+      if ((model = fopen(model_path,"rb")) == NULL) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to find model %s\n", model_path);
+      } else {
+        fclose(model);
+        s->ptr_sr_model_init(&s->handle, model_path, atoi(s->dev_id), atoi(s->channel_id));
+      }
+    }
+  }
+  return 0;
+}
+
+#define OFFSET(x) offsetof(MLUSRContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "model",     "model path",     OFFSET(model_path),   AV_OPT_TYPE_STRING, { .str = ""    }, .flags = FLAGS },
+    { "dev_id",    "device index",   OFFSET(dev_id),       AV_OPT_TYPE_STRING, { .str = "0"   }, .flags = FLAGS },
+    { "channel_id","channel index",  OFFSET(channel_id),   AV_OPT_TYPE_STRING, { .str = "-1"  }, .flags = FLAGS },
+    { "trace",     "trace switch",   OFFSET(trace_flag),   AV_OPT_TYPE_INT,    { .i64 = 0     },  0, 1, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlu_sr_class = {
+    .class_name = "mlu_sr",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlu_sr_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlu_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlu_sr_outputs[] = {
+    {
+        .name         = "default",
+        .config_props = mlu_config_props,
+        .type         = AVMEDIA_TYPE_VIDEO,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_sr_mlu = {
+    .name      = "sr_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video super-resolution reconstruction"),
+
+    .init          = mlu_sr_init,
+    .uninit        = mlu_sr_uninit,
+    .query_formats = mlu_sr_query_formats,
+
+    .priv_size = sizeof(MLUSRContext),
+    .priv_class = &mlu_sr_class,
+
+    .inputs    = mlu_sr_inputs,
+    .outputs   = mlu_sr_outputs,
+};
diff --git a/libavutil/Makefile b/libavutil/Makefile
index 8a7a44e4b5..0d80df750c 100644
--- a/libavutil/Makefile
+++ b/libavutil/Makefile
@@ -35,6 +35,7 @@ HEADERS = adler32.h                                                     \
           hmac.h                                                        \
           hwcontext.h                                                   \
           hwcontext_cuda.h                                              \
+          hwcontext_mlu.h                                               \
           hwcontext_d3d11va.h                                           \
           hwcontext_drm.h                                               \
           hwcontext_dxva2.h                                             \
@@ -163,6 +164,7 @@ OBJS = adler32.o                                                        \
        tx.o                                                             \
 
 OBJS-$(CONFIG_CUDA)                     += hwcontext_cuda.o
+OBJS-$(CONFIG_MLU)                      += hwcontext_mlu.o
 OBJS-$(CONFIG_D3D11VA)                  += hwcontext_d3d11va.o
 OBJS-$(CONFIG_DXVA2)                    += hwcontext_dxva2.o
 OBJS-$(CONFIG_LIBDRM)                   += hwcontext_drm.o
@@ -182,6 +184,7 @@ SLIBOBJS-$(HAVE_GNU_WINDRES)            += avutilres.o
 SKIPHEADERS-$(HAVE_CUDA_H)             += hwcontext_cuda.h
 SKIPHEADERS-$(CONFIG_CUDA)             += hwcontext_cuda_internal.h     \
                                           cuda_check.h
+SKIPHEADERS-$(CONFIG_MLU)              += hwcontext_mlu.h
 SKIPHEADERS-$(CONFIG_D3D11VA)          += hwcontext_d3d11va.h
 SKIPHEADERS-$(CONFIG_DXVA2)            += hwcontext_dxva2.h
 SKIPHEADERS-$(CONFIG_QSV)              += hwcontext_qsv.h
diff --git a/libavutil/hwcontext.c b/libavutil/hwcontext.c
index f1e404ab20..353d6eb8db 100644
--- a/libavutil/hwcontext.c
+++ b/libavutil/hwcontext.c
@@ -32,6 +32,9 @@ static const HWContextType * const hw_table[] = {
 #if CONFIG_CUDA
     &ff_hwcontext_type_cuda,
 #endif
+#if CONFIG_MLU
+    &ff_hwcontext_type_mlu,
+#endif
 #if CONFIG_D3D11VA
     &ff_hwcontext_type_d3d11va,
 #endif
@@ -64,6 +67,7 @@ static const HWContextType * const hw_table[] = {
 
 static const char *const hw_type_names[] = {
     [AV_HWDEVICE_TYPE_CUDA]   = "cuda",
+    [AV_HWDEVICE_TYPE_MLU]   = "mlu",
     [AV_HWDEVICE_TYPE_DRM]    = "drm",
     [AV_HWDEVICE_TYPE_DXVA2]  = "dxva2",
     [AV_HWDEVICE_TYPE_D3D11VA] = "d3d11va",
@@ -354,6 +358,7 @@ int av_hwframe_ctx_init(AVBufferRef *ref)
     if (ret < 0)
         return ret;
 
+
     /* format-specific init */
     if (ctx->internal->hw_type->frames_init) {
         ret = ctx->internal->hw_type->frames_init(ctx);
diff --git a/libavutil/hwcontext.h b/libavutil/hwcontext.h
index f5a4b62387..a2a272e1cf 100644
--- a/libavutil/hwcontext.h
+++ b/libavutil/hwcontext.h
@@ -28,6 +28,7 @@ enum AVHWDeviceType {
     AV_HWDEVICE_TYPE_NONE,
     AV_HWDEVICE_TYPE_VDPAU,
     AV_HWDEVICE_TYPE_CUDA,
+    AV_HWDEVICE_TYPE_MLU,
     AV_HWDEVICE_TYPE_VAAPI,
     AV_HWDEVICE_TYPE_DXVA2,
     AV_HWDEVICE_TYPE_QSV,
diff --git a/libavutil/hwcontext_internal.h b/libavutil/hwcontext_internal.h
index 77dc47ddd6..0f7bb9957f 100644
--- a/libavutil/hwcontext_internal.h
+++ b/libavutil/hwcontext_internal.h
@@ -163,6 +163,7 @@ int ff_hwframe_map_create(AVBufferRef *hwframe_ref,
 int ff_hwframe_map_replace(AVFrame *dst, const AVFrame *src);
 
 extern const HWContextType ff_hwcontext_type_cuda;
+extern const HWContextType ff_hwcontext_type_mlu;
 extern const HWContextType ff_hwcontext_type_d3d11va;
 extern const HWContextType ff_hwcontext_type_drm;
 extern const HWContextType ff_hwcontext_type_dxva2;
diff --git a/libavutil/hwcontext_mlu.c b/libavutil/hwcontext_mlu.c
new file mode 100644
index 0000000000..d1c96b57a9
--- /dev/null
+++ b/libavutil/hwcontext_mlu.c
@@ -0,0 +1,433 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <dlfcn.h>
+#include "buffer.h"
+#include "common.h"
+#include "hwcontext.h"
+#include "hwcontext_internal.h"
+#include "hwcontext_mlu.h"
+#include "mem.h"
+#include "pixdesc.h"
+#include "pixfmt.h"
+#include "imgutils.h"
+
+#define MLU_FRAME_ALIGNMENT 1 // mlu align
+
+#define CNRT_ERROR_CHECK(ctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(ctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return -1;                                                                         \
+    }
+
+typedef struct MLUFramesContext {
+    int shift_width, shift_height;
+} MLUFramesContext;
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_P010, AV_PIX_FMT_YUV420P,
+};
+
+static int mlu_frames_get_constraints(AVHWDeviceContext *ctx, const void *hwconfig,
+                                       AVHWFramesConstraints *constraints)
+{
+    int i;
+
+    constraints->valid_sw_formats = av_malloc_array(FF_ARRAY_ELEMS(supported_formats) + 1,
+                                                    sizeof(*constraints->valid_sw_formats));
+    if (!constraints->valid_sw_formats)
+        return AVERROR(ENOMEM);
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        constraints->valid_sw_formats[i] = supported_formats[i];
+    constraints->valid_sw_formats[FF_ARRAY_ELEMS(supported_formats)] = AV_PIX_FMT_NONE;
+
+    constraints->valid_hw_formats = av_malloc_array(2, sizeof(*constraints->valid_hw_formats));
+    if (!constraints->valid_hw_formats)
+        return AVERROR(ENOMEM);
+
+    constraints->valid_hw_formats[0] = AV_PIX_FMT_MLU;
+    constraints->valid_hw_formats[1] = AV_PIX_FMT_NONE;
+
+    return 0;
+}
+
+static void mlu_buffer_free(void *opaque, uint8_t *data)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    mlu_ctx->mluMemFree(data); // check
+}
+
+static AVBufferRef *mlu_pool_alloc(void *opaque, int size)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    AVBufferRef *ret = NULL;
+    void* data = NULL;
+
+    cnrtRet_t cnrt_ret;
+    cnrt_ret = mlu_ctx->mluMemAlloc((void **)(&data), size);
+    if (cnrt_ret != CNRT_RET_SUCCESS) {
+        av_log(ctx, AV_LOG_ERROR, "cnrtMalloc failed: dev addr %p, size %d \n", data, size);
+        return NULL;
+    }
+    ret = av_buffer_create((uint8_t*)data, size, mlu_buffer_free, ctx, 0);
+    if (!ret) {
+        mlu_ctx->mluMemFree(data);
+    }
+    return ret;
+}
+
+static int mlu_frames_init(AVHWFramesContext *ctx)
+{
+    MLUFramesContext *priv = ctx->internal->priv;
+    int i;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++) {
+        if (ctx->sw_format == supported_formats[i])
+            break;
+    }
+    if (i == FF_ARRAY_ELEMS(supported_formats)) {
+        av_log(ctx, AV_LOG_ERROR, "Pixel format '%s' is not supported\n",
+               av_get_pix_fmt_name(ctx->sw_format));
+        return AVERROR(ENOSYS);
+    }
+
+    av_pix_fmt_get_chroma_sub_sample(ctx->sw_format, &priv->shift_width, &priv->shift_height);
+
+    if (!ctx->pool) {
+        int size = av_image_get_buffer_size(ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+        if (size < 0)
+            return size;
+
+        ctx->internal->pool_internal = av_buffer_pool_init2(size, ctx, mlu_pool_alloc, NULL);
+        if (!ctx->internal->pool_internal)
+            return AVERROR(ENOMEM);
+    }
+
+    return 0;
+}
+
+static int mlu_get_buffer(AVHWFramesContext *ctx, AVFrame *frame)
+{
+    int res;
+
+    frame->buf[0] = av_buffer_pool_get(ctx->pool);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    res = av_image_fill_arrays(frame->data, frame->linesize, frame->buf[0]->data,
+                               ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+    if (res < 0)
+        return res;
+
+    frame->format = AV_PIX_FMT_MLU;
+    frame->width  = ctx->width;
+    frame->height = ctx->height;
+
+    return 0;
+}
+
+static int mlu_transfer_get_formats(AVHWFramesContext *ctx,
+                                     enum AVHWFrameTransferDirection dir,
+                                     enum AVPixelFormat **formats)
+{
+    enum AVPixelFormat *fmts;
+
+    fmts = av_malloc_array(2, sizeof(*fmts));
+    if (!fmts)
+        return AVERROR(ENOMEM);
+
+    fmts[0] = ctx->sw_format;
+    fmts[1] = AV_PIX_FMT_NONE;
+
+    *formats = fmts;
+
+    return 0;
+}
+
+static int mlu_transfer_data_from(AVHWFramesContext *ctx, AVFrame *dst,
+                                   const AVFrame *src)
+{
+    // MLUFramesContext        *priv = ctx->internal->priv;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext    *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    int i;
+    size_t nBytes;
+    cnrtRet_t cnrt_ret;
+    for (i = 0; i < FF_ARRAY_ELEMS(src->data) && src->data[i]; i++) {
+        // nBytes = src->linesize[i] * src->height * (i ? 1.0 / 2 : 1);
+        nBytes = FFMIN(src->linesize[i], dst->linesize[i]) * src->height * (i ? 1.0 / 2 : 1);
+        cnrt_ret = mlu_ctx->mluMemcpyD2H(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_DEV2HOST);
+        if (cnrt_ret != CNRT_RET_SUCCESS) {
+            av_log(ctx, AV_LOG_ERROR, "d2h: dev %p -> host %p size %lu \n", src->data[i], dst->data[i], nBytes);
+            av_log(ctx, AV_LOG_ERROR, " mluMemcpyD2H error occur, fuc: %s, line:%d\n", __func__, __LINE__);
+            return -1;
+        }
+    }
+
+    return 0;
+}
+
+static int mlu_transfer_data_to(AVHWFramesContext *ctx, AVFrame *dst,
+                                 const AVFrame *src)
+{
+    // MLUFramesContext        *priv = ctx->internal->priv;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    int i;
+    size_t nBytes;
+    cnrtRet_t cnrt_ret;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(src->data) && src->data[i]; i++) {
+        // nBytes = src->linesize[i] * src->height * (i ? 1.0 / 2 : 1);
+        nBytes = FFMIN(src->linesize[i], dst->linesize[i]) * src->height * (i ? 1.0 / 2 : 1);
+        cnrt_ret = mlu_ctx->mluMemcpyH2D(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_HOST2DEV);
+        if (cnrt_ret != CNRT_RET_SUCCESS) {
+            av_log(ctx, AV_LOG_ERROR, "h2d: host %p -> dev %p, size %lu \n", src->data[i], dst->data[i], nBytes);
+            av_log(ctx, AV_LOG_ERROR, "mluMemcpyH2D error occur, func: %s, line: %d\n", __func__, __LINE__);
+            return -1;
+        }
+    }
+
+    return 0;
+}
+
+static void mlu_device_uninit(AVHWDeviceContext *device_ctx)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+    if (hwctx->mlu_cnrt_lib) {
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_cnrt_lib = NULL;
+    }
+
+    hwctx->mlu_ctx->mluDestroy();
+
+    if (hwctx->mlu_ctx) {
+        av_freep(&hwctx->mlu_ctx);
+        hwctx->mlu_ctx = NULL;
+    }
+}
+
+static int mlu_device_init(AVHWDeviceContext *ctx)
+{
+    AVMLUDeviceContext *hwctx = ctx->hwctx;
+    if (!hwctx->mlu_ctx) {
+        hwctx->mlu_ctx = av_mallocz(sizeof(*hwctx->mlu_ctx));
+        if (!hwctx->mlu_ctx)
+            return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static int mlu_load_functions(AVMLUDeviceContext *hwctx, void *ctx) {
+    const char *cnrt_path = "libcnrt.so";
+    hwctx->mlu_cnrt_lib = dlopen(cnrt_path, RTLD_NOW | RTLD_GLOBAL);
+    if (!hwctx->mlu_cnrt_lib) {
+        av_log(ctx, AV_LOG_ERROR, "dlopen cnrt lib failed. \n");
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluInit = (cnrtRet_t (*)(int))dlsym(hwctx->mlu_cnrt_lib, "cnrtInit");
+    if (!hwctx->mlu_ctx->mluInit) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluInit()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluDestroy = (void (*)(void))dlsym(hwctx->mlu_cnrt_lib, "cnrtDestroy");
+    if (!hwctx->mlu_ctx->mluDestroy) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluDestroy()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceCount = (cnrtRet_t (*)(int *))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceCount");
+    if (!hwctx->mlu_ctx->mluGetDeviceCount) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceCount()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceHandle = (cnrtRet_t (*)(cnrtDev_t *, int))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceHandle");
+    if (!hwctx->mlu_ctx->mluGetDeviceHandle) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceHandle()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluSetDevice = (cnrtRet_t (*)(cnrtDev_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtSetCurrentDevice");
+    if (!hwctx->mlu_ctx->mluSetDevice) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluSetDevice()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluSetChannel = (cnrtRet_t (*)(cnrtChannelType_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtSetCurrentChannel");
+    if (!hwctx->mlu_ctx->mluSetChannel) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluSetChannel()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceInfo = (cnrtRet_t (*)(cnrtDeviceInfo_t *, int))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceInfo");
+    if (!hwctx->mlu_ctx->mluGetDeviceInfo) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceInfo()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+
+    hwctx->mlu_ctx->mluMemAlloc = (cnrtRet_t (*)(void **, size_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMalloc");
+    if (!hwctx->mlu_ctx->mluMemAlloc) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemAlloc()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemFree = (cnrtRet_t (*)(void *))dlsym(hwctx->mlu_cnrt_lib, "cnrtFree");
+    if (!hwctx->mlu_ctx->mluMemFree) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemFree()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyH2D = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyH2D) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyH2D()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyD2H = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyD2H) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyD2H()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyD2D = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyD2D) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyD2D()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+
+    return 0;
+}
+
+static int mlu_device_create(AVHWDeviceContext *device_ctx,
+                              const char *device,
+                              AVDictionary *opts, int flags)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+
+    MluContext *mlu_ctx = NULL;
+
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+    cnrtDeviceInfo_t dev_info;
+
+    int ret = 0;
+    int device_idx = 0;
+    unsigned int dev_num = 0;
+    if (device) device_idx = strtol(device, NULL, 0);
+
+    if (mlu_device_init(device_ctx) < 0)
+        goto error;
+
+    ret = mlu_load_functions(hwctx, device_ctx);
+    if (ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu load functions failed\n");
+        goto error;
+    }
+    mlu_ctx = hwctx->mlu_ctx;
+    cnrt_ret = mlu_ctx->mluInit(0);
+    if (cnrt_ret < 0){
+        av_log(device_ctx, AV_LOG_ERROR, "mlu init failed \n");
+        goto error;
+    }
+
+    cnrt_ret = mlu_ctx->mluGetDeviceCount(&dev_num);
+    if (cnrt_ret !=0 || dev_num == 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "Can't find MLU card, or dev count is 0 \n");
+        goto error;
+    }
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, device_idx);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        goto error;
+    }
+
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        goto error;
+    }
+
+    //cnrt_ret = mluSetChnnel(0);
+    //if (cnrt_ret < 0) goto error;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceInfo(&dev_info, device_idx);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu mluGetDeviceInfo failed \n");
+        goto error;
+    }
+
+    return 0;
+
+error:
+    mlu_device_uninit(device_ctx);
+    return AVERROR_UNKNOWN;
+}
+
+const HWContextType ff_hwcontext_type_mlu = {
+    .type                 = AV_HWDEVICE_TYPE_MLU,
+    .name                 = "MLU",
+
+    .device_hwctx_size    = sizeof(AVMLUDeviceContext),
+    .frames_priv_size     = sizeof(MLUFramesContext),
+
+    .device_create        = mlu_device_create,
+    .device_init          = mlu_device_init,
+    .device_uninit        = mlu_device_uninit,
+    .frames_get_constraints = mlu_frames_get_constraints,
+    .frames_init          = mlu_frames_init,
+    .frames_get_buffer    = mlu_get_buffer,
+    .transfer_get_formats = mlu_transfer_get_formats,
+    .transfer_data_to     = mlu_transfer_data_to,
+    .transfer_data_from   = mlu_transfer_data_from,
+
+    .pix_fmts             = (const enum AVPixelFormat[]){ AV_PIX_FMT_MLU, AV_PIX_FMT_NONE },
+};
diff --git a/libavutil/hwcontext_mlu.h b/libavutil/hwcontext_mlu.h
new file mode 100644
index 0000000000..4e78be91fa
--- /dev/null
+++ b/libavutil/hwcontext_mlu.h
@@ -0,0 +1,62 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+
+#ifndef AVUTIL_HWCONTEXT_MLU_H
+#define AVUTIL_HWCONTEXT_MLU_H
+
+#include <cnrt.h>
+#include "pixfmt.h"
+
+typedef struct MluContext {
+    // int ret = 0;
+    // cnrtRet_t cnrt_ret;
+    // cnrtDev_t dev;
+    // cnrtDeviceInfo_t dev_info;
+
+    /** operate dev **/
+    void      (*mluDestroy)(void);
+    cnrtRet_t (*mluInit)(int);
+    cnrtRet_t (*mluGetDeviceCount)(int *);
+    cnrtRet_t (*mluGetDeviceHandle)(cnrtDev_t *, int);
+    cnrtRet_t (*mluSetDevice)(cnrtDev_t);
+    cnrtRet_t (*mluSetChannel)(cnrtChannelType_t);
+    cnrtRet_t (*mluGetDeviceInfo)(cnrtDeviceInfo_t *, int);
+
+    // operate mem
+    cnrtRet_t (*mluMemFree)(void *);
+    cnrtRet_t (*mluMemAlloc)(void **, size_t);
+    cnrtRet_t (*mluMemcpyH2D)(void *, void *, size_t, cnrtMemTransDir_t);
+    cnrtRet_t (*mluMemcpyD2H)(void *, void *, size_t, cnrtMemTransDir_t);
+    cnrtRet_t (*mluMemcpyD2D)(void *, void *, size_t, cnrtMemTransDir_t);
+}MluContext;
+
+/**
+ * @file
+ * This struct is allocated as AVHWDeviceContext.hwctx
+ */
+typedef struct AVMLUDeviceContext {
+    void *mlu_cnrt_lib;
+    MluContext *mlu_ctx;
+} AVMLUDeviceContext;
+
+/**
+ * AVHWFramesContext.hwctx is currently not used
+ */
+
+#endif /* AVUTIL_HWCONTEXT_MLU_H */
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index b97b0665b0..db47325536 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -2050,6 +2050,10 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         .name = "cuda",
         .flags = AV_PIX_FMT_FLAG_HWACCEL,
     },
+    [AV_PIX_FMT_MLU] = {
+        .name = "mlu",
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
     [AV_PIX_FMT_AYUV64LE] = {
         .name = "ayuv64le",
         .nb_components = 4,
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 8b54c9415b..ace8536389 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -234,6 +234,12 @@ enum AVPixelFormat {
      */
     AV_PIX_FMT_CUDA,
 
+    /**
+     * HW acceleration through MLU. data[i] contain mlu deviceptr pointers
+     * exactly as for system memory frames.
+     */
+    AV_PIX_FMT_MLU,
+
     AV_PIX_FMT_0RGB,        ///< packed RGB 8:8:8, 32bpp, XRGBXRGB...   X=unused/undefined
     AV_PIX_FMT_RGB0,        ///< packed RGB 8:8:8, 32bpp, RGBXRGBX...   X=unused/undefined
     AV_PIX_FMT_0BGR,        ///< packed BGR 8:8:8, 32bpp, XBGRXBGR...   X=unused/undefined
-- 
2.17.1

