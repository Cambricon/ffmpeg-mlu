From 0a2454206324428c1b2ccb3926ae6fb8335b7020 Mon Sep 17 00:00:00 2001
From: solution-sdk <solution-sdk@cambricon.com>
Date: Mon, 9 May 2022 15:43:32 +0800
Subject: [PATCH] gen new patch

---
 configure                               |   14 +-
 doc/examples/Makefile                   |    3 +
 doc/examples/decode_mlu.c               |  213 ++++
 doc/examples/encode_mlu.c               |  252 +++++
 doc/examples/hw_decode_mlu.c            |  270 +++++
 fftools/Makefile                        |    1 +
 fftools/ffmpeg.h                        |    2 +
 fftools/ffmpeg_mlu.c                    |   74 ++
 fftools/ffmpeg_opt.c                    |    3 +
 libavcodec/Makefile                     |    8 +
 libavcodec/allcodecs.c                  |    8 +
 libavcodec/hwaccel.h                    |    2 +
 libavcodec/mlumpp_codec.h               |  236 ++++
 libavcodec/mlumpp_dec.c                 | 1325 +++++++++++++++++++++++
 libavcodec/mlumpp_enc_h264.c            |  215 ++++
 libavcodec/mlumpp_enc_hevc.c            |  224 ++++
 libavcodec/mlumpp_enc_jpeg.c            |  109 ++
 libavcodec/mlumpp_vid_enc.c             |  978 +++++++++++++++++
 libavcodec/mlumpp_vid_enc.h             |  120 ++
 libavfilter/Makefile                    |    8 +
 libavfilter/allfilters.c                |    9 +
 libavfilter/vf_cvt_rgbx2rgbx_mlu.c      |  526 +++++++++
 libavfilter/vf_cvt_rgbx2yuv_mlu.c       |  580 ++++++++++
 libavfilter/vf_cvt_yuv2rgbx_mlu.c       |  569 ++++++++++
 libavfilter/vf_hwdownload_mlu.c         |  214 ++++
 libavfilter/vf_hwupload_mlu.c           |  198 ++++
 libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c |  542 +++++++++
 libavfilter/vf_scale_rgbx2rgbx_mlu.c    |  555 ++++++++++
 libavfilter/vf_scale_yuv2yuv_mlu.c      |  567 ++++++++++
 libavutil/Makefile                      |    3 +
 libavutil/hwcontext.c                   |    5 +
 libavutil/hwcontext.h                   |    1 +
 libavutil/hwcontext_internal.h          |    1 +
 libavutil/hwcontext_mlu.c               |  435 ++++++++
 libavutil/hwcontext_mlu.h               |   63 ++
 libavutil/pixdesc.c                     |    4 +
 libavutil/pixfmt.h                      |    6 +
 37 files changed, 8342 insertions(+), 1 deletion(-)
 create mode 100644 doc/examples/decode_mlu.c
 create mode 100644 doc/examples/encode_mlu.c
 create mode 100644 doc/examples/hw_decode_mlu.c
 create mode 100644 fftools/ffmpeg_mlu.c
 mode change 100644 => 100755 libavcodec/Makefile
 mode change 100644 => 100755 libavcodec/allcodecs.c
 create mode 100644 libavcodec/mlumpp_codec.h
 create mode 100755 libavcodec/mlumpp_dec.c
 create mode 100644 libavcodec/mlumpp_enc_h264.c
 create mode 100644 libavcodec/mlumpp_enc_hevc.c
 create mode 100644 libavcodec/mlumpp_enc_jpeg.c
 create mode 100644 libavcodec/mlumpp_vid_enc.c
 create mode 100644 libavcodec/mlumpp_vid_enc.h
 create mode 100644 libavfilter/vf_cvt_rgbx2rgbx_mlu.c
 create mode 100644 libavfilter/vf_cvt_rgbx2yuv_mlu.c
 create mode 100644 libavfilter/vf_cvt_yuv2rgbx_mlu.c
 create mode 100644 libavfilter/vf_hwdownload_mlu.c
 create mode 100644 libavfilter/vf_hwupload_mlu.c
 create mode 100644 libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
 create mode 100644 libavfilter/vf_scale_rgbx2rgbx_mlu.c
 create mode 100644 libavfilter/vf_scale_yuv2yuv_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.h

diff --git a/configure b/configure
index 34c2adb4a4..1861c2ae4e 100755
--- a/configure
+++ b/configure
@@ -340,6 +340,7 @@ External library support:
   --disable-vaapi          disable Video Acceleration API (mainly Unix/Intel) code [autodetect]
   --disable-vdpau          disable Nvidia Video Decode and Presentation API for Unix code [autodetect]
   --disable-videotoolbox   disable VideoToolbox code [autodetect]
+  --enable-mlumpp          enable Cambricon MLU Media Process Platform code (mlumpp) [no]
 
 Toolchain options:
   --arch=ARCH              select architecture [$arch]
@@ -1685,6 +1686,9 @@ EXAMPLE_LIST="
     transcoding_example
     vaapi_encode_example
     vaapi_transcode_example
+    hw_decode_mlu_example
+    decode_mlu_example
+    encode_mlu_example
 "
 
 EXTERNAL_AUTODETECT_LIBRARY_LIST="
@@ -1738,6 +1742,7 @@ EXTERNAL_LIBRARY_VERSION3_LIST="
     libvo_amrwbenc
     mbedtls
     rkmpp
+    mlumpp
 "
 
 EXTERNAL_LIBRARY_GPLV3_LIST="
@@ -1831,6 +1836,7 @@ HWACCEL_AUTODETECT_LIBRARY_LIST="
     videotoolbox
     v4l2_m2m
     xvmc
+    mlu
 "
 
 # catchall list of things that require external libs to link
@@ -3019,6 +3025,8 @@ h264_qsv_decoder_select="h264_mp4toannexb_bsf h264_parser qsvdec"
 h264_qsv_encoder_select="qsvenc"
 h264_rkmpp_decoder_deps="rkmpp"
 h264_rkmpp_decoder_select="h264_mp4toannexb_bsf"
+h264_mlumpp_decoder_deps="mlumpp"
+h264_mlumpp_decoder_select="h264_mp4toannexb_bsf"
 h264_vaapi_encoder_select="cbs_h264 vaapi_encode"
 h264_v4l2m2m_decoder_deps="v4l2_m2m h264_v4l2_m2m"
 h264_v4l2m2m_decoder_select="h264_mp4toannexb_bsf"
@@ -3033,12 +3041,15 @@ hevc_qsv_decoder_select="hevc_mp4toannexb_bsf hevc_parser qsvdec"
 hevc_qsv_encoder_select="hevcparse qsvenc"
 hevc_rkmpp_decoder_deps="rkmpp"
 hevc_rkmpp_decoder_select="hevc_mp4toannexb_bsf"
+hevc_mlumpp_decoder_deps="mlumpp"
+hevc_mlumpp_decoder_select="hevc_mp4toannexb_bsf"
 hevc_vaapi_encoder_deps="VAEncPictureParameterBufferHEVC"
 hevc_vaapi_encoder_select="cbs_h265 vaapi_encode"
 hevc_v4l2m2m_decoder_deps="v4l2_m2m hevc_v4l2_m2m"
 hevc_v4l2m2m_decoder_select="hevc_mp4toannexb_bsf"
 hevc_v4l2m2m_encoder_deps="v4l2_m2m hevc_v4l2_m2m"
 mjpeg_cuvid_decoder_deps="cuvid"
+mjpeg_mlumpp_decoder_deps="mlumpp"
 mjpeg_qsv_encoder_deps="libmfx"
 mjpeg_qsv_encoder_select="qsvenc"
 mjpeg_vaapi_encoder_deps="VAEncPictureParameterBufferJPEG"
@@ -3069,6 +3080,7 @@ vc1_mmal_decoder_deps="mmal"
 vc1_qsv_decoder_select="qsvdec vc1_parser"
 vc1_v4l2m2m_decoder_deps="v4l2_m2m vc1_v4l2_m2m"
 vp8_cuvid_decoder_deps="cuvid"
+vp8_mlumpp_decoder_deps="mlumpp"
 vp8_mediacodec_decoder_deps="mediacodec"
 vp8_qsv_decoder_select="qsvdec vp8_parser"
 vp8_rkmpp_decoder_deps="rkmpp"
@@ -3077,6 +3089,7 @@ vp8_vaapi_encoder_select="vaapi_encode"
 vp8_v4l2m2m_decoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp8_v4l2m2m_encoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp9_cuvid_decoder_deps="cuvid"
+vp9_mlumpp_decoder_deps="mlumpp"
 vp9_mediacodec_decoder_deps="mediacodec"
 vp9_rkmpp_decoder_deps="rkmpp"
 vp9_vaapi_encoder_deps="VAEncPictureParameterBufferVP9"
@@ -6367,7 +6380,6 @@ enabled rkmpp             && { require_pkg_config rkmpp rockchip_mpp  rockchip/r
                              }
 enabled vapoursynth       && require_pkg_config vapoursynth "vapoursynth-script >= 42" VSScript.h vsscript_init
 
-
 if enabled gcrypt; then
     GCRYPT_CONFIG="${cross_prefix}libgcrypt-config"
     if "${GCRYPT_CONFIG}" --version > /dev/null 2>&1; then
diff --git a/doc/examples/Makefile b/doc/examples/Makefile
index 2935424e54..ee14c08ffc 100644
--- a/doc/examples/Makefile
+++ b/doc/examples/Makefile
@@ -21,6 +21,9 @@ EXAMPLES-$(CONFIG_TRANSCODE_AAC_EXAMPLE)     += transcode_aac
 EXAMPLES-$(CONFIG_TRANSCODING_EXAMPLE)       += transcoding
 EXAMPLES-$(CONFIG_VAAPI_ENCODE_EXAMPLE)      += vaapi_encode
 EXAMPLES-$(CONFIG_VAAPI_TRANSCODE_EXAMPLE)   += vaapi_transcode
+EXAMPLES-$(CONFIG_HW_DECODE_MLU_EXAMPLE)     += hw_decode_mlu
+EXAMPLES-$(CONFIG_DECODE_MLU_EXAMPLE)        += decode_mlu
+EXAMPLES-$(CONFIG_ENCODE_MLU_EXAMPLE)        += encode_mlu
 
 EXAMPLES       := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)$(EXESUF))
 EXAMPLES_G     := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)_g$(EXESUF))
diff --git a/doc/examples/decode_mlu.c b/doc/examples/decode_mlu.c
new file mode 100644
index 0000000000..233bb81daf
--- /dev/null
+++ b/doc/examples/decode_mlu.c
@@ -0,0 +1,213 @@
+/*
+ * MLU MPP Video Acceleration API decode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated decoding example.
+ *
+ * @example decode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated decoding with output
+ * frames from the video surfaces.
+ * Usage: decode_mlu input.mp4 output.yuv
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+
+static FILE *fp_yuv;
+static int video_stream_idx;
+static AVCodecContext  *g_dec_ctx;
+static AVFormatContext *g_ifmt_ctx;
+
+static int init_decode(const char *in_file, const char *out_file, int dev_id) {
+    int ret;
+    AVStream     *video    = NULL;
+    AVCodec      *p_codec  = NULL;
+    AVDictionary *options  = NULL;
+    AVDictionary *dec_opts = NULL;
+
+    if ((ret = avformat_network_init()) != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_network_init failed, ret(%d)\n", ret);
+        return ret;
+    }
+    if (!strncmp(in_file, "rtsp", 4) || !strncmp(in_file, "rtmp", 4)) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode rtsp/rtmp stream\n");
+        av_dict_set(&options, "buffer_size",    "1024000",  0);
+        av_dict_set(&options, "max_delay",      "500000",   0);
+        av_dict_set(&options, "stimeout",       "20000000", 0);
+        av_dict_set(&options, "rtsp_transport", "tcp",      0);
+    } else {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode local file stream\n");
+        av_dict_set(&options, "stimeout", "20000000", 0);
+        av_dict_set(&options, "vsync", "0",           0);
+    }
+
+    g_ifmt_ctx = avformat_alloc_context();
+    ret = avformat_open_input(&g_ifmt_ctx, in_file, NULL, &options);
+    av_dict_free(&options);
+    if (ret != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_open_input failed, ret(%d)\n",ret);
+        return ret;
+    }
+    ret = avformat_find_stream_info(g_ifmt_ctx, NULL);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_find_stream_info failed, ret(%d)\n", ret);
+        return ret;
+    }
+    for (size_t i = 0; i < g_ifmt_ctx->nb_streams; i++) {
+        if (g_ifmt_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            video = g_ifmt_ctx->streams[i];
+            video_stream_idx = i;
+            break;
+        }
+    }
+    if (NULL == video) {
+        av_log(g_dec_ctx, AV_LOG_ERROR, "video stream is NULL\n");
+        return -1;
+    }
+    switch(video->codecpar->codec_id) {
+    case AV_CODEC_ID_H264:
+        p_codec = avcodec_find_decoder_by_name("h264_mludec");     break;
+    case AV_CODEC_ID_HEVC:
+        p_codec = avcodec_find_decoder_by_name("hevc_mludec");     break;
+    case AV_CODEC_ID_VP8:
+        p_codec = avcodec_find_decoder_by_name("vp8_mludec");      break;
+    case AV_CODEC_ID_VP9:
+        p_codec = avcodec_find_decoder_by_name("vp9_mludec");      break;
+    case AV_CODEC_ID_MJPEG:
+        p_codec = avcodec_find_decoder_by_name("mjpeg_mludec");    break;
+    default:
+        p_codec = avcodec_find_decoder(video->codecpar->codec_id); break;
+    }
+    if(p_codec == NULL) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Unsupported codec! \n");
+        return -1;
+    }
+    g_dec_ctx = avcodec_alloc_context3(p_codec);
+    if(avcodec_parameters_to_context(g_dec_ctx, video->codecpar) != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Could not copy codec context, ret(%d)\n", ret);
+        return -1;
+    }
+
+    av_dict_set_int(&dec_opts, "device_id", dev_id, 0);
+
+    if(avcodec_open2(g_dec_ctx, p_codec, &dec_opts) < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Could not open codec, ret(%d)\n", ret);
+        return -1;
+    }
+    av_dict_free(&dec_opts);
+
+    fp_yuv = fopen(out_file, "wb+");
+
+    return 0;
+}
+
+static void  save_yuv_file(AVFrame *p_frame) {
+    fwrite(p_frame->data[0], 1, p_frame->width * p_frame->height, fp_yuv);
+    fwrite(p_frame->data[1], 1, (p_frame->width * p_frame->height) / 2, fp_yuv);
+}
+
+static int decode(AVCodecContext *dec_ctx) {
+   int ret;
+    AVPacket packet;
+    AVFrame *p_frame;
+    av_init_packet(&packet);
+    p_frame = av_frame_alloc();
+    while(1) {
+        ret = av_read_frame(g_ifmt_ctx, &packet);
+        if (ret == AVERROR_EOF) {
+            // av_log(g_dec_ctx, AV_LOG_INFO, "av_read_frame got eof\n");
+        } else if (ret < 0) {
+            av_log(g_dec_ctx, AV_LOG_ERROR, "av_read_frame failed, ret(%d)\n", ret);
+            return ret;
+        }
+        if (packet.stream_index != video_stream_idx) {
+            av_packet_unref(&packet);
+            continue;
+        }
+        ret = avcodec_send_packet(dec_ctx, &packet);
+        if (ret < 0) {
+            av_log(dec_ctx, AV_LOG_ERROR,
+                "send pkt failed, ret(%d), %s, %d\n", ret, __FILE__, __LINE__);
+            return ret;
+        }
+        while (ret >= 0) {
+            ret = avcodec_receive_frame(dec_ctx, p_frame);
+            if (ret == AVERROR_EOF) {
+                // av_log(g_dec_ctx, AV_LOG_INFO, "dec receive eof\n");
+                av_frame_unref(p_frame);
+                return 0;
+            } else if (ret == 0) {
+                save_yuv_file(p_frame);
+                av_frame_unref(p_frame);
+            } else if (ret < 0 && ret != AVERROR(EAGAIN)) {
+                av_log(dec_ctx, AV_LOG_ERROR, "receive frame failed\n");
+                return ret;
+            }
+        }
+        av_packet_unref(&packet);
+    }
+
+    av_frame_free(&p_frame);
+
+    return 0;
+}
+
+int main (int argc, char **argv) {
+    int ret = -1;
+    int dev_id = 0;
+    const char *in_file, *out_file;
+
+    if (argc <= 2) {
+        av_log(g_dec_ctx, AV_LOG_WARNING,
+            "Usage: %s <in file> <out file> [option dev_id]\n", argv[0]);
+        return -1;
+    }
+    in_file  = argv[1];
+    out_file = argv[2];
+    if (argv[3]) {
+        dev_id = atoi(argv[3]);
+    }
+
+    ret = init_decode(in_file, out_file, dev_id);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "init decode failed \n");
+        return -1;
+    }
+
+    ret = decode(g_dec_ctx);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode failed\n");
+        return -1;
+    }
+
+    av_log(g_dec_ctx, AV_LOG_INFO, "decode_mlu test finish\n");
+    fclose(fp_yuv);
+    avformat_close_input(&g_ifmt_ctx);
+    avcodec_free_context(&g_dec_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/encode_mlu.c b/doc/examples/encode_mlu.c
new file mode 100644
index 0000000000..611d5165b0
--- /dev/null
+++ b/doc/examples/encode_mlu.c
@@ -0,0 +1,252 @@
+/*
+ * MLU MPP Video Acceleration API encode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated encoding example.
+ *
+ * @example encode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated encoding.
+ * Usage: encode_mlu output.h264 h264
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+
+static FILE *fp_yuv;
+static AVCodecContext *g_enc_ctx;
+
+static int init_encode(const char *out_file,
+                       const char *codec_type,
+                       int in_w, int int_h, int dev_id) {
+    int ret;
+    AVCodec      *p_codec  = NULL;
+    AVDictionary *enc_opts = NULL;
+
+    if ((ret = avformat_network_init()) != 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avformat_network_init failed, ret(%d)\n", ret);
+        return ret;
+    }
+    if (!strcmp(codec_type, "h264")) {
+        p_codec = avcodec_find_encoder_by_name("h264_mluenc");
+    } else if (!strcmp(codec_type, "hevc")) {
+        p_codec = avcodec_find_encoder_by_name("hevc_mluenc");
+    } else if (!strcmp(codec_type, "mjpeg")) {
+        p_codec = avcodec_find_encoder_by_name("mjpeg_mluenc");
+    } else {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "unsupport mlu encoder\n");
+        return -1;
+    }
+    if(!p_codec) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "encoder find failed.\n");
+        return -1;
+    }
+
+    g_enc_ctx = avcodec_alloc_context3(p_codec);
+    if (!g_enc_ctx) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "could not allocate video codec context\n");
+        return -1;
+    }
+
+    g_enc_ctx->width     = in_w;
+    g_enc_ctx->height    = int_h;
+    g_enc_ctx->bit_rate  = 1000000;
+    g_enc_ctx->time_base = (AVRational) {1, 25};
+    g_enc_ctx->framerate = (AVRational) {25, 1};
+    // g_enc_ctx->gop_size = 10;
+    // g_enc_ctx->max_b_frames = 1;
+    g_enc_ctx->pix_fmt = AV_PIX_FMT_NV12;
+
+    av_dict_set_int(&enc_opts, "device_id", dev_id, 0);
+
+    ret = avcodec_open2(g_enc_ctx, p_codec, &enc_opts);
+    if(ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avcodec open failed.\n");
+        return -1;
+    }
+    av_dict_free(&enc_opts);
+
+    fp_yuv = fopen(out_file, "wb");
+    if (!fp_yuv) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "Could not open %s\n", out_file);
+        return -1;
+    }
+
+    return 0;
+}
+
+static int make_frame_auto(AVCodecContext *enc_ctx, AVFrame *frame, int frame_id) {
+    int ret, x, y;
+    /* make sure the frame data is writable */
+    ret = av_frame_make_writable(frame);
+    if (ret < 0)
+        return -1;
+    /* prepare a dummy image, NV12 */
+    /* Y */
+    for (y = 0; y < enc_ctx->height; y++) {
+        for (x = 0; x < enc_ctx->width; x++) {
+            frame->data[0][y*frame->linesize[0]+x] = x + y + frame_id * 3;
+        }
+    }
+    /* Cb and Cr */
+    for (y = 0; y < enc_ctx->height / 2; y++) {
+        for (x = 0; x < enc_ctx->width; x+=2) {
+            frame->data[1][y*frame->linesize[1]+x]   = 128 + y + frame_id * 2;
+            frame->data[1][y*frame->linesize[1]+x+1] = 64  + x + frame_id * 5;
+        }
+    }
+
+    frame->pts = frame_id;
+    return 0;
+}
+
+static int encode_frame(AVCodecContext *enc_ctx, AVFrame *frame, AVPacket *pkt,
+                   FILE *outfile)
+{
+    int ret;
+    if (frame)
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Send frame %3"PRId64"\n", frame->pts);
+
+    ret = avcodec_send_frame(enc_ctx, frame);
+    if (ret < 0) {
+        av_log(enc_ctx, AV_LOG_ERROR,
+            "Error sending a frame for encoding\n");
+        return -1;
+    }
+
+    while (ret >= 0) {
+        ret = avcodec_receive_packet(enc_ctx, pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+            return 0;
+        else if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "Error during encoding\n");
+            return -1;
+        }
+
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Write packet %3"PRId64" (size=%5d)\n", pkt->pts, pkt->size);
+        fwrite(pkt->data, 1, pkt->size, outfile);
+        av_packet_unref(pkt);
+    }
+
+    return 0;
+}
+
+static int encode(AVCodecContext *enc_ctx, FILE *outfile, int frame_num) {
+    int ret, cnt = -1;
+    AVFrame *frame;
+    AVPacket *pkt;
+    uint8_t endcode[] = {0, 0, 1, 0xb7};
+
+    pkt = av_packet_alloc();
+    av_init_packet(pkt);
+    frame = av_frame_alloc();
+    frame->width  = enc_ctx->width;
+    frame->height = enc_ctx->height;
+    frame->format = enc_ctx->pix_fmt;
+    ret = av_frame_get_buffer(frame, 0);
+    if (ret < 0) {
+        av_log(enc_ctx, AV_LOG_ERROR,
+            "Could not allocate the video frame data\n");
+        return -1;
+    }
+
+    while (cnt++ < frame_num) {
+        ret = make_frame_auto(enc_ctx, frame, cnt);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "make frame auto failed, ret%d\n", ret);
+            return -1;
+        }
+        ret = encode_frame(enc_ctx, frame, pkt, outfile);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "encode_frame failed, ret%d\n", ret);
+            return -1;
+        }
+    }
+
+    encode_frame(enc_ctx, NULL, pkt, outfile);
+    // add sequence end code to have a real MPEG file
+    fwrite(endcode, 1, sizeof(endcode), outfile);
+
+    av_frame_free(&frame);
+    av_packet_free(&pkt);
+
+    return 0;
+}
+
+int main (int argc, char **argv) {
+    int ret = -1;
+    int dev_id = 0, in_w, in_h, frame_num;
+    const char *out_file;
+    char codec_type[10] = "h264";
+    char *enc_type = NULL;
+
+    if (argc <= 1) {
+        av_log(g_enc_ctx, AV_LOG_WARNING,
+            "Usage: %s <out file> <dev_id> [option <enc_type>, h264 or hevc]\n",
+                argv[0]);
+        return -1;
+    }
+
+    out_file = argv[1];
+    if (argv[2]) dev_id = atoi(argv[2]);
+    else         dev_id = 0;
+    if (argv[3]) enc_type = argv[3];
+    else         enc_type = codec_type;
+
+    in_w      = 960;
+    in_h      = 540;
+    frame_num = 500;
+
+    ret = init_encode(out_file, enc_type, in_w, in_h, dev_id);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "init decode failed \n");
+        return -1;
+    }
+
+    ret = encode(g_enc_ctx, fp_yuv, frame_num);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "decode failed\n");
+        return -1;
+    }
+
+    av_log(g_enc_ctx, AV_LOG_INFO,
+        "\n enc type:%s w:%d, h:%d, dev id:%d, frame num:%d\n",
+        enc_type, in_w, in_h, dev_id, frame_num);
+    av_log(g_enc_ctx, AV_LOG_INFO, "encode_mlu test finish\n");
+    fclose(fp_yuv);
+    avcodec_free_context(&g_enc_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/hw_decode_mlu.c b/doc/examples/hw_decode_mlu.c
new file mode 100644
index 0000000000..e1e04e3d47
--- /dev/null
+++ b/doc/examples/hw_decode_mlu.c
@@ -0,0 +1,270 @@
+/*
+ * MLU MPP Video Acceleration API (video transcoding) transcode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated decoding example.
+ *
+ * @example hw_decode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated decoding with output
+ * frames from the HW video surfaces.
+ * Usage: hw_decode_mlu mlu input.mp4 output.yuv
+ */
+
+#include <stdio.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+#include <libavutil/pixdesc.h>
+#include <libavutil/hwcontext.h>
+#include <libavutil/opt.h>
+#include <libavutil/avassert.h>
+#include <libavutil/imgutils.h>
+
+static AVBufferRef *hw_device_ctx = NULL;
+static FILE *output_file          = NULL;
+static enum AVPixelFormat hw_pix_fmt;
+
+static int hw_decoder_init(
+    AVCodecContext *ctx, const enum AVHWDeviceType type, const char *dev_id) {
+    int err = 0;
+
+    if ((err = av_hwdevice_ctx_create(&hw_device_ctx, type,
+                                      dev_id, NULL, 0)) < 0) {
+        fprintf(stderr, "Failed to create specified HW device.\n");
+        return err;
+    }
+    ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);
+
+    return err;
+}
+
+static enum AVPixelFormat get_hw_format(AVCodecContext *ctx,
+                                        const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+
+    for (p = pix_fmts; *p != -1; p++) {
+        if (*p == hw_pix_fmt)
+            return *p;
+    }
+
+    fprintf(stderr, "Failed to get HW surface format.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int decode_write(AVCodecContext *avctx, AVPacket *packet)
+{
+    AVFrame *frame     = NULL;
+    AVFrame *sw_frame  = NULL;
+    AVFrame *tmp_frame = NULL;
+    uint8_t *buffer    = NULL;
+    int size;
+    int ret = -1;
+
+    ret = avcodec_send_packet(avctx, packet);
+    if (ret < 0) {
+        fprintf(stderr, "Error during decoding\n");
+        return ret;
+    }
+
+    while (1) {
+        if (!(frame = av_frame_alloc()) || !(sw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Can not alloc frame\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        ret = avcodec_receive_frame(avctx, frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            av_frame_free(&frame);
+            av_frame_free(&sw_frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding\n");
+            goto fail;
+        }
+
+        if (frame->format == hw_pix_fmt) {
+            if ((ret = av_hwframe_transfer_data(sw_frame, frame, 0)) < 0) {
+                fprintf(stderr, "Error transferring the data to system memory\n");
+                goto fail;
+            }
+            tmp_frame = sw_frame;
+        } else
+            tmp_frame = frame;
+
+        size = av_image_get_buffer_size(tmp_frame->format, tmp_frame->width,
+                                        tmp_frame->height, 1);
+        buffer = av_malloc(size);
+        if (!buffer) {
+            fprintf(stderr, "Can not alloc buffer\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        ret = av_image_copy_to_buffer(buffer, size,
+                                      (const uint8_t * const *)tmp_frame->data,
+                                      (const int *)tmp_frame->linesize, tmp_frame->format,
+                                      tmp_frame->width, tmp_frame->height, 1);
+        if (ret < 0) {
+            fprintf(stderr, "Can not copy image to buffer\n");
+            goto fail;
+        }
+
+        if ((ret = fwrite(buffer, 1, size, output_file)) < 0) {
+            fprintf(stderr, "Failed to dump raw data.\n");
+            goto fail;
+        }
+
+    fail:
+        av_frame_free(&frame);
+        av_frame_free(&sw_frame);
+        av_freep(&buffer);
+        if (ret < 0)
+            return ret;
+    }
+    return 0;
+}
+
+int main(int argc, char *argv[])
+{
+    AVFormatContext *input_ctx = NULL;
+    AVStream        *video     = NULL;
+    AVCodecContext *decode_ctx = NULL;
+    AVCodec       *decoder     = NULL;
+    AVDictionary  *dec_opts    = NULL;
+
+    AVPacket packet;
+    enum AVHWDeviceType type;
+    int i, video_stream, ret;
+    const char *dev_type, *dev_id;
+    const char *in_file, *out_file;
+
+    if (argc < 2) {
+        fprintf(stderr,
+            "Usage:%s <input file> <output file> <dev id>\n", argv[0]);
+        return -1;
+    }
+
+    dev_type = "mlu";
+    in_file  = argv[1];
+    out_file = argv[2];
+    dev_id   = argv[3];
+
+    type = av_hwdevice_find_type_by_name(dev_type);
+    if (type == AV_HWDEVICE_TYPE_NONE) {
+        fprintf(stderr, "Device type %s is not supported.\n", dev_type);
+        fprintf(stderr, "Available device types:");
+        while((type = av_hwdevice_iterate_types(type)) != AV_HWDEVICE_TYPE_NONE)
+            fprintf(stderr, " %s", av_hwdevice_get_type_name(type));
+        fprintf(stderr, "\n");
+        return -1;
+    }
+
+    if (avformat_open_input(&input_ctx,in_file, NULL, NULL) != 0) {
+        fprintf(stderr, "Cannot open input file '%s'\n", in_file);
+        return -1;
+    }
+
+    if (avformat_find_stream_info(input_ctx, NULL) < 0) {
+        fprintf(stderr, "Cannot find input stream information.\n");
+        return -1;
+    }
+
+    decoder = avcodec_find_decoder_by_name("h264_mludec");
+    if (!decoder) {
+        fprintf(stderr, "The MLU decoder is not present in libavcodec\n");
+        return -1;
+    }
+
+    for (size_t i = 0; i < input_ctx->nb_streams; i++) {
+        if (input_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            video_stream = i;
+        }
+    }
+
+    for (i = 0;; i++) {
+        const AVCodecHWConfig *config = avcodec_get_hw_config(decoder, i);
+        if (!config) {
+            fprintf(stderr, "Decoder %s does not support device type %s.\n",
+                    decoder->name, av_hwdevice_get_type_name(type));
+            return -1;
+        }
+        if (config->methods & AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &&
+            config->device_type == type) {
+            hw_pix_fmt = config->pix_fmt;
+            break;
+        }
+    }
+
+    if (!(decode_ctx = avcodec_alloc_context3(decoder)))
+        return AVERROR(ENOMEM);
+
+    video = input_ctx->streams[video_stream];
+    if (avcodec_parameters_to_context(decode_ctx, video->codecpar) < 0)
+        return -1;
+
+    decode_ctx->get_format  = get_hw_format;
+
+    if (hw_decoder_init(decode_ctx, type, dev_id) < 0)
+        return -1;
+
+    av_dict_set(&dec_opts, "device_id", dev_id, 0);
+    if ((ret = avcodec_open2(decode_ctx, decoder, &dec_opts)) < 0) {
+        fprintf(stderr, "Failed to open codec for stream #%d\n", video_stream);
+        return -1;
+    }
+    av_dict_free(&dec_opts);
+
+    /* open the file to dump raw data */
+    output_file = fopen(out_file, "w+");
+
+    while (ret >= 0) {
+        if ((ret = av_read_frame(input_ctx, &packet)) < 0)
+            break;
+
+        if (video_stream != packet.stream_index) {
+            continue;
+        }
+        ret = decode_write(decode_ctx, &packet);
+        if (ret)
+            break;
+
+        av_packet_unref(&packet);
+    }
+
+    /* flush the decoder */
+    packet.data = NULL;
+    packet.size = 0;
+    ret = decode_write(decode_ctx, &packet);
+    av_packet_unref(&packet);
+
+    if (output_file) {
+        fclose(output_file);
+    }
+    av_log(decode_ctx, AV_LOG_INFO, "decode_mlu test finish\n");
+    avcodec_free_context(&decode_ctx);
+    avformat_close_input(&input_ctx);
+    av_buffer_unref(&hw_device_ctx);
+
+    return 0;
+}
diff --git a/fftools/Makefile b/fftools/Makefile
index 6cec666dd9..ea35e26a4c 100644
--- a/fftools/Makefile
+++ b/fftools/Makefile
@@ -12,6 +12,7 @@ ALLAVPROGS_G = $(AVBASENAMES:%=%$(PROGSSUF)_g$(EXESUF))
 OBJS-ffmpeg                        += fftools/ffmpeg_opt.o fftools/ffmpeg_filter.o fftools/ffmpeg_hw.o
 OBJS-ffmpeg-$(CONFIG_CUVID)        += fftools/ffmpeg_cuvid.o
 OBJS-ffmpeg-$(CONFIG_LIBMFX)       += fftools/ffmpeg_qsv.o
+OBJS-ffmpeg-$(CONFIG_MLU)          += fftools/ffmpeg_mlu.o
 ifndef CONFIG_VIDEOTOOLBOX
 OBJS-ffmpeg-$(CONFIG_VDA)          += fftools/ffmpeg_videotoolbox.o
 endif
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 7b6f802082..210ebbe01b 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -62,6 +62,7 @@ enum HWAccelID {
     HWACCEL_VIDEOTOOLBOX,
     HWACCEL_QSV,
     HWACCEL_CUVID,
+    HWACCEL_MLU,
 };
 
 typedef struct HWAccel {
@@ -655,6 +656,7 @@ int ffmpeg_parse_options(int argc, char **argv);
 int videotoolbox_init(AVCodecContext *s);
 int qsv_init(AVCodecContext *s);
 int cuvid_init(AVCodecContext *s);
+int mlu_init(AVCodecContext *s);
 
 HWDevice *hw_device_get_by_name(const char *name);
 int hw_device_init_from_string(const char *arg, HWDevice **dev);
diff --git a/fftools/ffmpeg_mlu.c b/fftools/ffmpeg_mlu.c
new file mode 100644
index 0000000000..68764b6173
--- /dev/null
+++ b/fftools/ffmpeg_mlu.c
@@ -0,0 +1,74 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/pixdesc.h"
+
+#include "ffmpeg.h"
+
+static void mlu_uninit(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    av_buffer_unref(&ist->hw_frames_ctx);
+}
+
+int mlu_init(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    AVHWFramesContext *frames_ctx;
+    int ret;
+
+    av_log(avctx, AV_LOG_VERBOSE, "Initializing mlu hwaccel\n");
+
+    if (!hw_device_ctx) {
+        ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_MLU,
+                                     ist->hwaccel_device, NULL, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Error creating a MLU device\n");
+            return ret;
+        }
+    }
+
+    av_buffer_unref(&ist->hw_frames_ctx);
+    ist->hw_frames_ctx = av_hwframe_ctx_alloc(hw_device_ctx);
+    if (!ist->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR, "Error creating a MLU frames context\n");
+        return AVERROR(ENOMEM);
+    }
+
+    frames_ctx = (AVHWFramesContext*)ist->hw_frames_ctx->data;
+    frames_ctx->format    = AV_PIX_FMT_MLU;
+    frames_ctx->sw_format = avctx->sw_pix_fmt;
+    frames_ctx->width     = avctx->width;
+    // frames_ctx->height = avctx->height;
+    frames_ctx->height    = FFALIGN(avctx->height, 16);
+
+    av_log(avctx, AV_LOG_DEBUG, "Initializing MLU frames context: sw_format = %s, width = %d, height = %d\n",
+           av_get_pix_fmt_name(frames_ctx->sw_format), frames_ctx->width, frames_ctx->height);
+
+    ret = av_hwframe_ctx_init(ist->hw_frames_ctx);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error initializing a MLU frame pool\n");
+        return ret;
+    }
+
+    ist->hwaccel_uninit = mlu_uninit;
+
+    return 0;
+}
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index f5ca18aa64..1609135935 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -74,6 +74,9 @@ const HWAccel hwaccels[] = {
 #endif
 #if CONFIG_CUVID
     { "cuvid", cuvid_init, HWACCEL_CUVID, AV_PIX_FMT_CUDA },
+#endif
+#if CONFIG_MLU
+   { "mlu", mlu_init, HWACCEL_MLU, AV_PIX_FMT_MLU },
 #endif
     { 0 },
 };
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
old mode 100644
new mode 100755
index 3cd73fbcc6..b058f9d4b2
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -347,6 +347,8 @@ OBJS-$(CONFIG_H264_DECODER)            += h264dec.o h264_cabac.o h264_cavlc.o \
                                           h264_mb.o h264_picture.o \
                                           h264_refs.o h264_sei.o \
                                           h264_slice.o h264data.o
+OBJS-$(CONFIG_H264_MLUMPP_DECODER)     += mlumpp_dec.o
+OBJS-$(CONFIG_H264_MLUMPP_ENCODER)     += mlumpp_vid_enc.o mlumpp_enc_h264.o
 OBJS-$(CONFIG_H264_AMF_ENCODER)        += amfenc_h264.o
 OBJS-$(CONFIG_H264_CUVID_DECODER)      += cuviddec.o
 OBJS-$(CONFIG_H264_MEDIACODEC_DECODER) += mediacodecdec.o
@@ -368,6 +370,8 @@ OBJS-$(CONFIG_HCOM_DECODER)            += hcom.o
 OBJS-$(CONFIG_HEVC_DECODER)            += hevcdec.o hevc_mvs.o \
                                           hevc_cabac.o hevc_refs.o hevcpred.o    \
                                           hevcdsp.o hevc_filter.o hevc_data.o
+OBJS-$(CONFIG_HEVC_MLUMPP_DECODER)     += mlumpp_dec.o
+OBJS-$(CONFIG_HEVC_MLUMPP_ENCODER)     += mlumpp_vid_enc.o mlumpp_enc_hevc.o
 OBJS-$(CONFIG_HEVC_AMF_ENCODER)        += amfenc_hevc.o
 OBJS-$(CONFIG_HEVC_CUVID_DECODER)      += cuviddec.o
 OBJS-$(CONFIG_HEVC_MEDIACODEC_DECODER) += mediacodecdec.o
@@ -427,10 +431,12 @@ OBJS-$(CONFIG_MIMIC_DECODER)           += mimic.o
 OBJS-$(CONFIG_MJPEG_DECODER)           += mjpegdec.o
 OBJS-$(CONFIG_MJPEG_ENCODER)           += mjpegenc.o mjpegenc_common.o \
                                           mjpegenc_huffman.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_DECODER)    += mlumpp_dec.o
 OBJS-$(CONFIG_MJPEGB_DECODER)          += mjpegbdec.o
 OBJS-$(CONFIG_MJPEG_CUVID_DECODER)     += cuviddec.o
 OBJS-$(CONFIG_MJPEG_QSV_ENCODER)       += qsvenc_jpeg.o
 OBJS-$(CONFIG_MJPEG_VAAPI_ENCODER)     += vaapi_encode_mjpeg.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_ENCODER)    += mlumpp_vid_enc.o mlumpp_enc_jpeg.o
 OBJS-$(CONFIG_MLP_DECODER)             += mlpdec.o mlpdsp.o
 OBJS-$(CONFIG_MLP_ENCODER)             += mlpenc.o mlp.o
 OBJS-$(CONFIG_MMVIDEO_DECODER)         += mmvideo.o
@@ -666,6 +672,7 @@ OBJS-$(CONFIG_VP3_DECODER)             += vp3.o
 OBJS-$(CONFIG_VP5_DECODER)             += vp5.o vp56.o vp56data.o vp56rac.o
 OBJS-$(CONFIG_VP6_DECODER)             += vp6.o vp56.o vp56data.o \
                                           vp6dsp.o vp56rac.o
+OBJS-$(CONFIG_VP8_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VP7_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_DECODER)             += vp8.o vp56rac.o
 OBJS-$(CONFIG_VP8_CUVID_DECODER)       += cuviddec.o
@@ -678,6 +685,7 @@ OBJS-$(CONFIG_VP8_V4L2M2M_ENCODER)     += v4l2_m2m_enc.o
 OBJS-$(CONFIG_VP9_DECODER)             += vp9.o vp9data.o vp9dsp.o vp9lpf.o vp9recon.o \
                                           vp9block.o vp9prob.o vp9mvs.o vp56rac.o \
                                           vp9dsp_8bpp.o vp9dsp_10bpp.o vp9dsp_12bpp.o
+OBJS-$(CONFIG_VP9_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VP9_CUVID_DECODER)       += cuviddec.o
 OBJS-$(CONFIG_VP9_MEDIACODEC_DECODER)  += mediacodecdec.o
 OBJS-$(CONFIG_VP9_RKMPP_DECODER)       += rkmppdec.o
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
old mode 100644
new mode 100755
index d2f9a39ce5..526573f208
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -143,11 +143,15 @@ extern AVCodec ff_h264_mediacodec_decoder;
 extern AVCodec ff_h264_mmal_decoder;
 extern AVCodec ff_h264_qsv_decoder;
 extern AVCodec ff_h264_rkmpp_decoder;
+extern AVCodec ff_h264_mlumpp_decoder;
+extern AVCodec ff_h264_mlumpp_encoder;
 extern AVCodec ff_hap_encoder;
 extern AVCodec ff_hap_decoder;
 extern AVCodec ff_hevc_decoder;
 extern AVCodec ff_hevc_qsv_decoder;
 extern AVCodec ff_hevc_rkmpp_decoder;
+extern AVCodec ff_hevc_mlumpp_decoder;
+extern AVCodec ff_hevc_mlumpp_encoder;
 extern AVCodec ff_hevc_v4l2m2m_decoder;
 extern AVCodec ff_hnm4_video_decoder;
 extern AVCodec ff_hq_hqa_decoder;
@@ -181,6 +185,7 @@ extern AVCodec ff_mdec_decoder;
 extern AVCodec ff_mimic_decoder;
 extern AVCodec ff_mjpeg_encoder;
 extern AVCodec ff_mjpeg_decoder;
+extern AVCodec ff_mjpeg_mlumpp_encoder;
 extern AVCodec ff_mjpegb_decoder;
 extern AVCodec ff_mmvideo_decoder;
 extern AVCodec ff_motionpixels_decoder;
@@ -762,6 +767,7 @@ extern AVCodec ff_hevc_vaapi_encoder;
 extern AVCodec ff_hevc_videotoolbox_encoder;
 extern AVCodec ff_libkvazaar_encoder;
 extern AVCodec ff_mjpeg_cuvid_decoder;
+extern AVCodec ff_mjpeg_mlumpp_decoder;
 extern AVCodec ff_mjpeg_qsv_encoder;
 extern AVCodec ff_mjpeg_vaapi_encoder;
 extern AVCodec ff_mpeg1_cuvid_decoder;
@@ -773,11 +779,13 @@ extern AVCodec ff_mpeg4_mediacodec_decoder;
 extern AVCodec ff_mpeg4_v4l2m2m_encoder;
 extern AVCodec ff_vc1_cuvid_decoder;
 extern AVCodec ff_vp8_cuvid_decoder;
+extern AVCodec ff_vp8_mlumpp_decoder;
 extern AVCodec ff_vp8_mediacodec_decoder;
 extern AVCodec ff_vp8_qsv_decoder;
 extern AVCodec ff_vp8_v4l2m2m_encoder;
 extern AVCodec ff_vp8_vaapi_encoder;
 extern AVCodec ff_vp9_cuvid_decoder;
+extern AVCodec ff_vp9_mlumpp_decoder;
 extern AVCodec ff_vp9_mediacodec_decoder;
 extern AVCodec ff_vp9_vaapi_encoder;
 
diff --git a/libavcodec/hwaccel.h b/libavcodec/hwaccel.h
index 3aaa92571c..6a0ea9f6f9 100644
--- a/libavcodec/hwaccel.h
+++ b/libavcodec/hwaccel.h
@@ -70,6 +70,8 @@ typedef struct AVCodecHWConfigInternal {
     HW_CONFIG_HWACCEL(1, 1, 0, D3D11,        D3D11VA,      ff_ ## codec ## _d3d11va2_hwaccel)
 #define HWACCEL_NVDEC(codec) \
     HW_CONFIG_HWACCEL(1, 1, 0, CUDA,         CUDA,         ff_ ## codec ## _nvdec_hwaccel)
+#define HWACCEL_MLUDEC(codec) \
+    HW_CONFIG_HWACCEL(1, 1, 0, MLU,          MLU,         ff_ ## codec ## _mludec_hwaccel)
 #define HWACCEL_VAAPI(codec) \
     HW_CONFIG_HWACCEL(1, 1, 1, VAAPI,        VAAPI,        ff_ ## codec ## _vaapi_hwaccel)
 #define HWACCEL_VDPAU(codec) \
diff --git a/libavcodec/mlumpp_codec.h b/libavcodec/mlumpp_codec.h
new file mode 100644
index 0000000000..8900bd493f
--- /dev/null
+++ b/libavcodec/mlumpp_codec.h
@@ -0,0 +1,236 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef MLUMPP_CODEC_H
+#define MLUMPP_CODEC_H
+
+#include "libavutil/buffer.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/fifo.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+#include "libavutil/time.h"
+#include "libavutil/common.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/thread.h"
+#include "libavutil/version.h"
+#include "config.h"
+#include "avcodec.h"
+#include "decode.h"
+#include "hwaccel.h"
+#include "internal.h"
+#include "libavutil/avutil.h"
+// Cambricon header file
+#include "cnrt.h"
+#include "cncodec_v3_common.h"
+
+#ifdef CNCODEC_MAJOR_VERSION
+#define CNCODEC_VERSION_INT AV_VERSION_INT(CNCODEC_MAJOR_VERSION, \
+                                           CNCODEC_MINOR_VERSION, \
+                                           CNCODEC_PATCH_VERSION)
+#endif
+#define FF_MLU_MAJPR_VERSION 2
+#define FF_MLU_MINOR_VERSION 3
+#define FF_MLU_PATCH_VERSION 0
+
+static struct {
+    cncodecRetCode_t codecerr;
+    int         averr;
+    const char *desc;
+} cncodec_errors[] = {
+    { CNCODEC_SUCCESS,                  0,                          "cncodec success"                       },
+    { CNCODEC_ERROR_INVALID_VALUE,      AVERROR(EINVAL),            "cncodec invalid parameters"            },
+    { CNCODEC_ERROR_INVALID_MEMORY,     AVERROR(EINVAL),            "cncodec invalid memory"                },
+    { CNCODEC_ERROR_INVALID_HANDLE,     AVERROR(EINVAL),            "cncodec invalid codec handle"        },
+    { CNCODEC_ERROR_CREATE_FAILED,      AVERROR_EXTERNAL,           "cncodec create codec failed"         },
+    { CNCODEC_ERROR_TIMEOUT,            AVERROR_EXTERNAL,           "cncodec func call time-out"            },
+    { CNCODEC_ERROR_BUFFER_EMPTY,       AVERROR_EXTERNAL,           "cncodec no output buf available"       },
+    { CNCODEC_ERROR_TRANSMIT_FAILED,    AVERROR_EXTERNAL,           "cncodec transmit msg failed"           },
+    { CNCODEC_ERROR_OUT_OF_MEMORY,      AVERROR(ENOMEM),            "cncodec out of memory"                 },
+    { CNCODEC_ERROR_NOT_SUPPORTED,      AVERROR(EPERM),             "cncodec function not permitted"        },
+    { CNCODEC_ERROR_NOT_PERMITED,       AVERROR(EPERM),             "cncodec operation not permitted"       },
+    { CNCODEC_ERROR_BAD_STREAM,         AVERROR_INVALIDDATA,        "cncodec invalid input stream"          },
+    { CNCODEC_ERROR_BUFFER_OVERFLOW,    AVERROR_BUFFER_TOO_SMALL,   "cncodec output buf overflow"   },
+    { CNCODEC_ERROR_UNKNOWN,            AVERROR(INT_MAX),           "cncodec unknown error"                 },
+};
+
+static inline int cncodec_map_error(int32_t err, const char **desc) {
+    int i;
+    if (err > 632005 && err < 632048) {
+        *desc = "cn extra-lib error";
+        return AVERROR_EXTERNAL;
+    }
+    if (999991 == err) {
+        *desc = "cn extra-lib unknown error";
+        return AVERROR_EXTERNAL;
+    }
+    for (i = 0; i < FF_ARRAY_ELEMS(cncodec_errors); ++i) {
+        if (cncodec_errors[i].codecerr == err) {
+            if (desc)
+                *desc = cncodec_errors[i].desc;
+            return cncodec_errors[i].averr;
+        }
+    }
+    if (desc)
+        *desc = "unknown error";
+    return AVERROR_UNKNOWN;
+}
+
+static inline int print_cncodec_error(void* log_ctx, int32_t err, const char* err_msg) {
+    const char* desc;
+    int ret;
+    ret = cncodec_map_error(err, &desc);
+    av_log(log_ctx, AV_LOG_ERROR, "%s: %s (%d)\n", err_msg, desc, err);
+    return ret;
+}
+
+static inline cncodecPixelFormat_t cndec_ff_map_cn_pixfmt(enum AVPixelFormat pixfmt)
+{
+    switch (pixfmt) {
+    case AV_PIX_FMT_NV12:       return CNCODEC_PIX_FMT_NV12;
+    case AV_PIX_FMT_NV21:       return CNCODEC_PIX_FMT_NV21;
+    case AV_PIX_FMT_YUV420P:
+    case AV_PIX_FMT_YUVJ420P:   return CNCODEC_PIX_FMT_I420;
+    case AV_PIX_FMT_P010:       return CNCODEC_PIX_FMT_P010;
+    default:                    return CNCODEC_PIX_FMT_NV12;
+    }
+}
+
+static inline cncodecPixelFormat_t cndec_str_map_cn_pixfmt(char *pixfmt)
+{
+    if (!strcmp("nv12", pixfmt) || !strcmp("NV12", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV12;
+    } else if (!strcmp("nv21", pixfmt) || !strcmp("NV21", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV21;
+    } else if (!strcmp("yuv420p", pixfmt) || !strcmp("YUV420p", pixfmt) ||
+               !strcmp("YUV420P", pixfmt) || !strcmp("yuv420P", pixfmt)) {
+        return CNCODEC_PIX_FMT_I420;
+    } else if (!strcmp("p010", pixfmt)   || !strcmp("P010", pixfmt) ||
+               !strcmp("p010le", pixfmt) || !strcmp("P010LE", pixfmt) ||
+               !strcmp("p010be", pixfmt) || !strcmp("P010BE", pixfmt)) {
+        return CNCODEC_PIX_FMT_P010;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt: %s, cndecoder \
+            only suport nv12/nv21/yuv420p/p010 \n", pixfmt);
+        return -1;
+    }
+}
+
+static inline enum AVPixelFormat cndec_cn_map_ff_pixfmt(cncodecPixelFormat_t pixfmt)
+{
+    switch (pixfmt) {
+    case CNCODEC_PIX_FMT_NV12:  return AV_PIX_FMT_NV12;
+    case CNCODEC_PIX_FMT_NV21:  return AV_PIX_FMT_NV21;
+    case CNCODEC_PIX_FMT_I420:  return AV_PIX_FMT_YUV420P;
+    case CNCODEC_PIX_FMT_P010:  return AV_PIX_FMT_P010;
+    default:                    return AV_PIX_FMT_NV12;
+    }
+}
+
+static const struct {
+    cncodecPixelFormat_t pixel_format;
+    int sum_plane;
+    int plane_index;
+    float width_depth;
+    float height_depth;
+} fmt_num_depth_map[] = {
+    { CNCODEC_PIX_FMT_YUYV, 1, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_UYVY, 1, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_ARGB, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_ABGR, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_BGRA, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_RGBA, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV12, 2, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV12, 2, 1, 1.0f, 0.5f  },
+    { CNCODEC_PIX_FMT_NV21, 2, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV21, 2, 1, 1.0f, 0.5f  },
+    { CNCODEC_PIX_FMT_P010, 2, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_P010, 2, 1, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_I420, 3, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_I420, 3, 1, 0.5f, 0.5f },
+    { CNCODEC_PIX_FMT_I420, 3, 2, 0.5f, 0.5f },
+};
+
+static inline int cncodec_get_plane_num(const cncodecPixelFormat_t pix_fmt) {
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(fmt_num_depth_map); ++i) {
+        if (fmt_num_depth_map[i].pixel_format == pix_fmt) {
+            return fmt_num_depth_map[i].sum_plane;
+        }
+    }
+    return -1;
+}
+
+static inline int cncodec_get_plane_depth(const cncodecPixelFormat_t pix_fmt, const int p_index, float* w_depth, float* h_depth) {
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(fmt_num_depth_map); ++i) {
+        if (fmt_num_depth_map[i].pixel_format == pix_fmt &&
+            fmt_num_depth_map[i].plane_index == p_index) {
+            *w_depth = fmt_num_depth_map[i].width_depth;
+            *h_depth = fmt_num_depth_map[i].height_depth;
+            return 0;
+        }
+    }
+    return -1;
+}
+
+static inline enum AVPictureType cndec_map_frame_type(const cncodecPicType_t pic_type) {
+    switch (pic_type) {
+    case CNCODEC_PIC_TYPE_P:       return AV_PICTURE_TYPE_P;
+    case CNCODEC_PIC_TYPE_B:       return AV_PICTURE_TYPE_B;
+    case CNCODEC_PIC_TYPE_I:       return AV_PICTURE_TYPE_I;
+    case CNCODEC_PIC_TYPE_IDR:     return AV_PICTURE_TYPE_I;
+#if CNCODEC_MAJOR_VERSION >= 1
+    case CNCODEC_PIC_TYPE_UNKNOWN: return AV_PICTURE_TYPE_NONE;
+#endif
+    default:                       return AV_PICTURE_TYPE_NONE;
+    }
+}
+
+static inline int cndec_get_keyframe_flag(const cncodecPicType_t pic_type) {
+    if (pic_type == CNCODEC_PIC_TYPE_I || pic_type == CNCODEC_PIC_TYPE_IDR) {
+        return 1;
+    }
+    return 0;
+}
+
+#define cndec_version_info(void)                                              \
+    av_log(NULL, AV_LOG_VERBOSE, "REL FLAG: 05052022\n");                     \
+    av_log(NULL, AV_LOG_INFO, "CNCODEC: %d.%d.%d \n",                         \
+        CNCODEC_MAJOR_VERSION, CNCODEC_MINOR_VERSION, CNCODEC_PATCH_VERSION); \
+    av_log(NULL, AV_LOG_INFO, "FFMPEG_MLU: %d.%d.%d \n",                      \
+        FF_MLU_MAJPR_VERSION, FF_MLU_MINOR_VERSION, FF_MLU_PATCH_VERSION);
+
+// common defines
+#define CN_ERROR_CHECK(avctx, ret, err_msg)                                                       \
+    if (ret != 0) {                                                                               \
+        av_log(avctx, AV_LOG_ERROR, "CNtoolkit Error, func: %s, line: %d\n", __func__, __LINE__); \
+        return print_cncodec_error(avctx, ret, err_msg);                                          \
+    }
+
+#define cncodec_get_plane_num(pix_fmt) cncodec_get_plane_num(pix_fmt)
+
+#define cncodec_get_plane_depth(pix_fmt, p_index, w_depth, h_depth) cncodec_get_plane_depth(pix_fmt, p_index, w_depth, h_depth)
+
+#define TIMESTAMP_QUEUE_SIZE 100
+
+#endif /* MLUMPP_CODEC_H */
diff --git a/libavcodec/mlumpp_dec.c b/libavcodec/mlumpp_dec.c
new file mode 100755
index 0000000000..136b8f39eb
--- /dev/null
+++ b/libavcodec/mlumpp_dec.c
@@ -0,0 +1,1325 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <stdint.h>
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <semaphore.h>
+#include <stdatomic.h>
+
+#include "cncodec_v3_dec.h"
+#include "mlumpp_codec.h"
+
+#define VFRAME_STRIDE_ALIGN  1
+#define VFRAME_HEIGHT_ALIGN  16
+#define JFRAME_STRIDE_ALIGN  64
+#define JFRAME_HEIGHT_ALIGN  16
+
+typedef struct DecEventInfoMsg {
+    cncodecEventType_t event_type;
+    void *cnctx;
+    union {
+        cncodecFrame_t frame;
+        cncodecStream_t stream;
+    }event_output;
+} DecEventInfoMsg_t;
+
+typedef struct MLUMPPContext
+{
+    AVClass *avclass;
+    int device_id;
+    int instance_id;
+    int num_input_buffers;
+    int num_output_buffers;
+    char *crop_str;
+    char *resize_str;
+    int trace_flag;
+    int cnrt_init_flag;
+    int async_queue_depth;
+    char *output_pixfmt;
+    struct {
+        int x;
+        int y;
+        int w;
+        int h;
+    }crop;
+    struct {
+        int width;
+        int height;
+    }resize;
+    int progressive;
+    float compress_scale;
+    void *handle;
+
+    AVBufferRef *hw_device_ref;
+    AVBufferRef *hw_frame_ref;
+    AVBufferRef *hw_resize_frame_ref;
+    AVMLUDeviceContext *hwdevice_ctx;
+    AVHWFramesContext  *hwframes_ctx;
+
+    sem_t eos_sema;
+    AVBSFContext *bsf;
+    AVCodecContext *avctx;
+    AVFifoBuffer *frame_queue;
+
+    MluContext *mlu_ctx;
+
+    cncodecType_t codec_type;
+    cncodecDecCreateInfo_t create_info_;
+    cncodecDecParams_t codec_params_;
+    cncodecHandle_t codec_handle_;
+
+    AVMutex queue_mutex;
+
+    int coded_width;
+    int coded_height;
+    int stride_align;
+    int first_packet;
+    int max_width;
+    int max_height;
+    int first_max_width;
+    int first_max_height;
+    volatile int first_seq;
+    volatile int eos_received;
+    volatile int decoder_flushing;
+    volatile int codec_abort_flag;
+    volatile int decoder_init_flag;
+
+    // AVMutex count_mutex;
+    unsigned long long total_frame_count;
+    unsigned long long total_packet_count;
+    unsigned long long total_outframe_count;
+} MLUMPPContext_t;
+
+static inline int cndec_params_checking(AVCodecContext* avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+
+    if (ctx->resize_str) {
+        if ((ctx->resize.width & 1) || (ctx->resize.height & 1)) {
+            av_log(avctx, AV_LOG_ERROR, "Cndec scale w and h must be even\n");
+            return -1;
+        }
+        if (AV_CODEC_ID_MJPEG == avctx->codec->id) {
+            if ((ctx->resize.width != avctx->width/2 && ctx->resize.height != avctx->height/2) ||
+                (ctx->resize.width != avctx->width/4 && ctx->resize.height != avctx->height/4) ||
+                (ctx->resize.width != avctx->width/8 && ctx->resize.height != avctx->height/8)) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Jdec scale params error, only support 1/2, 1/4 and 1/8 scale\n");
+                return -1;
+            }
+        } else {
+            if (ctx->resize.width<48 || ctx->resize.width>8192 || ctx->resize.height<48 || ctx->resize.height>4320) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Vdec only support scale range:48x48~8192x4320, now:%dx%d\n",
+                    ctx->resize.width, ctx->resize.height);
+                return -1;
+            }
+        }
+    }
+    if (ctx->crop_str) {
+        if ((ctx->crop.x & 1) || (ctx->crop.y & 1) || (ctx->crop.w & 1) || (ctx->crop.h & 1)) {
+            av_log(avctx, AV_LOG_ERROR, "Cndec crop x/y/w/h must be even\n");
+            return -1;
+        }
+        if (AV_CODEC_ID_MJPEG == avctx->codec->id) {
+            if (ctx->crop.w<16 || ctx->crop.w>8192 || ctx->crop.h<16 || ctx->crop.h>8192) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Jdec only support crop range:16x16~8192x8192, now:%dx%d\n",
+                    ctx->crop.w, ctx->crop.h);
+                return -1;
+            }
+        } else {
+            if (ctx->crop.w<48 || ctx->crop.w>8192 || ctx->crop.h<48 || ctx->crop.h>4320) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Vdec only support crop range:48x48~8192x4320, now:%dx%d\n",
+                    ctx->crop.w, ctx->crop.h);
+                return -1;
+            }
+        }
+    }
+
+    switch (avctx->codec->id) {
+    case AV_CODEC_ID_MJPEG:
+        if (avctx->width<16 || avctx->width>8192 || avctx->height<16 || avctx->height>8192) {
+            av_log(avctx, AV_LOG_ERROR,
+                "Jdec only support resolution: 16x16~8192x8192, now:%dx%d\n", avctx->width, avctx->height);
+            return -1;
+        }
+        break;
+    case AV_CODEC_ID_HEVC:
+        if (avctx->width<144 ||  avctx->width>8192 ||avctx->height<144 || avctx->height>4320) {
+            av_log(avctx, AV_LOG_ERROR,
+                "HEVC dec only support resolution:144x144~8192x4320, now:%dx%d\n",
+                avctx->width, avctx->height);
+            return -1;
+        }
+        break;
+    case AV_CODEC_ID_H264:
+        if (ctx->progressive) {
+            if (avctx->width<144 || avctx->width>8192 || avctx->height<144 || avctx->height>4320) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "H264 dec(progressive) only support resolution:144x144~8192x4320, now:%dx%d\n",
+                    avctx->width, avctx->height);
+                return -1;
+            }
+        } else {
+            if (avctx->width<144 || avctx->width>4096 || avctx->height<144 || avctx->height>2160) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "H264 dec(interlaced) only support resolution:144x144~4096x2160, now:%dx%d\n",
+                    avctx->width, avctx->height);
+                return -1;
+            }
+        }
+        break;
+    case AV_CODEC_ID_VP8:
+        if (avctx->width > 1920 || avctx->width < 48 || avctx->height > 1080 || avctx->height < 48) {
+            av_log(avctx, AV_LOG_ERROR,
+                "VP8 dec only support resolution:48x48~1920x1080, now:%dx%d\n",
+                avctx->width, avctx->height);
+            return -1;
+        }
+        break;
+    case AV_CODEC_ID_VP9:
+        if (avctx->width > 8192 || avctx->width < 144 || avctx->height > 4320 || avctx->height < 144) {
+            av_log(avctx, AV_LOG_ERROR,
+                "VP9 dec only support resolution:144x144~8192x4320, now:%dx%d\n",
+                avctx->width, avctx->height);
+            return -1;
+        }
+        break;
+    default:
+        break;
+    }
+    return 0;
+}
+
+static bool cndec_input_buf_available(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 1;
+    uint32_t probe_pkt_size = 0;
+    cncodecDecBufStatus_t buf_status;
+
+    probe_pkt_size = avctx->coded_width * avctx->coded_height / 2;// guess
+    if (ctx->codec_type == CNCODEC_JPEG) {
+        return true;
+    }
+    ret = cncodecDecQueryBufStatus(ctx->codec_handle_, &buf_status);
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR, "Decoder query buf status failed, error code(%d)\n", ret);
+        return false;
+    }
+    if (buf_status.free_stream_buf_bytes >= probe_pkt_size &&
+        buf_status.free_stream_buf_num > 0) {
+        return true;
+    }
+    return false;
+}
+
+static bool cndec_output_buf_available(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 1;
+    cncodecDecBufStatus_t buf_status;
+
+    ret = cncodecDecQueryBufStatus(ctx->codec_handle_, &buf_status);
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Vdec query frame buf status failed, error code(%d)\n", ret);
+        return false;
+    }
+    if (buf_status.used_frame_buf_num == 0) {
+        return true;
+    }
+    return false;
+}
+
+static int mlu_device_binding(MLUMPPContext_t *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "MLU GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "MLU mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static int cndec_send_pkt_to_decoder(AVCodecContext *avctx,const AVPacket *avpkt)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    cncodecStream_t input;
+    const int feed_timeout = 3000;
+    int ret = 0;
+    memset(&input, 0, sizeof(cncodecStream_t));
+    if (!ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR, "Decoder without handle, return AVERROR_EXTERNAL \n");
+        return AVERROR_EXTERNAL;
+    }
+    if (ctx->codec_type != CNCODEC_JPEG && ctx->first_packet) {
+        if (avctx->extradata_size) {
+            input.mem_addr = (uint64_t)avctx->extradata;
+            input.data_len = avctx->extradata_size;
+            input.pts = avpkt->pts;
+            ret = cncodecDecSendStream(ctx->codec_handle_, &input, feed_timeout);
+            CN_ERROR_CHECK(avctx, ret, "Decoder send stream");
+        }
+        ctx->first_packet = 0;
+    }
+    input.mem_addr = (uint64_t)avpkt->data;
+    input.data_offset = 0;
+    input.data_len = avpkt->size;
+    input.pts = avpkt->pts;
+    input.mem_type = CNCODEC_MEM_TYPE_HOST;
+    input.alloc_len = avpkt->size;
+    ret = cncodecDecSendStream(ctx->codec_handle_, &input, feed_timeout);
+    CN_ERROR_CHECK(avctx, ret, "Decoder send stream");
+
+    ctx->total_packet_count++;
+    return ret;
+}
+
+static int cndec_sequence_callback(void *pData, cncodecDecSequenceInfo_t *info)
+{
+    int ret = CNCODEC_SUCCESS;
+    MLUMPPContext_t *ctx  = (MLUMPPContext_t *)pData;
+    AVCodecContext *avctx = ctx->avctx;
+    AVHWFramesContext* hwframe_ctx;
+    AVHWFramesContext* resize_frame_ctx;
+    cncodecDecParams_t params;
+
+    if(mlu_device_binding(ctx) < 0) {
+        av_log(ctx->avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    memset(&params, 0, sizeof(params));
+    if (ctx->first_seq) {
+        params.max_width = info->coded_width > ctx->max_width ? info->coded_width : ctx->max_width;
+        params.max_height = info->coded_height > ctx->max_height ? info->coded_height : ctx->max_height;
+        ctx->first_max_width = params.max_width;
+        ctx->first_max_height = params.max_height;
+        ctx->first_seq = 0;
+    } else {
+        if (info->coded_width > ctx->first_max_width || info->coded_height > ctx->first_max_height) {
+            av_log(avctx, AV_LOG_ERROR,
+                    "Resolution has changed, buffer max width and max height was too small.\n");
+            ctx->codec_abort_flag = 1;
+            return CNCODEC_ERROR_INVALID_VALUE;
+        } else {
+            params.max_width = ctx->first_max_width;
+            params.max_height = ctx->first_max_height;
+        }
+    }
+    params.output_buf_num    = info->min_output_buf_num + ctx->num_output_buffers;
+    params.pixel_format      = cndec_ff_map_cn_pixfmt(avctx->sw_pix_fmt);
+    params.color_space       = CNCODEC_COLOR_SPACE_BT_709;
+    params.stride_align      = ctx->stride_align;
+    params.dec_mode          = CNCODEC_DEC_MODE_IPB;
+    params.output_order      = CNCODEC_DEC_OUTPUT_ORDER_DISPLAY;
+    params.output_buf_source = CNCODEC_BUF_SOURCE_LIB;
+
+    params.pp_attr.crop.enable = 1;
+    if (ctx->crop_str) {
+        params.pp_attr.crop.x = ctx->crop.x;
+        params.pp_attr.crop.y = ctx->crop.y;
+        params.pp_attr.crop.width  = ctx->crop.w;
+        params.pp_attr.crop.height = ctx->crop.h;
+    } else {
+        params.pp_attr.crop.x = 0;
+        params.pp_attr.crop.y = 0;
+        params.pp_attr.crop.width = info->display_area.width;
+        params.pp_attr.crop.height= info->display_area.height;
+    }
+    if (!ctx->resize_str) {
+        params.pp_attr.scale.vid_scale.enable = 0;
+    } else {
+        if (ctx->resize.width/avctx->width > 3 || ctx->resize.height/avctx->height > 3) {
+            av_log(avctx, AV_LOG_ERROR,
+                "Video upscale support no more than triple magnification\n");
+            return CNCODEC_ERROR_INVALID_VALUE;
+        }
+        params.pp_attr.scale.vid_scale.enable = 1;
+        params.pp_attr.scale.vid_scale.width  = ctx->resize.width;
+        params.pp_attr.scale.vid_scale.height = ctx->resize.height;
+    }
+
+    ctx->async_queue_depth = params.output_buf_num * 4;
+
+    // while the vairable resolution vp8 is used, the queue may not be empty.
+    while (!cndec_output_buf_available(avctx)) {
+        av_usleep(10000);
+        av_log(avctx, AV_LOG_WARNING,
+            "Vdec resolution changed, wait pre-resolution ready\n");
+    }
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (ctx->frame_queue) {
+        if (av_fifo_size(ctx->frame_queue) != 0) {
+            av_log(avctx, AV_LOG_WARNING, "Vdec frame queue not empty\n");
+        }
+        av_fifo_free(ctx->frame_queue);
+        ctx->frame_queue = NULL;
+    }
+    ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(DecEventInfoMsg_t));
+    ff_mutex_unlock(&ctx->queue_mutex);
+    if (!ctx->frame_queue) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create frame queue\n");
+        return CNCODEC_ERROR_INVALID_MEMORY;
+    }
+
+    avctx->width  = info->display_area.width;
+    avctx->height = info->display_area.height;
+    avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+    avctx->coded_height = avctx->height;
+
+    if (cndec_params_checking(avctx)) {
+        return CNCODEC_ERROR_INVALID_VALUE;
+    }
+    if (!ctx->resize_str && ctx->crop_str) {
+        avctx->width  = ctx->crop.w;
+        avctx->height = ctx->crop.h;
+        avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+        avctx->coded_height = avctx->height;
+    } else if (ctx->resize_str) {
+        avctx->width  = ctx->resize.width;
+        avctx->height = ctx->resize.height;
+        avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+        avctx->coded_height = avctx->height;
+    }
+
+    hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+    if (hwframe_ctx->pool) {
+        av_buffer_pool_uninit(&hwframe_ctx->pool);
+        hwframe_ctx->format    = AV_PIX_FMT_MLU;
+        hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+        hwframe_ctx->width     = avctx->coded_width;
+        hwframe_ctx->height    = avctx->coded_height;
+        hwframe_ctx->initial_pool_size = 2;
+        if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+            return CNCODEC_ERROR_INVALID_VALUE;
+        }
+    }
+
+    if ((ctx->resize_str || ctx->crop_str) && avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        ctx->hw_resize_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+        if (!ctx->hw_resize_frame_ref) {
+            av_log(avctx, AV_LOG_ERROR, "Alloc video resize hwframe failed\n");
+            return CNCODEC_ERROR_INVALID_VALUE;
+        }
+        resize_frame_ctx = (AVHWFramesContext*)ctx->hw_resize_frame_ref->data;
+        resize_frame_ctx->format    = AV_PIX_FMT_MLU;
+        resize_frame_ctx->sw_format = avctx->sw_pix_fmt;
+        resize_frame_ctx->width     = avctx->coded_width;
+        resize_frame_ctx->height    = avctx->coded_height;
+        resize_frame_ctx->initial_pool_size = 2;
+        if ((ret = av_hwframe_ctx_init(ctx->hw_resize_frame_ref)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Init resize hwframe: av_hwframe_ctx_init failed\n");
+            return CNCODEC_ERROR_INVALID_VALUE;
+        }
+    }
+
+    ret = cncodecDecSetParams(ctx->codec_handle_, &params);
+    CN_ERROR_CHECK(avctx, ret, "Set params to decoder");
+
+    ctx->total_frame_count = 0;
+    av_log(avctx, AV_LOG_DEBUG, "Video decode got seq cb, handle:%lu \n",
+        (long unsigned)ctx->codec_handle_);
+    return ret;
+}
+
+static int cndec_newframe_callback(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    DecEventInfoMsg_t msg;
+    int ret = CNCODEC_SUCCESS;
+
+    msg.event_type = CNCODEC_EVENT_NEW_FRAME;
+    msg.cnctx = userptr;
+    msg.event_output.frame = *((cncodecFrame_t *)data);
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    ret = cncodecDecFrameRef(ctx->codec_handle_, &msg.event_output.frame);
+    av_fifo_generic_write(ctx->frame_queue, &msg, sizeof(DecEventInfoMsg_t), NULL);
+    ff_mutex_unlock(&ctx->queue_mutex);
+    CN_ERROR_CHECK(ctx->avctx, ret, "Callback func, ref new frame");
+
+    ctx->total_frame_count++;
+    return ret;
+}
+
+static int cndec_eos_callback(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    DecEventInfoMsg_t msg;
+
+    memset(&msg, 0 ,sizeof(DecEventInfoMsg_t));
+    msg.event_type = CNCODEC_EVENT_EOS;
+    msg.cnctx = userptr;
+    ff_mutex_lock(&ctx->queue_mutex);
+    av_fifo_generic_write(ctx->frame_queue, &msg, sizeof(DecEventInfoMsg_t), NULL);
+    ff_mutex_unlock(&ctx->queue_mutex);
+    sem_post(&ctx->eos_sema);
+    av_log(ctx->avctx, AV_LOG_DEBUG,
+        "Decode got eos cb, thread: %lu\n", (long unsigned)pthread_self());
+    return CNCODEC_SUCCESS;
+}
+
+static int cndec_event_callback(cncodecEventType_t event_type, void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    cncodecDecStreamCorruptInfo_t *corrupt_info = NULL;
+    int cb_ret = CNCODEC_SUCCESS;
+
+    if (ctx == NULL && data == NULL) {
+        av_log(NULL, AV_LOG_FATAL,
+            "Decoder callback error, event type: %d \n", event_type);
+        return CNCODEC_ERROR_INVALID_HANDLE;
+    }
+
+    switch (event_type) {
+    case CNCODEC_EVENT_NEW_FRAME:
+        cb_ret = cndec_newframe_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_SEQUENCE:
+        cb_ret = cndec_sequence_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_EOS:
+        cb_ret = cndec_eos_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_STREAM_CORRUPT:
+        corrupt_info = (cncodecDecStreamCorruptInfo_t *)data;
+        av_log(ctx->avctx, AV_LOG_WARNING, "Decoder corrupt stream: %d \n", event_type);
+        av_log(ctx->avctx, AV_LOG_DEBUG, "Decoder stream error pts: %lu, err num: %lu \n",
+                            corrupt_info->pts, corrupt_info->total_num);
+        cb_ret = CNCODEC_ERROR_BAD_STREAM;
+        break;
+    case CNCODEC_EVENT_STREAM_NOT_SUPPORTED:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Not supported stream, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_BAD_STREAM;
+        break;
+    case CNCODEC_EVENT_OUT_OF_MEMORY:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Out of memory, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_OUT_OF_MEMORY;
+        break;
+    case CNCODEC_EVENT_BUFFER_OVERFLOW:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Stream buf overflow, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_BUFFER_OVERFLOW;
+        break;
+    case CNCODEC_EVENT_FATAL_ERROR:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Fatal error, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_UNKNOWN;
+        break;
+    default:
+        av_log(ctx->avctx, AV_LOG_FATAL, "Unknown event type, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_UNKNOWN;
+        break;
+    }
+    return cb_ret;
+}
+
+static int cndec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVPacket filter_packet = { 0 };
+    AVPacket filtered_packet = { 0 };
+    int ret = 0;
+    if (ctx->bsf && avpkt && avpkt->size) {
+        if ((ret = av_packet_ref(&filter_packet, avpkt)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_packet_ref\n");
+            return ret;
+        }
+        if ((ret = av_bsf_send_packet(ctx->bsf, &filter_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_bsf_send_packet \n");
+            av_packet_unref(&filter_packet);
+            return ret;
+        }
+        if ((ret = av_bsf_receive_packet(ctx->bsf, &filtered_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_bsf_receive_packet \n");
+            return ret;
+        }
+        avpkt = &filtered_packet;
+    }
+    av_packet_unref(&filter_packet);
+
+    if (avpkt && avpkt->size) {
+        ret = cndec_send_pkt_to_decoder(avctx, avpkt);
+        if (ret < 0) {
+            av_packet_unref(&filtered_packet);
+            return AVERROR(EINVAL);
+        }
+    } else {
+        if (!ctx->decoder_flushing) {
+            ret = cncodecDecSetEos(ctx->codec_handle_);
+            CN_ERROR_CHECK(avctx, ret, "Decoder send Eos");
+            ctx->decoder_flushing = 1;
+        }
+    }
+    av_packet_unref(&filtered_packet);
+
+    return 0;
+}
+
+static int cndec_frame_copyout(AVCodecContext *avctx, AVFrame *avframe, cncodecFrame_t *cnframe)
+{
+    MLUMPPContext_t *ctx             = (MLUMPPContext_t*)avctx->priv_data;
+    AVHWDeviceContext *device_ctx    = (AVHWDeviceContext*)ctx->hw_device_ref->data;
+    AVMLUDeviceContext *hwdevice_ctx = device_ctx->hwctx;
+    MluContext *mlu_ctx              = hwdevice_ctx->mlu_ctx;
+
+    cnrtRet_t cnrt_ret;
+    int i = 0, ret = 0, factor = 0;
+    ctx->total_outframe_count++;
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU && (ctx->resize_str || ctx->crop_str)) {
+        ret = av_hwframe_get_buffer(ctx->hw_resize_frame_ref, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode av_hwframe_get_buffer failed, ret(%d)\n", ret);
+            return AVERROR(EINVAL);
+        }
+
+        ret = ff_decode_frame_props(avctx, avframe);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_decode_frame_props failed. ret(%d)\n", ret);
+            return AVERROR(EINVAL);
+        }
+    } else if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        ret = av_hwframe_get_buffer(ctx->hw_frame_ref, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode av_hwframe_get_buffer failed, ret(%d)\n", ret);
+            return AVERROR(EINVAL);
+        }
+
+        ret = ff_decode_frame_props(avctx, avframe);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_decode_frame_props failed, ret(%d)\n", ret);
+            return AVERROR(EINVAL);
+        }
+    } else {
+        ret = ff_get_buffer(avctx, avframe, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Decode ff_get_buffer failed, ret(%d)\n", ret);
+            return AVERROR(EINVAL);
+        }
+    }
+
+    switch (cnframe->pixel_format) {
+    case CNCODEC_PIX_FMT_NV21:
+    case CNCODEC_PIX_FMT_NV12:
+        for (i = 0; i < cnframe->plane_num; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->plane[i].stride;
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void *)avframe->data[i], (void *)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride * cnframe->height/factor, cnrtMemcpyDevToDev);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2D failed!");
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void *)avframe->data[i], (void *)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride * cnframe->height/factor, cnrtMemcpyDevToHost);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2H failed!");
+            }
+        }
+        break;
+    case CNCODEC_PIX_FMT_P010:
+        for (i = 0; i < cnframe->plane_num; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->plane[i].stride;
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)avframe->data[i], (void*)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride*cnframe->height/factor, cnrtMemcpyDevToDev);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2D failed!");
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)avframe->data[i], (void*)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride*cnframe->height/factor, cnrtMemcpyDevToHost);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2H failed!");
+            }
+        }
+        break;
+    case CNCODEC_PIX_FMT_I420:
+        for (i = 0; i < cnframe->plane_num; ++i) {
+            factor = (i == 0) ? 1 : 2;
+            avframe->linesize[i] = cnframe->plane[i].stride;
+
+            if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)avframe->data[i], (void*)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride*cnframe->height/factor, cnrtMemcpyDevToDev);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2D failed!");
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)avframe->data[i], (void*)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride*cnframe->height/factor, cnrtMemcpyDevToHost);
+                CN_ERROR_CHECK(avctx, cnrt_ret, "Output frame D2H failed!");
+            }
+        }
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unsupport pixfmt: %d, except NV12/NV21/YUV420P/P010\n",
+            cnframe->pixel_format);
+        break;
+    }
+
+    return 0;
+}
+
+static int cndec_output_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+
+    int ret = 0;
+    int64_t pts = -1;
+    cncodecPicType_t pic_type;
+    DecEventInfoMsg_t frame_info;
+
+    if (!ctx->frame_queue) return AVERROR(EAGAIN);
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (av_fifo_size(ctx->frame_queue) != 0) {
+        av_fifo_generic_read(ctx->frame_queue, &frame_info, sizeof(DecEventInfoMsg_t), NULL);
+    } else {
+        ff_mutex_unlock(&ctx->queue_mutex);
+        return AVERROR(EAGAIN);
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    if (CNCODEC_EVENT_EOS == frame_info.event_type) {
+        return AVERROR_EOF;
+    }
+    pts      = frame_info.event_output.frame.pts;
+    pic_type = frame_info.event_output.frame.pic_type;
+
+    ret = cndec_frame_copyout(avctx, frame, &frame_info.event_output.frame);
+    cncodecDecFrameUnref(ctx->codec_handle_, &frame_info.event_output.frame);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "cndec frame copyout failed\n");
+        return ret;
+    }
+
+    frame->pkt_pos      = -1;
+    frame->pkt_duration = 0;
+    frame->pkt_size     = -1;
+    frame->interlaced_frame = ctx->progressive ? 0 : 1;
+    frame->pts          = pts;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+    frame->pkt_pts = frame->pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    frame->width  = avctx->width;
+    frame->height = avctx->height;
+    frame->pict_type = cndec_map_frame_type(pic_type);
+    frame->key_frame = cndec_get_keyframe_flag(pic_type);
+
+    return ret;
+}
+
+static int cndec_output_jpeg_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = -1;
+
+    while (!ctx->codec_abort_flag) {
+        ret = cndec_output_frame(avctx, frame);
+        if (ret == AVERROR(EAGAIN)) {
+            av_usleep(100);
+            continue;
+        }
+        if (ret == AVERROR_EOF) {
+            ctx->eos_received = 1;
+        }
+        return ret;
+    }
+    av_log(avctx, AV_LOG_ERROR, "Receive frame ABORT->EOF, [%lu]\n",
+        (long unsigned)pthread_self());
+
+    return AVERROR_EOF;
+}
+
+static int ff_cndec_receive_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+
+    AVPacket pkt = {0};
+    int in_ret = -1, out_ret = -1;
+
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_receive_frame\n");
+        return AVERROR_BUG;
+    }
+    if (ctx->codec_abort_flag || !ctx->decoder_init_flag || !ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Decode got abort or not init or no handle, return AVERROR_BUG \n");
+        return AVERROR_BUG;
+    }
+    if (mlu_device_binding(ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    if (ctx->eos_received) {
+        return AVERROR_EOF;
+    }
+    while (!ctx->codec_abort_flag) {
+        if (!ctx->decoder_flushing && cndec_input_buf_available(avctx)) {
+            in_ret = ff_decode_get_packet(avctx, &pkt);
+            if (in_ret < 0 && in_ret != AVERROR_EOF) {
+                return in_ret;
+            }
+            in_ret = cndec_send_packet(avctx, &pkt);
+            av_packet_unref(&pkt);
+            if (in_ret < 0 && in_ret != AVERROR_EOF) {
+                av_log(avctx, AV_LOG_ERROR, "Dec send packet failed, ret:%d\n",
+                    in_ret);
+                return in_ret;
+            }
+        }
+
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            return cndec_output_jpeg_frame(avctx, frame);
+        }
+
+        out_ret = cndec_output_frame(avctx, frame);
+        if (out_ret != 0 && out_ret != AVERROR_EOF) {
+            if (out_ret != AVERROR(EAGAIN)) {
+                return out_ret;
+            }
+            if (ctx->decoder_flushing) {
+                av_usleep(10000);
+            }
+        } else {
+            if (out_ret == AVERROR_EOF) {
+                ctx->eos_received = 1;
+            }
+            return out_ret;
+        }
+    }
+
+    av_log(avctx, AV_LOG_ERROR, "Dec abort, fatal error\n");
+    return AVERROR_BUG;
+}
+
+static av_cold int ff_cndec_decode_end(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = -1;
+    int semvalue = 0;
+    struct timespec ts;
+    if (NULL == avctx || NULL == avctx->priv_data || 0 == ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_decode_end \n");
+        return AVERROR_BUG;
+    }
+
+    av_log(avctx, AV_LOG_DEBUG, "Decoder closing, thread:%lu \n", (long unsigned)pthread_self());
+    if(mlu_device_binding(ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    // sem_wait(&ctx->eos_sema);
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ts.tv_sec += 3;
+    if (-1 == sem_timedwait(&(ctx->eos_sema), &ts)) {
+        semvalue = -1;
+        sem_getvalue(&ctx->eos_sema, &semvalue);
+        av_log(avctx, AV_LOG_ERROR, "Decode sem_timewait = -1, semvalue = %d\n", semvalue);
+    }
+
+    ret = cncodecDecDestroy(ctx->codec_handle_);
+    if (CNCODEC_SUCCESS != ret) {
+        print_cncodec_error(avctx, ret, "decoder destroy");
+    }
+
+    sem_destroy(&ctx->eos_sema);
+    if (ctx->frame_queue) {
+        av_fifo_freep(&ctx->frame_queue);
+        ctx->frame_queue = NULL;
+    }
+    ff_mutex_destroy(&ctx->queue_mutex);
+    if (ctx->bsf) {
+        av_bsf_free(&ctx->bsf);
+        ctx->bsf = NULL;
+    }
+
+    ctx->decoder_init_flag = 0;
+    av_buffer_unref(&ctx->hw_frame_ref);
+    av_buffer_unref(&ctx->hw_device_ref);
+    av_buffer_unref(&ctx->hw_resize_frame_ref);
+
+    av_log(avctx, AV_LOG_DEBUG, "decode flushing flag:%d \n", ctx->decoder_flushing);
+    av_log(avctx, AV_LOG_DEBUG, "decode hw out pict count:%llu\n", ctx->total_outframe_count);
+    av_log(avctx, AV_LOG_DEBUG, "decode received pict count:%llu\n", ctx->total_frame_count);
+    av_log(avctx, AV_LOG_DEBUG, "decode feed data count:%llu\n", ctx->total_packet_count);
+    av_log(avctx, AV_LOG_DEBUG, "decoder close done, thread:%lu\n", (long unsigned)pthread_self());
+
+    return 0;
+}
+
+static av_cold int ff_cndec_decode_init(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVMLUDeviceContext *hwdevice_ctx;
+    AVHWFramesContext  *hwframe_ctx;
+    AVHWFramesContext  *resize_frame_ctx;
+
+    int ret = 0;
+    int probe_w = 0, probe_h = 0;
+    int probed_buf_size = 0;
+    char dev_idx[sizeof(int)];
+    const AVBitStreamFilter *bsf;
+    enum AVPixelFormat dec_pix_format = cndec_cn_map_ff_pixfmt(
+                                        cndec_str_map_cn_pixfmt(ctx->output_pixfmt));
+    enum AVPixelFormat pix_fmts[3] = { AV_PIX_FMT_MLU, dec_pix_format, AV_PIX_FMT_NONE };
+
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_decode_init func\n");
+        return AVERROR_BUG;
+    }
+
+    if (ctx->decoder_init_flag == 1) {
+        av_log(avctx, AV_LOG_ERROR, "Error, cndecode double init. \n");
+        return AVERROR_BUG;
+    }
+
+    cndec_version_info();
+    avctx->sw_pix_fmt = cndec_cn_map_ff_pixfmt(
+                        cndec_str_map_cn_pixfmt(ctx->output_pixfmt));
+    avctx->pix_fmt = ff_get_format(avctx, pix_fmts);
+    if (avctx->pix_fmt < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error, ff_get_format failed: %d\n", avctx->pix_fmt);
+        return avctx->pix_fmt;
+    }
+
+    ctx->avctx = avctx;
+    ctx->coded_width  = avctx->codec->id == AV_CODEC_ID_MJPEG?
+                        FFALIGN(avctx->width,  JFRAME_STRIDE_ALIGN):
+                        FFALIGN(avctx->width,  ctx->stride_align);
+    ctx->coded_height = FFALIGN(avctx->height, VFRAME_HEIGHT_ALIGN);
+    if (ctx->resize_str && sscanf(ctx->resize_str, "%dx%d",
+                                &ctx->resize.width, &ctx->resize.height) != 2) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid resize string\n");
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+    if (ctx->crop_str && sscanf(ctx->crop_str, "%dx%dx%dx%d", &ctx->crop.x,
+                                &ctx->crop.y, &ctx->crop.w, &ctx->crop.h) != 4) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid crop string\n");
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+    if(0 != cndec_params_checking(avctx)) return AVERROR(EINVAL);
+
+    sprintf(dev_idx, "%d", ctx->device_id);
+    if (avctx->hw_frames_ctx) {
+        av_buffer_unref(&ctx->hw_frame_ref);
+        ctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+        if (!ctx->hw_frame_ref) {
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+        if (!hwframe_ctx->pool || ctx->coded_width != hwframe_ctx->width) {
+            av_log(avctx, AV_LOG_WARNING, "hwframe width from [%d] change to [%d]\n",
+                hwframe_ctx->width, ctx->coded_width);
+            if (hwframe_ctx->pool)
+                av_buffer_pool_uninit(&hwframe_ctx->pool);
+            hwframe_ctx->format    = AV_PIX_FMT_MLU;
+            hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            hwframe_ctx->width     = ctx->coded_width;
+            hwframe_ctx->height    = ctx->coded_height;
+            hwframe_ctx->initial_pool_size = 2;
+            if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+                return AVERROR(ENAVAIL);
+            }
+        }
+        ctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+        if (!ctx->hw_device_ref) {
+            av_log(avctx, AV_LOG_ERROR, "A hardware frames or device context is "
+                "required for hardware accelerated decoding.\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+    } else {
+        if (avctx->hw_device_ctx) {
+            ctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+            if (!ctx->hw_device_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Error, ref hwdev failed\n");
+                ret = AVERROR(EINVAL);
+                goto error;
+            }
+        } else {
+            ret = av_hwdevice_ctx_create(&ctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, dev_idx,NULL,0);
+            if (ret < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Hardware dev_ctx create failed, ret(%d).\n", ret);
+                goto error;
+            }
+        }
+        ctx->hw_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+        if (!ctx->hw_frame_ref) {
+            av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_alloc failed\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+        if (!hwframe_ctx->pool) {
+            hwframe_ctx->format = AV_PIX_FMT_MLU;
+            hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            hwframe_ctx->width  = FFALIGN(avctx->coded_width, ctx->stride_align);
+            hwframe_ctx->height = FFALIGN(avctx->coded_height,VFRAME_HEIGHT_ALIGN);
+            hwframe_ctx->initial_pool_size = 2;
+            if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+                return AVERROR(EINVAL);
+            }
+        }
+    }
+    hwdevice_ctx = ((AVHWDeviceContext*)ctx->hw_device_ref->data)->hwctx;
+    ctx->hwdevice_ctx = hwdevice_ctx;
+    ctx->hwframes_ctx = hwframe_ctx;
+    ctx->mlu_ctx      = ctx->hwdevice_ctx->mlu_ctx;
+
+    ctx->first_packet         = 1;
+    ctx->first_seq            = 1;
+    ctx->eos_received         = 0;
+    ctx->decoder_flushing     = 0;
+    ctx->codec_abort_flag     = 0;
+    ctx->total_frame_count    = 0;
+    ctx->total_packet_count   = 0;
+    ctx->total_outframe_count = 0;
+
+    sem_init(&(ctx->eos_sema), 0, 0);
+    ff_mutex_init(&ctx->queue_mutex, NULL);
+
+    switch (avctx->codec->id) {
+#if CONFIG_H264_MLUMPP_DECODER
+    case AV_CODEC_ID_H264:
+        ctx->codec_type = CNCODEC_H264;
+        break;
+#endif
+#if CONFIG_HEVC_MLUMPP_DECODER
+    case AV_CODEC_ID_HEVC:
+        ctx->codec_type = CNCODEC_HEVC;
+        break;
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+    case AV_CODEC_ID_MJPEG:
+        ctx->codec_type = CNCODEC_JPEG;
+        break;
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+    case AV_CODEC_ID_VP8:
+        ctx->codec_type = CNCODEC_VP8;
+        break;
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+    case AV_CODEC_ID_VP9:
+        ctx->codec_type = CNCODEC_VP9;
+        break;
+#endif
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Invalid codec type, %d\n",avctx->codec->id);
+        return AVERROR_BUG;
+    }
+
+    ctx->bsf = NULL;
+    if (avctx->codec->id == AV_CODEC_ID_H264 || avctx->codec->id == AV_CODEC_ID_HEVC) {
+        if (avctx->codec->id == AV_CODEC_ID_H264)
+            bsf = av_bsf_get_by_name("h264_mp4toannexb");
+        else
+            bsf = av_bsf_get_by_name("hevc_mp4toannexb");
+        if (!bsf) {
+            ret = AVERROR_BSF_NOT_FOUND;
+            goto error;
+        }
+        if (ret = av_bsf_alloc(bsf, &ctx->bsf)) {
+            goto error;
+        }
+        if (((ret = avcodec_parameters_from_context(ctx->bsf->par_in, avctx)) < 0) ||
+            ((ret = av_bsf_init(ctx->bsf)) < 0)) {
+            av_bsf_free(&ctx->bsf);
+            goto error;
+        }
+    }
+
+    if (ctx->codec_type == CNCODEC_VP8) {
+        if (avctx->sw_pix_fmt != AV_PIX_FMT_NV12 && avctx->sw_pix_fmt != AV_PIX_FMT_NV21) {
+            av_log(avctx, AV_LOG_ERROR, "VP8 decoder only support nv12 and nv21!\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+    }
+    /*At this moment, if the demuxer does not set this value (avctx->field_order == UNKNOWN),
+    *   the input stream will be assumed as progressive one.
+    */
+    switch(avctx->field_order) {
+    case AV_FIELD_TT:
+    case AV_FIELD_BB:
+    case AV_FIELD_TB:
+    case AV_FIELD_BT:
+        ctx->progressive = 0;
+        break;
+    case AV_FIELD_PROGRESSIVE:
+    default:
+        ctx->progressive = 1;
+        break;
+    }
+
+    ctx->frame_queue = NULL;
+    ctx->max_width = FFALIGN(ctx->max_width, 64);
+    ctx->max_height = FFALIGN(ctx->max_height, 16);
+    probed_buf_size = (ctx->max_width > 0 && ctx->max_height > 0) ?
+        ctx->max_width * ctx->max_height * ctx->compress_scale :
+        ctx->coded_width * ctx->coded_height * ctx->compress_scale;
+
+    memset(&(ctx->create_info_), 0, sizeof(cncodecDecCreateInfo_t));
+    memset(&(ctx->codec_params_), 0, sizeof(cncodecDecParams_t));
+
+    ctx->create_info_.codec     = ctx->codec_type;
+    ctx->create_info_.device_id = ctx->mlu_ctx->mlu_id; // ctx->device_id;
+    ctx->create_info_.send_mode = CNCODEC_DEC_SEND_MODE_FRAME;
+    ctx->create_info_.run_mode  = CNCODEC_RUN_MODE_ASYNC;
+    ctx->create_info_.stream_buf_size = FFALIGN(probed_buf_size, 4096);
+    ctx->create_info_.user_context    = (void*)ctx;
+    ret = cncodecDecCreate(&ctx->codec_handle_, &cndec_event_callback, &ctx->create_info_);
+    if (CNCODEC_SUCCESS != ret) {
+        print_cncodec_error(avctx, ret, "Failed to create decoder");
+        ctx->codec_handle_ = 0;
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+
+    if (CNCODEC_JPEG == ctx->codec_type) {
+        ctx->codec_params_.max_width      = FFALIGN(avctx->width,  JFRAME_STRIDE_ALIGN);
+        ctx->codec_params_.max_height     = FFALIGN(avctx->height, JFRAME_HEIGHT_ALIGN);
+        ctx->codec_params_.stride_align   = JFRAME_STRIDE_ALIGN; // ctx->stride_align;
+        ctx->codec_params_.output_buf_num = ctx->num_output_buffers;
+        ctx->codec_params_.pixel_format   = cndec_ff_map_cn_pixfmt(avctx->sw_pix_fmt);
+        ctx->codec_params_.color_space    = CNCODEC_COLOR_SPACE_BT_709;
+        ctx->codec_params_.dec_mode       = CNCODEC_DEC_MODE_IPB;
+        ctx->codec_params_.output_order   = CNCODEC_DEC_OUTPUT_ORDER_DISPLAY;
+        ctx->codec_params_.output_buf_source = CNCODEC_BUF_SOURCE_LIB;
+
+        if (CNCODEC_PIX_FMT_NV12 != ctx->codec_params_.pixel_format &&
+            CNCODEC_PIX_FMT_NV21 != ctx->codec_params_.pixel_format) {
+            av_log(avctx, AV_LOG_ERROR, "Mjpeg decoder only support nv12 and nv21, now!\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+
+        if (!ctx->resize_str) {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 0;
+        } else {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 1;
+            if (ctx->resize.width == avctx->width / 2) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 1;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 1;
+            } else if (ctx->resize.width == avctx->width / 4) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 2;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 2;
+            } else if (ctx->resize.width == avctx->width / 8) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 3;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 3;
+            }
+        }
+        if (!ctx->crop_str) {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 0;
+        } else {
+            ctx->codec_params_.pp_attr.crop.enable = 1;
+            ctx->codec_params_.pp_attr.crop.x = ctx->crop.x;
+            ctx->codec_params_.pp_attr.crop.y = ctx->crop.y;
+            ctx->codec_params_.pp_attr.crop.width  = ctx->crop.w;
+            ctx->codec_params_.pp_attr.crop.height = ctx->crop.h;
+        }
+
+        ret = cncodecDecSetParams(ctx->codec_handle_, &ctx->codec_params_);
+        if (ret != CNCODEC_SUCCESS) {
+            print_cncodec_error(avctx, ret, "Set jdec params failed");
+            goto error;
+        }
+
+        ctx->async_queue_depth = ctx->num_output_buffers;
+        ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(cncodecFrame_t));
+        if (!ctx->frame_queue) {
+            av_log(avctx, AV_LOG_ERROR, "Failed to create jpeg frame queue \n");
+            goto error;
+        }
+        if ((ctx->resize_str || ctx->crop_str) && avctx->pix_fmt == AV_PIX_FMT_MLU) {
+            probe_w = ctx->resize.width ? ctx->resize.width : ctx->crop.w;
+            probe_h = ctx->resize.height? ctx->resize.height: ctx->crop.h;
+            ctx->hw_resize_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+            if (!ctx->hw_resize_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Alloc resize hwframe failed\n");
+                ret = AVERROR(EINVAL);
+                goto error;
+            }
+            resize_frame_ctx = (AVHWFramesContext*)ctx->hw_resize_frame_ref->data;
+            resize_frame_ctx->format    = AV_PIX_FMT_MLU;
+            resize_frame_ctx->sw_format = avctx->sw_pix_fmt;
+            resize_frame_ctx->width     = FFALIGN(probe_w, JFRAME_STRIDE_ALIGN);
+            resize_frame_ctx->height    = FFALIGN(probe_h, JFRAME_HEIGHT_ALIGN);
+            resize_frame_ctx->initial_pool_size = 2;
+            if ((ret = av_hwframe_ctx_init(ctx->hw_resize_frame_ref)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Init resize hwframe: av_hwframe_ctx_init failed\n");
+                return 0;
+            }
+        }
+        if (ctx->resize_str || ctx->crop_str) {
+            avctx->width  = ctx->resize.width ? ctx->resize.width : ctx->crop.w;
+            avctx->height = ctx->resize.height? ctx->resize.height: ctx->crop.h;
+            avctx->coded_width = FFALIGN(avctx->width, JFRAME_STRIDE_ALIGN);
+            avctx->coded_height= avctx->height;
+        }
+    } else {
+        if(!ctx->resize_str && !ctx->crop_str) {
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        } else if (!ctx->resize_str && ctx->crop_str) {
+            avctx->width  = ctx->crop.w;
+            avctx->height = ctx->crop.h;
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        } else {
+            avctx->width  = ctx->resize.width;
+            avctx->height = ctx->resize.height;
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        }
+    }
+    if(mlu_device_binding(ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    ctx->decoder_init_flag = 1;
+    avctx->pkt_timebase.num = 1;
+    avctx->pkt_timebase.den = 90000;
+    if (!avctx->pkt_timebase.num || !avctx->pkt_timebase.den) {
+        av_log(avctx, AV_LOG_WARNING, "Invalid pkt_timebase, passing timestamps as-is.\n");
+    }
+    av_log(avctx, AV_LOG_DEBUG, "Decoder init done, thread: %lu \n", (long unsigned)pthread_self());
+
+    return 0;
+
+error:
+    sem_post(&ctx->eos_sema);
+    ff_cndec_decode_end(avctx);
+    return ret;
+}
+
+static void ff_cndec_flush(AVCodecContext *avctx) {
+    ff_cndec_decode_end(avctx);
+    ff_cndec_decode_init(avctx);
+}
+
+#define OFFSET(x) offsetof(MLUMPPContext_t, x)
+#define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",     "use to choose the accelerator card",     OFFSET(device_id),       AV_OPT_TYPE_INT, { .i64 = 0 },0, INT_MAX, VD },\
+    { "input_buf_num",  "Number of input buffers for decoder",   OFFSET(num_input_buffers),   AV_OPT_TYPE_INT, { .i64 = 4}, 1, 18, VD },\
+    { "output_buf_num","Number of output buffers for decoder",   OFFSET(num_output_buffers),  AV_OPT_TYPE_INT, { .i64 = 2}, 1, 18, VD },\
+    { "stride_align","stride align of output buffers for decoder",OFFSET(stride_align),   AV_OPT_TYPE_INT, { .i64 = 1 },0, 128, VD },\
+    { "max_width","max width of decoder buffer",    OFFSET(max_width),   AV_OPT_TYPE_INT, { .i64 = 0 },0, 8192, VD },\
+    { "max_height","max height of decoder buffer",  OFFSET(max_height),   AV_OPT_TYPE_INT, { .i64 = 0 },0, 4320, VD },\
+    { "output_pixfmt",        "output pix fmt",                   OFFSET(output_pixfmt),   AV_OPT_TYPE_STRING, { .str = "nv12" },0, 0, VD }, /*NV12, NV21, YUV420P, P010*/
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "crop",   "Crop (left)x(top)x(width)x(height)", OFFSET(crop_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "resize", "Resize (width)x(height)", OFFSET(resize_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "trace",  "Whether open trace switch or not",    OFFSET(trace_flag),  AV_OPT_TYPE_INT, { .i64 = 0 },0, 3, VD },
+    { "compress_scale", "Set the scale value of the stream_buf_size based on the image size", OFFSET(compress_scale), AV_OPT_TYPE_FLOAT, { .dbl = 1.5f }, 0.f, 4.f, VD },
+    { NULL }
+};
+
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX | \
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+
+#define MLUMPP_DEC_CODEC(x, X) \
+    static const AVClass x##_mlumpp_class = { \
+        .class_name = #x "_mludec", \
+        .item_name = av_default_item_name, \
+        .option = options, \
+        .version = LIBAVUTIL_VERSION_INT, \
+    }; \
+    AVCodec ff_##x##_mlumpp_decoder = { \
+        .name           = #x "_mludec", \
+        .long_name      = NULL_IF_CONFIG_SMALL("Cambricon MLUMPP " #X " decoder"), \
+        .type           = AVMEDIA_TYPE_VIDEO, \
+        .id             = AV_CODEC_ID_##X, \
+        .priv_data_size = sizeof(MLUMPPContext_t), \
+        .priv_class     = &x##_mlumpp_class, \
+        .init           = ff_cndec_decode_init, \
+        .close          = ff_cndec_decode_end, \
+        .receive_frame  = ff_cndec_receive_frame, \
+        .flush          = ff_cndec_flush,  \
+        .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_HARDWARE, \
+        .pix_fmts       = (const enum AVPixelFormat[]){ AV_PIX_FMT_MLU, \
+                                                        AV_PIX_FMT_NV12, \
+                                                        AV_PIX_FMT_NV21, \
+                                                        AV_PIX_FMT_YUV420P, \
+                                                        AV_PIX_FMT_P010, \
+                                                        AV_PIX_FMT_NONE }, \
+        .hw_configs     = mlu_hw_configs, \
+        .wrapper_name   = "mludec", \
+    };
+
+#if CONFIG_HEVC_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(hevc, HEVC)
+#endif
+#if CONFIG_H264_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(h264, H264)
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(mjpeg, MJPEG)
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp8, VP8)
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp9, VP9)
+#endif
diff --git a/libavcodec/mlumpp_enc_h264.c b/libavcodec/mlumpp_enc_h264.c
new file mode 100644
index 0000000000..721589b664
--- /dev/null
+++ b/libavcodec/mlumpp_enc_h264.c
@@ -0,0 +1,215 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencH264EncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencH264EncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencH264EncContext *cnctx =(CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+}
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+
+static const AVCodecDefault h264_defaults[] = {
+    { "b",                "2M" },
+    { "bf",               "0"  },
+    { "g",                "30" },
+    { "qmin",             "0"  },
+    { "qmax",             "51" },
+    { "qdiff",            "-1" },
+    { "qblur",            "-1" },
+    { "qcomp",            "-1" },
+    { "refs",             "0"  },
+    { NULL },
+};
+
+#define OFFSET(x) offsetof(CNencH264EncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",      "accelerator card index",   OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "trace",          "trace log switch",         OFFSET(cnenc.trace_flag),     AV_OPT_TYPE_INT, { .i64 = 0 },  0,  2,       VE },                        \
+    { "stride_align",   "pic stride_align. the number MUST be a power of 2", OFFSET(cnenc.stride_align), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 128,VE },        \
+    { "input_buf_num",  "input buffer num. value 0 means AUTOmatic. Manual setting value MUST greater than frame_interval_p + 1",                           \
+                                                    OFFSET(cnenc.input_buf_num),  AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "stream_buf_size","stream buffer size. value 0 means AUTOmatic",                                                                                      \
+                                                    OFFSET(cnenc.stream_buf_size),AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "frame_interval_p","the number of B frames between two P frames", OFFSET(cnenc.frame_interval_p), AV_OPT_TYPE_INT, { .i64 = 1 }, 0,  INT_MAX, VE },   \
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "preset",             "encode preset mode", OFFSET(cnenc.preset), AV_OPT_TYPE_INT,  { .i64 = CNCODEC_ENC_PRESET_FAST }, CNCODEC_ENC_PRESET_FAST, CNCODEC_ENC_PRESET_MAX, VE, "preset"},
+    { "fast",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_FAST },    0,  0,  VE,  "preset" },
+    { "medium",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_MEDIUM },  0,  0,  VE,  "preset" },
+    { "slow",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_SLOW },    0,  0,  VE,  "preset" },
+
+    { "rdo_level",          "encode rdo level", OFFSET(cnenc.rdo_level), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 4, VE, "rdo_level"},
+
+    { "colorspace",         "encode color space", OFFSET(cnenc.color_space), AV_OPT_TYPE_INT, { .i64 = CNCODEC_COLOR_SPACE_BT_709 }, CNCODEC_COLOR_SPACE_BT_709, CNCODEC_COLOR_SPACE_BT_709_ER, VE, "colorspace"},
+    { "bt709",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709 },    0,  0,  VE,  "colorspace" },
+    { "bt601",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601 },    0,  0,  VE,  "colorspace" },
+    { "bt2020",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020 },   0,  0,  VE,  "colorspace" },
+    { "bt601er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601_ER }, 0,  0,  VE,  "colorspace" },
+    { "bt709er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709_ER }, 0,  0,  VE,  "colorspace" },
+
+    { "stream_type",        "encode output stream type.", OFFSET(cnenc.stream_type), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BYTE_STREAM }, CNCODEC_ENC_BYTE_STREAM, CNCODEC_ENC_STREAM_TYPE_MAX, VE, "stream_type"},
+    { "byte_stream",        "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BYTE_STREAM }, 0,  0,  VE,  "stream_type" },
+    { "nalu_stream",        "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_NALU_STREAM }, 0,  0,  VE,  "stream_type" },
+
+    { "rc",                 "encode output stream type.", OFFSET(cnenc.rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_RATE_CTRL_VBR }, CNCODEC_ENC_RATE_CTRL_CBR, CNCODEC_ENC_RATE_CTRL_MODE_MAX, VE, "rc"},
+    { "cbr",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CBR },           0,  0,  VE,  "rc" },
+    { "vbr",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_VBR },           0,  0,  VE,  "rc" },
+    { "cvbr",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CVBR },          0,  0,  VE,  "rc" },
+    { "crf",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CRF },           0,  0,  VE,  "rc" },
+    { "fixedqp",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_FIXEDQP },       0,  0,  VE,  "rc" },
+    { "mode_max",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_MODE_MAX },      0,  0,  VE,  "rc" },
+#if CNCODEC_MINOR_VERSION >= 8
+    { "block_size",         "encode block size.", OFFSET(cnenc.block_size), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 }, CNCODEC_ENC_BLOCK_UNIT_64x64, CNCODEC_ENC_BLOCK_UNIT_MAX, VE, "block_size"},
+    { "64",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 },       0,  0, VE,   "block_size" },
+    { "32",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_32x32 },       0,  0, VE,   "block_size" },
+    { "16",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_16x16 },       0,  0, VE,   "block_size" },
+    { "block_max",          "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_MAX   },       0,  0, VE,   "block_size" },
+
+    { "ctb_rc",             "encode CTB RC mode.", OFFSET(cnenc.ctb_rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_CTB_RC_DISABLED }, CNCODEC_ENC_CTB_RC_DISABLED, CNCODEC_ENC_CTB_RC_MAX, VE, "ctb_rc"},
+    { "disable",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_DISABLED },              0,  0, VE,  "ctb_rc" },
+    { "sub",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_SUBJECTIVE_QUALITY },    0,  0, VE,  "ctb_rc" },
+    { "obj",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_OBJECTIVE_QUALITY  },    0,  0, VE,  "ctb_rc" },
+    { "both",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_BOTH   },                0,  0, VE,  "ctb_rc" },
+    { "ctb_rc_max",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_MAX    },                0,  0, VE,  "ctb_rc" },
+
+    { "target_quality",     "target quality, only works in rc mode crf", OFFSET(cnenc.target_quality), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 51, VE, "target_quality"},
+    { "lookahead",          "lookahead depth, value range [0] and [4 ,40], lower than 4 will be set as 0.", OFFSET(cnenc.lookahead_depth), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 40, VE, "lookahead_depth"},
+    { "ctb_row",            "ctb row qp step", OFFSET(cnenc.ctb_row_qp_step), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 64, VE, "ctb_row_qp_step"},
+    { "rc_qp_delta_range",  "specified the max delta qp value", OFFSET(cnenc.rc_qp_delta_range), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 15, VE, "rc_qp_delta_range"},
+    { "base_ctb",           "specifies the rc base ctb complexity in ctb rc", OFFSET(cnenc.rc_base_ctb_comp), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 30, VE, "ctb_row_qp_step"},
+#endif
+    { "rc_bufsize",         "vbv bufsize.", OFFSET(cnenc.rc_bufsize), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE, "bufsize"},
+
+    { "init_qpI",           "the QP for I frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_i), AV_OPT_TYPE_INT,      { .i64 = 30 },    0,  51, VE },
+    { "init_qpB",           "the QP for B frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_b), AV_OPT_TYPE_INT,      { .i64 = 32 },    0,  51, VE },
+    { "init_qpP",           "the QP for P frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_p), AV_OPT_TYPE_INT,      { .i64 = 32 },    0,  51, VE },
+    { "qp",                 "the initial QP value",                         OFFSET(cnenc.init_qp),    AV_OPT_TYPE_INT,      { .i64 = 27 },    -1, 51, VE },
+    { "rc_windows",         "the windows of rc to ensure bitrate",          OFFSET(cnenc.rc_windows), AV_OPT_TYPE_INT,      { .i64 = 100},    0,  400,VE },
+    { "idr_period",         "interval of two idr frames",                   OFFSET(cnenc.idr_period), AV_OPT_TYPE_INT,      { .i64 = 30 },    1,  4294967295, VE },
+
+    { "profile",            "the encode profile. value range 0 to 3", OFFSET(cnenc.profile), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_PROFILE_H264_MAIN }, CNCODEC_ENC_PROFILE_H264_BASELINE, CNCODEC_ENC_PROFILE_H264_HIGH_10, VE, "profile"},
+    { "baseline",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_BASELINE },   0,  0,  VE,  "profile" },
+    { "main",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_MAIN },       0,  0,  VE,  "profile" },
+    { "high",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_HIGH },       0,  0,  VE,  "profile" },
+    { "high10",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_HIGH_10 },    0,  0,  VE,  "profile" },
+
+    { "level",              "the encode level. value range 0 to 19", OFFSET(cnenc.level), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_LEVEL_H264_51 }, CNCODEC_ENC_LEVEL_H264_1, CNCODEC_ENC_LEVEL_H264_62, VE, "level"},
+    { "auto",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_13 },           0,  0,  VE,  "level" },
+    { "1",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1 },            0,  0,  VE,  "level" },
+    { "1.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1 },            0,  0,  VE,  "level" },
+    { "1b",                 "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1B },           0,  0,  VE,  "level" },
+    { "1.0b",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1B },           0,  0,  VE,  "level" },
+    { "1.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_11 },           0,  0,  VE,  "level" },
+    { "1.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_12 },           0,  0,  VE,  "level" },
+    { "1.3",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_13 },           0,  0,  VE,  "level" },
+    { "2",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_2 },            0,  0,  VE,  "level" },
+    { "2.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_2 },            0,  0,  VE,  "level" },
+    { "2.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_21 },           0,  0,  VE,  "level" },
+    { "2.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_22 },           0,  0,  VE,  "level" },
+    { "3",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_3 },            0,  0,  VE,  "level" },
+    { "3.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_3 },            0,  0,  VE,  "level" },
+    { "3.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_31 },           0,  0,  VE,  "level" },
+    { "3.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_32 },           0,  0,  VE,  "level" },
+    { "4",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_4 },            0,  0,  VE,  "level" },
+    { "4.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_4 },            0,  0,  VE,  "level" },
+    { "4.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_41 },           0,  0,  VE,  "level" },
+    { "4.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_42 },           0,  0,  VE,  "level" },
+    { "5",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_5 },            0,  0,  VE,  "level" },
+    { "5.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_5 },            0,  0,  VE,  "level" },
+    { "5.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_51 },           0,  0,  VE,  "level" },
+    { "5.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_52 },           0,  0,  VE,  "level" },
+    { "6",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_6 },            0,  0,  VE,  "level" },
+    { "6.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_6 },            0,  0,  VE,  "level" },
+    { "6.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_61 },           0,  0,  VE,  "level" },
+    { "6.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_62 },           0,  0,  VE,  "level" },
+    { NULL },
+};
+static const AVClass class = {
+    .class_name = "h264_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_h264_mlumpp_encoder = {
+    .name = "h264_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("H.264 ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_H264,
+    .init = mlumpp_enc_init,
+    .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    /*.encode2        = mlumpp_enc_frame,*/
+    .close = mlumpp_enc_close,
+    .priv_data_size = sizeof(CNencH264EncContext),
+    .priv_class = &class,
+    .defaults = h264_defaults,
+    .capabilities = AV_CODEC_CAP_DELAY,
+    .caps_internal = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_P010,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_ARGB,
+                                             AV_PIX_FMT_BGRA,
+                                             AV_PIX_FMT_RGBA,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
diff --git a/libavcodec/mlumpp_enc_hevc.c b/libavcodec/mlumpp_enc_hevc.c
new file mode 100644
index 0000000000..2444da1530
--- /dev/null
+++ b/libavcodec/mlumpp_enc_hevc.c
@@ -0,0 +1,224 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencHevcEncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencHevcEncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+
+static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+}
+
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt){
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+
+static const AVCodecDefault hevc_defaults[] = {
+    { "b",                "2M" },
+    { "bf",               "0"  },
+    { "g",                "30" },
+    { "qmin",             "0"  },
+    { "qmax",             "51" },
+    { "qdiff",            "-1" },
+    { "qblur",            "-1" },
+    { "qcomp",            "-1" },
+    { "refs",             "0"  },
+#if FF_API_CODER_TYPE
+    { "coder",            "-1" },
+#endif
+    { NULL },
+};
+
+#define OFFSET(x) offsetof(CNencHevcEncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",       "accelerator card index", OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "trace",           "trace log switch",       OFFSET(cnenc.trace_flag),     AV_OPT_TYPE_INT, { .i64 = 0 },  0, 2,  VE },                            \
+    { "stride_align",    "pic stride_align. the number MUST be a power of 2", OFFSET(cnenc.stride_align), AV_OPT_TYPE_INT, { .i64 = 1 }, 1,  128, VE },  \
+    { "input_buf_num",   "input buffer num. value 0 means AUTOmatic(2pass proposed). Manual setting value MUST greater than frame_interval_p + 1.",                       \
+                                                   OFFSET(cnenc.input_buf_num),  AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "stream_buf_size", "stream buffer size. value 0 means AUTOmatic",                                                                                  \
+                                                   OFFSET(cnenc.stream_buf_size),AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "frame_interval_p","the number of B frames between two P frames", OFFSET(cnenc.frame_interval_p), AV_OPT_TYPE_INT, { .i64 = 1 }, 0,  INT_MAX, VE },\
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "preset",             "encode preset mode", OFFSET(cnenc.preset), AV_OPT_TYPE_INT,    { .i64 = CNCODEC_ENC_PRESET_FAST }, CNCODEC_ENC_PRESET_FAST, CNCODEC_ENC_PRESET_MAX, VE, "preset"},
+    { "fast",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_FAST },            0,  0, VE,  "preset" },
+    { "medium",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_MEDIUM },          0,  0, VE,  "preset" },
+    { "slow",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_SLOW },            0,  0, VE,  "preset" },
+
+    { "rdo_level",          "encode rdo level", OFFSET(cnenc.rdo_level), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 4, VE, "rdo_level"},
+
+    { "colorspace",         "encode colorspace.", OFFSET(cnenc.color_space), AV_OPT_TYPE_INT,{ .i64 = CNCODEC_COLOR_SPACE_BT_709 }, CNCODEC_COLOR_SPACE_BT_709, CNCODEC_COLOR_SPACE_BT_709_ER, VE, "colorspace"},
+    { "bt709",              "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709 },         0,  0, VE,  "colorspace" },
+    { "bt601",              "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601 },         0,  0, VE,  "colorspace" },
+    { "bt2020",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020 },        0,  0, VE,  "colorspace" },
+    { "bt601er",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601_ER },      0,  0, VE,  "colorspace" },
+    { "bt709er",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709_ER },      0,  0, VE,  "colorspace" },
+
+    { "stream_type",        "encode output stream type.", OFFSET(cnenc.stream_type), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BYTE_STREAM }, CNCODEC_ENC_BYTE_STREAM, CNCODEC_ENC_STREAM_TYPE_MAX, VE, "stream_type"},
+    { "byte_stream",        "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BYTE_STREAM },            0,  0, VE,  "stream_type" },
+    { "nalu_stream",        "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_NALU_STREAM },            0,  0, VE,  "stream_type" },
+
+    { "rc",                 "encode output stream type.", OFFSET(cnenc.rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_RATE_CTRL_VBR }, CNCODEC_ENC_RATE_CTRL_CBR, CNCODEC_ENC_RATE_CTRL_MODE_MAX, VE, "rc"},
+    { "cbr",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CBR },          0,  0, VE,  "rc" },
+    { "vbr",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_VBR },          0,  0, VE,  "rc" },
+    { "cvbr",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CVBR },         0,  0, VE,  "rc" },
+    { "crf",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CRF },          0,  0, VE,  "rc" },
+    { "fixedqp",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_FIXEDQP },      0,  0, VE,  "rc" },
+    { "mode_max",           "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_MODE_MAX },     0,  0, VE,  "rc" },
+#if CNCODEC_MINOR_VERSION >= 8
+    { "block_size",         "encode block size.", OFFSET(cnenc.block_size), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 }, CNCODEC_ENC_BLOCK_UNIT_64x64, CNCODEC_ENC_BLOCK_UNIT_MAX, VE, "block_size"},
+    { "64",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 },       0,  0, VE,   "block_size" },
+    { "32",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_32x32 },       0,  0, VE,   "block_size" },
+    { "16",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_16x16 },       0,  0, VE,   "block_size" },
+    { "8",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_8x8   },       0,  0, VE,   "block_size" },
+    { "block_max",          "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_MAX   },       0,  0, VE,   "block_size" },
+
+    { "ctb_rc",             "encode CTB RC mode.", OFFSET(cnenc.ctb_rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_CTB_RC_DISABLED }, CNCODEC_ENC_CTB_RC_DISABLED, CNCODEC_ENC_CTB_RC_MAX, VE, "ctb_rc"},
+    { "disable",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_DISABLED },              0,  0, VE,  "ctb_rc" },
+    { "sub",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_SUBJECTIVE_QUALITY },    0,  0, VE,  "ctb_rc" },
+    { "obj",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_OBJECTIVE_QUALITY  },    0,  0, VE,  "ctb_rc" },
+    { "both",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_BOTH   },                0,  0, VE,  "ctb_rc" },
+    { "ctb_rc_max",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_MAX    },                0,  0, VE,  "ctb_rc" },
+
+    { "target_quality",     "target quality, only works in rc mode crf", OFFSET(cnenc.target_quality), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 51, VE, "target_quality"},
+    { "lookahead",          "lookahead depth, value range [0] and [4 ,40], lower than 4 will be set as 0.", OFFSET(cnenc.lookahead_depth), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 40, VE, "lookahead_depth"},
+    { "ctb_row",            "ctb row qp step, only works in obj and both ctb rc mode", OFFSET(cnenc.ctb_row_qp_step), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 64, VE, "ctb_row_qp_step"},
+    { "rc_qp_delta_range",  "specified the max delta qp value", OFFSET(cnenc.rc_qp_delta_range), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 15, VE, "rc_qp_delta_range"},
+    { "base_ctb",           "specifies the rc base ctb complexity in ctb rc, only works in sub and obj ctb rc mode", OFFSET(cnenc.rc_base_ctb_comp), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 30, VE, "ctb_row_qp_step"},
+#endif
+    { "rc_bufsize",         "vbv bufsize.", OFFSET(cnenc.rc_bufsize), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE, "bufsize"},
+
+    { "init_qpI",           "set the QP for I frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_i),     AV_OPT_TYPE_INT, { .i64 = 30 },  0, 51, VE },
+    { "init_qpB",           "set the QP for B frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_b),     AV_OPT_TYPE_INT, { .i64 = 32 },  0, 51, VE },
+    { "init_qpP",           "set the QP for P frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_p),     AV_OPT_TYPE_INT, { .i64 = 30 },  0, 51, VE },
+    { "qp",                 "set the initial QP value",                         OFFSET(cnenc.init_qp),        AV_OPT_TYPE_INT, { .i64 = 27 },  0, 51, VE },
+    { "rc_windows",         "set the windows of rc to ensure bitrate",          OFFSET(cnenc.rc_windows),     AV_OPT_TYPE_INT, { .i64 = 60 },  0, INT_MAX, VE },
+    { "enable_sao",         "hevc encode params for enable sao",                OFFSET(cnenc.enable_sao),     AV_OPT_TYPE_INT, { .i64 = 1  },  0, 1,  VE },
+    { "idr_period",         "interval of two idr frames",                       OFFSET(cnenc.idr_period),     AV_OPT_TYPE_INT, { .i64 = 30 },  1, 4294967295, VE },
+
+    { "profile",            "set the encoder profile. Effective value range 4 to 7", OFFSET(cnenc.profile), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN }, CNCODEC_ENC_PROFILE_HEVC_MAIN, CNCODEC_ENC_PROFILE_MAX, VE, "profile"},
+    { "main",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN },       0,  0, VE,  "profile" },
+    { "main_still",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN_STILL }, 0,  0, VE,  "profile" },
+    { "prof_max",           "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_MAX},              0,  0, VE,  "profile" },
+    { "main10",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN_10 },    0,  0, VE,  "profile" },
+
+    { "tier",               "set the HEVC encoder tier. Effective value range 0 to 2", OFFSET(cnenc.tier), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_TIER_HEVC_MAIN }, CNCODEC_ENC_TIER_HEVC_MAIN, CNCODEC_ENC_TIER_HEVC_MAX, VE, "tier"},
+    { "main",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_MAIN },          0,  0, VE,  "tier" },
+#if CNCODEC_MAJOR_VERSION < 1
+    { "high",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_HIGHT },         0,  0, VE,  "tier" },
+#else
+    { "high",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_HIGH },         0,  0, VE,  "tier" },
+#endif
+
+    { "level",              "set the encoder level. Effective value range 20 to 33", OFFSET(cnenc.level), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_LEVEL_HEVC_51 }, CNCODEC_ENC_LEVEL_HEVC_1, CNCODEC_ENC_LEVEL_MAX, VE, "level"},
+    { "auto",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "1",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_1 },            0,  0,  VE, "level" },
+    { "1.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_1 },            0,  0,  VE, "level" },
+    { "2",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_2 },            0,  0,  VE, "level" },
+    { "2.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_2 },            0,  0,  VE, "level" },
+    { "2.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_21 },           0,  0,  VE, "level" },
+    { "3",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_3 },            0,  0,  VE, "level" },
+    { "3.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_3 },            0,  0,  VE, "level" },
+    { "3.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_31 },           0,  0,  VE, "level" },
+    { "4",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_4 },            0,  0,  VE, "level" },
+    { "4.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_4 },            0,  0,  VE, "level" },
+    { "4.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_41 },           0,  0,  VE, "level" },
+    { "5",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "5.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "5.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_51 },           0,  0,  VE, "level" },
+    { "5.2",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_52 },           0,  0,  VE, "level" },
+    { "6",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_6 },            0,  0,  VE, "level" },
+    { "6.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_6 },            0,  0,  VE, "level" },
+    { "6.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_61 },           0,  0,  VE, "level" },
+    { "6.2",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_62 },           0,  0,  VE, "level" },
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "hevc_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_hevc_mlumpp_encoder = {
+    .name = "hevc_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("HEVC ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_HEVC,
+    .init = mlumpp_enc_init,
+    .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    /*.encode2 = mlumpp_enc_frame,*/
+    .close = mlumpp_enc_close,
+    .priv_data_size = sizeof(CNencHevcEncContext),
+    .priv_class = &class,
+    .defaults = hevc_defaults,
+    .capabilities = AV_CODEC_CAP_DELAY,
+    .caps_internal = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_P010,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_ARGB,
+                                             AV_PIX_FMT_BGRA,
+                                             AV_PIX_FMT_RGBA,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
diff --git a/libavcodec/mlumpp_enc_jpeg.c b/libavcodec/mlumpp_enc_jpeg.c
new file mode 100644
index 0000000000..a0c68e3eee
--- /dev/null
+++ b/libavcodec/mlumpp_enc_jpeg.c
@@ -0,0 +1,109 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencJpegEncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencJpegEncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+
+static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+{
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+}
+
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt){
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+
+#define OFFSET(x) offsetof(CNencJpegEncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+// #define MLU3XX_COMMON_OPTS
+static const AVOption options[] = {
+    { "device_id",          "accelerator card index",       OFFSET(cnenc.device_id),       AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },
+    { "trace",              "trace log switch",             OFFSET(cnenc.trace_flag),      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 2,       VE },
+    { "stride_align",       "pic stride_align. the number MUST be a power of 2",
+                                                            OFFSET(cnenc.stride_align),    AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 128,     VE },
+    { "input_buf_num",      "input buffer num. value 0 means decided AUTOmatic",
+                                                            OFFSET(cnenc.input_buf_num),   AV_OPT_TYPE_INT, { .i64 = 2 }, 0, INT_MAX, VE },
+    { "stream_buf_size",    "stream buffer size. value 0 means decided AUTOmatic",
+                                                            OFFSET(cnenc.stream_buf_size), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },
+    { "quality",            "jpeg encoder picure quality",  OFFSET(cnenc.quality),         AV_OPT_TYPE_INT, { .i64 = 80 },1, INT_MAX, VE },
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "mjpeg_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX |
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_mjpeg_mlumpp_encoder = {
+    .name = "mjpeg_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("Jpeg ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_MJPEG,
+    .init = mlumpp_enc_init,
+    .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    .close = mlumpp_enc_close,
+    .priv_data_size = sizeof(CNencJpegEncContext),
+    .priv_class = &class,
+    .capabilities = AV_CODEC_CAP_FRAME_THREADS | AV_CODEC_CAP_INTRA_ONLY,
+    .caps_internal = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]){AV_PIX_FMT_NV12,
+                                             AV_PIX_FMT_NV21,
+                                             AV_PIX_FMT_YUYV422,
+                                             AV_PIX_FMT_UYVY422,
+                                             AV_PIX_FMT_MLU,
+                                             AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
\ No newline at end of file
diff --git a/libavcodec/mlumpp_vid_enc.c b/libavcodec/mlumpp_vid_enc.c
new file mode 100644
index 0000000000..c2a078d202
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.c
@@ -0,0 +1,978 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+#define CN_JFRAME_ALIGN_H 16
+#define CN_JFRAME_ALIGN_W 64
+#define CN_VFRAME_ALIGN_W 1
+
+static inline int cnenc_check_stride_align(AVCodecContext* avctx, MLUMPPEncContext_t *cnctx)
+{
+    int tmp;
+    int align = cnctx->stride_align;
+    if (align & (align - 1)) {
+        av_log(avctx, AV_LOG_ERROR,
+              "Parames error, stride align must be a power of 2, now is %d\n", cnctx->enc_attr.input_stride_align);
+        return -1;
+    }
+    tmp = 0;
+    while (align > 1) {
+        align >>= 1;
+        tmp++;
+    }
+    av_log(cnctx->avctx, AV_LOG_DEBUG, "stride align is the %d power of 2.\n", tmp);
+
+    return 0;
+}
+
+static inline int cnenc_check_resolution(AVCodecContext* avctx)
+{
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_HEVC:
+        if (avctx->width < 136 ||  avctx->width > 8192 || avctx->height < 136 || avctx->height > 8192) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU video encoder only support resolution: 136x136~8192x8192 for HEVC format\n");
+            return -1;
+        }
+        break;
+    case AV_CODEC_ID_H264:
+        if (avctx->width < 144 ||  avctx->width > 8192 || avctx->height < 144 || avctx->height > 8192) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU video encoder only support resolution: 144x144~8192x8192 for H264 format\n");
+            return -1;
+        }
+        break;
+    //TO-DOadd JPEG case:
+    case AV_CODEC_ID_MJPEG:
+        if (avctx->width < 16 ||  avctx->width > 8192 || avctx->height < 16 || avctx->height > 8192) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU video encoder only support resolution: 144x144~8192x8192 for Jpeg format\n");
+            return -1;
+        }
+        break;
+    default:
+        if (avctx->width < 144 ||  avctx->width > 8192 || avctx->height < 144 || avctx->height > 8192) {
+            av_log(avctx, AV_LOG_ERROR, "Unsupport resoution: %dx%d\n", avctx->width, avctx->height);
+            av_log(avctx, AV_LOG_ERROR, "MLU video encoder only support resolution: 144x144~4096x4096 for %d ID [unknown] format\n", avctx->codec_id);
+            return -1;
+        }
+        break;
+    }
+    return 0;
+}
+
+static int mlu_device_binding(MLUMPPEncContext_t *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static inline unsigned int cnenc_fifo_elem_size(void)
+{
+    return sizeof(EventInfoMsg_t);
+}
+
+static inline unsigned int cnenc_fifo_size(const AVFifoBuffer *fifo)
+{
+    return av_fifo_size(fifo) / cnenc_fifo_elem_size();
+}
+
+static int cnenc_is_fifo_empty(MLUMPPEncContext_t *cnctx)
+{
+    int is_fifo_empty = 0;
+    ff_mutex_lock(&cnctx->queue_mutex);
+    is_fifo_empty = (cnenc_fifo_size(cnctx->frame_queue) == 0);
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    return is_fifo_empty;
+}
+
+static int cnenc_event_cb(cncodecEventType_t eventType, void *pUserData, void *cbInfo)
+{
+    EventInfoMsg_t msg;
+    MLUMPPEncContext_t *userctx = (MLUMPPEncContext_t *)pUserData;
+    msg.event_type = eventType;
+    msg.cnctx = pUserData;
+    if (!userctx->handle) {
+        av_log(userctx->avctx, AV_LOG_ERROR, "Callback func can't find userctx handle!\n");
+        sem_post(&userctx->eos_sema);
+        return AVERROR(EPERM);
+    }
+    if(mlu_device_binding(userctx) < 0) {
+        av_log(userctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    switch (eventType) {
+    case CNCODEC_EVENT_NEW_FRAME:
+        msg.event_output.stream = *((cncodecStream_t *)cbInfo);
+        ff_mutex_lock(&userctx->queue_mutex);
+        av_fifo_generic_write(userctx->frame_queue, &msg, sizeof(EventInfoMsg_t), NULL);
+        CN_ERROR_CHECK(userctx->avctx,
+            cncodecEncStreamRef(userctx->handle,&(msg.event_output.stream)),
+            "Callback func, add new stream ref");
+        ff_mutex_unlock(&userctx->queue_mutex);
+        break;
+    case CNCODEC_EVENT_EOS:
+        // msg.event_output.stream = *((cncodecStream_t *)cbInfo);
+        msg.event_output.stream.stream_type = CNCODEC_NALU_TYPE_EOS;
+        msg.event_output.stream.data_len = 0;
+        msg.event_output.stream.mem_addr = msg.event_output.stream.data_offset
+                                         = msg.event_output.stream.alloc_len = 0;
+        ff_mutex_lock(&userctx->queue_mutex);
+        av_log(userctx->avctx, AV_LOG_DEBUG, "callback func set EOS to fifo.\n");
+        av_fifo_generic_write(userctx->frame_queue, &msg, sizeof(EventInfoMsg_t), NULL);
+        if (!userctx->eos_post_flag) {
+            userctx->eos_post_flag = 1;
+        }
+        ff_mutex_unlock(&userctx->queue_mutex);
+        sem_post(&userctx->eos_sema);
+        break;
+    case CNCODEC_EVENT_OUT_OF_MEMORY:
+        av_log(userctx->avctx, AV_LOG_ERROR,
+            "Encode got [OUT OF MEMORY] eventType, encoder abort\n");
+        if (!userctx->codec_abort_flag) {
+            sem_post(&userctx->eos_sema);
+            userctx->codec_abort_flag = 1;
+        }
+        break;
+    case CNCODEC_EVENT_STREAM_NOT_SUPPORTED:
+        av_log(userctx->avctx, AV_LOG_ERROR,
+            "Encode got [STREAM NOT SUPPORTED] eventType, encoder abort\n");
+        if (!userctx->codec_abort_flag) {
+            sem_post(&userctx->eos_sema);
+            userctx->codec_abort_flag = 1;
+        }
+        break;
+    default:
+        av_log(userctx->avctx, AV_LOG_ERROR,
+            "Encode got [UNKNOW] eventType: %d \n", eventType);
+        if (!userctx->codec_abort_flag) {
+            sem_post(&userctx->eos_sema);
+            userctx->codec_abort_flag = 1;
+        }
+        break;
+    }
+    return 0;
+}
+
+static int cnenc_memcpy_block(MLUMPPEncContext_t *cnctx, void *dst, void *src, size_t data_size) {
+    MluContext *mlu_ctx = NULL;
+    cnrtRet_t cnrt_ret;
+
+    mlu_ctx = cnctx->mlu_ctx;
+    if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        cnrt_ret = mlu_ctx->mluMemcpyD2D(dst, src, data_size, CNRT_MEM_TRANS_DIR_DEV2DEV);
+        CN_ERROR_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy D2D");
+    } else {
+        cnrt_ret = mlu_ctx->mluMemcpyH2D(dst, src, data_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+        CN_ERROR_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy H2D");
+    }
+    return 0;
+}
+
+static int cnenc_memcpy_by_line(MLUMPPEncContext_t *cnctx, void *dst, void *src, size_t data_size,
+                                int cnframe_stride, int avlinesize, int width) {
+    cnrtRet_t cnrt_ret;
+    int linecount, line_index;
+    uint8_t *dst_ptr = NULL;
+    uint8_t *src_ptr = NULL;
+    uint8_t *line_space = NULL;
+    MluContext *mlu_ctx = NULL;
+
+    mlu_ctx = cnctx->mlu_ctx;
+    linecount = data_size / avlinesize;
+
+    line_space = (uint8_t*)malloc(cnframe_stride * linecount);
+    if (NULL == line_space) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "input buf memcpy malloc failed!\n");
+        return AVERROR(EINVAL);
+    }
+    memset(line_space, 0, cnframe_stride * linecount);
+
+    if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        for (line_index = 0; line_index < linecount; ++line_index) {
+            dst_ptr = (uint8_t*)(dst) + cnframe_stride * line_index;
+            src_ptr = (uint8_t*)(src) + avlinesize * line_index;
+            cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)dst_ptr, (void*)src_ptr,
+                                width, CNRT_MEM_TRANS_DIR_DEV2DEV);
+            if (CNRT_RET_SUCCESS != cnrt_ret) {
+                free(line_space);
+                CN_ERROR_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy D2D");
+            }
+        }
+    } else {
+        for (line_index = 0; line_index < linecount; ++line_index) {
+            src_ptr = (uint8_t*)(src) + avlinesize * line_index;
+            memcpy(line_space + cnframe_stride * line_index, src_ptr, width);
+        }
+        cnrt_ret = mlu_ctx->mluMemcpyH2D(dst, (void*)line_space,
+                                         cnframe_stride * linecount,
+                                         CNRT_MEM_TRANS_DIR_HOST2DEV);
+        if (CNRT_RET_SUCCESS != cnrt_ret) {
+            free(line_space);
+            CN_ERROR_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy H2D");
+        }
+    }
+    free(line_space);
+    return 0;
+}
+
+static int cnenc_build_input_buffer(MLUMPPEncContext_t *cnctx, cncodecFrame_t *tempInput, const AVFrame *frame)
+{
+    int ret = -1;
+    int time_out = 3000;
+    cncodecPixelFormat_t pix_fmt;
+    int plane_sum;
+    int plane_i;
+    int cnframe_stride;
+    int avlinesize;
+    float w_depth;
+    float h_depth;
+
+    pix_fmt = cnctx->enc_attr.pixel_format;
+    plane_sum = cncodec_get_plane_num(pix_fmt);
+    ret = cncodecEncWaitAvailInputBuf(cnctx->handle, tempInput, time_out);
+    CN_ERROR_CHECK(cnctx->avctx, ret, "wait avail input buf");
+    // ptr mem check
+    for (plane_i = 0; plane_i < plane_sum; ++plane_i) {
+        if (!tempInput->plane[plane_i].dev_addr) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Enc input buffer dst address is NULL \n");
+            return AVERROR(EINVAL);
+        }
+        if (NULL == frame->data[plane_i]) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Enc input data src address is NULL \n");
+            return AVERROR(EINVAL);
+        }
+    }
+
+    for (plane_i = 0; plane_i < plane_sum; ++plane_i) {
+        cnframe_stride = tempInput->plane[plane_i].stride;
+        avlinesize = frame->linesize[plane_i];
+        if (cncodec_get_plane_depth(pix_fmt, plane_i, &w_depth, &h_depth)) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Unsupported pix format!\n");
+        }
+        if (cnframe_stride == avlinesize) {
+            ret = cnenc_memcpy_block(cnctx, (void *)tempInput->plane[plane_i].dev_addr,
+                                     (void *)frame->data[plane_i], avlinesize * frame->height * h_depth);
+        } else {
+            av_log(cnctx->avctx, AV_LOG_WARNING,
+                   "Warning: data is not aligned! This can lead to a speed loss\n");
+            ret = cnenc_memcpy_by_line(cnctx, (void *)tempInput->plane[plane_i].dev_addr,
+                                       (void *)frame->data[plane_i], avlinesize * frame->height * h_depth,
+                                       cnframe_stride, avlinesize, frame->width * w_depth);
+        }
+        if (ret)
+            break;
+    }
+    return ret;
+}
+
+static inline void cnenc_timestamp_queue_push(AVFifoBuffer* queue, int64_t timestamp) {
+    av_fifo_generic_write(queue, &timestamp, sizeof(timestamp), NULL);
+    return;
+}
+
+static inline int64_t cnenc_timestamp_queue_pop(AVFifoBuffer* queue) {
+    int64_t timestamp = AV_NOPTS_VALUE;
+    if (av_fifo_size(queue) > 0) {
+        av_fifo_generic_read(queue, &timestamp, sizeof(timestamp), NULL);
+    }
+    return timestamp;
+}
+
+static int cnenc_set_packet_timestamp(MLUMPPEncContext_t *cnctx, EventInfoMsg_t *encodedmsg, AVPacket *pkt) {
+    int64_t ts0, ts1, tsbase;
+    AVCodecContext *avctx = cnctx->avctx;
+    pkt->pts = encodedmsg->event_output.stream.pts;
+    if (avctx->max_b_frames > 0 && !cnctx->first_pts_out
+        && cnctx->initial_pts[1] != AV_NOPTS_VALUE) {
+        ts0 = cnctx->initial_pts[0];
+        ts1 = cnctx->initial_pts[1];
+        if ((ts0 < 0 && ts1 > INT64_MAX + ts0) ||
+            (ts0 > 0 && ts1 < INT64_MIN + ts0))
+            return AVERROR(ERANGE);
+        tsbase = ts1 - ts0;
+        if ((tsbase < 0 && ts0 > INT64_MAX + tsbase) ||
+            (tsbase > 0 && ts0 < INT64_MIN + tsbase))
+            return AVERROR(ERANGE);
+        pkt->dts = ts0 - tsbase;
+        cnctx->first_pts_out = 1;
+        return 0;
+    }
+    pkt->dts = cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+    cnctx->first_pts_out = 1;
+    return 0;
+}
+
+static int cnenc_output_packet(MLUMPPEncContext_t *cnctx, AVPacket *pkt, int *got_packet)
+{
+    int ret = -1;
+    cnrtRet_t cnrt_ret;
+    EventInfoMsg_t encodedmsg;
+    MluContext *mlu_ctx = cnctx->mlu_ctx;
+    enum AVPictureType pict_type = AV_PICTURE_TYPE_NONE;
+    if (cnenc_is_fifo_empty(cnctx)) {
+        *got_packet = 0;
+        return AVERROR(EAGAIN);
+    }
+    ff_mutex_lock(&cnctx->queue_mutex);
+    av_fifo_generic_read(cnctx->frame_queue, &encodedmsg, sizeof(EventInfoMsg_t), NULL);
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    if (CNCODEC_EVENT_EOS == encodedmsg.event_type) {
+        memset(&encodedmsg, 0 ,sizeof(encodedmsg));
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "Got EOS frame in cnenc_output_packet\n");
+        return AVERROR_EOF;
+    }
+    ret = pkt->data ? ff_alloc_packet2(cnctx->avctx, pkt, encodedmsg.event_output.stream.data_len,
+            encodedmsg.event_output.stream.data_len) :
+            av_new_packet(pkt, encodedmsg.event_output.stream.data_len);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Failed to allocate pkt memory\n");
+        *got_packet = 0;
+        cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+        return AVERROR(EINVAL);
+    }
+
+    if (encodedmsg.event_output.stream.data_len > 0) {
+        if (NULL == (void *)(encodedmsg.event_output.stream.mem_addr + encodedmsg.event_output.stream.data_offset)) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, " encodedframe[MLU] address is null, func: %s, line: %d\n",
+                    __func__, __LINE__);
+            cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+            return AVERROR(EINVAL);
+        }
+
+        ff_mutex_lock(&cnctx->queue_mutex);
+        cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)pkt->data,
+                                (void*)(encodedmsg.event_output.stream.mem_addr + encodedmsg.event_output.stream.data_offset),
+                                encodedmsg.event_output.stream.data_len,
+                                CNRT_MEM_TRANS_DIR_DEV2HOST);
+        CN_ERROR_CHECK(cnctx->avctx, cncodecEncStreamUnref(cnctx->handle, &encodedmsg.event_output.stream),"Unref output stream");
+        ff_mutex_unlock(&cnctx->queue_mutex);
+        if (CNRT_RET_SUCCESS != cnrt_ret) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Enc d2h error, ret(%u), func: %s, line: %d\n", cnrt_ret, __func__, __LINE__);
+            cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+            return AVERROR(EINVAL);
+        }
+    }
+    pkt->size = encodedmsg.event_output.stream.data_len;
+    *got_packet = 1;
+
+    switch (encodedmsg.event_output.stream.stream_type) {
+    case CNCODEC_NALU_TYPE_IDR:
+        pkt->flags |= AV_PKT_FLAG_KEY;
+    case CNCODEC_NALU_TYPE_I:
+        pict_type = AV_PICTURE_TYPE_I;
+        break;
+    case CNCODEC_NALU_TYPE_P:
+        pict_type = AV_PICTURE_TYPE_P;
+        break;
+    case CNCODEC_NALU_TYPE_B:
+        pict_type = AV_PICTURE_TYPE_B;
+        break;
+    case CNCODEC_HEVC_NALU_TYPE_VPS_SPS_PPS:
+        pkt->pts = 0;
+        pkt->dts = -1;
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "output pkt func get VPS SPS PPS TYPE, type:%d \n", encodedmsg.event_output.stream.stream_type);
+        break;
+    case CNCODEC_H264_NALU_TYPE_SPS_PPS:
+        pkt->pts = 0;
+        pkt->dts = -1;
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "output pkt func get SPS PPS TYPE, type:%d \n", encodedmsg.event_output.stream.stream_type);
+        break;
+    case CNCODEC_NALU_TYPE_EOS:
+        pkt->pts = cnctx->top_pts + 1;
+        pkt->dts = cnctx->top_dts + 1;
+        if (CNCODEC_EVENT_EOS == encodedmsg.event_type) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Error picture type encountered, EOS stream unprocessed. \n");
+        }
+        break;
+    case CNCODEC_NALU_TYPE_UNKNOWN:
+    default:
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Error picture type encountered, type:%d \n", encodedmsg.event_output.stream.stream_type);
+        break;
+    }
+#if FF_API_CODED_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    cnctx->avctx->coded_frame->pict_type = pict_type;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    if (pict_type == AV_PICTURE_TYPE_I || pict_type == AV_PICTURE_TYPE_P ||
+        pict_type == AV_PICTURE_TYPE_B) {
+        ret = cnenc_set_packet_timestamp(cnctx, &encodedmsg, pkt);
+        if (ret != 0) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Set timestamp failed! Please check encoder params!\n");
+            return ret;
+        }
+        cnctx->top_pts = pkt->pts;
+        cnctx->top_dts = pkt->dts;
+    }
+    return 0;
+}
+
+int ff_mlumpp_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame)
+{
+    cncodecFrame_t input_frame;
+    cncodecEncPicAttr_t frame_attr;
+    int ret = -1;
+    memset(&frame_attr, 0, sizeof(frame_attr));
+    if (NULL == avctx || NULL == cnctx || !cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in func: ff_mlumpp_enc_send_frame\n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_FATAL, "encoder got abort flag before send frame, return AVERROR_EXTERNAL");
+        return AVERROR_EXTERNAL;
+    }
+    if (!cnctx->handle) {
+        av_log(avctx, AV_LOG_WARNING, "Enc handle is NULL, guess couldn't create encode\n");
+        return AVERROR(EINVAL);
+    }
+    if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        frame_attr.jpg_pic_attr.jpeg_param.quality = cnctx->quality;
+    }
+    //av_log(avctx, AV_LOG_WARNING, "avctx->codec_id is: %d\n", avctx->codec_id);
+    if(mlu_device_binding(cnctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if (frame && !cnctx->encoder_flushing) {
+        av_log(avctx, AV_LOG_DEBUG, "Send frame size: %ux%u, pts:%ld, frame type:%d\n",
+            frame->width, frame->height, frame->pts, frame->pict_type);
+        memset(&input_frame, 0, sizeof(input_frame));
+        input_frame.width = frame->width;
+        input_frame.height = frame->height;
+        input_frame.pixel_format = cnctx->enc_attr.pixel_format;
+        input_frame.color_space  = cnctx->enc_attr.color_space;
+        input_frame.pts = frame->pts;
+        // main_still only support 1 frame encode
+        if (cnctx->frame_send_sum >=1 && CNCODEC_ENC_PROFILE_HEVC_MAIN_STILL == cnctx->profile) {
+            av_log(avctx, AV_LOG_ERROR, "HEVC main_still mode can only support encoding 1 frame! \n");
+            CN_ERROR_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Send EOS");
+            cnctx->encoder_flushing = 1;
+            return 0;
+        }
+        ret = cnenc_build_input_buffer(cnctx, &input_frame, frame);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_WARNING, "Get cnencode build std buffer failed, ret(%d)\n", ret);
+            return AVERROR(EAGAIN);
+        }
+        ret = cncodecEncSendFrame(cnctx->handle, &input_frame, &frame_attr, 2000);
+        CN_ERROR_CHECK(cnctx->avctx, ret, "Enc send frame failed");
+        cnenc_timestamp_queue_push(cnctx->timestamp_queue, frame->pts);
+        if (cnctx->initial_pts[0] == AV_NOPTS_VALUE) {
+            cnctx->initial_pts[0] = frame->pts;
+        } else if (cnctx->initial_pts[1] == AV_NOPTS_VALUE) {
+            cnctx->initial_pts[1] = frame->pts;
+        }
+        cnctx->frame_send_sum++;
+        // if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        //     CN_ERROR_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Jpeg send Eos");
+        // }
+        return ret;
+    } else {
+        av_log(avctx, AV_LOG_DEBUG, "Send frame NULL, and send eos to encoder\n");
+        CN_ERROR_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Send EOS");
+
+        cnctx->encoder_flushing = 1;
+        return 0; // fix me: neet to dicided "send eos" ret value
+    }
+
+    av_log(avctx, AV_LOG_WARNING, "Both valid frame and eos were sent, skip senc func\n");
+    return AVERROR_EOF;
+}
+
+int ff_mlumpp_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt)
+{
+    int ret = -1;
+    int got_packet = 0;
+    int waittime;
+    if (NULL == avctx || NULL == cnctx || NULL == pkt || !cnctx->encoder_init_flag) { //Sanity checks... these are all serious usage bugs.
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_receive_packet \n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_FATAL, "Encode got abort before receiving packet, return error\n");
+        return AVERROR_EXTERNAL;
+    }
+    if(mlu_device_binding(cnctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        waittime = 5000;
+        while (waittime>0) {
+            ret = cnenc_output_packet(cnctx, pkt, &got_packet);
+            if (!ret) {
+                cnctx->pkt_recv_sum += 1;
+                return ret;
+            } else if (ret == AVERROR(EAGAIN)) {
+                if (cnctx->pkt_recv_sum == cnctx->frame_send_sum) {
+                    return ret;
+                }
+            } else {
+                return ret;
+            }
+            av_usleep(10);
+            waittime-=1;
+        }
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Receive packet TIME-OUT, return EOF.\n");
+        return AVERROR_EOF;
+    }
+
+    if (!cnctx->encoder_flushing) {
+        av_log(avctx, AV_LOG_DEBUG, "Ready to output packet.\n");
+        return cnenc_output_packet(cnctx, pkt, &got_packet);
+    } else {
+        waittime = 5000;
+        while (waittime > 0) {
+            ret = cnenc_output_packet(cnctx, pkt, &got_packet);
+            if (ret == AVERROR(EAGAIN)) {
+                av_log(avctx, AV_LOG_DEBUG, "Wait packet from queue\n");
+                if (waittime <= 0 && !cnctx->eos_post_flag) {
+                    av_log(avctx, AV_LOG_WARNING, "Wait packet from queue TIME-OUT\n");
+                    cnctx->codec_abort_flag = 1;
+                    return AVERROR_EOF;
+                }
+                if (cnctx->eos_post_flag && cnenc_is_fifo_empty(cnctx)) {
+                    av_log(avctx, AV_LOG_WARNING, "EOS in queue LOST! Unkonwn Error!\n");
+                    cnctx->codec_abort_flag = 1;
+                    return AVERROR_EOF;
+                }
+                av_usleep(10);
+                waittime-=1;
+                continue;
+            }
+            return ret;
+        }
+    }
+    av_log(avctx, AV_LOG_ERROR, "[%lu] Receive frame ABORT->EOF\n", (long unsigned)pthread_self());
+    return ret;
+}
+
+static int probe_buf_num(int lookahead_depth, int frame_interval_p, int rdo_level) {
+    int extra_num = 0;
+    int frame_num = 0;
+    frame_num = frame_interval_p < 2 ? 1 : frame_interval_p;
+    if (lookahead_depth) {
+        frame_num = lookahead_depth + 8 + (8 >> 2);
+        extra_num = 8;
+        if (rdo_level > 1) {
+            extra_num = (extra_num >> 1);
+        }
+        if (lookahead_depth <= 20) {
+            extra_num = (extra_num >> 1);
+        }
+        frame_num += extra_num;
+    } else {
+        frame_num = frame_interval_p + 2;
+    }
+    return frame_num;
+}
+
+av_cold int ff_mlumpp_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    AVMLUDeviceContext *device_hwctx;
+    AVHWFramesContext *hwframe_ctx;
+    int ret = -1;
+    int bitstream_buf_size = 0;
+    char device_idx[sizeof(int)];
+    int min_input_buf_num = 0;
+    int probe_input_buf_num = 0;
+
+    if (NULL == avctx || NULL == cnctx || cnctx->encoder_init_flag ) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_init.\n");
+        return AVERROR_BUG;
+    }
+    if (AV_CODEC_ID_MJPEG == avctx->codec->id && 64 != cnctx->stride_align) {
+        cnctx->stride_align = CN_JFRAME_ALIGN_W;
+    }
+    if (cnenc_check_stride_align(avctx, cnctx) || cnenc_check_resolution(avctx)) {
+        return AVERROR(EINVAL);
+    }
+
+    memset(&cnctx->enc_attr, 0, sizeof(cnctx->enc_attr));
+    cnctx->avctx = avctx;
+    cnctx->coded_width  = avctx->codec->id == AV_CODEC_ID_MJPEG?
+                            FFALIGN(avctx->coded_width, CN_JFRAME_ALIGN_W):
+                            FFALIGN(avctx->coded_width, cnctx->stride_align);
+    // avctx->coded_height = avctx->codec->id == AV_CODEC_ID_MJPEG?
+    //                        FFALIGN(avctx->coded_height, CN_JFRAME_ALIGN_H) : avctx->coded_height;
+    //avctx->coded_height = avctx->coded_height;
+    //cnctx->coded_width  = avctx->coded_width;
+    cnctx->coded_height = avctx->codec->id == AV_CODEC_ID_MJPEG?
+                          FFALIGN(avctx->coded_height, CN_JFRAME_ALIGN_H) : avctx->coded_height;
+
+    cnctx->enc_attr.pic_width   = avctx->width;
+    cnctx->enc_attr.pic_height  = avctx->height;
+    cnctx->enc_attr.max_width   = cnctx->coded_width;
+    cnctx->enc_attr.max_height  = cnctx->coded_height;
+    cnctx->enc_attr.color_space = cnctx->color_space;
+    cnctx->enc_attr.input_stride_align = cnctx->stride_align;
+    cnctx->enc_attr.input_buf_source   = CNCODEC_BUF_SOURCE_LIB;
+
+    if (avctx->codec_id != AV_CODEC_ID_MJPEG) {
+        if (cnctx->frame_interval_p > 1) {
+            avctx->max_b_frames = cnctx->frame_interval_p - 1;
+        } else if (cnctx->frame_interval_p == 0) {
+            avctx->max_b_frames = 0;
+        } else {
+            if(avctx->max_b_frames > 0) {
+                cnctx->frame_interval_p = avctx->max_b_frames + 1;
+            }
+        }
+    }
+
+    min_input_buf_num = cnctx->frame_interval_p >= 0 ? cnctx->frame_interval_p + 2 : 3;
+    if(cnctx->input_buf_num != 0) {
+        probe_input_buf_num = probe_buf_num(cnctx->lookahead_depth, cnctx->frame_interval_p, cnctx->rdo_level);
+        if (cnctx->input_buf_num < probe_input_buf_num) {
+            av_log(avctx, AV_LOG_ERROR,
+            "input buf num %d is too small. \
+            Set buf num to a larger value or use 0(auto) when using 2Pass mode.\n", cnctx->input_buf_num);
+            return AVERROR(EINVAL);
+        }
+    }
+    cnctx->enc_attr.input_buf_num      = cnctx->input_buf_num;
+
+    sprintf(device_idx, "%d", cnctx->device_id);
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        if (avctx->hw_frames_ctx) {
+            av_buffer_unref(&cnctx->hw_frame_ref);
+            cnctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+            if (!cnctx->hw_frame_ref) {
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            cnctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+            if (!cnctx->hw_device_ref) {
+                return AVERROR(EINVAL);
+            }
+            device_hwctx         = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx  = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+            // if (cnctx->coded_width != hwframe_ctx->width
+            //     /*|| cnctx->coded_height != hwframe_ctx->height*/) {
+            //     if (hwframe_ctx->pool) {
+            //         av_buffer_pool_uninit(&hwframe_ctx->pool);
+            //          hwframe_ctx->pool = NULL;
+            //     }
+            //     hwframe_ctx->format    = AV_PIX_FMT_MLU;
+            //     hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            //     hwframe_ctx->width     = cnctx->coded_width;
+            //     hwframe_ctx->height    = cnctx->coded_height;
+            //     if ((ret = av_hwframe_ctx_init(cnctx->hw_frame_ref)) < 0) {
+            //         av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_init failed\n");
+            //         return AVERROR(EINVAL);
+            //     }
+            // }
+        } else {
+            if (avctx->hw_device_ctx) {
+                cnctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+                if (!cnctx->hw_device_ref) {
+                    return AVERROR(EINVAL);
+                }
+            } else {
+                ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+                if (ret < 0) {
+                    return AVERROR(EINVAL);
+                }
+            }
+            cnctx->hw_frame_ref = av_hwframe_ctx_alloc(cnctx->hw_device_ref);
+            if (!cnctx->hw_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_alloc\n");
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx          = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            device_hwctx         = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx  = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+
+            if (!hwframe_ctx->pool) {
+                hwframe_ctx->format    = AV_PIX_FMT_MLU;
+                hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+                hwframe_ctx->width     = cnctx->coded_width;
+                hwframe_ctx->height    = cnctx->coded_height;
+                if ((ret = av_hwframe_ctx_init(cnctx->hw_frame_ref)) < 0) {
+                    av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_init\n");
+                    return AVERROR(EINVAL);
+                }
+            }
+        }
+        cnctx->in_sw_pixfmt = avctx->sw_pix_fmt;
+    } else {
+        av_buffer_unref(&cnctx->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed in av_hwdevice_ctx_create\n");
+            return AVERROR(EINVAL);
+        }
+        cnctx->hw_device_ctx = ((AVHWDeviceContext*)cnctx->hw_device_ref->data)->hwctx;
+        cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+        cnctx->in_sw_pixfmt  = avctx->pix_fmt;
+    }
+
+    bitstream_buf_size = cnctx->coded_width * cnctx->coded_height;
+    switch (cnctx->in_sw_pixfmt) {
+    case AV_PIX_FMT_NV21:
+        cnctx->enc_attr.pixel_format = CNCODEC_PIX_FMT_NV21;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_NV12:
+        cnctx->enc_attr.pixel_format = CNCODEC_PIX_FMT_NV12;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    case AV_PIX_FMT_YUV420P:
+    case AV_PIX_FMT_YUVJ420P:
+        cnctx->enc_attr.pixel_format = CNCODEC_PIX_FMT_I420;
+        bitstream_buf_size += (bitstream_buf_size >> 1);
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unknow pixfmt: %d, only support nv12/nv21/yuv420\n", cnctx->in_sw_pixfmt);
+        return AVERROR(EINVAL);
+    }
+
+    cnctx->enc_attr.user_context    = cnctx;
+    cnctx->enc_attr.run_mode        = CNCODEC_RUN_MODE_ASYNC;
+    cnctx->enc_attr.device_id       = cnctx->device_id;
+    // cnctx->enc_attr.stream_buf_size = bitstream_buf_size * probe_input_buf_num;
+    // cnctx->enc_attr.stream_buf_size = avctx->codec->id == AV_CODEC_ID_MJPEG ?
+    //                                   bitstream_buf_size * 16: cnctx->stream_buf_size;
+    cnctx->enc_attr.stream_buf_size = 0;
+#if CNCODEC_MINOR_VERSION >= 8
+    cnctx->enc_attr.coding_attr.rdo_level     = cnctx->rdo_level;
+#elif CNCODEC_MINOR_VERSION >= 7
+    cnctx->enc_attr.rdo_level       = cnctx->rdo_level;
+#endif
+    cnctx->enc_attr.frame_rate_den  = avctx->time_base.num; // fps = (1/time_base)
+    cnctx->enc_attr.frame_rate_num  = avctx->time_base.den;
+    cnctx->enc_attr.coding_attr.stream_type            = cnctx->stream_type;
+    cnctx->enc_attr.coding_attr.gop_size               = avctx->gop_size;
+    cnctx->enc_attr.coding_attr.frame_interval_p       = cnctx->frame_interval_p;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_mode        = cnctx->rc_mode;
+    cnctx->enc_attr.coding_attr.rc_attr.initial_qp     = cnctx->init_qp;
+#if CNCODEC_MINOR_VERSION >= 8
+    if (cnctx->block_size >= 3 && cnctx->ctb_rc_mode != 0) {
+        av_log(avctx, AV_LOG_ERROR, "ctb rc mode do not support block size value 3!\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->enc_attr.coding_attr.rc_attr.ctb_rc_mode = cnctx->ctb_rc_mode;
+    cnctx->lookahead_depth = cnctx->lookahead_depth < 4 ? 0 : cnctx->lookahead_depth;
+    cnctx->enc_attr.coding_attr.rc_attr.block_size     = cnctx->block_size;
+    cnctx->enc_attr.coding_attr.rc_attr.ctb_row_qp_step = cnctx->ctb_row_qp_step;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_qp_delta_range = cnctx->rc_qp_delta_range;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_base_ctb_complexity = cnctx->rc_base_ctb_comp;
+    // cnctx->enc_attr.coding_attr.rc_attr.target_bitrate = avctx->bit_rate;
+    // cnctx->enc_attr.coding_attr.rc_attr.rc_windows     = cnctx->rc_windows;
+#endif
+
+    switch (cnctx->rc_mode) {
+#if CNCODEC_MINOR_VERSION >= 8
+    case CNCODEC_ENC_RATE_CTRL_CRF:
+        cnctx->enc_attr.coding_attr.rc_attr.target_quality      = cnctx->target_quality;
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth     = cnctx->lookahead_depth;
+        if (cnctx->lookahead_depth < 4) {
+            av_log(avctx, AV_LOG_ERROR, "CRF RC mode lookahead value should not less than 4!\n");
+            return AVERROR(EINVAL);
+        }
+        break;
+#endif
+    case CNCODEC_ENC_RATE_CTRL_CBR:
+        if (cnctx->rc_bufsize > 0) {
+            avctx->rc_buffer_size = cnctx->rc_bufsize;
+            cnctx->enc_attr.coding_attr.rc_attr.vbv_buffer_size = avctx->rc_buffer_size;
+        } else {
+            avctx->rc_buffer_size = avctx->bit_rate * 2;
+            cnctx->enc_attr.coding_attr.rc_attr.vbv_buffer_size = avctx->bit_rate * 2;
+        }
+#if CNCODEC_MINOR_VERSION >= 8
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_VBR:
+#if CNCODEC_MINOR_VERSION >= 8
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_CVBR:
+#if CNCODEC_MINOR_VERSION >= 8
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        cnctx->enc_attr.coding_attr.rc_attr.min_qp     = avctx->qmin;
+        cnctx->enc_attr.coding_attr.rc_attr.max_qp     = avctx->qmax;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_FIXEDQP:
+#if CNCODEC_MINOR_VERSION >= 8
+        if (cnctx->lookahead_depth != 0) {
+            av_log(avctx, AV_LOG_WARNING, "fixed qp mode only support lookahead depth value 0!\n");
+            return AVERROR(EINVAL);
+        }
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_i = cnctx->const_qp_i;
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_b = cnctx->const_qp_b;
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_p = cnctx->const_qp_p;
+        break;
+    default:
+        av_log(avctx, AV_LOG_WARNING, "Unknown rc mode, only support crf/cbr/vbr/cvbr/fixedqp at present\n");
+        return AVERROR(EINVAL);
+    }
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_HEVC:
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_HEVC;
+        cnctx->enc_attr.coding_attr.profile          = cnctx->profile;
+        cnctx->enc_attr.coding_attr.level            = cnctx->level;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.tier = cnctx->tier;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.idr_period = cnctx->idr_period;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.enable_sao = cnctx->enable_sao;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.enable_repeat_sps_pps = 1;
+        break;
+    case AV_CODEC_ID_H264:
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_H264;
+        cnctx->enc_attr.coding_attr.profile          = cnctx->profile;
+        cnctx->enc_attr.coding_attr.level            = cnctx->level;
+        cnctx->enc_attr.coding_attr.codec_attr.h264_attr.idr_period = cnctx->idr_period;
+        cnctx->enc_attr.coding_attr.codec_attr.h264_attr.enable_repeat_sps_pps = 1;
+        break;
+    //TO-DO: add JPEG case
+    case AV_CODEC_ID_MJPEG:
+        // memset(&cnctx->enc_attr.coding_attr, 0, sizeof(cnctx->enc_attr.coding_attr));
+        cnctx->enc_attr.coding_attr.gop_size = 0;
+        cnctx->enc_attr.frame_rate_den = 0;
+        cnctx->enc_attr.frame_rate_num = 0;
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_JPEG;
+        if (cnctx->input_buf_num != 1 && cnctx->input_buf_num != 2) {
+            av_log(avctx, AV_LOG_ERROR, "Jpeg encode only support set input buf num 1 and 2 at present\n");
+            return AVERROR(EINVAL);
+        }
+        cnctx->enc_attr.input_buf_num = cnctx->input_buf_num; // FIX-ME:v3 Jpeg encoder not supported set input_buf_num 0 at present.
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unknown codec type, ret(%d)\n", avctx->codec_id);
+        return AVERROR(EINVAL);
+    }
+
+    cnctx->eos_post_flag    = 0;
+    cnctx->codec_abort_flag = 0;
+    sem_init(&(cnctx->eos_sema), 0, 0);
+    ff_mutex_init(&cnctx->queue_mutex, NULL);
+    cnctx->async_queue_depth = min_input_buf_num * 2;
+    cnctx->frame_queue = av_fifo_alloc(cnctx->async_queue_depth * cnenc_fifo_elem_size());
+    if (!cnctx->frame_queue) {
+        sem_post(&(cnctx->eos_sema));
+        av_log(avctx, AV_LOG_FATAL, "Failed to alloc memory for async fifo\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->timestamp_queue = av_fifo_alloc(TIMESTAMP_QUEUE_SIZE * sizeof(int64_t));
+    if (!cnctx->timestamp_queue) {
+        sem_post(&(cnctx->eos_sema));
+        av_log(avctx, AV_LOG_FATAL, "Failed to alloc memory for timestamp fifo\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->initial_pts[0] = AV_NOPTS_VALUE;
+    cnctx->initial_pts[1] = AV_NOPTS_VALUE;
+    cnctx->first_pts_out = 0;
+    cnctx->top_pts = 0;
+    cnctx->top_dts = 0;
+
+    CN_ERROR_CHECK(avctx, cncodecEncCreate(&cnctx->handle, cnenc_event_cb, &cnctx->enc_attr), "Create encoder");
+    cnctx->encoder_init_flag = 1;
+    av_log(avctx, AV_LOG_DEBUG, "enc init func: encoder created. \n");
+    return 0;
+}
+
+int ff_mlumpp_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    int ret = -1;
+    int semvalue = -1;
+    struct timespec ts;
+    if (NULL == avctx || NULL == cnctx || !cnctx->handle) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_close\n");
+        return AVERROR(EINVAL);
+    }
+    av_log(avctx, AV_LOG_DEBUG, "Cnencode closing\n");
+    if(mlu_device_binding(cnctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device binding error! func: %s, line: %d\n", __func__, __LINE__);
+    }
+    if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        CN_ERROR_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Jpeg send Eos");
+    }
+    if (!cnctx->eos_post_flag && !cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_DEBUG, "Haven't got EOS, waiting\n");
+        clock_gettime(CLOCK_REALTIME, &ts);
+        ts.tv_sec += 3;
+        if(-1 == sem_timedwait(&(cnctx->eos_sema), &ts)) {
+            sem_getvalue(&cnctx->eos_sema, &semvalue);
+            av_log(avctx, AV_LOG_ERROR, "Enc sem_timewait = -1, time out,semvalue = %d ... \n", semvalue);
+        }
+    }
+
+    ff_mutex_lock(&cnctx->queue_mutex);
+    av_fifo_free(cnctx->frame_queue);
+    cnctx->frame_queue = NULL;
+    av_fifo_free(cnctx->timestamp_queue);
+    cnctx->timestamp_queue = NULL;
+    cnctx->initial_pts[0] = AV_NOPTS_VALUE;
+    cnctx->initial_pts[1] = AV_NOPTS_VALUE;
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    ff_mutex_destroy(&cnctx->queue_mutex);
+
+    ret = cncodecEncDestroy(cnctx->handle);
+    cnctx->handle = 0;
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR,
+               "CNtoolkit Error: destroy encoder failed, func: %s, line: %d, error code(%d)\n", __func__, __LINE__, ret);
+    }
+    if (avctx->extradata) {
+        av_free(avctx->extradata);
+        avctx->extradata = NULL;
+    }
+    sem_destroy(&(cnctx->eos_sema));
+    if (cnctx->hw_frame_ref) {
+        av_buffer_unref(&cnctx->hw_frame_ref);
+    }
+    if (cnctx->hw_device_ref) {
+        av_buffer_unref(&cnctx->hw_device_ref);
+    }
+    cnctx->encoder_init_flag = 0;
+    av_log(avctx, AV_LOG_DEBUG, "Cnencode closed\n");
+
+    return 0;
+}
diff --git a/libavcodec/mlumpp_vid_enc.h b/libavcodec/mlumpp_vid_enc.h
new file mode 100644
index 0000000000..68ffdf820c
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.h
@@ -0,0 +1,120 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef AVCODEC_MLUMPP_VID_ENC_H
+#define AVCODEC_MLUMPP_VID_ENC_H
+#include <stdint.h>
+#include <unistd.h>
+#include <time.h>
+#include <semaphore.h>
+#include <stdatomic.h>
+#include <fcntl.h>
+#include <sys/time.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+
+#include "cncodec_v3_enc.h"
+#include "mlumpp_codec.h"
+
+typedef struct EventInfoMsg {
+    cncodecEventType_t event_type;
+    void *cnctx;
+    union {
+        cncodecFrame_t frame;
+        cncodecStream_t stream;
+    }event_output;
+}EventInfoMsg_t;
+
+typedef struct MLUMPPEncContext {
+    cncodecHandle_t                 handle;
+    cncodecEncParam_t               enc_attr;
+    AVCodecContext                  *avctx;
+    cnrtDev_t                       cnrt_dev;
+
+    int                             trace_flag;
+    int                             device_id;
+    int                             color_space;
+    int                             stride_align;
+    int                             input_buf_num;
+    int                             stream_buf_size;
+    int                             encoder_flushing;
+    int                             codec_abort_flag;
+    int                             async_queue_depth;
+    volatile int                    eos_post_flag;
+    volatile int                    encoder_init_flag;
+    volatile int                    frame_send_sum;
+    volatile int                    pkt_recv_sum;
+
+    int                             tier;
+    int                             level;
+    int                             profile;
+    int                             quality;
+    int                             rc_mode;
+    int                             rc_bufsize;
+    int                             rc_windows;
+    int                             init_qp;
+    int                             const_qp_i;
+    int                             const_qp_b;
+    int                             const_qp_p;
+    int                             ctb_row_qp_step;
+    int                             rc_qp_delta_range;
+    int                             rc_base_ctb_comp;
+    int                             ctb_rc_mode;
+    int                             block_size;
+    int                             lookahead_depth;
+    int                             target_quality;
+    int                             preset;
+    int                             rdo_level;
+    int                             gop_size;
+    int                             stream_type;
+    int                             target_bitrate;
+    int                             frame_interval_p;
+    int                             idr_period;
+    int                             enable_sao;
+
+    int                             coded_width;
+    int                             coded_height;
+    sem_t                           eos_sema;
+    int64_t                         initial_pts[2];
+    int                             first_pts_out;
+    int64_t                         top_pts;
+    int64_t                         top_dts;
+    AVFifoBuffer                    *frame_queue;
+    AVFifoBuffer                    *timestamp_queue;
+    AVMutex                         queue_mutex;
+
+    AVBufferRef                     *hw_frame_ref;
+    AVBufferRef                     *hw_device_ref;
+
+    MluContext                      *mlu_ctx;
+    AVMLUDeviceContext              *hw_device_ctx;
+    AVHWFramesContext               *hw_frame_ctx;
+    enum AVPixelFormat              in_sw_pixfmt;
+
+}MLUMPPEncContext_t;
+
+// main functions
+int ff_mlumpp_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t* cnctx);
+int ff_mlumpp_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame);
+int ff_mlumpp_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt);
+int ff_mlumpp_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx);
+
+#endif /* AVCODEC_MLUMPP_VID_ENC_H */
\ No newline at end of file
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 455c809b15..4c321e1605 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -196,6 +196,9 @@ OBJS-$(CONFIG_CROP_FILTER)                   += vf_crop.o
 OBJS-$(CONFIG_CROPDETECT_FILTER)             += vf_cropdetect.o
 OBJS-$(CONFIG_CUE_FILTER)                    += f_cue.o
 OBJS-$(CONFIG_CURVES_FILTER)                 += vf_curves.o
+OBJS-$(CONFIG_CVT_RGBX2RGBX_MLU_FILTER)      += vf_cvt_rgbx2rgbx_mlu.o
+OBJS-$(CONFIG_CVT_YUV2RGBX_MLU_FILTER)       += vf_cvt_yuv2rgbx_mlu.o
+OBJS-$(CONFIG_CVT_RGBX2YUV_MLU_FILTER)       += vf_cvt_rgbx2yuv_mlu.o
 OBJS-$(CONFIG_DATASCOPE_FILTER)              += vf_datascope.o
 OBJS-$(CONFIG_DCTDNOIZ_FILTER)               += vf_dctdnoiz.o
 OBJS-$(CONFIG_DEBAND_FILTER)                 += vf_deband.o
@@ -263,8 +266,10 @@ OBJS-$(CONFIG_HQX_FILTER)                    += vf_hqx.o
 OBJS-$(CONFIG_HSTACK_FILTER)                 += vf_stack.o framesync.o
 OBJS-$(CONFIG_HUE_FILTER)                    += vf_hue.o
 OBJS-$(CONFIG_HWDOWNLOAD_FILTER)             += vf_hwdownload.o
+OBJS-$(CONFIG_HWDOWNLOAD_MLU_FILTER)         += vf_hwdownload_mlu.o
 OBJS-$(CONFIG_HWMAP_FILTER)                  += vf_hwmap.o
 OBJS-$(CONFIG_HWUPLOAD_CUDA_FILTER)          += vf_hwupload_cuda.o
+OBJS-$(CONFIG_HWUPLOAD_MLU_FILTER)           += vf_hwupload_mlu.o
 OBJS-$(CONFIG_HWUPLOAD_FILTER)               += vf_hwupload.o
 OBJS-$(CONFIG_HYSTERESIS_FILTER)             += vf_hysteresis.o framesync.o
 OBJS-$(CONFIG_IDET_FILTER)                   += vf_idet.o
@@ -350,8 +355,11 @@ OBJS-$(CONFIG_ROTATE_FILTER)                 += vf_rotate.o
 OBJS-$(CONFIG_SAB_FILTER)                    += vf_sab.o
 OBJS-$(CONFIG_SCALE_FILTER)                  += vf_scale.o scale.o
 OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o vf_scale_cuda.ptx.o
+OBJS-$(CONFIG_SCALE_CVT_YUV2RGBX_MLU_FILTER) += vf_scale_cvt_yuv2rgbx_mlu.o
 OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale.o
 OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
+OBJS-$(CONFIG_SCALE_YUV2YUV_MLU_FILTER)      += vf_scale_yuv2yuv_mlu.o
+OBJS-$(CONFIG_SCALE_RGBX2RGBX_MLU_FILTER)    += vf_scale_rgbx2rgbx_mlu.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale.o vaapi_vpp.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale.o
 OBJS-$(CONFIG_SELECT_FILTER)                 += f_select.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 04a3df7d56..3effe9e370 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -183,6 +183,9 @@ extern AVFilter ff_vf_crop;
 extern AVFilter ff_vf_cropdetect;
 extern AVFilter ff_vf_cue;
 extern AVFilter ff_vf_curves;
+extern AVFilter ff_vf_cvt_rgbx2rgbx_mlu;
+extern AVFilter ff_vf_cvt_yuv2rgbx_mlu;
+extern AVFilter ff_vf_cvt_rgbx2yuv_mlu;
 extern AVFilter ff_vf_datascope;
 extern AVFilter ff_vf_dctdnoiz;
 extern AVFilter ff_vf_deband;
@@ -248,8 +251,10 @@ extern AVFilter ff_vf_hqx;
 extern AVFilter ff_vf_hstack;
 extern AVFilter ff_vf_hue;
 extern AVFilter ff_vf_hwdownload;
+extern AVFilter ff_vf_hwdownload_mlu;
 extern AVFilter ff_vf_hwmap;
 extern AVFilter ff_vf_hwupload;
+extern AVFilter ff_vf_hwupload_mlu;
 extern AVFilter ff_vf_hwupload_cuda;
 extern AVFilter ff_vf_hysteresis;
 extern AVFilter ff_vf_idet;
@@ -332,8 +337,11 @@ extern AVFilter ff_vf_rotate;
 extern AVFilter ff_vf_sab;
 extern AVFilter ff_vf_scale;
 extern AVFilter ff_vf_scale_cuda;
+extern AVFilter ff_vf_scale_cvt_yuv2rgbx_mlu;
 extern AVFilter ff_vf_scale_npp;
 extern AVFilter ff_vf_scale_qsv;
+extern AVFilter ff_vf_scale_yuv2yuv_mlu;
+extern AVFilter ff_vf_scale_rgbx2rgbx_mlu;
 extern AVFilter ff_vf_scale_vaapi;
 extern AVFilter ff_vf_scale2ref;
 extern AVFilter ff_vf_select;
@@ -361,6 +369,7 @@ extern AVFilter ff_vf_sobel_opencl;
 extern AVFilter ff_vf_split;
 extern AVFilter ff_vf_spp;
 extern AVFilter ff_vf_sr;
+// extern AVFilter ff_vf_sr_mlu;
 extern AVFilter ff_vf_ssim;
 extern AVFilter ff_vf_stereo3d;
 extern AVFilter ff_vf_streamselect;
diff --git a/libavfilter/vf_cvt_rgbx2rgbx_mlu.c b/libavfilter/vf_cvt_rgbx2rgbx_mlu.c
new file mode 100644
index 0000000000..975eaef9d2
--- /dev/null
+++ b/libavfilter/vf_cvt_rgbx2rgbx_mlu.c
@@ -0,0 +1,526 @@
+/*
+ * Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright no5tice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+#include <dlfcn.h>
+#include <stdio.h>
+#include <string.h>
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "scale.h"
+#include "video.h"
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCvtRgbx2RgbxContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    void *input_mlu_rgbx;
+    void *output_mlu_rgbx;
+
+    int input_mlu_rgbx_size;
+    int output_mlu_rgbx_size;
+
+    int (*ptr_convert_rgbx2rgbx_init)(void **, int, int, const char *, const char *, const char *);
+    int (*ptr_convert_rgbx2rgbx_exec)(void *, void *, void *);
+    int (*ptr_convert_rgbx2rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluCvtRgbx2RgbxContext;
+
+static int mluop_load(MluCvtRgbx2RgbxContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, /*RTLD_NOW | RTLD_GLOBAL*/ RTLD_LAZY);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s failed, dlerror=%s\n", libname, dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_VERBOSE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_convert_rgbx2rgbx_init = dlsym(ctx->lib, "MluopConvertRgbx2RgbxInit");
+    ctx->ptr_convert_rgbx2rgbx_exec = dlsym(ctx->lib, "MluopConvertRgbx2RgbxExec");
+    ctx->ptr_convert_rgbx2rgbx_destroy = dlsym(ctx->lib, "MluopConvertRgbx2RgbxDestroy");
+    if (!ctx->ptr_convert_rgbx2rgbx_init || !ctx->ptr_convert_rgbx2rgbx_exec
+        || !ctx->ptr_convert_rgbx2rgbx_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n", libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluCvtRgbx2RgbxContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+               "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluCvtRgbx2RgbxContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";  break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";  break;
+    case AV_PIX_FMT_RGB24:
+        ctx->pic_pixfmt = "rgb24"; break;
+    case AV_PIX_FMT_BGR24:
+        ctx->pic_pixfmt = "bgr24"; break;
+    case AV_PIX_FMT_ARGB:
+        ctx->pic_pixfmt = "argb";  break;
+    case AV_PIX_FMT_ABGR:
+        ctx->pic_pixfmt = "abgr";  break;
+    case AV_PIX_FMT_BGRA:
+        ctx->pic_pixfmt = "bgra";  break;
+    case AV_PIX_FMT_RGBA:
+        ctx->pic_pixfmt = "rgba";  break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow"; break;
+    }
+}
+
+static int mlurgbx2rgbx_query_formats(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbx2rgbx_init(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_rgbx = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mlurgbx2rgbx_uninit(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_convert_rgbx2rgbx_destroy(s->op_handle);
+    }
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    // mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbx2rgbx_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCvtRgbx2RgbxContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+    int ret;
+    char device_idx[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->output_mlu_rgbx_size = outlink->w * outlink->h * get_pixfmt_channel_num(s->out_fmt);
+    s->input_mlu_rgbx_size  = inlink->w * inlink->h * get_pixfmt_channel_num(s->in_fmt);
+
+    // checkout infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mlu op
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_convert_rgbx2rgbx_init(&s->op_handle, inlink->w, inlink->h,
+                                      s->pic_pixfmt, s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_rgbx),
+                                       sizeof(char) * s->input_mlu_rgbx_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx),
+                                       sizeof(char) * s->output_mlu_rgbx_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbx2rgbx_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx      = link->dst;
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    AVFilterLink *outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx       = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+    out->linesize[1] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            av_log(ctx, AV_LOG_WARNING, "filter frame func: cpu case, copy H2D\n");
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                                        s->input_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_convert_rgbx2rgbx_exec(s->op_handle, s->input_mlu_rgbx,
+                                            s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2rgbx with mlu\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                                        s->output_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCvtRgbx2RgbxContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixfmt", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS },
+    { "n",     "device index",  OFFSET(n_expr),        AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbx2rgbx_class = {
+    .class_name = "mlurgbx2rgbx",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbx2rgbx_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbx2rgbx_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbx2rgbx_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbx2rgbx_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_rgbx2rgbx_mlu = {
+    .name      = "cvt_rgbx2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert rgbx to rgbx"),
+
+    .init          = mlurgbx2rgbx_init,
+    .uninit        = mlurgbx2rgbx_uninit,
+    .query_formats = mlurgbx2rgbx_query_formats,
+
+    .priv_size = sizeof(MluCvtRgbx2RgbxContext),
+    .priv_class = &mlurgbx2rgbx_class,
+
+    .inputs    = mlurgbx2rgbx_inputs,
+    .outputs   = mlurgbx2rgbx_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_cvt_rgbx2yuv_mlu.c b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
new file mode 100644
index 0000000000..f5adb3a682
--- /dev/null
+++ b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
@@ -0,0 +1,580 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTRGBX2YUVContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    void *input_mlu_rgbx;
+    void *output_mlu_y;
+    void *output_mlu_uv;
+
+    int output_mlu_y_size;
+    int output_mlu_uv_size;
+    int input_mlu_rgbx_size;
+
+    int (*ptr_convert_rgbx2yuv_init)(void **, int, int, const char *, const char *, const char *);
+    int (*ptr_convert_rgbx2yuv_exec)(void *, void *, void *, void *);
+    int (*ptr_convert_rgbx2yuv_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluCVTRGBX2YUVContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluCVTRGBX2YUVContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_convert_rgbx2yuv_init =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_init", "mluop");
+    ctx->ptr_convert_rgbx2yuv_exec =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_exec", "mluop");
+    ctx->ptr_convert_rgbx2yuv_destroy =
+        dlsym_prefixed(ctx->lib, "convert_rgbx2yuv_destroy", "mluop");
+    if (!ctx->ptr_convert_rgbx2yuv_init || !ctx->ptr_convert_rgbx2yuv_exec ||
+        !ctx->ptr_convert_rgbx2yuv_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluCVTRGBX2YUVContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static int mlu_device_binding(MluCVTRGBX2YUVContext *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluCVTRGBX2YUVContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12"; break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21"; break;
+    case AV_PIX_FMT_RGB24:
+        ctx->pic_pixfmt = "rgb24";break;
+    case AV_PIX_FMT_BGR24:
+        ctx->pic_pixfmt = "bgr24";break;
+    case AV_PIX_FMT_ARGB:
+        ctx->pic_pixfmt = "argb"; break;
+    case AV_PIX_FMT_ABGR:
+        ctx->pic_pixfmt = "abgr"; break;
+    case AV_PIX_FMT_BGRA:
+        ctx->pic_pixfmt = "bgra"; break;
+    case AV_PIX_FMT_RGBA:
+        ctx->pic_pixfmt = "rgba"; break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow"; break;
+    }
+}
+
+static int mlurgbx2yuv_query_formats(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbx2yuv_init(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mlurgbx2yuv_uninit(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if (s->op_handle) {
+        s->ptr_convert_rgbx2yuv_destroy(s->op_handle);
+    }
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbx2yuv_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTRGBX2YUVContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char device_idx[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    av_log(ctx, AV_LOG_VERBOSE, "w:%d h:%d -> w:%d h:%d\n",
+                                inlink->w, inlink->h, outlink->w, outlink->h);
+
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = FFALIGN(outlink->h, 1);
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+    // init mlu op
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    s->output_mlu_y_size   = outlink->w * outlink->h;
+    s->output_mlu_uv_size  = outlink->w * outlink->h / 2;
+    s->input_mlu_rgbx_size = inlink->w * inlink->h * get_pixfmt_channel_num(s->in_fmt);
+
+    // checkout infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+
+        s->ptr_convert_rgbx2yuv_init(&s->op_handle, inlink->w, inlink->h,
+                                     s->pic_pixfmt, s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_rgbx_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), sizeof(char) * s->output_mlu_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), sizeof(char) * s->output_mlu_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbx2yuv_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx     = link->dst;
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    AVFilterLink *outlink    = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+    out->linesize[1] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_y = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                             s->input_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_convert_rgbx2yuv_exec(s->op_handle, s->input_mlu_rgbx,
+                                           s->output_mlu_y, s->output_mlu_uv);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2yuv with mlu\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->output_mlu_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->output_mlu_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTRGBX2YUVContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixel format", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, { .str = "of" }, .flags = FLAGS },
+    { "n",     "device index",        OFFSET(n_expr),        AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbx2yuv_class = {
+    .class_name = "mlurgbx2yuv",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbx2yuv_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbx2yuv_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbx2yuv_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbx2yuv_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_rgbx2yuv_mlu = {
+    .name      = "cvt_rgbx2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mlurgbx2yuv_init,
+    .uninit        = mlurgbx2yuv_uninit,
+    .query_formats = mlurgbx2yuv_query_formats,
+
+    .priv_size = sizeof(MluCVTRGBX2YUVContext),
+    .priv_class = &mlurgbx2yuv_class,
+
+    .inputs    = mlurgbx2yuv_inputs,
+    .outputs   = mlurgbx2yuv_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_cvt_yuv2rgbx_mlu.c b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
new file mode 100644
index 0000000000..dc0e713979
--- /dev/null
+++ b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
@@ -0,0 +1,569 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12,
+    AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,
+    AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR,
+    AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTYUV2RGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    int in_y_size;
+    int in_uv_size;
+    int out_mlu_size;
+
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_rgbx;
+
+    int (*ptr_convert_yuv2rgbx_init)(void **, int, int, const char *, const char *, const char *);
+    int (*ptr_convert_yuv2rgbx_exec)(void *, void *, void *, void *);
+    int (*ptr_convert_yuv2rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluCVTYUV2RGBXContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluCVTYUV2RGBXContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_convert_yuv2rgbx_init =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_init", "mluop");
+    ctx->ptr_convert_yuv2rgbx_exec =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_exec", "mluop");
+    ctx->ptr_convert_yuv2rgbx_destroy =
+        dlsym_prefixed(ctx->lib, "convert_yuv2rgbx_destroy", "mluop");
+    if (!ctx->ptr_convert_yuv2rgbx_init || !ctx->ptr_convert_yuv2rgbx_exec ||
+        !ctx->ptr_convert_yuv2rgbx_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluCVTYUV2RGBXContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static int get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluCVTYUV2RGBXContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";
+        break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";
+        break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow";
+        break;
+    }
+}
+
+static int mlu_device_binding(MluCVTYUV2RGBXContext *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static int mluyuv2rgbx_query_formats(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+   int ret;
+   out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluyuv2rgbx_init(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_rgbx = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mluyuv2rgbx_uninit(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_convert_yuv2rgbx_destroy(s->op_handle);
+    }
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    mluop_unload(s);
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluyuv2rgbx_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTYUV2RGBXContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char device_idx[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    s->in_y_size    = inlink->w * inlink->h;
+    s->in_uv_size   = inlink->w * inlink->h / 2;
+    s->out_mlu_size = outlink->w * outlink->h *
+                    get_pixfmt_channel_num(get_av_pixfmt_from_idx(s->enter_out_fmt));
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = FFALIGN(outlink->h, 1);
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+    // init mlu
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_convert_yuv2rgbx_init(&s->op_handle, inlink->w, inlink->h, s->pic_pixfmt,
+                                    s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), sizeof(char) * s->in_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), sizeof(char) * s->in_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->out_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluyuv2rgbx_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext*ctx      = link->dst;
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    AVFilterLink*outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(ENAVAIL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y = in->data[0];
+            s->input_mlu_uv = in->data[1];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                                  s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                                  s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_convert_yuv2rgbx_exec(s->op_handle, s->input_mlu_y,
+                                        s->input_mlu_uv, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2rgbx filter with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->out_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTYUV2RGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixel format", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, { .str = "of" }, .flags = FLAGS },
+    { "n",     "device index",        OFFSET(n_expr),        AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mluyuv2rgbx_class = {
+    .class_name = "mluyuv2rgbx",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluyuv2rgbx_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluyuv2rgbx_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluyuv2rgbx_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluyuv2rgbx_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_yuv2rgbx_mlu = {
+    .name      = "cvt_yuv2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mluyuv2rgbx_init,
+    .uninit        = mluyuv2rgbx_uninit,
+    .query_formats = mluyuv2rgbx_query_formats,
+
+    .priv_size = sizeof(MluCVTYUV2RGBXContext),
+    .priv_class = &mluyuv2rgbx_class,
+
+    .inputs    = mluyuv2rgbx_inputs,
+    .outputs   = mluyuv2rgbx_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwdownload_mlu.c b/libavfilter/vf_hwdownload_mlu.c
new file mode 100644
index 0000000000..91115f0bb1
--- /dev/null
+++ b/libavfilter/vf_hwdownload_mlu.c
@@ -0,0 +1,214 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MLUDownloadContext {
+    const AVClass *class;
+    int device_idx;
+
+    AVBufferRef   *hwframes_ref;
+    AVHWFramesContext *hwframes;
+} MLUDownloadContext;
+
+static int hwdownload_query_formats(AVFilterContext *avctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_RGB24,   AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR,    AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA,    AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_NV12,    AV_PIX_FMT_NV21,
+        AV_PIX_FMT_YUV420P, AV_PIX_FMT_P010,
+        AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &avctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &avctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+    return 0;
+}
+
+static int hwdownload_config_input(AVFilterLink *inlink)
+{
+    AVFilterContext *avctx = inlink->dst;
+    MLUDownloadContext *ctx = avctx->priv;
+
+    if (!inlink->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "The input must have a hardware frame reference.\n");
+        return AVERROR(EINVAL);
+    }
+    av_buffer_unref(&ctx->hwframes_ref);
+    ctx->hwframes_ref = av_buffer_ref(inlink->hw_frames_ctx);
+    if (!ctx->hwframes_ref)
+        return AVERROR(ENOMEM);
+
+    ctx->hwframes = (AVHWFramesContext*)ctx->hwframes_ref->data;
+
+    return 0;
+}
+
+static int hwdownload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *avctx  = outlink->src;
+    AVFilterLink *inlink    = avctx->inputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+
+    int err;
+    enum AVPixelFormat *formats;
+
+    if (!ctx->hwframes_ref)
+        return AVERROR(EINVAL);
+
+    err = av_hwframe_transfer_get_formats(ctx->hwframes_ref,
+                                          AV_HWFRAME_TRANSFER_DIRECTION_FROM,
+                                          &formats, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Hwframe transfer get formats failed \n");
+        return err;
+    }
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    outlink->format = formats[0];
+
+    av_freep(&formats);
+    return 0;
+}
+
+static int hwdownload_filter_frame(AVFilterLink *link, AVFrame *input) // input on mlu
+{
+    AVFilterContext *avctx  = link->dst;
+    AVFilterLink  *outlink  = avctx->outputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+    AVMLUDeviceContext *hwdevice_ctx = ctx->hwframes->device_ctx->hwctx;
+    MluContext *mlu_ctx = hwdevice_ctx->mlu_ctx;
+    int err;
+    AVFrame *output = NULL;
+
+    if (!ctx->hwframes_ref || !input->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+    if ((void*)ctx->hwframes != input->hw_frames_ctx->data) {
+        av_log(ctx, AV_LOG_ERROR, "Input frame is not the in the configured hwframe context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    output = ff_get_video_buffer(outlink, ctx->hwframes->width,
+                                 ctx->hwframes->height);
+    if (!output) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    output->width  = outlink->w;
+    output->height = outlink->h;
+    for (int i = 0; i < FF_ARRAY_ELEMS(input->data) && input->data[i]; i++) {
+        output->linesize[i] = input->linesize[i];
+    }
+
+    err = av_hwframe_transfer_data(output, input, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to download frame: %d.\n", err);
+        goto fail;
+    }
+
+    output->width  = outlink->w;
+    output->height = outlink->h;
+
+    err = av_frame_copy_props(output, input);
+    if (err < 0) {
+        goto fail;
+    }
+
+    av_frame_free(&input);
+    return ff_filter_frame(avctx->outputs[0], output);
+
+fail:
+    av_frame_free(&input);
+    av_frame_free(&output);
+    return err;
+}
+
+static av_cold void hwdownload_uninit(AVFilterContext *avctx)
+{
+    MLUDownloadContext *ctx = avctx->priv;
+    av_buffer_unref(&ctx->hwframes_ref);
+}
+
+static const AVClass hwdownload_class = {
+    .class_name = "hwdownload_mlu",
+    .item_name  = av_default_item_name,
+    .option     = NULL,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad hwdownload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_input,
+        .filter_frame = hwdownload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad hwdownload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwdownload_mlu = {
+    .name          = "hwdownload_mlu",
+    .description   = NULL_IF_CONFIG_SMALL("Download a hardware frame to a normal frame"),
+    .uninit        = hwdownload_uninit,
+    .query_formats = hwdownload_query_formats,
+    .priv_size     = sizeof(MLUDownloadContext),
+    .priv_class    = &hwdownload_class,
+    .inputs        = hwdownload_inputs,
+    .outputs       = hwdownload_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwupload_mlu.c b/libavfilter/vf_hwupload_mlu.c
new file mode 100644
index 0000000000..9602ed5a5d
--- /dev/null
+++ b/libavfilter/vf_hwupload_mlu.c
@@ -0,0 +1,198 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MluUploadContext {
+    const AVClass *class;
+    int device_idx;
+
+    AVBufferRef *hwdevice;
+    AVBufferRef *hwframe;
+} MluUploadContext;
+
+static av_cold int mlu_upload_init(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+    char buf[64] = { 0 };
+
+    snprintf(buf, sizeof(buf), "%d", s->device_idx);
+
+    // here depend on hwcontext
+    return av_hwdevice_ctx_create(&s->hwdevice, AV_HWDEVICE_TYPE_MLU, buf, NULL, 0);
+}
+
+static av_cold void mlu_upload_uninit(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+
+    av_buffer_unref(&s->hwframe);
+    av_buffer_unref(&s->hwdevice);
+}
+
+static int mlu_upload_query_formats(AVFilterContext *ctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR,  AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA,  AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_NV12,  AV_PIX_FMT_NV21,
+        AV_PIX_FMT_P010,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int mlu_upload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluUploadContext *s = ctx->priv;
+
+    int ret;
+    AVHWFramesContext *hwframe_ctx;
+
+    av_buffer_unref(&s->hwframe);
+    s->hwframe = av_hwframe_ctx_alloc(s->hwdevice);
+    if (!s->hwframe)
+        return AVERROR(EINVAL);
+
+    hwframe_ctx            = (AVHWFramesContext*)s->hwframe->data;
+    hwframe_ctx->format    = AV_PIX_FMT_MLU;
+    hwframe_ctx->sw_format = inlink->format;
+    hwframe_ctx->width     = inlink->w;
+    hwframe_ctx->height    = inlink->h;
+
+    ret = av_hwframe_ctx_init(s->hwframe);
+    if (ret < 0)
+        return ret;
+
+    outlink->hw_frames_ctx = av_buffer_ref(s->hwframe);
+    if (!outlink->hw_frames_ctx)
+        return AVERROR(EINVAL);
+
+    return 0;
+}
+
+static int mlu_upload_filter_frame(AVFilterLink *link, AVFrame *in) // in on cpu
+{
+    AVFilterContext   *ctx = link->dst;
+    AVFilterLink  *outlink = ctx->outputs[0];
+    MluUploadContext *s = ctx->priv;
+    AVHWFramesContext *hwframe_ctx;
+
+    AVFrame *out = NULL;
+    int ret;
+
+    hwframe_ctx = (AVHWFramesContext*)s->hwframe->data;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    for (int i = 0; i < FF_ARRAY_ELEMS(in->data) && in->data[i]; i++) {
+        out->linesize[i] = in->linesize[i];
+    }
+
+    ret = av_hwframe_transfer_data(out, in, 0); // H2D
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Error transferring data to the MLU\n");
+        goto fail;
+    }
+
+    ret = av_frame_copy_props(out, in); // props copy
+    if (ret < 0)
+        goto fail;
+
+    av_frame_free(&in);
+
+    return ff_filter_frame(ctx->outputs[0], out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluUploadContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption mlu_upload_options[] = {
+    { "device", "use to choose the accelerator card", OFFSET(device_idx), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { NULL },
+};
+
+AVFILTER_DEFINE_CLASS(mlu_upload);
+
+static const AVFilterPad mlu_upload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlu_upload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlu_upload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlu_upload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwupload_mlu = {
+    .name        = "hwupload_mlu",
+    .description = NULL_IF_CONFIG_SMALL("Upload a system memory frame to a mlu device."),
+
+    .init      = mlu_upload_init,
+    .uninit    = mlu_upload_uninit,
+
+    .query_formats = mlu_upload_query_formats,
+
+    .priv_size  = sizeof(MluUploadContext),
+    .priv_class = &mlu_upload_class,
+
+    .inputs    = mlu_upload_inputs,
+    .outputs   = mlu_upload_outputs,
+
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c b/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
new file mode 100644
index 0000000000..d23e85e2a9
--- /dev/null
+++ b/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
@@ -0,0 +1,542 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12,
+    AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,
+    AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR,
+    AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluScaleCvtYUV2RGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; //Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *w_expr;
+    char *h_expr;
+    char *n_expr;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    // buffers and op func-ptrs
+    int in_y_size;
+    int in_uv_size;
+    int out_mlu_size;
+
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_rgbx;
+
+    int (*ptr_scale_cvt_yuv2rgbx_init)(void **, int, int, int, int, const char *, const char *, const char *);
+    int (*ptr_scale_cvt_yuv2rgbx_exec)(void *, void *, void *, void *);
+    int (*ptr_scale_cvt_yuv2rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluScaleCvtYUV2RGBXContext;
+
+static int mluop_load(MluScaleCvtYUV2RGBXContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, /*RTLD_NOW | RTLD_GLOBAL*/ RTLD_LAZY);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s failed, dlerror=%s\n", libname, dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_VERBOSE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_scale_cvt_yuv2rgbx_init = dlsym(ctx->lib, "MluopResizeCvtInit");
+    ctx->ptr_scale_cvt_yuv2rgbx_exec = dlsym(ctx->lib, "MluopResizeCvtExec");
+    ctx->ptr_scale_cvt_yuv2rgbx_destroy = dlsym(ctx->lib, "MluopResizeCvtDestroy");
+    if (!ctx->ptr_scale_cvt_yuv2rgbx_init || !ctx->ptr_scale_cvt_yuv2rgbx_exec || !ctx->ptr_scale_cvt_yuv2rgbx_destroy) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n", libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluScaleCvtYUV2RGBXContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static int get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static enum AVPixelFormat get_av_pixfmt_from_idx(const char* pix_fmt) {
+    if (strcmp(pix_fmt, "NV12") == 0 || strcmp(pix_fmt, "nv12") == 0) {
+        return AV_PIX_FMT_NV12;
+    } else if (strcmp(pix_fmt, "NV21") == 0 || strcmp(pix_fmt, "nv21") == 0) {
+        return AV_PIX_FMT_NV21;
+    } else if (strcmp(pix_fmt, "RGB24") == 0 || strcmp(pix_fmt, "rgb24") == 0) {
+        return AV_PIX_FMT_RGB24;
+    } else if (strcmp(pix_fmt, "BGR24") == 0 || strcmp(pix_fmt, "bgr24") == 0) {
+        return AV_PIX_FMT_BGR24;
+    } else if (strcmp(pix_fmt, "ARGB") == 0 || strcmp(pix_fmt, "argb") == 0) {
+        return AV_PIX_FMT_ARGB;
+    } else if (strcmp(pix_fmt, "ABGR") == 0 || strcmp(pix_fmt, "abgr") == 0) {
+        return AV_PIX_FMT_ABGR;
+    } else if (strcmp(pix_fmt, "RGBA") == 0 || strcmp(pix_fmt, "rgba") == 0) {
+        return AV_PIX_FMT_RGBA;
+    } else if (strcmp(pix_fmt, "BGRA") == 0 || strcmp(pix_fmt, "bgra") == 0) {
+        return AV_PIX_FMT_BGRA;
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", pix_fmt);
+        return AV_PIX_FMT_NONE;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluScaleCvtYUV2RGBXContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";
+        break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";
+        break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixfmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow";
+        break;
+    }
+}
+
+static int mluscale_cvt_query_formats(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+   int ret;
+   out_pixfmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->out_formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->in_formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluscale_cvt_init(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_rgbx = NULL;
+
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mluscale_cvt_uninit(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        s->ptr_scale_cvt_yuv2rgbx_destroy(s->op_handle);
+    }
+    // mluop_unload(s);
+    if(s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluscale_cvt_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluScaleCvtYUV2RGBXContext *s  = ctx->priv;
+
+    int w, h;
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char device_idx[sizeof(int)];
+
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    s->in_y_size    = inlink->w * inlink->h;
+    s->in_uv_size   = inlink->w * inlink->h / 2;
+    s->out_mlu_size = outlink->w * outlink->h *
+                    get_pixfmt_channel_num(get_av_pixfmt_from_idx(s->enter_out_fmt));
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = get_av_pixfmt_from_idx(s->enter_out_fmt);
+        outlink->format = get_av_pixfmt_from_idx(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mlu
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_scale_cvt_yuv2rgbx_init(&s->op_handle,
+                                       inlink->w, inlink->h,
+                                       outlink->w, outlink->h,
+                                       s->pic_pixfmt, s->enter_out_fmt,
+                                       s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), sizeof(char) * s->in_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), sizeof(char) * s->in_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->out_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluscale_cvt_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext*ctx      = link->dst;
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    AVFilterLink*outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y = in->data[0];
+            s->input_mlu_uv = in->data[1];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                                  s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                                  s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        ret = s->ptr_scale_cvt_yuv2rgbx_exec(s->op_handle, s->input_mlu_y,
+                                             s->input_mlu_uv, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2rgbx filter with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->out_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleCvtYUV2RGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "Output video width",  OFFSET(w_expr), AV_OPT_TYPE_STRING, {.str = "iw"}, .flags = FLAGS },
+    { "h", "Output video height", OFFSET(h_expr), AV_OPT_TYPE_STRING, {.str = "ih"}, .flags = FLAGS },
+    { "o_fmt", "output pixfmt",   OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS},
+    { "n",     "device index",    OFFSET(n_expr),        AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mluscale_cvt_class = {
+    .class_name = "mluscale_cvt",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluscale_cvt_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluscale_cvt_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluscale_cvt_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluscale_cvt_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_cvt_yuv2rgbx_mlu = {
+    .name      = "scale_cvt_yuv2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated resize and convert yuv to rgbx"),
+
+    .init          = mluscale_cvt_init,
+    .uninit        = mluscale_cvt_uninit,
+    .query_formats = mluscale_cvt_query_formats,
+
+    .priv_size = sizeof(MluScaleCvtYUV2RGBXContext),
+    .priv_class = &mluscale_cvt_class,
+
+    .inputs    = mluscale_cvt_inputs,
+    .outputs   = mluscale_cvt_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_rgbx2rgbx_mlu.c b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
new file mode 100644
index 0000000000..94366107f6
--- /dev/null
+++ b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
@@ -0,0 +1,555 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+#include <dlfcn.h>
+
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluScaleRGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame     *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format; // Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *w_expr;
+    char *h_expr;
+    char *n_expr;
+    char *depth;
+    const char *pic_pixfmt;
+
+    bool is_crop;
+    int crop_x, crop_y, crop_w, crop_h;
+    int dst_crop_x, dst_crop_y, dst_crop_w, dst_crop_h;
+
+    // buffers and mlu-resize func-ptrs
+    int input_mlu_size;
+    int output_mlu_size;
+    void *input_mlu_rgbx;
+    void *output_mlu_rgbx;
+
+    int (*ptr_resize_rgbx_init)(void **, int, int, int, int, const char *, const char *);
+    int (*ptr_resize_rgbx_exec)(void *, void *, void *);
+    int (*ptr_resize_pad_rgbx_exec)(void *, void *, void *);
+    int (*ptr_resize_crop_rgbx_exec)(void *, void *, void *, int, int, int, int, int, int, int, int);
+    int (*ptr_resize_rgbx_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluScaleRGBXContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluScaleRGBXContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_resize_rgbx_init =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_init", "mluop");
+    ctx->ptr_resize_rgbx_exec =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_exec", "mluop");
+    ctx->ptr_resize_pad_rgbx_exec =
+        dlsym_prefixed(ctx->lib, "resize_pad_rgbx_exec", "mluop");
+    ctx->ptr_resize_crop_rgbx_exec =
+        dlsym_prefixed(ctx->lib, "resize_roi_rgbx_exec", "mluop");
+    ctx->ptr_resize_rgbx_destroy =
+        dlsym_prefixed(ctx->lib, "resize_rgbx_destroy", "mluop");
+    if (!ctx->ptr_resize_rgbx_init || !ctx->ptr_resize_rgbx_exec || !ctx->ptr_resize_pad_rgbx_exec ||
+        !ctx->ptr_resize_rgbx_destroy || !ctx->ptr_resize_crop_rgbx_exec) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluScaleRGBXContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+  if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+    return 1;
+  } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+    return 3;
+  } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+             pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+    return 4;
+  } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "Unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+    return 0;
+  }
+}
+
+static void convert_av_pixfmt_to_idx(MluScaleRGBXContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12";  break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21";  break;
+    case AV_PIX_FMT_RGB24:
+        ctx->pic_pixfmt = "rgb24"; break;
+    case AV_PIX_FMT_BGR24:
+        ctx->pic_pixfmt = "bgr24"; break;
+    case AV_PIX_FMT_ARGB:
+        ctx->pic_pixfmt = "argb";  break;
+    case AV_PIX_FMT_ABGR:
+        ctx->pic_pixfmt = "abgr";  break;
+    case AV_PIX_FMT_RGBA:
+        ctx->pic_pixfmt = "rgba";  break;
+    case AV_PIX_FMT_BGRA:
+        ctx->pic_pixfmt = "bgra";  break;
+    default:
+        av_log(NULL, AV_LOG_ERROR, "Unsupported pixfmt for converting, %s\n",
+                av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow"; break;
+    }
+}
+
+static int mlu_device_binding(MluScaleRGBXContext *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static int mlurgbxscale_query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    int ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->inputs[0]->out_formats)) < 0)
+        return ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->outputs[0]->in_formats)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbxscale_init(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+
+    static const char * const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->is_crop = false;
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mlurgbxscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if (s->op_handle) {
+        s->ptr_resize_rgbx_destroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbxscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx   = outlink->src;
+    AVFilterLink *inlink   = ctx->inputs[0];
+    MluScaleRGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx    = NULL;
+
+    AVHWFramesContext *in_frames_ctx;
+
+    int w, h, ret;
+    char device_idx[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx  = NULL;
+
+    if (s->crop_x != 0 || s->crop_y != 0) {
+        s->is_crop = true;
+        s->crop_w = atoi(s->w_expr);
+        s->crop_h = atoi(s->h_expr);
+        s->dst_crop_x = 0;
+        s->dst_crop_y = 0;
+        s->dst_crop_w = s->crop_w;
+        s->dst_crop_h = s->crop_h;
+    }
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "the input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = FFALIGN(outlink->h, 1);
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->input_mlu_size  = inlink->w * inlink->h * get_pixfmt_channel_num(s->in_fmt);
+    s->output_mlu_size = outlink->w * outlink->h * get_pixfmt_channel_num(s->out_fmt);
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mluop
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+
+        s->ptr_resize_rgbx_init(&s->op_handle, inlink->w, inlink->h, outlink->w, outlink->h,
+                                s->pic_pixfmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = cnrtMalloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = cnrtMalloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->output_mlu_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h * inlink->w,
+                                                             outlink->w * inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbxscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx   = link->dst;
+    MluScaleRGBXContext *s = ctx->priv;
+    AVFilterLink *outlink  = ctx->outputs[0];
+    MluContext *mlu_ctx    = s->hw_dev_ctx->mlu_ctx;
+
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(ENAVAIL);
+        goto fail;
+    }
+
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                              s->input_mlu_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        if (!s->is_crop) {
+            ret = s->ptr_resize_rgbx_exec(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx);
+            // ret = s->ptr_resize_pad_rgbx_exec(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx);
+        } else {
+            ret = s->ptr_resize_crop_rgbx_exec(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx,
+                        s->crop_x, s->crop_y, s->crop_w, s->crop_h,
+                        s->dst_crop_x, s->dst_crop_y, s->dst_crop_w, s->dst_crop_h);
+        }
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2rgbx scale with mluop \n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->output_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleRGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "width", "out width",  OFFSET(w_expr), AV_OPT_TYPE_STRING, { .str = "iw" }, .flags = FLAGS },
+    { "hight", "out height", OFFSET(h_expr), AV_OPT_TYPE_STRING, { .str = "ih" }, .flags = FLAGS },
+    { "n", "device index",   OFFSET(n_expr), AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { "x", "crop x",        OFFSET(crop_x), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { "y", "crop y",        OFFSET(crop_y), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mlurgbxscale_class = {
+    .class_name = "mlurgbxscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbxscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbxscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbxscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbxscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_rgbx2rgbx_mlu = {
+    .name      = "scale_rgbx2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer for rgbx only support 8U"),
+
+    .init          = mlurgbxscale_init,
+    .uninit        = mlurgbxscale_uninit,
+    .query_formats = mlurgbxscale_query_formats,
+
+    .priv_size = sizeof(MluScaleRGBXContext),
+    .priv_class = &mlurgbxscale_class,
+
+    .inputs    = mlurgbxscale_inputs,
+    .outputs   = mlurgbxscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_yuv2yuv_mlu.c b/libavfilter/vf_scale_yuv2yuv_mlu.c
new file mode 100644
index 0000000000..139bade0ca
--- /dev/null
+++ b/libavfilter/vf_scale_yuv2yuv_mlu.c
@@ -0,0 +1,567 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+#include <stdio.h>
+#include <string.h>
+#include <dlfcn.h>
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/pixfmt.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale.h"
+#include "video.h"
+
+#define CNFILTER_FRAME_ALIGNMENT 1
+#define CNRT_ERROR_CHECK(avctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(avctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        goto fail;                                                                         \
+    }
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12,
+    AV_PIX_FMT_NV21,
+};
+
+typedef struct MluScaleContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[4], planes_out[4];
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int stride_align;
+    int passthrough;
+    enum AVPixelFormat format; // Output sw format. AV_PIX_FMT_NONE for no conversion.
+
+    char *w_expr;
+    char *h_expr;
+    char *n_expr;
+    char *depth;
+    const char *pic_pixfmt;
+
+    bool is_crop;
+    int crop_x, crop_y, crop_w, crop_h;
+    int dst_crop_x, dst_crop_y, dst_crop_w, dst_crop_h;
+
+    // buffers and mlu-resize func-ptrs
+    int in_y_size;
+    int in_uv_size;
+    int out_y_size;
+    int out_uv_size;
+
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_y;
+    void *output_mlu_uv;
+
+    int (*ptr_resize_yuv_init)(void **, int, int, int, int, const char *, const char *);
+    int (*ptr_resize_yuv_exec)(void *, void *, void *, void *, void *);
+    int (*ptr_resize_pad_yuv_exec)(void *, void *, void *, void *, void *);
+    int (*ptr_resize_crop_yuv_exec)(void *, void *, void *, void *, void *, int, int, int, int, int, int, int, int);
+    int (*ptr_resize_yuv_destroy)(void *);
+
+    void *lib;
+    void *op_handle;
+} MluScaleContext;
+
+static av_cold void *dlsym_prefixed(void *handle, const char *symbol,
+                                    const char *prefix) {
+    char buf[50];
+    snprintf(buf, sizeof(buf), "%s_%s", prefix ? prefix : "", symbol);
+    return dlsym(handle, buf);
+}
+
+static int mluop_load(MluScaleContext *ctx,const char *libname, void *logctx) {
+    if (libname) {
+        ctx->lib = dlopen(libname, RTLD_NOW | RTLD_GLOBAL);
+        if (!ctx->lib) {
+            av_log(logctx, AV_LOG_WARNING, "dlopen %s  failed, dlerror = %s\n", libname,dlerror());
+            return AVERROR_EXTERNAL;
+        } else {
+            av_log(logctx, AV_LOG_TRACE, "dlopen %s successfully\n", libname);
+        }
+    }
+    ctx->ptr_resize_yuv_init =
+        dlsym_prefixed(ctx->lib, "resize_yuv_init", "mluop");
+    ctx->ptr_resize_yuv_exec =
+        dlsym_prefixed(ctx->lib, "resize_yuv_exec", "mluop");
+    ctx->ptr_resize_pad_yuv_exec =
+        dlsym_prefixed(ctx->lib, "resize_pad_yuv_exec", "mluop");
+    ctx->ptr_resize_crop_yuv_exec =
+        dlsym_prefixed(ctx->lib, "resize_roi_yuv_exec", "mluop");
+    ctx->ptr_resize_yuv_destroy =
+        dlsym_prefixed(ctx->lib, "resize_yuv_destroy", "mluop");
+    if (!ctx->ptr_resize_yuv_init || !ctx->ptr_resize_yuv_exec || !ctx->ptr_resize_pad_yuv_exec ||
+        !ctx->ptr_resize_yuv_destroy || !ctx->ptr_resize_crop_yuv_exec) {
+        av_log(logctx, AV_LOG_WARNING, "Not all functions found in %s\n",
+                libname);
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    return 0;
+}
+
+static int mluop_unload(MluScaleContext *ctx) {
+    if (ctx->lib) {
+        dlclose(ctx->lib);
+        ctx->lib = NULL;
+    }
+    return 0;
+}
+
+static uint32_t get_pixfmt_channel_num(enum AVPixelFormat pixfmt) {
+    if (pixfmt == AV_PIX_FMT_NV12 || pixfmt == AV_PIX_FMT_NV21) {
+        return 1;
+    } else if (pixfmt == AV_PIX_FMT_BGR24 || pixfmt == AV_PIX_FMT_RGB24) {
+        return 3;
+    } else if (pixfmt == AV_PIX_FMT_ABGR || pixfmt == AV_PIX_FMT_ARGB ||
+                pixfmt == AV_PIX_FMT_BGRA || pixfmt == AV_PIX_FMT_RGBA) {
+        return 4;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "Unsupported pixfmt for getting channel num, %s\n", av_get_pix_fmt_name(pixfmt));
+        return 0;
+    }
+}
+
+static void convert_av_pixfmt_to_idx(MluScaleContext *ctx, enum AVPixelFormat fmt) {
+    switch (fmt) {
+    case AV_PIX_FMT_NV12:
+        ctx->pic_pixfmt = "nv12"; break;
+    case AV_PIX_FMT_NV21:
+        ctx->pic_pixfmt = "nv21"; break;
+    default:
+        av_log(ctx, AV_LOG_ERROR, "Unsupported pix fmt, %s\n", av_get_pix_fmt_name(fmt));
+        ctx->pic_pixfmt = "unknow";   break;
+    }
+}
+
+static int mlu_device_binding(MluScaleContext *ctx) {
+    MluContext *mlu_ctx = ctx->mlu_ctx;
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, mlu_ctx->mlu_id);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        return AVERROR(EINVAL);
+    }
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static int mluscale_query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    AVFilterFormats *pix_fmts = ff_make_format_list(pixel_formats);
+
+    int ret;
+    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluscale_init(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+
+    static const char *const mluop_libname = "libeasyOP.so";
+    int ret = mluop_load(s, mluop_libname, ctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    s->format = AV_PIX_FMT_NONE; // for no conversion.
+
+    s->is_crop = false;
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+    s->op_handle = NULL;
+    return 0;
+}
+
+static av_cold void mluscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if (s->op_handle) {
+        s->ptr_resize_yuv_destroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+
+    mluop_unload(s);
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluScaleContext *s   = ctx->priv;
+    MluContext *mlu_ctx  = NULL;
+
+    int w, h, ret;
+    char device_idx[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx    = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    if (s->crop_x != 0 || s->crop_y != 0) {
+        s->is_crop = true;
+        s->crop_w = atoi(s->w_expr);
+        s->crop_h = atoi(s->h_expr);
+        s->dst_crop_x = 0;
+        s->dst_crop_y = 0;
+        s->dst_crop_w = s->crop_w;
+        s->dst_crop_h = s->crop_h;
+    }
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(device_idx, "%d", atoi(s->n_expr));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        s->stride_align = CNFILTER_FRAME_ALIGNMENT;
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(EINVAL);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format    = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width     = FFALIGN(outlink->w, s->stride_align);
+            out_hw_frames_ctx->height    = FFALIGN(outlink->h, 1);
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx) {
+            return AVERROR(EINVAL);
+        }
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, device_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+        s->stride_align = 1;
+    }
+
+    s->in_y_size   = FFALIGN(inlink->w,  s->stride_align) * inlink->h;
+    s->in_uv_size  = FFALIGN(inlink->w,  s->stride_align) * inlink->h / 2;
+    s->out_y_size  = FFALIGN(outlink->w, s->stride_align) * outlink->h;
+    s->out_uv_size = FFALIGN(outlink->w, s->stride_align) * outlink->h / 2;
+
+    // check infmt and outfmt is legal
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    // init mluop
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    if(s->lib && !s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        convert_av_pixfmt_to_idx(s, s->in_fmt);
+        s->ptr_resize_yuv_init(&s->op_handle,
+                                FFALIGN(inlink->w, s->stride_align), inlink->h,
+                                FFALIGN(outlink->w, s->stride_align), outlink->h,
+                                s->depth, s->pic_pixfmt);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), s->in_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), s->in_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), s->out_y_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), s->out_uv_size);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+
+    // set aspec ratio
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext  *ctx = link->dst;
+    MluScaleContext    *s = ctx->priv;
+    AVFilterLink *outlink = ctx->outputs[0];
+    MluContext *mlu_ctx   = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if(mlu_device_binding(s) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "MLU device binding error\n");
+    }
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(ENAVAIL);
+        goto fail;
+    }
+
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_pixfmt_channel_num(s->out_fmt);
+    out->linesize[1] = out->width * get_pixfmt_channel_num(s->out_fmt);
+
+    if(s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y   = in->data[0];
+            s->input_mlu_uv  = in->data[1];
+            s->output_mlu_y  = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                            s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                            s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+        if (!s->is_crop) {
+            ret = s->ptr_resize_yuv_exec(s->op_handle, s->input_mlu_y,
+                        s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv);
+            // ret = s->ptr_resize_pad_yuv_exec(s->op_handle, s->input_mlu_y,
+            //             s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv);
+        } else {
+            ret = s->ptr_resize_crop_yuv_exec(s->op_handle, s->input_mlu_y,
+                        s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv,
+                        s->crop_x, s->crop_y, s->crop_w, s->crop_h,
+                        s->dst_crop_x, s->dst_crop_y, s->dst_crop_w, s->dst_crop_h);
+        }
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2yuv scale with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->out_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->out_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            CNRT_ERROR_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "out width (crop w)", OFFSET(w_expr), AV_OPT_TYPE_STRING, { .str = "iw" }, .flags = FLAGS },
+    { "h", "out height(crop h)", OFFSET(h_expr), AV_OPT_TYPE_STRING, { .str = "ih" }, .flags = FLAGS },
+    { "n", "device index",       OFFSET(n_expr), AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { "x", "crop x",        OFFSET(crop_x), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { "y", "crop y",        OFFSET(crop_y), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mluscale_class = {
+    .class_name = "mluscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_yuv2yuv_mlu = {
+    .name      = "scale_yuv2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer"),
+
+    .init          = mluscale_init,
+    .uninit        = mluscale_uninit,
+    .query_formats = mluscale_query_formats,
+
+    .priv_size = sizeof(MluScaleContext),
+    .priv_class = &mluscale_class,
+
+    .inputs    = mluscale_inputs,
+    .outputs   = mluscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavutil/Makefile b/libavutil/Makefile
index 8a7a44e4b5..0d80df750c 100644
--- a/libavutil/Makefile
+++ b/libavutil/Makefile
@@ -35,6 +35,7 @@ HEADERS = adler32.h                                                     \
           hmac.h                                                        \
           hwcontext.h                                                   \
           hwcontext_cuda.h                                              \
+          hwcontext_mlu.h                                               \
           hwcontext_d3d11va.h                                           \
           hwcontext_drm.h                                               \
           hwcontext_dxva2.h                                             \
@@ -163,6 +164,7 @@ OBJS = adler32.o                                                        \
        tx.o                                                             \
 
 OBJS-$(CONFIG_CUDA)                     += hwcontext_cuda.o
+OBJS-$(CONFIG_MLU)                      += hwcontext_mlu.o
 OBJS-$(CONFIG_D3D11VA)                  += hwcontext_d3d11va.o
 OBJS-$(CONFIG_DXVA2)                    += hwcontext_dxva2.o
 OBJS-$(CONFIG_LIBDRM)                   += hwcontext_drm.o
@@ -182,6 +184,7 @@ SLIBOBJS-$(HAVE_GNU_WINDRES)            += avutilres.o
 SKIPHEADERS-$(HAVE_CUDA_H)             += hwcontext_cuda.h
 SKIPHEADERS-$(CONFIG_CUDA)             += hwcontext_cuda_internal.h     \
                                           cuda_check.h
+SKIPHEADERS-$(CONFIG_MLU)              += hwcontext_mlu.h
 SKIPHEADERS-$(CONFIG_D3D11VA)          += hwcontext_d3d11va.h
 SKIPHEADERS-$(CONFIG_DXVA2)            += hwcontext_dxva2.h
 SKIPHEADERS-$(CONFIG_QSV)              += hwcontext_qsv.h
diff --git a/libavutil/hwcontext.c b/libavutil/hwcontext.c
index f1e404ab20..353d6eb8db 100644
--- a/libavutil/hwcontext.c
+++ b/libavutil/hwcontext.c
@@ -32,6 +32,9 @@ static const HWContextType * const hw_table[] = {
 #if CONFIG_CUDA
     &ff_hwcontext_type_cuda,
 #endif
+#if CONFIG_MLU
+    &ff_hwcontext_type_mlu,
+#endif
 #if CONFIG_D3D11VA
     &ff_hwcontext_type_d3d11va,
 #endif
@@ -64,6 +67,7 @@ static const HWContextType * const hw_table[] = {
 
 static const char *const hw_type_names[] = {
     [AV_HWDEVICE_TYPE_CUDA]   = "cuda",
+    [AV_HWDEVICE_TYPE_MLU]   = "mlu",
     [AV_HWDEVICE_TYPE_DRM]    = "drm",
     [AV_HWDEVICE_TYPE_DXVA2]  = "dxva2",
     [AV_HWDEVICE_TYPE_D3D11VA] = "d3d11va",
@@ -354,6 +358,7 @@ int av_hwframe_ctx_init(AVBufferRef *ref)
     if (ret < 0)
         return ret;
 
+
     /* format-specific init */
     if (ctx->internal->hw_type->frames_init) {
         ret = ctx->internal->hw_type->frames_init(ctx);
diff --git a/libavutil/hwcontext.h b/libavutil/hwcontext.h
index f5a4b62387..95ac2780c9 100644
--- a/libavutil/hwcontext.h
+++ b/libavutil/hwcontext.h
@@ -36,6 +36,7 @@ enum AVHWDeviceType {
     AV_HWDEVICE_TYPE_DRM,
     AV_HWDEVICE_TYPE_OPENCL,
     AV_HWDEVICE_TYPE_MEDIACODEC,
+    AV_HWDEVICE_TYPE_MLU,
 };
 
 typedef struct AVHWDeviceInternal AVHWDeviceInternal;
diff --git a/libavutil/hwcontext_internal.h b/libavutil/hwcontext_internal.h
index 77dc47ddd6..0f7bb9957f 100644
--- a/libavutil/hwcontext_internal.h
+++ b/libavutil/hwcontext_internal.h
@@ -163,6 +163,7 @@ int ff_hwframe_map_create(AVBufferRef *hwframe_ref,
 int ff_hwframe_map_replace(AVFrame *dst, const AVFrame *src);
 
 extern const HWContextType ff_hwcontext_type_cuda;
+extern const HWContextType ff_hwcontext_type_mlu;
 extern const HWContextType ff_hwcontext_type_d3d11va;
 extern const HWContextType ff_hwcontext_type_drm;
 extern const HWContextType ff_hwcontext_type_dxva2;
diff --git a/libavutil/hwcontext_mlu.c b/libavutil/hwcontext_mlu.c
new file mode 100644
index 0000000000..7726831d68
--- /dev/null
+++ b/libavutil/hwcontext_mlu.c
@@ -0,0 +1,435 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <dlfcn.h>
+#include "buffer.h"
+#include "common.h"
+#include "hwcontext.h"
+#include "hwcontext_internal.h"
+#include "hwcontext_mlu.h"
+#include "mem.h"
+#include "pixdesc.h"
+#include "pixfmt.h"
+#include "imgutils.h"
+
+#define MLU_FRAME_ALIGNMENT 1 // mlu align
+
+#define CNRT_ERROR_CHECK(ctx, ret)                                                       \
+    if (ret != CNRT_RET_SUCCESS) {                                                         \
+        av_log(ctx,AV_LOG_ERROR,"error occur, func: %s, line: %d\n", __func__, __LINE__);\
+        return -1;                                                                         \
+    }
+
+typedef struct MLUFramesContext {
+    int shift_width, shift_height;
+} MLUFramesContext;
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_P010, AV_PIX_FMT_YUV420P,
+};
+
+static int mlu_frames_get_constraints(AVHWDeviceContext *ctx, const void *hwconfig,
+                                       AVHWFramesConstraints *constraints)
+{
+    int i;
+
+    constraints->valid_sw_formats = av_malloc_array(FF_ARRAY_ELEMS(supported_formats) + 1,
+                                                    sizeof(*constraints->valid_sw_formats));
+    if (!constraints->valid_sw_formats)
+        return AVERROR(ENOMEM);
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        constraints->valid_sw_formats[i] = supported_formats[i];
+    constraints->valid_sw_formats[FF_ARRAY_ELEMS(supported_formats)] = AV_PIX_FMT_NONE;
+
+    constraints->valid_hw_formats = av_malloc_array(2, sizeof(*constraints->valid_hw_formats));
+    if (!constraints->valid_hw_formats)
+        return AVERROR(ENOMEM);
+
+    constraints->valid_hw_formats[0] = AV_PIX_FMT_MLU;
+    constraints->valid_hw_formats[1] = AV_PIX_FMT_NONE;
+
+    return 0;
+}
+
+static void mlu_buffer_free(void *opaque, uint8_t *data)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    mlu_ctx->mluMemFree(data); // check
+}
+
+static AVBufferRef *mlu_pool_alloc(void *opaque, int size)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    AVBufferRef *ret = NULL;
+    void* data = NULL;
+
+    cnrtRet_t cnrt_ret;
+    cnrt_ret = mlu_ctx->mluMemAlloc((void **)(&data), size);
+    if (cnrt_ret != CNRT_RET_SUCCESS) {
+        av_log(ctx, AV_LOG_ERROR, "cnrtMalloc failed: dev addr %p, size %d \n", data, size);
+        return NULL;
+    }
+    ret = av_buffer_create((uint8_t*)data, size, mlu_buffer_free, ctx, 0);
+    if (!ret) {
+        mlu_ctx->mluMemFree(data);
+    }
+    return ret;
+}
+
+static int mlu_frames_init(AVHWFramesContext *ctx)
+{
+    MLUFramesContext *priv = ctx->internal->priv;
+    int i;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++) {
+        if (ctx->sw_format == supported_formats[i])
+            break;
+    }
+    if (i == FF_ARRAY_ELEMS(supported_formats)) {
+        av_log(ctx, AV_LOG_ERROR, "Pixel format '%s' is not supported\n",
+               av_get_pix_fmt_name(ctx->sw_format));
+        return AVERROR(ENOSYS);
+    }
+
+    av_pix_fmt_get_chroma_sub_sample(ctx->sw_format, &priv->shift_width, &priv->shift_height);
+
+    if (!ctx->pool) {
+        int size = av_image_get_buffer_size(ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+        if (size < 0)
+            return size;
+
+        ctx->internal->pool_internal = av_buffer_pool_init2(size, ctx, mlu_pool_alloc, NULL);
+        if (!ctx->internal->pool_internal)
+            return AVERROR(ENOMEM);
+    }
+
+    return 0;
+}
+
+static int mlu_get_buffer(AVHWFramesContext *ctx, AVFrame *frame)
+{
+    int res;
+
+    frame->buf[0] = av_buffer_pool_get(ctx->pool);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    res = av_image_fill_arrays(frame->data, frame->linesize, frame->buf[0]->data,
+                               ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+    if (res < 0)
+        return res;
+
+    frame->format = AV_PIX_FMT_MLU;
+    frame->width  = ctx->width;
+    frame->height = ctx->height;
+
+    return 0;
+}
+
+static int mlu_transfer_get_formats(AVHWFramesContext *ctx,
+                                     enum AVHWFrameTransferDirection dir,
+                                     enum AVPixelFormat **formats)
+{
+    enum AVPixelFormat *fmts;
+
+    fmts = av_malloc_array(2, sizeof(*fmts));
+    if (!fmts)
+        return AVERROR(ENOMEM);
+
+    fmts[0] = ctx->sw_format;
+    fmts[1] = AV_PIX_FMT_NONE;
+
+    *formats = fmts;
+
+    return 0;
+}
+
+static int mlu_transfer_data_from(AVHWFramesContext *ctx, AVFrame *dst,
+                                   const AVFrame *src)
+{
+    // MLUFramesContext        *priv = ctx->internal->priv;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext    *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    int i;
+    size_t nBytes;
+    cnrtRet_t cnrt_ret;
+    for (i = 0; i < FF_ARRAY_ELEMS(src->data) && src->data[i]; i++) {
+        // nBytes = src->linesize[i] * src->height * (i ? 1.0 / 2 : 1);
+        nBytes = FFMIN(src->linesize[i], dst->linesize[i]) * src->height * (i ? 1.0 / 2 : 1);
+        cnrt_ret = mlu_ctx->mluMemcpyD2H(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_DEV2HOST);
+        if (cnrt_ret != CNRT_RET_SUCCESS) {
+            av_log(ctx, AV_LOG_ERROR, "d2h: dev %p -> host %p size %lu \n", src->data[i], dst->data[i], nBytes);
+            av_log(ctx, AV_LOG_ERROR, " mluMemcpyD2H error occur, fuc: %s, line:%d\n", __func__, __LINE__);
+            return -1;
+        }
+    }
+
+    return 0;
+}
+
+static int mlu_transfer_data_to(AVHWFramesContext *ctx, AVFrame *dst,
+                                 const AVFrame *src)
+{
+    // MLUFramesContext        *priv = ctx->internal->priv;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    int i;
+    size_t nBytes;
+    cnrtRet_t cnrt_ret;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(src->data) && src->data[i]; i++) {
+        // nBytes = src->linesize[i] * src->height * (i ? 1.0 / 2 : 1);
+        nBytes = FFMIN(src->linesize[i], dst->linesize[i]) * src->height * (i ? 1.0 / 2 : 1);
+        cnrt_ret = mlu_ctx->mluMemcpyH2D(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_HOST2DEV);
+        if (cnrt_ret != CNRT_RET_SUCCESS) {
+            av_log(ctx, AV_LOG_ERROR, "h2d: host %p -> dev %p, size %lu \n", src->data[i], dst->data[i], nBytes);
+            av_log(ctx, AV_LOG_ERROR, "mluMemcpyH2D error occur, func: %s, line: %d\n", __func__, __LINE__);
+            return -1;
+        }
+    }
+
+    return 0;
+}
+
+static void mlu_device_uninit(AVHWDeviceContext *device_ctx)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+    if (hwctx->mlu_cnrt_lib) {
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_cnrt_lib = NULL;
+    }
+
+    // hwctx->mlu_ctx->mluDestroy();
+    if (hwctx->mlu_ctx) {
+        av_freep(&hwctx->mlu_ctx);
+        hwctx->mlu_ctx = NULL;
+    }
+}
+
+static int mlu_device_init(AVHWDeviceContext *ctx)
+{
+    AVMLUDeviceContext *hwctx = ctx->hwctx;
+    if (!hwctx->mlu_ctx) {
+        hwctx->mlu_ctx = av_mallocz(sizeof(*hwctx->mlu_ctx));
+        if (!hwctx->mlu_ctx)
+            return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static int mlu_load_functions(AVMLUDeviceContext *hwctx, void *ctx) {
+    const char *cnrt_path = "libcnrt.so";
+    hwctx->mlu_cnrt_lib = dlopen(cnrt_path, RTLD_NOW | RTLD_GLOBAL);
+    if (!hwctx->mlu_cnrt_lib) {
+        av_log(ctx, AV_LOG_ERROR, "dlopen cnrt lib failed. \n");
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluInit = (cnrtRet_t (*)(int))dlsym(hwctx->mlu_cnrt_lib, "cnrtInit");
+    if (!hwctx->mlu_ctx->mluInit) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluInit()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluDestroy = (void (*)(void))dlsym(hwctx->mlu_cnrt_lib, "cnrtDestroy");
+    if (!hwctx->mlu_ctx->mluDestroy) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluDestroy()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceCount = (cnrtRet_t (*)(int *))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceCount");
+    if (!hwctx->mlu_ctx->mluGetDeviceCount) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceCount()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceHandle = (cnrtRet_t (*)(cnrtDev_t *, int))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceHandle");
+    if (!hwctx->mlu_ctx->mluGetDeviceHandle) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceHandle()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluSetDevice = (cnrtRet_t (*)(cnrtDev_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtSetCurrentDevice");
+    if (!hwctx->mlu_ctx->mluSetDevice) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluSetDevice()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluSetChannel = (cnrtRet_t (*)(cnrtChannelType_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtSetCurrentChannel");
+    if (!hwctx->mlu_ctx->mluSetChannel) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluSetChannel()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluGetDeviceInfo = (cnrtRet_t (*)(cnrtDeviceInfo_t *, int))dlsym(hwctx->mlu_cnrt_lib, "cnrtGetDeviceInfo");
+    if (!hwctx->mlu_ctx->mluGetDeviceInfo) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluGetDeviceInfo()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+
+    hwctx->mlu_ctx->mluMemAlloc = (cnrtRet_t (*)(void **, size_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMalloc");
+    if (!hwctx->mlu_ctx->mluMemAlloc) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemAlloc()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemFree = (cnrtRet_t (*)(void *))dlsym(hwctx->mlu_cnrt_lib, "cnrtFree");
+    if (!hwctx->mlu_ctx->mluMemFree) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemFree()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyH2D = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyH2D) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyH2D()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyD2H = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyD2H) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyD2H()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+    hwctx->mlu_ctx->mluMemcpyD2D = (cnrtRet_t (*)(void *, void *, size_t, cnrtMemTransDir_t))dlsym(hwctx->mlu_cnrt_lib, "cnrtMemcpy");
+    if (!hwctx->mlu_ctx->mluMemcpyD2D) {
+        av_log(ctx, AV_LOG_ERROR, "do not found function: mluMemcpyD2D()\n");
+        dlclose(hwctx->mlu_cnrt_lib);
+        hwctx->mlu_ctx = NULL;
+        return AVERROR_EXTERNAL;
+    }
+
+    return 0;
+}
+
+static int mlu_device_create(AVHWDeviceContext *device_ctx,
+                              const char *device,
+                              AVDictionary *opts, int flags)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+
+    MluContext *mlu_ctx = NULL;
+
+    cnrtDev_t dev;
+    cnrtRet_t cnrt_ret;
+    cnrtDeviceInfo_t dev_info;
+
+    int ret = 0;
+    int device_idx = 0;
+    unsigned int dev_num = 0;
+    if (device) device_idx = strtol(device, NULL, 0);
+
+    if (mlu_device_init(device_ctx) < 0)
+        goto error;
+
+    ret = mlu_load_functions(hwctx, device_ctx);
+    if (ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu load functions failed\n");
+        goto error;
+    }
+
+    mlu_ctx = hwctx->mlu_ctx;
+    mlu_ctx->mlu_id = device_idx;
+
+    // cnrt_ret = mlu_ctx->mluInit(0);
+    // if (cnrt_ret < 0){
+    //     av_log(device_ctx, AV_LOG_ERROR, "mlu init failed \n");
+    //     goto error;
+    // }
+
+    cnrt_ret = mlu_ctx->mluGetDeviceCount(&dev_num);
+    if (cnrt_ret !=0 || dev_num == 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "Can't find MLU card, or dev count is 0 \n");
+        goto error;
+    }
+
+    cnrt_ret = mlu_ctx->mluGetDeviceHandle(&dev, device_idx);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu GetDeviceHandle failed \n");
+        goto error;
+    }
+
+    cnrt_ret = mlu_ctx->mluSetDevice(dev);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu mluSetDevice failed \n");
+        goto error;
+    }
+
+    //cnrt_ret = mluSetChnnel(0);
+    //if (cnrt_ret < 0) goto error;
+
+    cnrt_ret = mlu_ctx->mluGetDeviceInfo(&dev_info, device_idx);
+    if (cnrt_ret < 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "mlu mluGetDeviceInfo failed \n");
+        goto error;
+    }
+
+    return 0;
+
+error:
+    mlu_device_uninit(device_ctx);
+    return AVERROR_UNKNOWN;
+}
+
+const HWContextType ff_hwcontext_type_mlu = {
+    .type                 = AV_HWDEVICE_TYPE_MLU,
+    .name                 = "MLU",
+
+    .device_hwctx_size    = sizeof(AVMLUDeviceContext),
+    .frames_priv_size     = sizeof(MLUFramesContext),
+
+    .device_create        = mlu_device_create,
+    .device_init          = mlu_device_init,
+    .device_uninit        = mlu_device_uninit,
+    .frames_get_constraints = mlu_frames_get_constraints,
+    .frames_init          = mlu_frames_init,
+    .frames_get_buffer    = mlu_get_buffer,
+    .transfer_get_formats = mlu_transfer_get_formats,
+    .transfer_data_to     = mlu_transfer_data_to,
+    .transfer_data_from   = mlu_transfer_data_from,
+
+    .pix_fmts             = (const enum AVPixelFormat[]){ AV_PIX_FMT_MLU, AV_PIX_FMT_NONE },
+};
diff --git a/libavutil/hwcontext_mlu.h b/libavutil/hwcontext_mlu.h
new file mode 100644
index 0000000000..ecfaf4d30f
--- /dev/null
+++ b/libavutil/hwcontext_mlu.h
@@ -0,0 +1,63 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+
+#ifndef AVUTIL_HWCONTEXT_MLU_H
+#define AVUTIL_HWCONTEXT_MLU_H
+
+#include <cnrt.h>
+#include "pixfmt.h"
+
+typedef struct MluContext {
+    // int ret = 0;
+    // cnrtRet_t cnrt_ret;
+    // cnrtDev_t dev;
+    // cnrtDeviceInfo_t dev_info;
+    int mlu_id;
+
+    /** operate dev **/
+    void      (*mluDestroy)(void);
+    cnrtRet_t (*mluInit)(int);
+    cnrtRet_t (*mluGetDeviceCount)(int *);
+    cnrtRet_t (*mluGetDeviceHandle)(cnrtDev_t *, int);
+    cnrtRet_t (*mluSetDevice)(cnrtDev_t);
+    cnrtRet_t (*mluSetChannel)(cnrtChannelType_t);
+    cnrtRet_t (*mluGetDeviceInfo)(cnrtDeviceInfo_t *, int);
+
+    // operate mem
+    cnrtRet_t (*mluMemFree)(void *);
+    cnrtRet_t (*mluMemAlloc)(void **, size_t);
+    cnrtRet_t (*mluMemcpyH2D)(void *, void *, size_t, cnrtMemTransDir_t);
+    cnrtRet_t (*mluMemcpyD2H)(void *, void *, size_t, cnrtMemTransDir_t);
+    cnrtRet_t (*mluMemcpyD2D)(void *, void *, size_t, cnrtMemTransDir_t);
+}MluContext;
+
+/**
+ * @file
+ * This struct is allocated as AVHWDeviceContext.hwctx
+ */
+typedef struct AVMLUDeviceContext {
+    void *mlu_cnrt_lib;
+    MluContext *mlu_ctx;
+} AVMLUDeviceContext;
+
+/**
+ * AVHWFramesContext.hwctx is currently not used
+ */
+
+#endif /* AVUTIL_HWCONTEXT_MLU_H */
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index b97b0665b0..db47325536 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -2050,6 +2050,10 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         .name = "cuda",
         .flags = AV_PIX_FMT_FLAG_HWACCEL,
     },
+    [AV_PIX_FMT_MLU] = {
+        .name = "mlu",
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
     [AV_PIX_FMT_AYUV64LE] = {
         .name = "ayuv64le",
         .nb_components = 4,
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 8b54c9415b..ace8536389 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -234,6 +234,12 @@ enum AVPixelFormat {
      */
     AV_PIX_FMT_CUDA,
 
+    /**
+     * HW acceleration through MLU. data[i] contain mlu deviceptr pointers
+     * exactly as for system memory frames.
+     */
+    AV_PIX_FMT_MLU,
+
     AV_PIX_FMT_0RGB,        ///< packed RGB 8:8:8, 32bpp, XRGBXRGB...   X=unused/undefined
     AV_PIX_FMT_RGB0,        ///< packed RGB 8:8:8, 32bpp, RGBXRGBX...   X=unused/undefined
     AV_PIX_FMT_0BGR,        ///< packed BGR 8:8:8, 32bpp, XBGRXBGR...   X=unused/undefined
-- 
2.17.1

