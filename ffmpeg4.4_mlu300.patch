From a18d47098398833a58b374ce47271e38c8b99aa5 Mon Sep 17 00:00:00 2001
From: fanhairui <fanhairui@cambricon.com>
Date: Wed, 25 Sep 2024 16:12:56 +0800
Subject: [PATCH] release mlu300

---
 configure                               |   48 +
 doc/examples/Makefile                   |    6 +
 doc/examples/decode_mlu.c               |  213 +++
 doc/examples/encode_change_mlu.c        |  284 ++++
 doc/examples/encode_mlu.c               |  252 ++++
 doc/examples/hw_decode_mlu.c            |  270 ++++
 doc/examples/hw_encode_change_mlu.c     |  286 ++++
 doc/examples/hw_encode_mlu.c            |  257 ++++
 fftools/Makefile                        |    1 +
 fftools/ffmpeg.h                        |    2 +
 fftools/ffmpeg_mlu.c                    |   75 ++
 fftools/ffmpeg_opt.c                    |    4 +
 libavcodec/Makefile                     |   10 +
 libavcodec/allcodecs.c                  |   10 +
 libavcodec/hwconfig.h                   |    2 +
 libavcodec/mlumpp_codec.h               |  449 +++++++
 libavcodec/mlumpp_dec.c                 | 1599 +++++++++++++++++++++++
 libavcodec/mlumpp_enc_h264.c            |  219 ++++
 libavcodec/mlumpp_enc_hevc.c            |  230 ++++
 libavcodec/mlumpp_enc_jpeg.c            |  125 ++
 libavcodec/mlumpp_vid_enc.c             | 1166 +++++++++++++++++
 libavcodec/mlumpp_vid_enc.h             |  130 ++
 libavfilter/Makefile                    |   10 +
 libavfilter/allfilters.c                |   10 +
 libavfilter/mlu_filter_common.h         |  146 +++
 libavfilter/vf_cvt_rgbx2rgbx_mlu.c      |  413 ++++++
 libavfilter/vf_cvt_rgbx2yuv_mlu.c       |  429 ++++++
 libavfilter/vf_cvt_yuv2rgbx_mlu.c       |  425 ++++++
 libavfilter/vf_hwdownload_mlu.c         |  215 +++
 libavfilter/vf_hwupload_mlu.c           |  198 +++
 libavfilter/vf_overlay_mlu.c            |  702 ++++++++++
 libavfilter/vf_rotate_mlu.c             |  326 +++++
 libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c |  431 ++++++
 libavfilter/vf_scale_rgbx2rgbx_mlu.c    |  421 ++++++
 libavfilter/vf_scale_yuv2yuv_mlu.c      |  436 ++++++
 libavutil/Makefile                      |    3 +
 libavutil/hwcontext.c                   |    5 +
 libavutil/hwcontext.h                   |    1 +
 libavutil/hwcontext_internal.h          |    1 +
 libavutil/hwcontext_mlu.c               |  436 ++++++
 libavutil/hwcontext_mlu.h               |  170 +++
 libavutil/hwcontext_mlu_internal.h      |   86 ++
 libavutil/pixdesc.c                     |    5 +
 libavutil/pixfmt.h                      |    7 +
 44 files changed, 10514 insertions(+)
 create mode 100644 doc/examples/decode_mlu.c
 create mode 100644 doc/examples/encode_change_mlu.c
 create mode 100644 doc/examples/encode_mlu.c
 create mode 100644 doc/examples/hw_decode_mlu.c
 create mode 100644 doc/examples/hw_encode_change_mlu.c
 create mode 100644 doc/examples/hw_encode_mlu.c
 create mode 100644 fftools/ffmpeg_mlu.c
 create mode 100644 libavcodec/mlumpp_codec.h
 create mode 100755 libavcodec/mlumpp_dec.c
 create mode 100644 libavcodec/mlumpp_enc_h264.c
 create mode 100644 libavcodec/mlumpp_enc_hevc.c
 create mode 100644 libavcodec/mlumpp_enc_jpeg.c
 create mode 100644 libavcodec/mlumpp_vid_enc.c
 create mode 100644 libavcodec/mlumpp_vid_enc.h
 create mode 100644 libavfilter/mlu_filter_common.h
 create mode 100644 libavfilter/vf_cvt_rgbx2rgbx_mlu.c
 create mode 100644 libavfilter/vf_cvt_rgbx2yuv_mlu.c
 create mode 100644 libavfilter/vf_cvt_yuv2rgbx_mlu.c
 create mode 100644 libavfilter/vf_hwdownload_mlu.c
 create mode 100644 libavfilter/vf_hwupload_mlu.c
 create mode 100644 libavfilter/vf_overlay_mlu.c
 create mode 100644 libavfilter/vf_rotate_mlu.c
 create mode 100644 libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
 create mode 100644 libavfilter/vf_scale_rgbx2rgbx_mlu.c
 create mode 100644 libavfilter/vf_scale_yuv2yuv_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.c
 create mode 100644 libavutil/hwcontext_mlu.h
 create mode 100644 libavutil/hwcontext_mlu_internal.h

diff --git a/configure b/configure
index fb55e04ee7..791e63dd95 100755
--- a/configure
+++ b/configure
@@ -349,6 +349,9 @@ External library support:
   --disable-vaapi          disable Video Acceleration API (mainly Unix/Intel) code [autodetect]
   --disable-vdpau          disable Nvidia Video Decode and Presentation API for Unix code [autodetect]
   --disable-videotoolbox   disable VideoToolbox code [autodetect]
+  --enable-mlumpp          enable Cambricon MLU Media Process Platform code (mlumpp) [no]
+  --enable-mlufilter       enable Cambricon MLU Hardware filter code (mlufilter) [no]
+  --enable-mluaffinity     enable Cambricon MLU Hardware affinity code (mluaffinity) [no]
 
 Toolchain options:
   --arch=ARCH              select architecture [$arch]
@@ -1695,6 +1698,12 @@ EXAMPLE_LIST="
     transcoding_example
     vaapi_encode_example
     vaapi_transcode_example
+    hw_decode_mlu_example
+    hw_encode_mlu_example
+    decode_mlu_example
+    encode_mlu_example
+    encode_change_mlu_example
+    hw_encode_change_mlu_example
 "
 
 EXTERNAL_AUTODETECT_LIBRARY_LIST="
@@ -1748,6 +1757,10 @@ EXTERNAL_LIBRARY_VERSION3_LIST="
     libvo_amrwbenc
     mbedtls
     rkmpp
+    mlu
+    mlumpp
+    mlufilter
+    mluaffinity
 "
 
 EXTERNAL_LIBRARY_GPLV3_LIST="
@@ -3062,6 +3075,17 @@ transpose_npp_filter_deps="ffnvcodec libnpp"
 overlay_cuda_filter_deps="ffnvcodec"
 overlay_cuda_filter_deps_any="cuda_nvcc cuda_llvm"
 
+hwdownload_mlu_filter_deps="mlu"
+hwupload_mlu_filter_deps="mlu"
+cvt_yuv2rgbx_mlu_filter_deps="mlufilter"
+cvt_rgbx2yuv_mlu_filter_deps="mlufilter"
+cvt_rgbx2rgbx_mlu_filter_deps="mlufilter"
+scale_yuv2yuv_mlu_filter_deps="mlufilter"
+scale_rgbx2rgbx_mlu_filter_deps="mlufilter"
+scale_cvt_yuv2rgbx_mlu_filter_deps="mlufilter"
+overlay_mlu_filter_deps="mlufilter"
+rotate_mlu_filter_deps="mlufilter"
+
 amf_deps_any="libdl LoadLibrary"
 nvenc_deps="ffnvcodec"
 nvenc_deps_any="libdl LoadLibrary"
@@ -3091,6 +3115,9 @@ h264_vaapi_encoder_select="cbs_h264 vaapi_encode"
 h264_v4l2m2m_decoder_deps="v4l2_m2m h264_v4l2_m2m"
 h264_v4l2m2m_decoder_select="h264_mp4toannexb_bsf"
 h264_v4l2m2m_encoder_deps="v4l2_m2m h264_v4l2_m2m"
+h264_mlumpp_decoder_deps="mlumpp"
+h264_mlumpp_decoder_select="h264_mp4toannexb_bsf"
+h264_mlumpp_encoder_deps="mlumpp"
 hevc_amf_encoder_deps="amf"
 hevc_cuvid_decoder_deps="cuvid"
 hevc_cuvid_decoder_select="hevc_mp4toannexb_bsf"
@@ -3108,12 +3135,17 @@ hevc_vaapi_encoder_select="cbs_h265 vaapi_encode"
 hevc_v4l2m2m_decoder_deps="v4l2_m2m hevc_v4l2_m2m"
 hevc_v4l2m2m_decoder_select="hevc_mp4toannexb_bsf"
 hevc_v4l2m2m_encoder_deps="v4l2_m2m hevc_v4l2_m2m"
+hevc_mlumpp_decoder_deps="mlumpp"
+hevc_mlumpp_decoder_select="hevc_mp4toannexb_bsf"
+hevc_mlumpp_encoder_deps="mlumpp"
 mjpeg_cuvid_decoder_deps="cuvid"
 mjpeg_qsv_decoder_select="qsvdec"
 mjpeg_qsv_encoder_deps="libmfx"
 mjpeg_qsv_encoder_select="qsvenc"
 mjpeg_vaapi_encoder_deps="VAEncPictureParameterBufferJPEG"
 mjpeg_vaapi_encoder_select="cbs_jpeg jpegtables vaapi_encode"
+mjpeg_mlumpp_decoder_deps="mlumpp"
+mjpeg_mlumpp_encoder_deps="mlumpp"
 mp3_mf_encoder_deps="mediafoundation"
 mpeg1_cuvid_decoder_deps="cuvid"
 mpeg1_v4l2m2m_decoder_deps="v4l2_m2m mpeg1_v4l2_m2m"
@@ -3148,6 +3180,7 @@ vp8_vaapi_encoder_deps="VAEncPictureParameterBufferVP8"
 vp8_vaapi_encoder_select="vaapi_encode"
 vp8_v4l2m2m_decoder_deps="v4l2_m2m vp8_v4l2_m2m"
 vp8_v4l2m2m_encoder_deps="v4l2_m2m vp8_v4l2_m2m"
+vp8_mlumpp_decoder_deps="mlumpp"
 vp9_cuvid_decoder_deps="cuvid"
 vp9_mediacodec_decoder_deps="mediacodec"
 vp9_qsv_decoder_select="qsvdec"
@@ -3157,8 +3190,11 @@ vp9_vaapi_encoder_select="vaapi_encode"
 vp9_qsv_encoder_deps="libmfx MFX_CODEC_VP9"
 vp9_qsv_encoder_select="qsvenc"
 vp9_v4l2m2m_decoder_deps="v4l2_m2m vp9_v4l2_m2m"
+vp9_mlumpp_decoder_deps="mlumpp"
 wmv3_crystalhd_decoder_select="crystalhd"
 av1_qsv_decoder_select="qsvdec"
+avs_mlumpp_decoder_deps="mlumpp"
+avs2_mlumpp_decoder_deps="mlumpp"
 
 # parsers
 aac_parser_select="adts_header"
@@ -6546,6 +6582,18 @@ enabled rkmpp             && { require_pkg_config rkmpp rockchip_mpp  rockchip/r
                              }
 enabled vapoursynth       && require_pkg_config vapoursynth "vapoursynth-script >= 42" VSScript.h vsscript_init
 
+if enabled mlu; then
+    require_headers "cnrt.h" || die "ERROR: cnrt header not found"
+fi
+if enabled mlumpp; then
+    require_headers  "cncodec_v3_dec.h cncodec_v3_enc.h cncodec_v3_common.h" || die "ERROR: cncodec_v3 headers not found"
+fi
+if enabled mlufilter; then
+    require_headers  "cncv.h" || die "ERROR: cncv header not found"
+fi
+if enabled mluaffinity; then
+    require_headers  "cndev.h" || die "ERROR: cndev header not found"
+fi
 
 if enabled gcrypt; then
     GCRYPT_CONFIG="${cross_prefix}libgcrypt-config"
diff --git a/doc/examples/Makefile b/doc/examples/Makefile
index 81bfd34d5d..4f3a281d26 100644
--- a/doc/examples/Makefile
+++ b/doc/examples/Makefile
@@ -21,6 +21,12 @@ EXAMPLES-$(CONFIG_TRANSCODE_AAC_EXAMPLE)     += transcode_aac
 EXAMPLES-$(CONFIG_TRANSCODING_EXAMPLE)       += transcoding
 EXAMPLES-$(CONFIG_VAAPI_ENCODE_EXAMPLE)      += vaapi_encode
 EXAMPLES-$(CONFIG_VAAPI_TRANSCODE_EXAMPLE)   += vaapi_transcode
+EXAMPLES-$(CONFIG_HW_DECODE_MLU_EXAMPLE)     += hw_decode_mlu
+EXAMPLES-$(CONFIG_HW_ENCODE_MLU_EXAMPLE)     += hw_encode_mlu
+EXAMPLES-$(CONFIG_DECODE_MLU_EXAMPLE)        += decode_mlu
+EXAMPLES-$(CONFIG_ENCODE_MLU_EXAMPLE)        += encode_mlu
+EXAMPLES-$(CONFIG_ENCODE_CHANGE_MLU_EXAMPLE) += encode_change_mlu
+EXAMPLES-$(CONFIG_HW_ENCODE_CHANGE_MLU_EXAMPLE) += hw_encode_change_mlu
 
 EXAMPLES       := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)$(EXESUF))
 EXAMPLES_G     := $(EXAMPLES-yes:%=doc/examples/%$(PROGSSUF)_g$(EXESUF))
diff --git a/doc/examples/decode_mlu.c b/doc/examples/decode_mlu.c
new file mode 100644
index 0000000000..233bb81daf
--- /dev/null
+++ b/doc/examples/decode_mlu.c
@@ -0,0 +1,213 @@
+/*
+ * MLU MPP Video Acceleration API decode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated decoding example.
+ *
+ * @example decode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated decoding with output
+ * frames from the video surfaces.
+ * Usage: decode_mlu input.mp4 output.yuv
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+
+static FILE *fp_yuv;
+static int video_stream_idx;
+static AVCodecContext  *g_dec_ctx;
+static AVFormatContext *g_ifmt_ctx;
+
+static int init_decode(const char *in_file, const char *out_file, int dev_id) {
+    int ret;
+    AVStream     *video    = NULL;
+    AVCodec      *p_codec  = NULL;
+    AVDictionary *options  = NULL;
+    AVDictionary *dec_opts = NULL;
+
+    if ((ret = avformat_network_init()) != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_network_init failed, ret(%d)\n", ret);
+        return ret;
+    }
+    if (!strncmp(in_file, "rtsp", 4) || !strncmp(in_file, "rtmp", 4)) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode rtsp/rtmp stream\n");
+        av_dict_set(&options, "buffer_size",    "1024000",  0);
+        av_dict_set(&options, "max_delay",      "500000",   0);
+        av_dict_set(&options, "stimeout",       "20000000", 0);
+        av_dict_set(&options, "rtsp_transport", "tcp",      0);
+    } else {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode local file stream\n");
+        av_dict_set(&options, "stimeout", "20000000", 0);
+        av_dict_set(&options, "vsync", "0",           0);
+    }
+
+    g_ifmt_ctx = avformat_alloc_context();
+    ret = avformat_open_input(&g_ifmt_ctx, in_file, NULL, &options);
+    av_dict_free(&options);
+    if (ret != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_open_input failed, ret(%d)\n",ret);
+        return ret;
+    }
+    ret = avformat_find_stream_info(g_ifmt_ctx, NULL);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "avformat_find_stream_info failed, ret(%d)\n", ret);
+        return ret;
+    }
+    for (size_t i = 0; i < g_ifmt_ctx->nb_streams; i++) {
+        if (g_ifmt_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            video = g_ifmt_ctx->streams[i];
+            video_stream_idx = i;
+            break;
+        }
+    }
+    if (NULL == video) {
+        av_log(g_dec_ctx, AV_LOG_ERROR, "video stream is NULL\n");
+        return -1;
+    }
+    switch(video->codecpar->codec_id) {
+    case AV_CODEC_ID_H264:
+        p_codec = avcodec_find_decoder_by_name("h264_mludec");     break;
+    case AV_CODEC_ID_HEVC:
+        p_codec = avcodec_find_decoder_by_name("hevc_mludec");     break;
+    case AV_CODEC_ID_VP8:
+        p_codec = avcodec_find_decoder_by_name("vp8_mludec");      break;
+    case AV_CODEC_ID_VP9:
+        p_codec = avcodec_find_decoder_by_name("vp9_mludec");      break;
+    case AV_CODEC_ID_MJPEG:
+        p_codec = avcodec_find_decoder_by_name("mjpeg_mludec");    break;
+    default:
+        p_codec = avcodec_find_decoder(video->codecpar->codec_id); break;
+    }
+    if(p_codec == NULL) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Unsupported codec! \n");
+        return -1;
+    }
+    g_dec_ctx = avcodec_alloc_context3(p_codec);
+    if(avcodec_parameters_to_context(g_dec_ctx, video->codecpar) != 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Could not copy codec context, ret(%d)\n", ret);
+        return -1;
+    }
+
+    av_dict_set_int(&dec_opts, "device_id", dev_id, 0);
+
+    if(avcodec_open2(g_dec_ctx, p_codec, &dec_opts) < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "Could not open codec, ret(%d)\n", ret);
+        return -1;
+    }
+    av_dict_free(&dec_opts);
+
+    fp_yuv = fopen(out_file, "wb+");
+
+    return 0;
+}
+
+static void  save_yuv_file(AVFrame *p_frame) {
+    fwrite(p_frame->data[0], 1, p_frame->width * p_frame->height, fp_yuv);
+    fwrite(p_frame->data[1], 1, (p_frame->width * p_frame->height) / 2, fp_yuv);
+}
+
+static int decode(AVCodecContext *dec_ctx) {
+   int ret;
+    AVPacket packet;
+    AVFrame *p_frame;
+    av_init_packet(&packet);
+    p_frame = av_frame_alloc();
+    while(1) {
+        ret = av_read_frame(g_ifmt_ctx, &packet);
+        if (ret == AVERROR_EOF) {
+            // av_log(g_dec_ctx, AV_LOG_INFO, "av_read_frame got eof\n");
+        } else if (ret < 0) {
+            av_log(g_dec_ctx, AV_LOG_ERROR, "av_read_frame failed, ret(%d)\n", ret);
+            return ret;
+        }
+        if (packet.stream_index != video_stream_idx) {
+            av_packet_unref(&packet);
+            continue;
+        }
+        ret = avcodec_send_packet(dec_ctx, &packet);
+        if (ret < 0) {
+            av_log(dec_ctx, AV_LOG_ERROR,
+                "send pkt failed, ret(%d), %s, %d\n", ret, __FILE__, __LINE__);
+            return ret;
+        }
+        while (ret >= 0) {
+            ret = avcodec_receive_frame(dec_ctx, p_frame);
+            if (ret == AVERROR_EOF) {
+                // av_log(g_dec_ctx, AV_LOG_INFO, "dec receive eof\n");
+                av_frame_unref(p_frame);
+                return 0;
+            } else if (ret == 0) {
+                save_yuv_file(p_frame);
+                av_frame_unref(p_frame);
+            } else if (ret < 0 && ret != AVERROR(EAGAIN)) {
+                av_log(dec_ctx, AV_LOG_ERROR, "receive frame failed\n");
+                return ret;
+            }
+        }
+        av_packet_unref(&packet);
+    }
+
+    av_frame_free(&p_frame);
+
+    return 0;
+}
+
+int main (int argc, char **argv) {
+    int ret = -1;
+    int dev_id = 0;
+    const char *in_file, *out_file;
+
+    if (argc <= 2) {
+        av_log(g_dec_ctx, AV_LOG_WARNING,
+            "Usage: %s <in file> <out file> [option dev_id]\n", argv[0]);
+        return -1;
+    }
+    in_file  = argv[1];
+    out_file = argv[2];
+    if (argv[3]) {
+        dev_id = atoi(argv[3]);
+    }
+
+    ret = init_decode(in_file, out_file, dev_id);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "init decode failed \n");
+        return -1;
+    }
+
+    ret = decode(g_dec_ctx);
+    if (ret < 0) {
+        av_log(g_dec_ctx, AV_LOG_INFO, "decode failed\n");
+        return -1;
+    }
+
+    av_log(g_dec_ctx, AV_LOG_INFO, "decode_mlu test finish\n");
+    fclose(fp_yuv);
+    avformat_close_input(&g_ifmt_ctx);
+    avcodec_free_context(&g_dec_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/encode_change_mlu.c b/doc/examples/encode_change_mlu.c
new file mode 100644
index 0000000000..9afe53c1c5
--- /dev/null
+++ b/doc/examples/encode_change_mlu.c
@@ -0,0 +1,284 @@
+/*
+ * MLU MPP Video Acceleration API encode sample
+ * Copyright (C) [2024] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated encoding example.
+ *
+ * @example encode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated encoding.
+ * Usage: encode_mlu output.h264 h264
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+
+static FILE *fp_yuv;
+static AVCodecContext *g_enc_ctx;
+
+static int init_encode(const char *out_file,
+                       const char *codec_type,
+                       int in_w, int int_h, int dev_id) {
+    int ret;
+    AVCodec      *p_codec  = NULL;
+    AVDictionary *enc_opts = NULL;
+
+    if ((ret = avformat_network_init()) != 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avformat_network_init failed, ret(%d)\n", ret);
+        return ret;
+    }
+    if (!strcmp(codec_type, "h264")) {
+        p_codec = avcodec_find_encoder_by_name("h264_mluenc");
+    } else if (!strcmp(codec_type, "hevc")) {
+        p_codec = avcodec_find_encoder_by_name("hevc_mluenc");
+    } else if (!strcmp(codec_type, "mjpeg")) {
+        p_codec = avcodec_find_encoder_by_name("mjpeg_mluenc");
+    } else {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "unsupport mlu encoder\n");
+        return -1;
+    }
+    if(!p_codec) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "encoder find failed.\n");
+        return -1;
+    }
+
+    g_enc_ctx = avcodec_alloc_context3(p_codec);
+    if (!g_enc_ctx) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "could not allocate video codec context\n");
+        return -1;
+    }
+
+    g_enc_ctx->width     = in_w;
+    g_enc_ctx->height    = int_h;
+    g_enc_ctx->bit_rate  = 1000000;
+    g_enc_ctx->time_base = (AVRational) {1, 25};
+    g_enc_ctx->framerate = (AVRational) {25, 1};
+    // g_enc_ctx->gop_size = 10;
+    // g_enc_ctx->max_b_frames = 1;
+    g_enc_ctx->pix_fmt = AV_PIX_FMT_NV12;
+
+    av_dict_set_int(&enc_opts, "device_id", dev_id, 0);
+    av_dict_set_int(&enc_opts, "forced_idr", 1, 0);
+    av_dict_set_int(&enc_opts, "max_width", 1920, 0);
+    av_dict_set_int(&enc_opts, "max_height", 1080, 0);
+    // av_dict_set(&enc_opts, "rc", "cbr", 0);
+
+    // g_enc_ctx->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
+    g_enc_ctx->flags &= (~AV_CODEC_FLAG_GLOBAL_HEADER);
+
+    ret = avcodec_open2(g_enc_ctx, p_codec, &enc_opts);
+    if(ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avcodec open failed.\n");
+        return -1;
+    }
+    av_dict_free(&enc_opts);
+
+    fp_yuv = fopen(out_file, "wb");
+    if (!fp_yuv) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "Could not open %s\n", out_file);
+        return -1;
+    }
+
+    return 0;
+}
+
+static int make_frame_auto(AVCodecContext *enc_ctx, AVFrame *frame, int frame_id) {
+    int ret, x, y;
+    /* make sure the frame data is writable */
+    ret = av_frame_make_writable(frame);
+    if (ret < 0)
+        return -1;
+    /* prepare a dummy image, NV12 */
+    /* Y */
+    for (y = 0; y < enc_ctx->height; y++) {
+        for (x = 0; x < enc_ctx->width; x++) {
+            frame->data[0][y*frame->linesize[0]+x] = x + y + frame_id * 3;
+        }
+    }
+    /* Cb and Cr */
+    for (y = 0; y < enc_ctx->height / 2; y++) {
+        for (x = 0; x < enc_ctx->width; x+=2) {
+            frame->data[1][y*frame->linesize[1]+x]   = 128 + y + frame_id * 2;
+            frame->data[1][y*frame->linesize[1]+x+1] = 64  + x + frame_id * 5;
+        }
+    }
+
+    frame->pts = frame_id;
+    return 0;
+}
+
+static int encode_frame(AVCodecContext *enc_ctx, AVFrame *frame, AVPacket *pkt,
+                   FILE *outfile)
+{
+    int ret;
+    if (frame)
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Send frame %3"PRId64"\n", frame->pts);
+
+    ret = avcodec_send_frame(enc_ctx, frame);
+    if (ret < 0) {
+        av_log(enc_ctx, AV_LOG_ERROR,
+            "Error sending a frame for encoding\n");
+        return -1;
+    }
+
+    while (ret >= 0) {
+        ret = avcodec_receive_packet(enc_ctx, pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+            return 0;
+        else if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "Error during encoding\n");
+            return -1;
+        }
+
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Write packet %3"PRId64" (size=%5d)\n", pkt->pts, pkt->size);
+        fwrite(pkt->data, 1, pkt->size, outfile);
+        av_packet_unref(pkt);
+    }
+
+    return 0;
+}
+
+static int encode(AVCodecContext *enc_ctx, FILE *outfile, int frame_num) {
+    int ret, cnt = -1;
+    AVFrame *frame;
+    AVPacket *pkt;
+    uint8_t endcode[] = {0, 0, 1, 0xb7};
+
+    pkt = av_packet_alloc();
+    av_init_packet(pkt);
+
+    while (cnt++ < frame_num) {
+        frame = av_frame_alloc();
+        frame->width  = enc_ctx->width;
+        frame->height = enc_ctx->height;
+        frame->pict_type = cnt % 25 ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I;
+        if (cnt == 111) {
+            enc_ctx->bit_rate = 512 * 1024;
+            enc_ctx->framerate.num = 10;
+            enc_ctx->framerate.den = 1;
+            frame->pict_type = AV_PICTURE_TYPE_I;
+        }
+        if (cnt == 131) {
+            enc_ctx->bit_rate = 10 * 1024 * 1024;
+            enc_ctx->framerate.num = 20;
+            enc_ctx->framerate.den = 1;
+            frame->pict_type = AV_PICTURE_TYPE_I;
+        }
+        if (cnt >= 50) {
+            frame->width  = 1920;
+            frame->height = 1080;
+            enc_ctx->width = frame->width;
+            enc_ctx->height= frame->height;
+            enc_ctx->coded_width = frame->width;
+            enc_ctx->coded_height= frame->height;
+        }
+
+        frame->format = enc_ctx->pix_fmt;
+        ret = av_frame_get_buffer(frame, 0);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "Could not allocate the video frame data\n");
+            return -1;
+        }
+        ret = make_frame_auto(enc_ctx, frame, cnt);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "make frame auto failed, ret%d\n", ret);
+            return -1;
+        }
+        av_log(enc_ctx, AV_LOG_WARNING, "bit_rate:%ld, num:%d, den:%d\n",
+            enc_ctx->bit_rate, enc_ctx->framerate.num, enc_ctx->framerate.den);
+
+        ret = encode_frame(enc_ctx, frame, pkt, outfile);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "encode_frame failed, ret%d\n", ret);
+            return -1;
+        }
+        av_frame_free(&frame);
+    }
+
+    encode_frame(enc_ctx, NULL, pkt, outfile);
+    // add sequence end code to have a real MPEG file
+    fwrite(endcode, 1, sizeof(endcode), outfile);
+
+    av_packet_free(&pkt);
+
+    return 0;
+}
+
+int main (int argc, char **argv) {
+    int ret = -1;
+    int dev_id = 0, in_w, in_h, frame_num;
+    const char *out_file;
+    char codec_type[10] = "h264";
+    char *enc_type = NULL;
+
+    if (argc <= 1) {
+        av_log(g_enc_ctx, AV_LOG_WARNING,
+            "Usage: %s <out file> <dev_id> [option <enc_type>, h264 or hevc]\n",
+                argv[0]);
+        return -1;
+    }
+
+    out_file = argv[1];
+    if (argv[2]) dev_id = atoi(argv[2]);
+    else         dev_id = 0;
+    if (argv[3]) enc_type = argv[3];
+    else         enc_type = codec_type;
+
+    in_w      = 960;
+    in_h      = 540;
+    frame_num = 200;
+
+    ret = init_encode(out_file, enc_type, in_w, in_h, dev_id);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "init decode failed \n");
+        return -1;
+    }
+
+    ret = encode(g_enc_ctx, fp_yuv, frame_num);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "decode failed\n");
+        return -1;
+    }
+
+    av_log(g_enc_ctx, AV_LOG_INFO,
+        "\n enc type:%s w:%d, h:%d, dev id:%d, frame num:%d\n",
+        enc_type, in_w, in_h, dev_id, frame_num);
+    av_log(g_enc_ctx, AV_LOG_INFO, "encode_mlu test finish\n");
+    fclose(fp_yuv);
+    avcodec_free_context(&g_enc_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/encode_mlu.c b/doc/examples/encode_mlu.c
new file mode 100644
index 0000000000..611d5165b0
--- /dev/null
+++ b/doc/examples/encode_mlu.c
@@ -0,0 +1,252 @@
+/*
+ * MLU MPP Video Acceleration API encode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated encoding example.
+ *
+ * @example encode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated encoding.
+ * Usage: encode_mlu output.h264 h264
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+
+static FILE *fp_yuv;
+static AVCodecContext *g_enc_ctx;
+
+static int init_encode(const char *out_file,
+                       const char *codec_type,
+                       int in_w, int int_h, int dev_id) {
+    int ret;
+    AVCodec      *p_codec  = NULL;
+    AVDictionary *enc_opts = NULL;
+
+    if ((ret = avformat_network_init()) != 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avformat_network_init failed, ret(%d)\n", ret);
+        return ret;
+    }
+    if (!strcmp(codec_type, "h264")) {
+        p_codec = avcodec_find_encoder_by_name("h264_mluenc");
+    } else if (!strcmp(codec_type, "hevc")) {
+        p_codec = avcodec_find_encoder_by_name("hevc_mluenc");
+    } else if (!strcmp(codec_type, "mjpeg")) {
+        p_codec = avcodec_find_encoder_by_name("mjpeg_mluenc");
+    } else {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "unsupport mlu encoder\n");
+        return -1;
+    }
+    if(!p_codec) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "encoder find failed.\n");
+        return -1;
+    }
+
+    g_enc_ctx = avcodec_alloc_context3(p_codec);
+    if (!g_enc_ctx) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "could not allocate video codec context\n");
+        return -1;
+    }
+
+    g_enc_ctx->width     = in_w;
+    g_enc_ctx->height    = int_h;
+    g_enc_ctx->bit_rate  = 1000000;
+    g_enc_ctx->time_base = (AVRational) {1, 25};
+    g_enc_ctx->framerate = (AVRational) {25, 1};
+    // g_enc_ctx->gop_size = 10;
+    // g_enc_ctx->max_b_frames = 1;
+    g_enc_ctx->pix_fmt = AV_PIX_FMT_NV12;
+
+    av_dict_set_int(&enc_opts, "device_id", dev_id, 0);
+
+    ret = avcodec_open2(g_enc_ctx, p_codec, &enc_opts);
+    if(ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "avcodec open failed.\n");
+        return -1;
+    }
+    av_dict_free(&enc_opts);
+
+    fp_yuv = fopen(out_file, "wb");
+    if (!fp_yuv) {
+        av_log(g_enc_ctx, AV_LOG_ERROR,
+            "Could not open %s\n", out_file);
+        return -1;
+    }
+
+    return 0;
+}
+
+static int make_frame_auto(AVCodecContext *enc_ctx, AVFrame *frame, int frame_id) {
+    int ret, x, y;
+    /* make sure the frame data is writable */
+    ret = av_frame_make_writable(frame);
+    if (ret < 0)
+        return -1;
+    /* prepare a dummy image, NV12 */
+    /* Y */
+    for (y = 0; y < enc_ctx->height; y++) {
+        for (x = 0; x < enc_ctx->width; x++) {
+            frame->data[0][y*frame->linesize[0]+x] = x + y + frame_id * 3;
+        }
+    }
+    /* Cb and Cr */
+    for (y = 0; y < enc_ctx->height / 2; y++) {
+        for (x = 0; x < enc_ctx->width; x+=2) {
+            frame->data[1][y*frame->linesize[1]+x]   = 128 + y + frame_id * 2;
+            frame->data[1][y*frame->linesize[1]+x+1] = 64  + x + frame_id * 5;
+        }
+    }
+
+    frame->pts = frame_id;
+    return 0;
+}
+
+static int encode_frame(AVCodecContext *enc_ctx, AVFrame *frame, AVPacket *pkt,
+                   FILE *outfile)
+{
+    int ret;
+    if (frame)
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Send frame %3"PRId64"\n", frame->pts);
+
+    ret = avcodec_send_frame(enc_ctx, frame);
+    if (ret < 0) {
+        av_log(enc_ctx, AV_LOG_ERROR,
+            "Error sending a frame for encoding\n");
+        return -1;
+    }
+
+    while (ret >= 0) {
+        ret = avcodec_receive_packet(enc_ctx, pkt);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+            return 0;
+        else if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "Error during encoding\n");
+            return -1;
+        }
+
+        av_log(enc_ctx, AV_LOG_INFO,
+            "Write packet %3"PRId64" (size=%5d)\n", pkt->pts, pkt->size);
+        fwrite(pkt->data, 1, pkt->size, outfile);
+        av_packet_unref(pkt);
+    }
+
+    return 0;
+}
+
+static int encode(AVCodecContext *enc_ctx, FILE *outfile, int frame_num) {
+    int ret, cnt = -1;
+    AVFrame *frame;
+    AVPacket *pkt;
+    uint8_t endcode[] = {0, 0, 1, 0xb7};
+
+    pkt = av_packet_alloc();
+    av_init_packet(pkt);
+    frame = av_frame_alloc();
+    frame->width  = enc_ctx->width;
+    frame->height = enc_ctx->height;
+    frame->format = enc_ctx->pix_fmt;
+    ret = av_frame_get_buffer(frame, 0);
+    if (ret < 0) {
+        av_log(enc_ctx, AV_LOG_ERROR,
+            "Could not allocate the video frame data\n");
+        return -1;
+    }
+
+    while (cnt++ < frame_num) {
+        ret = make_frame_auto(enc_ctx, frame, cnt);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "make frame auto failed, ret%d\n", ret);
+            return -1;
+        }
+        ret = encode_frame(enc_ctx, frame, pkt, outfile);
+        if (ret < 0) {
+            av_log(enc_ctx, AV_LOG_ERROR,
+                "encode_frame failed, ret%d\n", ret);
+            return -1;
+        }
+    }
+
+    encode_frame(enc_ctx, NULL, pkt, outfile);
+    // add sequence end code to have a real MPEG file
+    fwrite(endcode, 1, sizeof(endcode), outfile);
+
+    av_frame_free(&frame);
+    av_packet_free(&pkt);
+
+    return 0;
+}
+
+int main (int argc, char **argv) {
+    int ret = -1;
+    int dev_id = 0, in_w, in_h, frame_num;
+    const char *out_file;
+    char codec_type[10] = "h264";
+    char *enc_type = NULL;
+
+    if (argc <= 1) {
+        av_log(g_enc_ctx, AV_LOG_WARNING,
+            "Usage: %s <out file> <dev_id> [option <enc_type>, h264 or hevc]\n",
+                argv[0]);
+        return -1;
+    }
+
+    out_file = argv[1];
+    if (argv[2]) dev_id = atoi(argv[2]);
+    else         dev_id = 0;
+    if (argv[3]) enc_type = argv[3];
+    else         enc_type = codec_type;
+
+    in_w      = 960;
+    in_h      = 540;
+    frame_num = 500;
+
+    ret = init_encode(out_file, enc_type, in_w, in_h, dev_id);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "init decode failed \n");
+        return -1;
+    }
+
+    ret = encode(g_enc_ctx, fp_yuv, frame_num);
+    if (ret < 0) {
+        av_log(g_enc_ctx, AV_LOG_ERROR, "decode failed\n");
+        return -1;
+    }
+
+    av_log(g_enc_ctx, AV_LOG_INFO,
+        "\n enc type:%s w:%d, h:%d, dev id:%d, frame num:%d\n",
+        enc_type, in_w, in_h, dev_id, frame_num);
+    av_log(g_enc_ctx, AV_LOG_INFO, "encode_mlu test finish\n");
+    fclose(fp_yuv);
+    avcodec_free_context(&g_enc_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/hw_decode_mlu.c b/doc/examples/hw_decode_mlu.c
new file mode 100644
index 0000000000..87f2cb78a7
--- /dev/null
+++ b/doc/examples/hw_decode_mlu.c
@@ -0,0 +1,270 @@
+/*
+ * MLU MPP Video Acceleration API (video decoding) decode sample
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated decoding example.
+ *
+ * @example hw_decode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated decoding with output
+ * frames from the HW video surfaces.
+ * Usage: hw_decode_mlu mlu input.mp4 output.yuv
+ */
+
+#include <stdio.h>
+#include <libavcodec/avcodec.h>
+#include <libavformat/avformat.h>
+#include <libavutil/pixdesc.h>
+#include <libavutil/hwcontext.h>
+#include <libavutil/opt.h>
+#include <libavutil/avassert.h>
+#include <libavutil/imgutils.h>
+
+static AVBufferRef *hw_device_ctx = NULL;
+static FILE *output_file          = NULL;
+static enum AVPixelFormat hw_pix_fmt;
+
+static int hw_decoder_init(
+    AVCodecContext *ctx, const enum AVHWDeviceType type, const char *dev_id) {
+    int err = 0;
+
+    if ((err = av_hwdevice_ctx_create(&hw_device_ctx, type,
+                                      dev_id, NULL, 0)) < 0) {
+        fprintf(stderr, "Failed to create specified HW device.\n");
+        return err;
+    }
+    ctx->hw_device_ctx = av_buffer_ref(hw_device_ctx);
+
+    return err;
+}
+
+static enum AVPixelFormat get_hw_format(AVCodecContext *ctx,
+                                        const enum AVPixelFormat *pix_fmts)
+{
+    const enum AVPixelFormat *p;
+
+    for (p = pix_fmts; *p != -1; p++) {
+        if (*p == hw_pix_fmt)
+            return *p;
+    }
+
+    fprintf(stderr, "Failed to get HW surface format.\n");
+    return AV_PIX_FMT_NONE;
+}
+
+static int decode_write(AVCodecContext *avctx, AVPacket *packet)
+{
+    AVFrame *frame     = NULL;
+    AVFrame *sw_frame  = NULL;
+    AVFrame *tmp_frame = NULL;
+    uint8_t *buffer    = NULL;
+    int size;
+    int ret = -1;
+
+    ret = avcodec_send_packet(avctx, packet);
+    if (ret < 0) {
+        fprintf(stderr, "Error during decoding\n");
+        return ret;
+    }
+
+    while (1) {
+        if (!(frame = av_frame_alloc()) || !(sw_frame = av_frame_alloc())) {
+            fprintf(stderr, "Can not alloc frame\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+
+        ret = avcodec_receive_frame(avctx, frame);
+        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
+            av_frame_free(&frame);
+            av_frame_free(&sw_frame);
+            return 0;
+        } else if (ret < 0) {
+            fprintf(stderr, "Error while decoding\n");
+            goto fail;
+        }
+
+        if (frame->format == hw_pix_fmt) {
+            if ((ret = av_hwframe_transfer_data(sw_frame, frame, 0)) < 0) {
+                fprintf(stderr, "Error transferring the data to system memory\n");
+                goto fail;
+            }
+            tmp_frame = sw_frame;
+        } else
+            tmp_frame = frame;
+
+        size = av_image_get_buffer_size(tmp_frame->format, tmp_frame->width,
+                                        tmp_frame->height, 1);
+        buffer = av_malloc(size);
+        if (!buffer) {
+            fprintf(stderr, "Can not alloc buffer\n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        ret = av_image_copy_to_buffer(buffer, size,
+                                      (const uint8_t * const *)tmp_frame->data,
+                                      (const int *)tmp_frame->linesize, tmp_frame->format,
+                                      tmp_frame->width, tmp_frame->height, 1);
+        if (ret < 0) {
+            fprintf(stderr, "Can not copy image to buffer\n");
+            goto fail;
+        }
+
+        if ((ret = fwrite(buffer, 1, size, output_file)) < 0) {
+            fprintf(stderr, "Failed to dump raw data.\n");
+            goto fail;
+        }
+
+    fail:
+        av_frame_free(&frame);
+        av_frame_free(&sw_frame);
+        av_freep(&buffer);
+        if (ret < 0)
+            return ret;
+    }
+    return 0;
+}
+
+int main(int argc, char *argv[])
+{
+    AVFormatContext *input_ctx = NULL;
+    AVStream        *video     = NULL;
+    AVCodecContext *decode_ctx = NULL;
+    AVCodec       *decoder     = NULL;
+    AVDictionary  *dec_opts    = NULL;
+
+    AVPacket packet;
+    enum AVHWDeviceType type;
+    int i, video_stream, ret;
+    const char *dev_type, *dev_id;
+    const char *in_file, *out_file;
+
+    if (argc < 2) {
+        fprintf(stderr,
+            "Usage:%s <input file> <output file> <dev id>\n", argv[0]);
+        return -1;
+    }
+
+    dev_type = "mlu";
+    in_file  = argv[1];
+    out_file = argv[2];
+    dev_id   = argv[3];
+
+    type = av_hwdevice_find_type_by_name(dev_type);
+    if (type == AV_HWDEVICE_TYPE_NONE) {
+        fprintf(stderr, "Device type %s is not supported.\n", dev_type);
+        fprintf(stderr, "Available device types:");
+        while((type = av_hwdevice_iterate_types(type)) != AV_HWDEVICE_TYPE_NONE)
+            fprintf(stderr, " %s", av_hwdevice_get_type_name(type));
+        fprintf(stderr, "\n");
+        return -1;
+    }
+
+    if (avformat_open_input(&input_ctx,in_file, NULL, NULL) != 0) {
+        fprintf(stderr, "Cannot open input file '%s'\n", in_file);
+        return -1;
+    }
+
+    if (avformat_find_stream_info(input_ctx, NULL) < 0) {
+        fprintf(stderr, "Cannot find input stream information.\n");
+        return -1;
+    }
+
+    decoder = avcodec_find_decoder_by_name("h264_mludec");
+    if (!decoder) {
+        fprintf(stderr, "The MLU decoder is not present in libavcodec\n");
+        return -1;
+    }
+
+    for (size_t i = 0; i < input_ctx->nb_streams; i++) {
+        if (input_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
+            video_stream = i;
+        }
+    }
+
+    for (i = 0;; i++) {
+        const AVCodecHWConfig *config = avcodec_get_hw_config(decoder, i);
+        if (!config) {
+            fprintf(stderr, "Decoder %s does not support device type %s.\n",
+                    decoder->name, av_hwdevice_get_type_name(type));
+            return -1;
+        }
+        if (config->methods & AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &&
+            config->device_type == type) {
+            hw_pix_fmt = config->pix_fmt;
+            break;
+        }
+    }
+
+    if (!(decode_ctx = avcodec_alloc_context3(decoder)))
+        return AVERROR(ENOMEM);
+
+    video = input_ctx->streams[video_stream];
+    if (avcodec_parameters_to_context(decode_ctx, video->codecpar) < 0)
+        return -1;
+
+    decode_ctx->get_format  = get_hw_format;
+
+    if (hw_decoder_init(decode_ctx, type, dev_id) < 0)
+        return -1;
+
+    av_dict_set(&dec_opts, "device_id", dev_id, 0);
+    if ((ret = avcodec_open2(decode_ctx, decoder, &dec_opts)) < 0) {
+        fprintf(stderr, "Failed to open codec for stream #%d\n", video_stream);
+        return -1;
+    }
+    av_dict_free(&dec_opts);
+
+    /* open the file to dump raw data */
+    output_file = fopen(out_file, "w+");
+
+    while (ret >= 0) {
+        if ((ret = av_read_frame(input_ctx, &packet)) < 0)
+            break;
+
+        if (video_stream != packet.stream_index) {
+            continue;
+        }
+        ret = decode_write(decode_ctx, &packet);
+        if (ret)
+            break;
+
+        av_packet_unref(&packet);
+    }
+
+    /* flush the decoder */
+    packet.data = NULL;
+    packet.size = 0;
+    ret = decode_write(decode_ctx, &packet);
+    av_packet_unref(&packet);
+
+    if (output_file) {
+        fclose(output_file);
+    }
+    av_log(decode_ctx, AV_LOG_INFO, "decode_mlu test finish\n");
+    avcodec_free_context(&decode_ctx);
+    avformat_close_input(&input_ctx);
+    av_buffer_unref(&hw_device_ctx);
+
+    return 0;
+}
diff --git a/doc/examples/hw_encode_change_mlu.c b/doc/examples/hw_encode_change_mlu.c
new file mode 100644
index 0000000000..c484838d7d
--- /dev/null
+++ b/doc/examples/hw_encode_change_mlu.c
@@ -0,0 +1,286 @@
+/*
+ * MLU MPP Video Acceleration API (video encoding) encode sample
+ * Copyright (C) [2024] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated eccoding example.
+ *
+ * @example hw_encode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated encoding.
+ * Usage: hw_encode_mlu width height input.yuv output.h264
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <errno.h>
+
+#include <libavutil/pixfmt.h>
+#include <libavutil/pixdesc.h>
+#include <libavutil/hwcontext.h>
+#include <libavutil/log.h>
+#include <libavutil/error.h>
+#include <libavcodec/avcodec.h>
+
+static int set_hwframe_ctx(AVCodecContext *ctx, AVBufferRef *hw_device_ctx)
+{
+    AVBufferRef *hw_frames_ref;
+    AVHWFramesContext *frames_ctx = NULL;
+    int ret = 0;
+    if (ctx->hw_frames_ctx) {
+        av_buffer_unref(&ctx->hw_frames_ctx);
+        ctx->hw_frames_ctx = NULL;
+    }
+
+    if (!(hw_frames_ref = av_hwframe_ctx_alloc(hw_device_ctx))) {
+        av_log(ctx, AV_LOG_ERROR, "create MLU hwframe context failed\n");
+        return -1;
+    }
+    frames_ctx = (AVHWFramesContext *)(hw_frames_ref->data);
+    frames_ctx->format    = AV_PIX_FMT_MLU;
+    frames_ctx->sw_format = AV_PIX_FMT_NV12;
+    frames_ctx->width     = ctx->width;
+    frames_ctx->height    = ctx->height;
+    frames_ctx->initial_pool_size = 5;
+    if ((ret = av_hwframe_ctx_init(hw_frames_ref)) < 0) {
+        av_log(ctx, AV_LOG_ERROR,
+            "initialize MLU hwframe context failed, err: %s\n",av_err2str(ret));
+        av_buffer_unref(&hw_frames_ref);
+        return ret;
+    }
+    ctx->hw_frames_ctx = av_buffer_ref(hw_frames_ref);
+    if (!ctx->hw_frames_ctx) {
+        ret = AVERROR(ENOMEM);
+    }
+
+    av_buffer_unref(&hw_frames_ref);
+    return ret;
+}
+
+static int encode_write(AVCodecContext *ctx, AVFrame *frame, FILE *fp_out)
+{
+    int ret = 0;
+    AVPacket enc_pkt;
+
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+
+    if ((ret = avcodec_send_frame(ctx, frame)) < 0) {
+        av_log(ctx, AV_LOG_ERROR,
+            "avcodec_send_frame failed, error: %s\n", av_err2str(ret));
+        goto end;
+    }
+
+    while (1) {
+        ret = avcodec_receive_packet(ctx, &enc_pkt);
+        if (ret) {
+            break;
+        }
+
+        av_log(ctx, AV_LOG_INFO, "avcodec_receive_packet ok, dts:%ld, pts:%ld\n",
+            enc_pkt.pts, enc_pkt.dts);
+        enc_pkt.stream_index = 0;
+        ret = fwrite(enc_pkt.data, enc_pkt.size, 1, fp_out);
+        av_packet_unref(&enc_pkt);
+        fflush(fp_out);
+    }
+
+end:
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : -1);
+    return ret;
+}
+
+#define FRAME_RATE 30
+#define TANSFER_POSITION 200
+
+int main(int argc, char *argv[])
+{
+    int size = 0, ret = 0;
+    int src_w = 0, src_h = 0;
+    int dst_w = 0, dst_h = 0;
+    int max_w = 0, max_h = 0;
+    int real_w = 0, real_h = 0;
+    int frame_cnt = -1;
+    FILE *fp_in = NULL, *fp_out = NULL;
+    AVCodec *codec = NULL;
+    AVFrame *sw_frame = NULL, *hw_frame = NULL;
+    AVCodecContext *avctx = NULL;
+    AVBufferRef *hw_device_ctx = NULL;
+
+    const char *enc_name = "h264_mluenc";
+    // av_log_set_level(AV_LOG_INFO);
+
+    if (argc < 5) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Usage: %s <w0> <h0> <w1> <h1> <in file> <out file>\n", argv[0]);
+        return -1;
+    }
+
+    src_w = atoi(argv[1]);
+    src_h = atoi(argv[2]);
+    dst_w = atoi(argv[3]);
+    dst_h = atoi(argv[4]);
+    if (!(fp_in = fopen(argv[5], "r"))) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open input file(%s) failed, error:%s\n", argv[5], strerror(errno));
+        return -1;
+    }
+    if (!(fp_out = fopen(argv[6], "w+b"))) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open output file(%s) failed, error:%s\n", argv[6], strerror(errno));
+        ret = -1;
+        goto close;
+    }
+
+    ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_MLU, "0", NULL, 0);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "create a MLU device failed, error: %s\n", av_err2str(ret));
+        goto close;
+    }
+    if (!(codec = avcodec_find_encoder_by_name(enc_name))) {
+        av_log(avctx, AV_LOG_ERROR, "find encoder(%s) failed\n", enc_name);
+        ret = -1;
+        goto close;
+    }
+
+    if (!(avctx = avcodec_alloc_context3(codec))) {
+        ret = AVERROR(ENOMEM);
+        goto close;
+    }
+
+    avctx->width     = src_w;
+    avctx->height    = src_h;
+    avctx->time_base = (AVRational){1, 25};
+    avctx->framerate = (AVRational){25, 1};
+    avctx->sample_aspect_ratio = (AVRational){1, 1};
+    avctx->pix_fmt   = AV_PIX_FMT_MLU;
+    /* set hw_frames_ctx for encoder's AVCodecContext */
+    if ((ret = set_hwframe_ctx(avctx, hw_device_ctx)) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "set hwframe context failed.\n");
+        goto close;
+    }
+
+    AVDictionary *enc_opts = NULL;
+    // av_dict_set_int(&enc_opts, "forced_idr", 1, 0);
+    av_dict_set_int(&enc_opts, "max_width",  FFMAX(src_w, dst_w), 0);
+    av_dict_set_int(&enc_opts, "max_height", FFMAX(src_h, dst_h), 0);
+    if ((ret = avcodec_open2(avctx, codec, &enc_opts)) < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open video encoder failed, error: %s\n", av_err2str(ret));
+        goto close;
+    }
+    av_dict_free(&enc_opts);
+
+    real_w = src_w;
+    real_h = src_h;
+    while (1) {
+        if (!(sw_frame = av_frame_alloc())) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+        sw_frame->format = AV_PIX_FMT_NV12;
+        sw_frame->pts    = frame_cnt++;
+        sw_frame->pkt_dts= sw_frame->pkt_dts;
+        /* change resolution src_w x src_h --> dst_w x dst_h */
+        if (sw_frame->pts == TANSFER_POSITION) {
+            real_w = dst_w;
+            real_h = dst_h;
+            avctx->width  = real_w;
+            avctx->height = real_h;
+            if ((ret = set_hwframe_ctx(avctx, hw_device_ctx)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "set hwframe context failed.\n");
+                goto close;
+            }
+        }
+
+        sw_frame->width  = real_w;
+        sw_frame->height = real_h;
+        if ((ret = av_frame_get_buffer(sw_frame, 32)) < 0)
+            goto close;
+
+        size = real_w * real_h;
+        if ((ret = fread((uint8_t*)(sw_frame->data[0]), size, 1, fp_in)) <= 0)
+            break;
+        if ((ret = fread((uint8_t*)(sw_frame->data[1]), size / 2, 1, fp_in)) <= 0)
+            break;
+
+
+        if (!(hw_frame = av_frame_alloc())) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+        if ((ret = av_hwframe_get_buffer(avctx->hw_frames_ctx, hw_frame, 0)) < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                "get hwframe buffer failed, error: %s.\n", av_err2str(ret));
+            goto close;
+        }
+        if (!hw_frame->hw_frames_ctx) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+
+        hw_frame->pts     = sw_frame->pts;
+        hw_frame->pkt_dts = sw_frame->pkt_dts;
+        hw_frame->pict_type = frame_cnt % FRAME_RATE ? AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_I;
+        if ((ret = av_hwframe_transfer_data(hw_frame, sw_frame, 0)) < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                "transfer swframe to hwframe failed, error:%s.\n", av_err2str(ret));
+            goto close;
+        }
+
+        if ((ret = (encode_write(avctx, hw_frame, fp_out))) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "encode write failed.\n");
+            goto close;
+        }
+        av_frame_free(&hw_frame);
+        av_frame_free(&sw_frame);
+    }
+
+    /* flush encoder */
+    ret = encode_write(avctx, NULL, fp_out);
+    if (ret == AVERROR_EOF) {
+        ret = 0;
+    }
+
+close:
+    if (fp_in) {
+        fclose(fp_in);
+    }
+    if (fp_out) {
+        fclose(fp_out);
+    }
+    if (sw_frame) {
+        av_frame_free(&sw_frame);
+    }
+    if (hw_frame) {
+        av_frame_free(&hw_frame);
+    }
+    if (hw_device_ctx) {
+        av_buffer_unref(&hw_device_ctx);
+    }
+    if (avctx) {
+        avcodec_free_context(&avctx);
+    }
+    return ret;
+}
diff --git a/doc/examples/hw_encode_mlu.c b/doc/examples/hw_encode_mlu.c
new file mode 100644
index 0000000000..3593a7e859
--- /dev/null
+++ b/doc/examples/hw_encode_mlu.c
@@ -0,0 +1,257 @@
+/*
+ * MLU MPP Video Acceleration API (video encoding) encode sample
+ * Copyright (C) [2024] by Cambricon, Inc. All rights reserved
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * Cambricon MLUMPP-HW-Accelerated eccoding example.
+ *
+ * @example hw_encode_mlu.c
+ * This example shows how to do mlumpp-HW-accelerated encoding.
+ * Usage: hw_encode_mlu width height input.yuv output.h264
+ */
+
+#include <stdio.h>
+#include <string.h>
+#include <errno.h>
+
+#include <libavutil/pixfmt.h>
+#include <libavutil/pixdesc.h>
+#include <libavutil/hwcontext.h>
+#include <libavutil/log.h>
+#include <libavutil/error.h>
+#include <libavcodec/avcodec.h>
+
+static int set_hwframe_ctx(AVCodecContext *ctx, AVBufferRef *hw_device_ctx)
+{
+    AVBufferRef *hw_frames_ref;
+    AVHWFramesContext *frames_ctx = NULL;
+    int ret = 0;
+
+    if (!(hw_frames_ref = av_hwframe_ctx_alloc(hw_device_ctx))) {
+        av_log(ctx, AV_LOG_ERROR, "create MLU hwframe context failed\n");
+        return -1;
+    }
+    frames_ctx = (AVHWFramesContext *)(hw_frames_ref->data);
+    frames_ctx->format    = AV_PIX_FMT_MLU;
+    frames_ctx->sw_format = AV_PIX_FMT_NV12;
+    frames_ctx->width     = ctx->width;
+    frames_ctx->height    = ctx->height;
+    frames_ctx->initial_pool_size = 5;
+    if ((ret = av_hwframe_ctx_init(hw_frames_ref)) < 0) {
+        av_log(ctx, AV_LOG_ERROR,
+            "initialize MLU hwframe context failed, err: %s\n",av_err2str(ret));
+        av_buffer_unref(&hw_frames_ref);
+        return ret;
+    }
+    ctx->hw_frames_ctx = av_buffer_ref(hw_frames_ref);
+    if (!ctx->hw_frames_ctx) {
+        ret = AVERROR(ENOMEM);
+    }
+
+    av_buffer_unref(&hw_frames_ref);
+    return ret;
+}
+
+static int encode_write(AVCodecContext *ctx, AVFrame *frame, FILE *fp_out)
+{
+    int ret = 0;
+    AVPacket enc_pkt;
+
+    av_init_packet(&enc_pkt);
+    enc_pkt.data = NULL;
+    enc_pkt.size = 0;
+
+    if ((ret = avcodec_send_frame(ctx, frame)) < 0) {
+        av_log(ctx, AV_LOG_ERROR,
+            "avcodec_send_frame failed, error: %s\n", av_err2str(ret));
+        goto end;
+    }
+
+    while (1) {
+        ret = avcodec_receive_packet(ctx, &enc_pkt);
+        if (ret) {
+            break;
+        }
+
+        av_log(ctx, AV_LOG_INFO, "avcodec_receive_packet ok, dts:%ld, pts:%ld\n",
+            enc_pkt.pts, enc_pkt.dts);
+        enc_pkt.stream_index = 0;
+        ret = fwrite(enc_pkt.data, enc_pkt.size, 1, fp_out);
+        av_packet_unref(&enc_pkt);
+        fflush(fp_out);
+    }
+
+end:
+    ret = ((ret == AVERROR(EAGAIN)) ? 0 : -1);
+    return ret;
+}
+
+int main(int argc, char *argv[])
+{
+    int size = 0, ret = 0;
+    int width = 0, height = 0;
+    int frame_cnt = 0;
+    FILE *fp_in = NULL, *fp_out = NULL;
+    AVCodec *codec = NULL;
+    AVFrame *sw_frame = NULL, *hw_frame = NULL;
+    AVCodecContext *avctx = NULL;
+    AVBufferRef *hw_device_ctx = NULL;
+
+    const char *enc_name = "h264_mluenc";
+    // av_log_set_level(AV_LOG_INFO);
+
+    if (argc < 5) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Usage: %s <width> <height> <in file> <out file>\n", argv[0]);
+        return -1;
+    }
+
+    width  = atoi(argv[1]);
+    height = atoi(argv[2]);
+    size   = width * height;
+
+    if (!(fp_in = fopen(argv[3], "r"))) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open input file(%s) failed, error:%s\n", argv[3], strerror(errno));
+        return -1;
+    }
+    if (!(fp_out = fopen(argv[4], "w+b"))) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open output file(%s) failed, error:%s\n", argv[4], strerror(errno));
+        ret = -1;
+        goto close;
+    }
+
+    ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_MLU,
+                                 "0", NULL, 0);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "create a MLU device failed, error: %s\n", av_err2str(ret));
+        goto close;
+    }
+
+    if (!(codec = avcodec_find_encoder_by_name(enc_name))) {
+        av_log(avctx, AV_LOG_ERROR, "find encoder(%s) failed\n", enc_name);
+        ret = -1;
+        goto close;
+    }
+
+    if (!(avctx = avcodec_alloc_context3(codec))) {
+        ret = AVERROR(ENOMEM);
+        goto close;
+    }
+
+    avctx->width     = width;
+    avctx->height    = height;
+    avctx->time_base = (AVRational){1, 25};
+    avctx->framerate = (AVRational){25, 1};
+    avctx->sample_aspect_ratio = (AVRational){1, 1};
+    avctx->pix_fmt   = AV_PIX_FMT_MLU;
+
+    /* set hw_frames_ctx for encoder's AVCodecContext */
+    if ((ret = set_hwframe_ctx(avctx, hw_device_ctx)) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "set hwframe context failed.\n");
+        goto close;
+    }
+
+    if ((ret = avcodec_open2(avctx, codec, NULL)) < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "open video encoder failed, error: %s\n", av_err2str(ret));
+        goto close;
+    }
+
+    while (1) {
+        if (!(sw_frame = av_frame_alloc())) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+        /* read data into software frame, and transfer them into hw frame */
+        sw_frame->width  = width;
+        sw_frame->height = height;
+        sw_frame->format = AV_PIX_FMT_NV12;
+        sw_frame->pts    = frame_cnt++;
+        sw_frame->pkt_dts= sw_frame->pkt_dts;
+        if ((ret = av_frame_get_buffer(sw_frame, 32)) < 0)
+            goto close;
+        if ((ret = fread((uint8_t*)(sw_frame->data[0]), size, 1, fp_in)) <= 0)
+            break;
+        if ((ret = fread((uint8_t*)(sw_frame->data[1]), size/2, 1, fp_in)) <= 0)
+            break;
+
+        if (!(hw_frame = av_frame_alloc())) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+        if ((ret = av_hwframe_get_buffer(avctx->hw_frames_ctx, hw_frame, 0)) < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                "get hwframe buffer failed, error: %s.\n", av_err2str(ret));
+            goto close;
+        }
+        if (!hw_frame->hw_frames_ctx) {
+            ret = AVERROR(ENOMEM);
+            goto close;
+        }
+
+        hw_frame->pts     = sw_frame->pts;
+        hw_frame->pkt_dts = sw_frame->pkt_dts;
+        if ((ret = av_hwframe_transfer_data(hw_frame, sw_frame, 0)) < 0) {
+            av_log(avctx, AV_LOG_ERROR,
+                "transfer swframe to hwframe failed, error:%s.\n", av_err2str(ret));
+            goto close;
+        }
+
+        if ((ret = (encode_write(avctx, hw_frame, fp_out))) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "encode write failed.\n");
+            goto close;
+        }
+        av_frame_free(&hw_frame);
+        av_frame_free(&sw_frame);
+    }
+
+    /* flush encoder */
+    ret = encode_write(avctx, NULL, fp_out);
+    if (ret == AVERROR_EOF) {
+        ret = 0;
+    }
+
+close:
+    if (fp_in) {
+        fclose(fp_in);
+    }
+    if (fp_out) {
+        fclose(fp_out);
+    }
+    if (sw_frame) {
+        av_frame_free(&sw_frame);
+    }
+    if (hw_frame) {
+        av_frame_free(&hw_frame);
+    }
+    if (hw_device_ctx) {
+        av_buffer_unref(&hw_device_ctx);
+    }
+    if (avctx) {
+        avcodec_free_context(&avctx);
+    }
+    return ret;
+}
diff --git a/fftools/Makefile b/fftools/Makefile
index 5affaa3f56..0eb7f25be7 100644
--- a/fftools/Makefile
+++ b/fftools/Makefile
@@ -11,6 +11,7 @@ ALLAVPROGS_G = $(AVBASENAMES:%=%$(PROGSSUF)_g$(EXESUF))
 
 OBJS-ffmpeg                        += fftools/ffmpeg_opt.o fftools/ffmpeg_filter.o fftools/ffmpeg_hw.o
 OBJS-ffmpeg-$(CONFIG_LIBMFX)       += fftools/ffmpeg_qsv.o
+OBJS-ffmpeg-$(CONFIG_MLU)          += fftools/ffmpeg_mlu.o
 ifndef CONFIG_VIDEOTOOLBOX
 OBJS-ffmpeg-$(CONFIG_VDA)          += fftools/ffmpeg_videotoolbox.o
 endif
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 606f2afe0c..dada67623d 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -61,6 +61,7 @@ enum HWAccelID {
     HWACCEL_GENERIC,
     HWACCEL_VIDEOTOOLBOX,
     HWACCEL_QSV,
+    HWACCEL_MLU,
 };
 
 typedef struct HWAccel {
@@ -668,6 +669,7 @@ int ffmpeg_parse_options(int argc, char **argv);
 
 int videotoolbox_init(AVCodecContext *s);
 int qsv_init(AVCodecContext *s);
+int mlu_init(AVCodecContext *s);
 
 HWDevice *hw_device_get_by_name(const char *name);
 int hw_device_init_from_string(const char *arg, HWDevice **dev);
diff --git a/fftools/ffmpeg_mlu.c b/fftools/ffmpeg_mlu.c
new file mode 100644
index 0000000000..e6958e25f4
--- /dev/null
+++ b/fftools/ffmpeg_mlu.c
@@ -0,0 +1,75 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/pixdesc.h"
+
+#include "ffmpeg.h"
+
+static void mlu_uninit(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    av_buffer_unref(&ist->hw_frames_ctx);
+}
+
+int mlu_init(AVCodecContext *avctx)
+{
+    InputStream *ist = avctx->opaque;
+    AVHWFramesContext *frames_ctx;
+    static AVBufferRef *hw_device_ctx;
+    int ret;
+
+    av_log(avctx, AV_LOG_VERBOSE, "Initializing mlu hwaccel\n");
+
+    if (!hw_device_ctx) {
+        ret = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_MLU,
+                                     ist->hwaccel_device, NULL, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Error creating a MLU device\n");
+            return ret;
+        }
+    }
+
+    av_buffer_unref(&ist->hw_frames_ctx);
+    ist->hw_frames_ctx = av_hwframe_ctx_alloc(hw_device_ctx);
+    if (!ist->hw_frames_ctx) {
+        av_log(avctx, AV_LOG_ERROR, "Error creating a MLU frames context\n");
+        return AVERROR(ENOMEM);
+    }
+
+    frames_ctx = (AVHWFramesContext*)ist->hw_frames_ctx->data;
+    frames_ctx->format    = AV_PIX_FMT_MLU;
+    frames_ctx->sw_format = avctx->sw_pix_fmt;
+    frames_ctx->width     = avctx->width;
+    // frames_ctx->height = avctx->height;
+    frames_ctx->height    = FFALIGN(avctx->height, 16);
+
+    av_log(avctx, AV_LOG_DEBUG, "Initializing MLU frames context: sw_format = %s, width = %d, height = %d\n",
+           av_get_pix_fmt_name(frames_ctx->sw_format), frames_ctx->width, frames_ctx->height);
+
+    ret = av_hwframe_ctx_init(ist->hw_frames_ctx);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Error initializing a MLU frame pool\n");
+        return ret;
+    }
+
+    ist->hwaccel_uninit = mlu_uninit;
+
+    return 0;
+}
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index 807e783422..e79bb59615 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -140,6 +140,10 @@ const HWAccel hwaccels[] = {
 #if CONFIG_LIBMFX
     { "qsv",   qsv_init,   HWACCEL_QSV,   AV_PIX_FMT_QSV },
 #endif
+#if CONFIG_MLU
+   { "mlu", mlu_init, HWACCEL_MLU, AV_PIX_FMT_MLU },
+#endif
+
     { 0 },
 };
 HWDevice *filter_hw_device;
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
index b3d284d7d0..e75960d7b3 100644
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -235,6 +235,7 @@ OBJS-$(CONFIG_AVRN_DECODER)            += avrndec.o
 OBJS-$(CONFIG_AVRP_DECODER)            += r210dec.o
 OBJS-$(CONFIG_AVRP_ENCODER)            += r210enc.o
 OBJS-$(CONFIG_AVS_DECODER)             += avs.o
+OBJS-$(CONFIG_AVS_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_AVUI_DECODER)            += avuidec.o
 OBJS-$(CONFIG_AVUI_ENCODER)            += avuienc.o
 OBJS-$(CONFIG_AYUV_DECODER)            += v408dec.o
@@ -254,6 +255,7 @@ OBJS-$(CONFIG_BRENDER_PIX_DECODER)     += brenderpix.o
 OBJS-$(CONFIG_C93_DECODER)             += c93.o
 OBJS-$(CONFIG_CAVS_DECODER)            += cavs.o cavsdec.o cavsdsp.o \
                                           cavsdata.o
+OBJS-$(CONFIG_AVS2_MLUMPP_DECODER)     += mlumpp_dec.o
 OBJS-$(CONFIG_CCAPTION_DECODER)        += ccaption_dec.o ass.o
 OBJS-$(CONFIG_CDGRAPHICS_DECODER)      += cdgraphics.o
 OBJS-$(CONFIG_CDTOONS_DECODER)         += cdtoons.o
@@ -385,6 +387,8 @@ OBJS-$(CONFIG_H264_VAAPI_ENCODER)      += vaapi_encode_h264.o h264_levels.o
 OBJS-$(CONFIG_H264_VIDEOTOOLBOX_ENCODER) += videotoolboxenc.o
 OBJS-$(CONFIG_H264_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_H264_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
+OBJS-$(CONFIG_H264_MLUMPP_DECODER)     += mlumpp_dec.o
+OBJS-$(CONFIG_H264_MLUMPP_ENCODER)    += mlumpp_vid_enc.o mlumpp_enc_h264.o
 OBJS-$(CONFIG_HAP_DECODER)             += hapdec.o hap.o
 OBJS-$(CONFIG_HAP_ENCODER)             += hapenc.o hap.o
 OBJS-$(CONFIG_HCA_DECODER)             += hcadec.o
@@ -405,6 +409,8 @@ OBJS-$(CONFIG_HEVC_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_HEVC_VAAPI_ENCODER)      += vaapi_encode_h265.o h265_profile_level.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_HEVC_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
+OBJS-$(CONFIG_HEVC_MLUMPP_DECODER)     += mlumpp_dec.o
+OBJS-$(CONFIG_HEVC_MLUMPP_ENCODER)     += mlumpp_vid_enc.o mlumpp_enc_hevc.o
 OBJS-$(CONFIG_HNM4_VIDEO_DECODER)      += hnm4video.o
 OBJS-$(CONFIG_HQ_HQA_DECODER)          += hq_hqa.o hq_hqadata.o hq_hqadsp.o \
                                           canopus.o
@@ -459,6 +465,8 @@ OBJS-$(CONFIG_MJPEGB_DECODER)          += mjpegbdec.o
 OBJS-$(CONFIG_MJPEG_CUVID_DECODER)     += cuviddec.o
 OBJS-$(CONFIG_MJPEG_QSV_ENCODER)       += qsvenc_jpeg.o
 OBJS-$(CONFIG_MJPEG_VAAPI_ENCODER)     += vaapi_encode_mjpeg.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_DECODER)    += mlumpp_dec.o
+OBJS-$(CONFIG_MJPEG_MLUMPP_ENCODER)    += mlumpp_vid_enc.o mlumpp_enc_jpeg.o
 OBJS-$(CONFIG_MLP_DECODER)             += mlpdec.o mlpdsp.o
 OBJS-$(CONFIG_MLP_ENCODER)             += mlpenc.o mlp.o
 OBJS-$(CONFIG_MMVIDEO_DECODER)         += mmvideo.o
@@ -720,6 +728,7 @@ OBJS-$(CONFIG_VP8_RKMPP_DECODER)       += rkmppdec.o
 OBJS-$(CONFIG_VP8_VAAPI_ENCODER)       += vaapi_encode_vp8.o
 OBJS-$(CONFIG_VP8_V4L2M2M_DECODER)     += v4l2_m2m_dec.o
 OBJS-$(CONFIG_VP8_V4L2M2M_ENCODER)     += v4l2_m2m_enc.o
+OBJS-$(CONFIG_VP8_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VP9_DECODER)             += vp9.o vp9data.o vp9dsp.o vp9lpf.o vp9recon.o \
                                           vp9block.o vp9prob.o vp9mvs.o vp56rac.o \
                                           vp9dsp_8bpp.o vp9dsp_10bpp.o vp9dsp_12bpp.o
@@ -728,6 +737,7 @@ OBJS-$(CONFIG_VP9_MEDIACODEC_DECODER)  += mediacodecdec.o
 OBJS-$(CONFIG_VP9_RKMPP_DECODER)       += rkmppdec.o
 OBJS-$(CONFIG_VP9_VAAPI_ENCODER)       += vaapi_encode_vp9.o
 OBJS-$(CONFIG_VP9_QSV_ENCODER)         += qsvenc_vp9.o
+OBJS-$(CONFIG_VP9_MLUMPP_DECODER)      += mlumpp_dec.o
 OBJS-$(CONFIG_VPLAYER_DECODER)         += textdec.o ass.o
 OBJS-$(CONFIG_VP9_V4L2M2M_DECODER)     += v4l2_m2m_dec.o
 OBJS-$(CONFIG_VQA_DECODER)             += vqavideo.o
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
index 2e9a3581de..3ea18eead6 100644
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -835,6 +835,16 @@ extern AVCodec ff_vp9_mediacodec_decoder;
 extern AVCodec ff_vp9_qsv_decoder;
 extern AVCodec ff_vp9_vaapi_encoder;
 extern AVCodec ff_vp9_qsv_encoder;
+extern AVCodec ff_h264_mlumpp_decoder;
+extern AVCodec ff_h264_mlumpp_encoder;
+extern AVCodec ff_hevc_mlumpp_decoder;
+extern AVCodec ff_hevc_mlumpp_encoder;
+extern AVCodec ff_mjpeg_mlumpp_encoder;
+extern AVCodec ff_mjpeg_mlumpp_decoder;
+extern AVCodec ff_vp8_mlumpp_decoder;
+extern AVCodec ff_vp9_mlumpp_decoder;
+extern AVCodec ff_avs2_mlumpp_decoder;
+extern AVCodec ff_avs_mlumpp_decoder;
 
 // The iterate API is not usable with ossfuzz due to the excessive size of binaries created
 #if CONFIG_OSSFUZZ
diff --git a/libavcodec/hwconfig.h b/libavcodec/hwconfig.h
index f421dc909f..9bc7e46a29 100644
--- a/libavcodec/hwconfig.h
+++ b/libavcodec/hwconfig.h
@@ -80,6 +80,8 @@ typedef struct AVCodecHWConfigInternal {
     HW_CONFIG_HWACCEL(0, 0, 1, D3D11VA_VLD,  NONE,         ff_ ## codec ## _d3d11va_hwaccel)
 #define HWACCEL_XVMC(codec) \
     HW_CONFIG_HWACCEL(0, 0, 1, XVMC,         NONE,         ff_ ## codec ## _xvmc_hwaccel)
+// #define HWACCEL_MLUDEC(codec) \
+//     HW_CONFIG_HWACCEL(1, 1, 0, MLU,          MLU,         ff_ ## codec ## _mludec_hwaccel)
 
 #define HW_CONFIG_ENCODER(device, frames, ad_hoc, format, device_type_) \
     &(const AVCodecHWConfigInternal) { \
diff --git a/libavcodec/mlumpp_codec.h b/libavcodec/mlumpp_codec.h
new file mode 100644
index 0000000000..7531aa17a6
--- /dev/null
+++ b/libavcodec/mlumpp_codec.h
@@ -0,0 +1,449 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef MLUMPP_CODEC_H
+#define MLUMPP_CODEC_H
+
+#include "libavutil/buffer.h"
+#include "libavutil/mathematics.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/fifo.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+#include "libavutil/time.h"
+#include "libavutil/common.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/thread.h"
+#include "libavutil/version.h"
+#include "config.h"
+#include "avcodec.h"
+#include "decode.h"
+#include "hwconfig.h"
+#include "internal.h"
+#include "libavutil/avutil.h"
+
+#include "cnrt.h"
+#include "cncodec_v3_common.h"
+#include "cncodec_v3_dec.h"
+#include "cncodec_v3_enc.h"
+
+#define FF_MLU_MAJOR_VERSION 4
+#define FF_MLU_MINOR_VERSION 1
+#define FF_MLU_PATCH_VERSION 1
+#define FF_MLU_VERSION  (FF_MLU_MAJOR_VERSION * 1000 + FF_MLU_MINOR_VERSION * 100 + FF_MLU_PATCH_VERSION)
+#define CNCODEC_VERSION (CNCODEC_MAJOR_VERSION* 1000 + CNCODEC_MINOR_VERSION* 100 + CNCODEC_PATCH_VERSION)
+
+#define cndec_version_info(void)                                              \
+    av_log(NULL, AV_LOG_DEBUG, "RELFLAG: 09252024\n");                        \
+    av_log(NULL, AV_LOG_DEBUG, "CNCODEC: %d.%d.%d \n",                        \
+        CNCODEC_MAJOR_VERSION, CNCODEC_MINOR_VERSION, CNCODEC_PATCH_VERSION); \
+    av_log(NULL, AV_LOG_INFO, "FFMPEG_MLU: %d.%d.%d \n",                      \
+        FF_MLU_MAJOR_VERSION, FF_MLU_MINOR_VERSION, FF_MLU_PATCH_VERSION);
+
+#define MLUMPP_CHECK(avctx, ret, err_msg) {                               \
+    int t_ret = ret;                                                      \
+    if (t_ret != 0) {                                                     \
+        av_log(avctx, AV_LOG_ERROR, "CNtoolkit Error, func:%s, line:%d\n",\
+            __func__, __LINE__);                                          \
+        return print_cncodec_error(avctx, t_ret, err_msg);                \
+    }                                                                     \
+}
+#define MLUMPP_CHECK_OPT(avctx, ret, err_msg, new_ret) {                  \
+    int t_ret = ret;                                                      \
+    if (t_ret != 0) {                                                     \
+        av_log(avctx, AV_LOG_ERROR, "%s, ret(%d), func%s, line:%d\n",     \
+            err_msg, t_ret, __func__, __LINE__);                          \
+        return new_ret;                                                   \
+    }                                                                     \
+}
+#define cncodec_get_plane_num(pix_fmt) cncodec_get_plane_num(pix_fmt)
+#define cncodec_get_plane_depth(pix_fmt, p_index, w_depth, h_depth) \
+            cncodec_get_plane_depth(pix_fmt, p_index, w_depth, h_depth)
+
+#define V_SCALE_MAX_W 8192
+#define V_SCALE_MAX_H 4320
+#define V_SCALE_MIN_W 48
+#define V_SCALE_MIN_H 48
+#define V_CROP_MAX_W  8192
+#define V_CROP_MAX_H  4320
+#define V_CROP_MIN_W  48
+#define V_CROP_MIN_H  48
+#define J_CROP_MAX_W  8192
+#define J_CROP_MAM_H  8192
+#define J_CROP_MIN_W  16
+#define J_CROP_MIN_H  16
+#define V_J_MIN_W  64
+#define V_J_MIN_H  64
+
+#define MAX_MLU_CNT 32
+#define CNENC_MIN_FPS 3
+#define CNENC_MAX_FPS 120
+#define CN_TIMEOUT_VALUE 3000
+#define CN_TIMEOUT_UNIT  1000
+#define TIMESTAMP_QUEUE_SIZE 100
+
+#define CN_CHECK_ODD(n)   (n & 1)
+#define CN_CHECK_EVEN(n) !(n & 1)
+
+enum mluType {
+    CN_365 = 0,
+    CN_370 = 1,
+    CN_NUM
+};
+
+static struct {
+    cncodecRetCode_t codecerr;
+    int         averr;
+    const char *desc;
+} cncodec_errors[] = {
+    { CNCODEC_SUCCESS,                  0,                          "cncodec success"                       },
+    { CNCODEC_ERROR_INVALID_VALUE,      AVERROR(EINVAL),            "cncodec invalid parameters"            },
+    { CNCODEC_ERROR_INVALID_MEMORY,     AVERROR(EINVAL),            "cncodec invalid memory"                },
+    { CNCODEC_ERROR_INVALID_HANDLE,     AVERROR(EINVAL),            "cncodec invalid codec handle"          },
+    { CNCODEC_ERROR_CREATE_FAILED,      AVERROR_EXTERNAL,           "cncodec create codec failed"           },
+    { CNCODEC_ERROR_TIMEOUT,            AVERROR_EXTERNAL,           "cncodec func call time-out"            },
+    { CNCODEC_ERROR_BUFFER_EMPTY,       AVERROR_EXTERNAL,           "cncodec no output buf available"       },
+    { CNCODEC_ERROR_TRANSMIT_FAILED,    AVERROR_EXTERNAL,           "cncodec transmit msg failed"           },
+    { CNCODEC_ERROR_OUT_OF_MEMORY,      AVERROR(ENOMEM),            "cncodec out of memory"                 },
+    { CNCODEC_ERROR_NOT_SUPPORTED,      AVERROR(EPERM),             "cncodec function not permitted"        },
+    { CNCODEC_ERROR_NOT_PERMITED,       AVERROR(EPERM),             "cncodec operation not permitted"       },
+    { CNCODEC_ERROR_BAD_STREAM,         AVERROR_INVALIDDATA,        "cncodec invalid input stream"          },
+    { CNCODEC_ERROR_BUFFER_OVERFLOW,    AVERROR_BUFFER_TOO_SMALL,   "cncodec output buf overflow"           },
+    { CNCODEC_ERROR_UNKNOWN,            AVERROR(INT_MAX),           "cncodec unknown error"                 },
+};
+
+static inline int cncodec_map_error(int32_t err, const char **desc) {
+    int i;
+    if (err > 632005 && err < 632048) {
+        *desc = "cn extra-lib error";
+        return AVERROR_EXTERNAL;
+    }
+    if (999991 == err) {
+        *desc = "cn extra-lib unknown error";
+        return AVERROR_EXTERNAL;
+    }
+    for (i = 0; i < FF_ARRAY_ELEMS(cncodec_errors); ++i) {
+        if (cncodec_errors[i].codecerr == err) {
+            if (desc)
+                *desc = cncodec_errors[i].desc;
+            return cncodec_errors[i].averr;
+        }
+    }
+    if (desc)
+        *desc = "unknown error";
+    return AVERROR_UNKNOWN;
+}
+
+static inline int print_cncodec_error(void* log_ctx, int32_t err, const char* err_msg) {
+    const char* desc;
+    int ret;
+    ret = cncodec_map_error(err, &desc);
+    av_log(log_ctx, AV_LOG_ERROR, "%s: %s (%d)\n", err_msg, desc, err);
+    return ret;
+}
+
+static inline cncodecPixelFormat_t cncodec_get_pixfmt_by_name(char *pixfmt)
+{
+    if (!strcmp("nv12", pixfmt) || !strcmp("NV12", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV12;
+    } else if (!strcmp("nv21", pixfmt) || !strcmp("NV21", pixfmt)) {
+        return CNCODEC_PIX_FMT_NV21;
+    } else if (!strcmp("yuv420p", pixfmt) || !strcmp("YUV420P", pixfmt)) {
+        return CNCODEC_PIX_FMT_I420;
+    } else if (!strcmp("p010", pixfmt)   || !strcmp("P010", pixfmt) ||
+               !strcmp("p010le", pixfmt) || !strcmp("P010LE", pixfmt) ||
+               !strcmp("p010be", pixfmt) || !strcmp("P010BE", pixfmt)) {
+        return CNCODEC_PIX_FMT_P010;
+    } else if (!strcmp("bgr24", pixfmt) || !strcmp("BGR24", pixfmt)) {
+        return CNCODEC_PIX_FMT_BGR888;
+    } else if (!strcmp("rgb24", pixfmt) || !strcmp("RGB24", pixfmt)) {
+        return CNCODEC_PIX_FMT_RGB888;
+    } else if (!strcmp("argb", pixfmt) || !strcmp("ARGB", pixfmt) ||
+        !strcmp("0rgb", pixfmt) || !strcmp("0RGB", pixfmt)) {
+        return CNCODEC_PIX_FMT_ARGB;
+    } else if (!strcmp("abgr", pixfmt) || !strcmp("ABGR", pixfmt) ||
+        !strcmp("0bgr", pixfmt) || !strcmp("0BGR", pixfmt)) {
+        return CNCODEC_PIX_FMT_ABGR;
+    } else if (!strcmp("bgra", pixfmt) || !strcmp("BGRA", pixfmt) ||
+        !strcmp("bgr0", pixfmt) || !strcmp("BGR0", pixfmt)) {
+        return CNCODEC_PIX_FMT_BGRA;
+    } else if (!strcmp("rgba", pixfmt) || !strcmp("RGBA", pixfmt) ||
+        !strcmp("rgb0", pixfmt) || !strcmp("RGB0", pixfmt)) {
+        return CNCODEC_PIX_FMT_RGBA;
+    } else if (!strcmp("gray", pixfmt) || !strcmp("GRAY", pixfmt)) {
+        return CNCODEC_PIX_FMT_MONOCHROME;
+    } else {
+        av_log(NULL, AV_LOG_ERROR,
+            "Unsupport pixfmt:%s, support nv12/nv21/yuv420p/p010/rgbx/gray at present\n",
+            pixfmt);
+        return -1;
+    }
+}
+
+static inline cncodecPixelFormat_t cncodec_get_cn_pixfmt_by_av_pixfmt(
+    enum AVPixelFormat pixfmt)
+{
+    switch (pixfmt) {
+    case AV_PIX_FMT_NV12:       return CNCODEC_PIX_FMT_NV12;
+    case AV_PIX_FMT_NV21:       return CNCODEC_PIX_FMT_NV21;
+    case AV_PIX_FMT_YUV420P:    return CNCODEC_PIX_FMT_I420;
+    case AV_PIX_FMT_YUVJ420P:   return CNCODEC_PIX_FMT_I420;
+    case AV_PIX_FMT_P010:       return CNCODEC_PIX_FMT_P010;
+    case AV_PIX_FMT_ABGR:       return CNCODEC_PIX_FMT_ABGR;
+    case AV_PIX_FMT_ARGB:       return CNCODEC_PIX_FMT_ARGB;
+    case AV_PIX_FMT_BGRA:       return CNCODEC_PIX_FMT_BGRA;
+    case AV_PIX_FMT_RGBA:       return CNCODEC_PIX_FMT_RGBA;
+    case AV_PIX_FMT_0BGR:       return CNCODEC_PIX_FMT_ABGR;
+    case AV_PIX_FMT_0RGB:       return CNCODEC_PIX_FMT_ARGB;
+    case AV_PIX_FMT_BGR0:       return CNCODEC_PIX_FMT_BGRA;
+    case AV_PIX_FMT_RGB0:       return CNCODEC_PIX_FMT_RGBA;
+    case AV_PIX_FMT_RGB24:      return CNCODEC_PIX_FMT_RGB888;
+    case AV_PIX_FMT_BGR24:      return CNCODEC_PIX_FMT_BGR888;
+    case AV_PIX_FMT_GRAY8:      return CNCODEC_PIX_FMT_MONOCHROME;
+    case AV_PIX_FMT_GRAY8A:     return CNCODEC_PIX_FMT_MONOCHROME;
+    default:                    return CNCODEC_PIX_FMT_NV12;
+    }
+}
+
+static inline enum AVPixelFormat cncodec_get_av_pixfmt_by_cn_pixfmt(
+    cncodecPixelFormat_t pixfmt)
+{
+    switch (pixfmt) {
+    case CNCODEC_PIX_FMT_NV12:  return AV_PIX_FMT_NV12;
+    case CNCODEC_PIX_FMT_NV21:  return AV_PIX_FMT_NV21;
+    case CNCODEC_PIX_FMT_I420:  return AV_PIX_FMT_YUV420P;
+    case CNCODEC_PIX_FMT_P010:  return AV_PIX_FMT_P010;
+    case CNCODEC_PIX_FMT_ABGR:  return AV_PIX_FMT_ABGR;
+    case CNCODEC_PIX_FMT_ARGB:  return AV_PIX_FMT_ARGB;
+    case CNCODEC_PIX_FMT_BGRA:  return AV_PIX_FMT_BGRA;
+    case CNCODEC_PIX_FMT_RGBA:  return AV_PIX_FMT_RGBA;
+    case CNCODEC_PIX_FMT_RGB888:return AV_PIX_FMT_RGB24;
+    case CNCODEC_PIX_FMT_BGR888:return AV_PIX_FMT_BGR24;
+    case CNCODEC_PIX_FMT_MONOCHROME:
+                                return AV_PIX_FMT_GRAY8;
+    default:                    return AV_PIX_FMT_NV12;
+    }
+}
+
+static inline cncodecType_t cncodec_get_cn_name_by_av_name(
+    enum AVCodecID avcodec_id)
+{
+    switch (avcodec_id) {
+    case AV_CODEC_ID_MJPEG: return CNCODEC_JPEG;
+    case AV_CODEC_ID_H264:  return CNCODEC_H264;
+    case AV_CODEC_ID_AVS:   return CNCODEC_AVS;
+    case AV_CODEC_ID_CAVS:  return CNCODEC_AVS;
+    case AV_CODEC_ID_AVS2:  return CNCODEC_AVS2;
+    case AV_CODEC_ID_HEVC:  return CNCODEC_HEVC;
+    case AV_CODEC_ID_VP8:   return CNCODEC_VP8;
+    case AV_CODEC_ID_VP9:   return CNCODEC_VP9;
+    default:
+        av_log(NULL, AV_LOG_WARNING, "unknown codec type(%d), default set h264\n",
+            avcodec_id);
+        return CNCODEC_H264;
+    }
+}
+
+static inline cncodecDecOutputOrder_t
+    cndec_get_output_order_by_name(char* output_order) {
+    if (!strcmp("display", output_order) || !strcmp("DISPLAY", output_order)) {
+        return CNCODEC_DEC_OUTPUT_ORDER_DISPLAY;
+    } else if (!strcmp("decode", output_order) || !strcmp("DECODE", output_order)) {
+        return CNCODEC_DEC_OUTPUT_ORDER_DECODE;
+    } else {
+        return CNCODEC_DEC_OUTPUT_ORDER_DISPLAY;
+    }
+}
+
+static inline int cndec_check_output_pixfmt(uint32_t out_fmt_mask,
+    cncodecPixelFormat_t cn_pixfmt) {
+    if (out_fmt_mask == 0) {
+        av_log(NULL, AV_LOG_ERROR,
+            "Cndec params invalid, got output pixfmt mask is 0\n");
+        return -1;
+    }
+    if (out_fmt_mask & (1 << cn_pixfmt)) {
+        av_log(NULL, AV_LOG_DEBUG, "Cndec output pixfmt idx is:%d\n", cn_pixfmt);
+        return 0;
+    }
+    return -1;
+}
+
+static inline int cnenc_check_input_pixfmt(uint32_t fmt_mask,
+    cncodecPixelFormat_t cn_pixfmt) {
+    if (fmt_mask == 0) {
+        av_log(NULL, AV_LOG_ERROR,
+            "Cnenc params invalid, got input pixfmt mask is 0\n");
+        return -1;
+    }
+    if (fmt_mask & (1 << cn_pixfmt)) {
+        av_log(NULL, AV_LOG_DEBUG, "Cnenc input pixfmt idx is:%d\n", cn_pixfmt);
+        return 0;
+    }
+    return -1;
+}
+
+static const struct {
+    cncodecPixelFormat_t pixel_format;
+    int sum_plane;
+    int plane_index;
+    float width_depth;
+    float height_depth;
+} fmt_num_depth_map[] = {
+    { CNCODEC_PIX_FMT_YUYV, 1, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_UYVY, 1, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_ARGB, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_ABGR, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_BGRA, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_RGBA, 1, 0, 4.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV12, 2, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV12, 2, 1, 1.0f, 0.5f  },
+    { CNCODEC_PIX_FMT_NV21, 2, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_NV21, 2, 1, 1.0f, 0.5f  },
+    { CNCODEC_PIX_FMT_P010, 2, 0, 2.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_P010, 2, 1, 2.0f, 0.5f  },
+    { CNCODEC_PIX_FMT_I420, 3, 0, 1.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_I420, 3, 1, 0.5f, 0.5f  },
+    { CNCODEC_PIX_FMT_I420, 3, 2, 0.5f, 0.5f  },
+    { CNCODEC_PIX_FMT_RGB888,1,0, 3.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_BGR888,1,0, 3.0f, 1.0f  },
+    { CNCODEC_PIX_FMT_MONOCHROME,1,0,1.0f,1.0f},
+};
+
+static inline int cncodec_get_plane_num(const cncodecPixelFormat_t pix_fmt) {
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(fmt_num_depth_map); ++i) {
+        if (fmt_num_depth_map[i].pixel_format == pix_fmt) {
+            return fmt_num_depth_map[i].sum_plane;
+        }
+    }
+    return -1;
+}
+
+static inline int cncodec_get_plane_depth(const cncodecPixelFormat_t pix_fmt,
+    const int p_index, float* w_depth, float* h_depth) {
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(fmt_num_depth_map); ++i) {
+        if (fmt_num_depth_map[i].pixel_format == pix_fmt &&
+            fmt_num_depth_map[i].plane_index == p_index) {
+            *w_depth = fmt_num_depth_map[i].width_depth;
+            *h_depth = fmt_num_depth_map[i].height_depth;
+            return 0;
+        }
+    }
+    return -1;
+}
+
+static inline enum AVPictureType cncodec_get_frame_type(const cncodecPicType_t pic_type) {
+    switch (pic_type) {
+    case CNCODEC_PIC_TYPE_P:       return AV_PICTURE_TYPE_P;
+    case CNCODEC_PIC_TYPE_B:       return AV_PICTURE_TYPE_B;
+    case CNCODEC_PIC_TYPE_I:       return AV_PICTURE_TYPE_I;
+    case CNCODEC_PIC_TYPE_IDR:     return AV_PICTURE_TYPE_I;
+#if CNCODEC_MAJOR_VERSION >= 1
+    case CNCODEC_PIC_TYPE_UNKNOWN: return AV_PICTURE_TYPE_NONE;
+#endif
+    default:                       return AV_PICTURE_TYPE_NONE;
+    }
+}
+
+static inline int cncodec_get_keyframe_flag(const cncodecPicType_t pic_type) {
+    if (pic_type == CNCODEC_PIC_TYPE_I || pic_type == CNCODEC_PIC_TYPE_IDR) {
+        return 1;
+    }
+    return 0;
+}
+
+#if CONFIG_MLUAFFINITY
+#ifndef mluDevCheckErrors
+#define __mluDevCheckErrors(ctx, err, file, line)                                    \
+    do {                                                                             \
+        mluDevRet_t _err = (err);                                                    \
+        if (0 != _err) {                                                             \
+            fprintf(stderr, "mluDevCheckErrors(%d): %s, from file <%s>, line %i.\n", \
+                _err, ctx->mluDevGetErrorString(_err), (char*)file, line);           \
+            exit(1);                                                                 \
+        }                                                                            \
+    } while (0)
+#define mluDevCheckErrors(ctx, err) __mluDevCheckErrors(ctx, (err), __FILE__, __LINE__)
+#endif
+#endif
+static inline int mlu_device_affinity(AVMLUDeviceContext *dev_ctx) {
+#if CONFIG_MLUAFFINITY
+    MluContext *mlu_ctx = dev_ctx->mlu_ctx;
+    int dev_hdl;
+    MLUMPP_CHECK_OPT(NULL, mlu_ctx->mluSetDevice(mlu_ctx->mlu_id),
+        "mluSetDevice failed", AVERROR(EINVAL));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevGetDeviceHandleByIndex(mlu_ctx->mlu_id, &dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevClearCurrentThreadAffinity(mlu_ctx->dev_version, dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevSetCurrentThreadAffinity(mlu_ctx->dev_version, dev_hdl));
+#endif
+
+    return 0;
+}
+
+static inline char *get_mlu_device_name(MluContext *mlu_ctx) {
+#if CNRT_MAJOR_VERSION < 5
+    return av_strdup(mlu_ctx->dev_info.device_name);
+#else
+    return av_strdup(mlu_ctx->dev_prop.name);
+#endif
+}
+
+static inline uint64_t cn_get_current_time(void) {
+    struct timeval tv;
+    gettimeofday(&tv, NULL);
+    return (uint64_t)tv.tv_sec * 1000 + (uint64_t)tv.tv_usec / 1000;
+}
+
+static inline void mlu_init_static(struct AVCodec *codec) {
+    int ret = 0;
+    int32_t hw_cnt = -1;
+    cncodecDecCaps_t dec_caps = {0};
+    const char* env_param = getenv("FF_MLU_PRELOAD_FIRMWARE");
+
+    cnrtGetDeviceCount(&hw_cnt);
+    if (hw_cnt > MAX_MLU_CNT || hw_cnt <= 0) {
+        av_log(NULL, AV_LOG_ERROR,
+            "Mlu get %s count error, cnt:%d\n", codec->name, hw_cnt);
+        return;
+    }
+    if (env_param != NULL) {
+        for (int n = 0; n < hw_cnt; n++) {
+            ret = cncodecDecGetCaps(CNCODEC_H264, n, &dec_caps);
+            if (ret != 0) {
+                av_log(NULL, AV_LOG_ERROR, "Cncodec register failed, hw(%d)\n", n);
+                return;
+            }
+        }
+    }
+}
+
+static inline int cncoedc_get_mlu_type(char* mlu_type) {
+    if (!strcmp("MLU365", mlu_type)) {
+        return CN_365;
+    } else if (!strcmp("MLU370", mlu_type)) {
+        return CN_370;
+    }
+    return CN_NUM;
+}
+
+#endif /* MLUMPP_CODEC_H */
diff --git a/libavcodec/mlumpp_dec.c b/libavcodec/mlumpp_dec.c
new file mode 100755
index 0000000000..6d3ee4e0ba
--- /dev/null
+++ b/libavcodec/mlumpp_dec.c
@@ -0,0 +1,1599 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include <stdint.h>
+#include <unistd.h>
+#include <time.h>
+#include <sys/time.h>
+#include <semaphore.h>
+#include <stdatomic.h>
+
+#include "h264_parse.h"
+#include "hevc_parse.h"
+#include "cncodec_v3_dec.h"
+#include "mlumpp_codec.h"
+
+#define VFRAME_STRIDE_ALIGN  1
+#define VFRAME_HEIGHT_ALIGN  16
+#define JFRAME_STRIDE_ALIGN  64
+#define JFRAME_HEIGHT_ALIGN  16
+
+typedef struct DecEventInfoMsg {
+    cncodecEventType_t event_type;
+    void *cnctx;
+    union {
+        cncodecFrame_t frame;
+        cncodecStream_t stream;
+    }event_output;
+} DecEventInfoMsg_t;
+
+typedef struct MLUMPPContext
+{
+    AVClass *avclass;
+    int device_id;
+    int instance_id;
+    int num_input_buffers;
+    int output_buf_num;
+    char *crop1_str;
+    char *crop2_str;
+    char *crop_str;
+    char *resize_str;
+    int trace_flag;
+    int cnrt_init_flag;
+    int async_queue_depth;
+    char *output_pixfmt;
+    char *output_order;
+    bool mem_async;
+    bool affinity_set;
+    struct {
+        int x;
+        int y;
+        int w;
+        int h;
+    } crop;
+    struct {
+        int width;
+        int height;
+    } resize;
+    int progressive;
+    float compress_scale;
+    void *handle;
+    unsigned char *seqhdr_data;
+    unsigned int  seqhdr_data_size;
+
+    AVBufferRef *hw_device_ref;
+    AVBufferRef *hw_frame_ref;
+    AVBufferRef *hw_resize_frame_ref;
+    AVMLUDeviceContext *hwdevice_ctx;
+    AVHWFramesContext  *hwframes_ctx;
+
+    sem_t eos_sema;
+    AVBSFContext *bsf;
+    AVCodecContext *avctx;
+    AVFifoBuffer *frame_queue;
+
+    MluContext *mlu_ctx;
+    cnrtQueue_t mlu_queue;
+
+    cncodecType_t codec_type;
+    cncodecDecCreateInfo_t create_info_;
+    cncodecDecParams_t codec_params_;
+    cncodecHandle_t codec_handle_;
+    cncodecJpegBackend_t image_dec_backend;
+    cncodecColorSpace_t color_space;
+
+    AVMutex queue_mutex;
+
+    int coded_width;
+    int coded_height;
+    int stride_align;
+    int max_width;
+    int max_height;
+    int first_max_width;
+    int first_max_height;
+    volatile int first_seq;
+    volatile int eos_received;
+    volatile int decoder_flushing;
+    volatile int codec_abort_flag;
+    volatile int decoder_init_flag;
+
+    // AVMutex count_mutex;
+    unsigned long long total_frame_count;
+    unsigned long long total_packet_count;
+    unsigned long long total_outframe_count;
+} MLUMPPContext_t;
+
+static int cndec_params_checking(AVCodecContext* avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    cncodecType_t codec_type;
+    cncodecDecCaps_t dec_caps;
+    int ret = 0;
+    codec_type = cncodec_get_cn_name_by_av_name(avctx->codec->id);
+    ret = cncodecDecGetCaps(codec_type, ctx->device_id, &dec_caps);
+    if (ret != 0 || !dec_caps.supported) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Cndec get caps failed, unsupport decode type:%s, ret(%d)\n",
+            avctx->codec->name, ret);
+        return -1;
+    }
+    if (AV_CODEC_ID_MJPEG == avctx->codec->id && ctx->image_dec_backend <= 1 &&
+       (strcmp("nv12", ctx->output_pixfmt) && strcmp("nv21", ctx->output_pixfmt))) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Jpg dec(backend=%d) only support nv12 and nv21 pixfmt\n",
+            ctx->image_dec_backend);
+        return -1;
+    }
+
+    ret = cndec_check_output_pixfmt(dec_caps.output_pixel_format_mask,
+          cncodec_get_pixfmt_by_name(ctx->output_pixfmt));
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "%s unsupport output pixfmt(%s)\n",
+            avctx->codec->name, ctx->output_pixfmt);
+        return -1;
+    }
+    if (ctx->resize_str) {
+        if (CN_CHECK_ODD(ctx->resize.width)||CN_CHECK_ODD(ctx->resize.height)) {
+            av_log(avctx, AV_LOG_ERROR, "Cndec scale w and h must be even\n");
+            return -1;
+        }
+        if (AV_CODEC_ID_MJPEG == avctx->codec->id) {
+            if ((ctx->resize.width != avctx->width / 2 &&
+                 ctx->resize.height!= avctx->height/ 2) ||
+                (ctx->resize.width != avctx->width / 4 &&
+                 ctx->resize.height != avctx->height/4) ||
+                (ctx->resize.width != avctx->width  / 8 &&
+                 ctx->resize.height != avctx->height/ 8)) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Jdec scale params invalid, only support 1/2,1/4,1/8 scale\n");
+                return -1;
+            }
+        } else {
+            if (ctx->resize.width < V_SCALE_MIN_W ||
+                ctx->resize.width > V_SCALE_MAX_W ||
+                ctx->resize.height< V_SCALE_MIN_H ||
+                ctx->resize.height> V_SCALE_MAX_H) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Vdec support scale range:48x48~8192x4320, now:%dx%d\n",
+                    ctx->resize.width, ctx->resize.height);
+                return -1;
+            }
+        }
+    }
+    if (ctx->crop_str) {
+        if (CN_CHECK_ODD(ctx->crop.x) || CN_CHECK_ODD(ctx->crop.y) ||
+            CN_CHECK_ODD(ctx->crop.w) || CN_CHECK_ODD(ctx->crop.h)) {
+            av_log(avctx, AV_LOG_ERROR, "Cndec crop x/y/w/h must be even\n");
+            return -1;
+        }
+        if (AV_CODEC_ID_MJPEG == avctx->codec->id) {
+            if (ctx->crop.w < J_CROP_MIN_W || ctx->crop.w > J_CROP_MAX_W ||
+                ctx->crop.h < J_CROP_MIN_H || ctx->crop.h > J_CROP_MAM_H) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Jdec only support crop range:16x16~8192x8192, now:%dx%d\n",
+                    ctx->crop.w, ctx->crop.h);
+                return -1;
+            }
+        } else {
+            if (ctx->crop.w < V_CROP_MIN_W || ctx->crop.w > V_CROP_MAX_W ||
+                ctx->crop.h < V_CROP_MIN_H || ctx->crop.h > V_CROP_MAX_H) {
+                av_log(avctx, AV_LOG_ERROR,
+                    "Vdec only support crop range:48x48~8192x4320, now:%dx%d\n",
+                    ctx->crop.w, ctx->crop.h);
+                return -1;
+            }
+        }
+    }
+    if (avctx->width <(ctx->image_dec_backend>1?V_J_MIN_W:dec_caps.min_width) ||
+        avctx->height<(ctx->image_dec_backend>1?V_J_MIN_H:dec_caps.min_height)||
+        avctx->width > dec_caps.max_width || avctx->height>dec_caps.max_height){
+        AV_CODEC_ID_MJPEG == avctx->codec->id ?
+        av_log(avctx, AV_LOG_ERROR,
+            "%s which backend(%d), support resolution:%dx%d~%dx%d, now:%dx%d\n",
+            avctx->codec->name, ctx->image_dec_backend,
+            (ctx->image_dec_backend > 1 ? V_J_MIN_W : dec_caps.min_width),
+            (ctx->image_dec_backend > 1 ? V_J_MIN_H : dec_caps.min_height),
+            dec_caps.max_width, dec_caps.max_height, avctx->width, avctx->height):
+        av_log(avctx, AV_LOG_ERROR,
+            "%s support resolution: %dx%d~%dx%d, now:%dx%d\n", avctx->codec->name,
+            dec_caps.min_width, dec_caps.min_height, dec_caps.max_width,
+            dec_caps.max_height, avctx->width, avctx->height);
+        return -1;
+    }
+    av_log(avctx, AV_LOG_DEBUG,
+        "Build decode:%s, instream size:%dx%d, resize:%dx%d, crop:%dx%dx%dx%d\n",
+        avctx->codec->name, avctx->width, avctx->height, ctx->resize.width,
+        ctx->resize.height, ctx->crop.x, ctx->crop.y, ctx->crop.w, ctx->crop.h);
+
+    return 0;
+}
+
+static int cndec_h2645_ps_to_nalu(const uint8_t *src, int src_size, uint8_t **out, int *out_size) {
+    int i;
+    int ret = 0;
+    uint8_t *p = NULL;
+    static const uint8_t nalu_header[] = { 0x00, 0x00, 0x00, 0x01 };
+
+    if (!out || !out_size) {
+        return AVERROR(EINVAL);
+    }
+
+    p = av_malloc(sizeof(nalu_header) + src_size);
+    if (!p) {
+        return AVERROR(ENOMEM);
+    }
+
+    *out = p;
+    *out_size = sizeof(nalu_header) + src_size;
+
+    memcpy(p, nalu_header, sizeof(nalu_header));
+    memcpy(p + sizeof(nalu_header), src, src_size);
+
+    /* Escape 0x00, 0x00, 0x0{0-3} pattern */
+    for (i = 4; i < *out_size; i++) {
+        if (i < *out_size - 3 &&
+            p[i + 0] == 0 &&
+            p[i + 1] == 0 &&
+            p[i + 2] <= 3) {
+            uint8_t *new;
+
+            *out_size += 1;
+            new = av_realloc(*out, *out_size);
+            if (!new) {
+                ret = AVERROR(ENOMEM);
+                goto done;
+            }
+            *out = p = new;
+
+            i = i + 2;
+            memmove(p + i + 1, p + i, *out_size - (i + 1));
+            p[i] = 0x03;
+        }
+    }
+
+done:
+    if (ret < 0) {
+        av_freep(out);
+        *out_size = 0;
+    }
+
+    return ret;
+}
+
+static int cndec_h264_set_extradata(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int i;
+    int ret;
+
+    H264ParamSets ps;
+    const PPS *pps = NULL;
+    const SPS *sps = NULL;
+    int is_avc = 0;
+    int nal_length_size = 0;
+
+    uint8_t *sps_data = NULL;
+    uint8_t *pps_data = NULL;
+    int sps_data_size = 0;
+    int pps_data_size = 0;
+
+    memset(&ps, 0, sizeof(ps));
+
+    ret = ff_h264_decode_extradata(avctx->extradata, avctx->extradata_size,
+                                   &ps, &is_avc, &nal_length_size, 0, avctx);
+    if (ret < 0) {
+        goto done;
+    }
+    for (i = 0; i < MAX_PPS_COUNT; i++) {
+        if (ps.pps_list[i]) {
+            pps = (const PPS*)ps.pps_list[i]->data;
+            break;
+        }
+    }
+    if (pps) {
+        if (ps.sps_list[pps->sps_id]) {
+            sps = (const SPS*)ps.sps_list[pps->sps_id]->data;
+        }
+    }
+
+    if (pps && sps) {
+        if ((ret = cndec_h2645_ps_to_nalu(sps->data, sps->data_size, &sps_data, &sps_data_size)) < 0) {
+            goto done;
+        }
+
+        if ((ret = cndec_h2645_ps_to_nalu(pps->data, pps->data_size, &pps_data, &pps_data_size)) < 0) {
+            goto done;
+        }
+
+        ctx->seqhdr_data_size = sps_data_size + pps_data_size;
+        ctx->seqhdr_data      = av_malloc(FFALIGN(ctx->seqhdr_data_size, 32));
+
+        memcpy(ctx->seqhdr_data                , sps_data, sps_data_size);
+        memcpy(ctx->seqhdr_data + sps_data_size, pps_data, pps_data_size);
+
+    } else {
+        av_log(avctx, AV_LOG_WARNING, "Could not extract PPS/SPS from extradata\n");
+        ret = AVERROR_INVALIDDATA;
+    }
+
+done:
+    ff_h264_ps_uninit(&ps);
+    av_freep(&sps_data);
+    av_freep(&pps_data);
+
+    return ret;
+}
+
+static int cndec_hevc_set_extradata(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int i;
+    int ret;
+
+    HEVCParamSets ps;
+    HEVCSEI sei;
+
+    const HEVCVPS *vps = NULL;
+    const HEVCPPS *pps = NULL;
+    const HEVCSPS *sps = NULL;
+    int is_nalff = 0;
+    int nal_length_size = 0;
+
+    uint8_t *vps_data = NULL;
+    uint8_t *sps_data = NULL;
+    uint8_t *pps_data = NULL;
+    int vps_data_size = 0;
+    int sps_data_size = 0;
+    int pps_data_size = 0;
+
+    memset(&ps, 0, sizeof(ps));
+    memset(&sei, 0, sizeof(sei));
+
+    ret = ff_hevc_decode_extradata(avctx->extradata, avctx->extradata_size,
+                                   &ps, &sei, &is_nalff, &nal_length_size, 0, 1, avctx);
+    if (ret < 0) {
+        goto done;
+    }
+    for (i = 0; i < HEVC_MAX_VPS_COUNT; i++) {
+        if (ps.vps_list[i]) {
+            vps = (const HEVCVPS*)ps.vps_list[i]->data;
+            break;
+        }
+    }
+    for (i = 0; i < HEVC_MAX_PPS_COUNT; i++) {
+        if (ps.pps_list[i]) {
+            pps = (const HEVCPPS*)ps.pps_list[i]->data;
+            break;
+        }
+    }
+    if (pps) {
+        if (ps.sps_list[pps->sps_id]) {
+            sps = (const HEVCSPS*)ps.sps_list[pps->sps_id]->data;
+        }
+    }
+    if (vps && pps && sps) {
+        if ((ret = cndec_h2645_ps_to_nalu(vps->data, vps->data_size, &vps_data, &vps_data_size)) < 0 ||
+            (ret = cndec_h2645_ps_to_nalu(sps->data, sps->data_size, &sps_data, &sps_data_size)) < 0 ||
+            (ret = cndec_h2645_ps_to_nalu(pps->data, pps->data_size, &pps_data, &pps_data_size)) < 0) {
+            goto done;
+        }
+
+        ctx->seqhdr_data_size = vps_data_size + sps_data_size + pps_data_size;
+        ctx->seqhdr_data      = av_malloc(FFALIGN(ctx->seqhdr_data_size, 32));
+
+        memcpy(ctx->seqhdr_data                                , vps_data, vps_data_size);
+        memcpy(ctx->seqhdr_data + vps_data_size                , sps_data, sps_data_size);
+        memcpy(ctx->seqhdr_data + vps_data_size + sps_data_size, pps_data, pps_data_size);
+    } else {
+        av_log(avctx, AV_LOG_WARNING, "Could not extract VPS/PPS/SPS from extradata\n");
+        ret = AVERROR_INVALIDDATA;
+    }
+
+done:
+    ff_hevc_ps_uninit(&ps);
+
+    av_freep(&vps_data);
+    av_freep(&sps_data);
+    av_freep(&pps_data);
+
+    return ret;
+}
+
+static int cndec_common_set_extradata(AVCodecContext *avctx) {
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 0;
+
+    if (avctx->extradata) {
+        ctx->seqhdr_data_size = avctx->extradata_size;
+        ctx->seqhdr_data      = av_malloc(FFALIGN(ctx->seqhdr_data_size, 32));
+        memcpy(ctx->seqhdr_data, avctx->extradata, avctx->extradata_size);
+    }
+
+    return ret;
+}
+
+static bool cndec_input_buf_available(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 1;
+    uint32_t probe_pkt_size = 0;
+    cncodecDecBufStatus_t buf_status;
+
+    probe_pkt_size = avctx->coded_width * avctx->coded_height / 2;
+    if (ctx->codec_type == CNCODEC_JPEG) {
+        return true;
+    }
+    ret = cncodecDecQueryBufStatus(ctx->codec_handle_, &buf_status);
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Dec query input buf status failed, ret(%d)\n", ret);
+        return false;
+    }
+    if (buf_status.free_stream_buf_bytes >= probe_pkt_size &&
+        buf_status.free_stream_buf_num > 0) {
+        return true;
+    }
+    return false;
+}
+
+static bool cndec_output_buf_available(AVCodecContext *avctx, int *cn_err)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = 1;
+    cncodecDecBufStatus_t buf_status;
+
+    ret = cncodecDecQueryBufStatus(ctx->codec_handle_, &buf_status);
+    if (CNCODEC_SUCCESS != ret) {
+        *cn_err = ret;
+        av_log(avctx, AV_LOG_ERROR,
+            "Dec query output buf status failed, ret(%d)\n", ret);
+        return false;
+    }
+    if (buf_status.used_frame_buf_num == 0) {
+        return true;
+    }
+    return false;
+}
+
+static int cndec_send_pkt_to_decoder(AVCodecContext *avctx,const AVPacket *avpkt)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    cncodecStream_t input;
+    int ret = 0;
+    memset(&input, 0, sizeof(cncodecStream_t));
+    if (!ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Dec handle is NULL, return AVERROR_EXTERNAL \n");
+        return AVERROR_EXTERNAL;
+    }
+
+    input.mem_addr = (uint64_t)avpkt->data;
+    input.data_offset = 0;
+    input.data_len = avpkt->size;
+    input.pts = avpkt->pts;
+    input.mem_type = CNCODEC_MEM_TYPE_HOST;
+    input.alloc_len = avpkt->size;
+    input.priv_data = avpkt->dts;
+    ret = cncodecDecSendStream(ctx->codec_handle_, &input, CN_TIMEOUT_VALUE);
+    MLUMPP_CHECK(avctx, ret, "Decoder send stream");
+
+    ctx->total_packet_count++;
+    return ret;
+}
+
+static int cndec_sequence_callback(void *pData, cncodecDecSequenceInfo_t *info)
+{
+    int ret = CNCODEC_SUCCESS;
+    int cn_err = 0;
+    int cn_wait_cnt = 0;
+    MLUMPPContext_t *ctx  = (MLUMPPContext_t *)pData;
+    AVCodecContext *avctx = ctx->avctx;
+    AVHWFramesContext* hwframe_ctx;
+    AVHWFramesContext* resize_frame_ctx;
+    cncodecDecParams_t params;
+
+    if (mlu_device_affinity(ctx->hwdevice_ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device set affinity failed, func:%s, line:%d\n",
+            __func__, __LINE__);
+        exit(-1);
+    }
+
+    memset(&params, 0, sizeof(params));
+    if (ctx->first_seq) {
+        params.max_width = info->coded_width > ctx->max_width ? info->coded_width : ctx->max_width;
+        params.max_height = info->coded_height > ctx->max_height ? info->coded_height : ctx->max_height;
+        ctx->first_max_width = params.max_width;
+        ctx->first_max_height = params.max_height;
+        ctx->output_buf_num = ctx->output_buf_num > (info->min_output_buf_num + 2) ?
+                ctx->output_buf_num : (info->min_output_buf_num + 2);
+        ctx->first_seq = 0;
+    } else {
+        if (info->coded_width > ctx->first_max_width || info->coded_height > ctx->first_max_height) {
+            av_log(avctx, AV_LOG_ERROR,
+                    "Resolution has changed, buffer max width and max height was too small.\n");
+            ctx->codec_abort_flag = 1;
+            return CNCODEC_ERROR_INVALID_VALUE;
+        } else {
+            params.max_width = ctx->first_max_width;
+            params.max_height = ctx->first_max_height;
+        }
+    }
+    if (ctx->output_buf_num < info->min_output_buf_num + 2) {
+        av_log(avctx, AV_LOG_ERROR, "reconfigure output buf num(%d) exceeds the initial value(%d)!\n",
+                info->min_output_buf_num + 2, ctx->output_buf_num);
+        return CNCODEC_ERROR_INVALID_VALUE;
+    }
+    params.output_buf_num    = ctx->output_buf_num;
+    params.pixel_format      = cncodec_get_cn_pixfmt_by_av_pixfmt(avctx->sw_pix_fmt);
+    params.color_space       = ctx->color_space;
+    params.stride_align      = ctx->stride_align;
+    params.dec_mode          = CNCODEC_DEC_MODE_IPB;
+    params.output_order      = cndec_get_output_order_by_name(ctx->output_order);
+    params.output_buf_source = CNCODEC_BUF_SOURCE_LIB;
+
+    params.pp_attr.crop.enable = 1;
+    if (ctx->crop_str) {
+        params.pp_attr.crop.x = ctx->crop.x;
+        params.pp_attr.crop.y = ctx->crop.y;
+        params.pp_attr.crop.width  = ctx->crop.w;
+        params.pp_attr.crop.height = ctx->crop.h;
+    } else {
+        params.pp_attr.crop.x = 0;
+        params.pp_attr.crop.y = 0;
+        params.pp_attr.crop.width = info->display_area.width;
+        params.pp_attr.crop.height= info->display_area.height;
+    }
+    if (!ctx->resize_str) {
+        params.pp_attr.scale.vid_scale.enable = 0;
+    } else {
+        if (ctx->resize.width/avctx->width > 3 || ctx->resize.height/avctx->height > 3) {
+            av_log(avctx, AV_LOG_ERROR,
+                "Video upscale support no more than triple magnification\n");
+            return CNCODEC_ERROR_INVALID_VALUE;
+        }
+        params.pp_attr.scale.vid_scale.enable = 1;
+        params.pp_attr.scale.vid_scale.width  = ctx->resize.width;
+        params.pp_attr.scale.vid_scale.height = ctx->resize.height;
+    }
+    ctx->async_queue_depth = params.output_buf_num * 4;
+
+    // while the vairable resolution vp8 is used, the queue may not be empty.
+    while (!ret && cn_wait_cnt++ <= CN_TIMEOUT_VALUE) {
+        ret = cndec_output_buf_available(avctx, &cn_err);
+        if (cn_err) {
+            return cn_err;
+        }
+        if (!ret) {
+            av_usleep(CN_TIMEOUT_UNIT);
+            av_log(avctx, AV_LOG_WARNING,
+                "Vdec resolution changed, wait pre-resolution ready\n");
+        }
+        if (cn_wait_cnt == 100) {
+            av_log(avctx, AV_LOG_WARNING,
+                "Vdec resolution changed, wait pre-resolution timeout\n");
+            return CNCODEC_ERROR_INVALID_MEMORY;
+        }
+    }
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    ret = av_fifo_realloc2(ctx->frame_queue, ctx->async_queue_depth * sizeof(DecEventInfoMsg_t));
+    ff_mutex_unlock(&ctx->queue_mutex);
+    if (!ctx->frame_queue || ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create frame queue, ret:%d\n", ret);
+        return CNCODEC_ERROR_INVALID_MEMORY;
+    }
+
+    avctx->width  = info->display_area.width;
+    avctx->height = info->display_area.height;
+    avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+    avctx->coded_height = avctx->height;
+
+    if (cndec_params_checking(avctx)) {
+        return CNCODEC_ERROR_INVALID_VALUE;
+    }
+    if (!ctx->resize_str && ctx->crop_str) {
+        avctx->width  = ctx->crop.w;
+        avctx->height = ctx->crop.h;
+        avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+        avctx->coded_height = avctx->height;
+    } else if (ctx->resize_str) {
+        avctx->width  = ctx->resize.width;
+        avctx->height = ctx->resize.height;
+        avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+        avctx->coded_height = avctx->height;
+    }
+
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU &&
+       (avctx->hw_frames_ctx || avctx->hw_device_ctx)) {
+        hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+        if (ctx->resize_str || ctx->crop_str) {
+            ctx->hw_resize_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+            if (!ctx->hw_resize_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Alloc video resize hwframe failed\n");
+                return CNCODEC_ERROR_INVALID_VALUE;
+            }
+            resize_frame_ctx = (AVHWFramesContext*)ctx->hw_resize_frame_ref->data;
+            resize_frame_ctx->format    = AV_PIX_FMT_MLU;
+            resize_frame_ctx->sw_format = avctx->sw_pix_fmt;
+            resize_frame_ctx->width     = avctx->coded_width;
+            resize_frame_ctx->height    = avctx->coded_height;
+            if ((ret = av_hwframe_ctx_init(ctx->hw_resize_frame_ref)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Init resize hwframe: av_hwframe_ctx_init failed\n");
+                return CNCODEC_ERROR_INVALID_VALUE;
+            }
+        } else {
+            if (!hwframe_ctx->pool || avctx->coded_width != hwframe_ctx->width) {
+                if (hwframe_ctx->pool) {
+                    av_log(avctx, AV_LOG_WARNING, "hwframe w from [%d] change to [%d]\n",
+                        hwframe_ctx->width, avctx->coded_width);
+                    av_buffer_pool_uninit(&hwframe_ctx->pool);
+                }
+                hwframe_ctx->format    = AV_PIX_FMT_MLU;
+                hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+                hwframe_ctx->width     = avctx->coded_width;
+                hwframe_ctx->height    = avctx->coded_height;
+                if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+                    av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+                    return CNCODEC_ERROR_INVALID_VALUE;
+                }
+            }
+        }
+    }
+
+    ret = cncodecDecSetParams(ctx->codec_handle_, &params);
+    MLUMPP_CHECK(avctx, ret, "Set params to decoder");
+
+    ctx->total_frame_count = 0;
+    av_log(avctx, AV_LOG_DEBUG, "Video decode got seq cb, handle:%lu \n",
+        (long unsigned)ctx->codec_handle_);
+    return ret;
+}
+
+static int cndec_newframe_callback(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    DecEventInfoMsg_t msg;
+    int ret = CNCODEC_SUCCESS;
+
+    msg.event_type = CNCODEC_EVENT_NEW_FRAME;
+    msg.cnctx = userptr;
+    msg.event_output.frame = *((cncodecFrame_t *)data);
+
+    ff_mutex_lock(&ctx->queue_mutex);
+    ret = cncodecDecFrameRef(ctx->codec_handle_, &msg.event_output.frame);
+    av_fifo_generic_write(ctx->frame_queue, &msg, sizeof(DecEventInfoMsg_t), NULL);
+    ff_mutex_unlock(&ctx->queue_mutex);
+    MLUMPP_CHECK(ctx->avctx, ret, "Callback func, ref new frame");
+
+    ctx->total_frame_count++;
+    return ret;
+}
+
+static int cndec_eos_callback(void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    DecEventInfoMsg_t msg;
+
+    memset(&msg, 0 ,sizeof(DecEventInfoMsg_t));
+    msg.event_type = CNCODEC_EVENT_EOS;
+    msg.cnctx = userptr;
+    ff_mutex_lock(&ctx->queue_mutex);
+    av_fifo_generic_write(ctx->frame_queue, &msg, sizeof(DecEventInfoMsg_t), NULL);
+    ff_mutex_unlock(&ctx->queue_mutex);
+    sem_post(&ctx->eos_sema);
+    av_log(ctx->avctx, AV_LOG_DEBUG,
+        "Decode got eos cb, thread: %lu\n", (long unsigned)pthread_self());
+    return CNCODEC_SUCCESS;
+}
+
+static int cndec_event_callback(cncodecEventType_t event_type, void *userptr, void *data)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t *)userptr;
+    cncodecDecStreamCorruptInfo_t *corrupt_info = NULL;
+    int cb_ret = CNCODEC_SUCCESS;
+
+    if (ctx == NULL && data == NULL) {
+        av_log(NULL, AV_LOG_FATAL,
+            "Decoder callback error, event type: %d \n", event_type);
+        return CNCODEC_ERROR_INVALID_HANDLE;
+    }
+
+    switch (event_type) {
+    case CNCODEC_EVENT_NEW_FRAME:
+        cb_ret = cndec_newframe_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_SEQUENCE:
+        cb_ret = cndec_sequence_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_EOS:
+        cb_ret = cndec_eos_callback(userptr, data);
+        break;
+    case CNCODEC_EVENT_STREAM_CORRUPT:
+        corrupt_info = (cncodecDecStreamCorruptInfo_t *)data;
+        av_log(ctx->avctx, AV_LOG_WARNING, "Decoder corrupt stream: %d \n", event_type);
+        av_log(ctx->avctx, AV_LOG_DEBUG, "Decoder stream error pts: %lu, err num: %lu \n",
+                            corrupt_info->pts, corrupt_info->total_num);
+        cb_ret = CNCODEC_SUCCESS;
+        break;
+    case CNCODEC_EVENT_STREAM_NOT_SUPPORTED:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Not supported stream, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_NOT_SUPPORTED;
+        break;
+    case CNCODEC_EVENT_OUT_OF_MEMORY:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Out of memory, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_OUT_OF_MEMORY;
+        break;
+    case CNCODEC_EVENT_BUFFER_OVERFLOW:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Stream buf overflow, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_BUFFER_OVERFLOW;
+        break;
+    case CNCODEC_EVENT_FATAL_ERROR:
+        av_log(ctx->avctx, AV_LOG_ERROR, "Fatal error, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_UNKNOWN;
+        break;
+    default:
+        av_log(ctx->avctx, AV_LOG_FATAL, "Unknown event type, event code:%d \n", event_type);
+        if (!ctx->codec_abort_flag) {
+            sem_post(&ctx->eos_sema);
+            ctx->codec_abort_flag = 1;
+        }
+        cb_ret = CNCODEC_ERROR_UNKNOWN;
+        break;
+    }
+    return cb_ret;
+}
+
+static int cndec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVPacket filter_packet   = { 0 };
+    AVPacket filtered_packet = { 0 };
+    int ret = 0;
+    if (ctx->bsf && avpkt && avpkt->size) {
+        if ((ret = av_packet_ref(&filter_packet, avpkt)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_packet_ref\n");
+            return ret;
+        }
+        if ((ret = av_bsf_send_packet(ctx->bsf, &filter_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_bsf_send_packet \n");
+            av_packet_unref(&filter_packet);
+            return ret;
+        }
+        if ((ret = av_bsf_receive_packet(ctx->bsf, &filtered_packet)) < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed av_bsf_receive_packet \n");
+            return ret;
+        }
+        avpkt = &filtered_packet;
+    }
+    av_packet_unref(&filter_packet);
+
+    if (avpkt && avpkt->size) {
+        ret = cndec_send_pkt_to_decoder(avctx, avpkt);
+        if (ret != 0) {
+            av_packet_unref(&filtered_packet);
+            return AVERROR(EINVAL);
+        }
+    } else {
+        if (!ctx->decoder_flushing) {
+            ret = cncodecDecSetEos(ctx->codec_handle_);
+            MLUMPP_CHECK(avctx, ret, "Decoder send Eos");
+            ctx->decoder_flushing = 1;
+        }
+    }
+    av_packet_unref(&filtered_packet);
+
+    return 0;
+}
+
+static int cndec_frame_copyout(AVCodecContext *avctx, AVFrame *avframe, cncodecFrame_t *cnframe)
+{
+    MLUMPPContext_t *ctx             = (MLUMPPContext_t*)avctx->priv_data;
+    AVHWDeviceContext *device_ctx    = (AVHWDeviceContext*)ctx->hw_device_ref->data;
+    AVMLUDeviceContext *hwdevice_ctx = device_ctx->hwctx;
+    MluContext *mlu_ctx              = hwdevice_ctx->mlu_ctx;
+
+    cnrtRet_t cnrt_ret;
+    int ret = 0, factor = 0;
+    ctx->total_outframe_count++;
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU && (ctx->resize_str || ctx->crop_str)) {
+        ret = av_hwframe_get_buffer(ctx->hw_resize_frame_ref, avframe, 0);
+        MLUMPP_CHECK_OPT(avctx, ret, "Decode av_hwframe_get_buffer failed", AVERROR(EINVAL));
+        ret = ff_decode_frame_props(avctx, avframe);
+        MLUMPP_CHECK_OPT(avctx, ret, "Decode ff_decode_frame_props failed", AVERROR(EINVAL));
+    } else if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        ret = av_hwframe_get_buffer(ctx->hw_frame_ref, avframe, 0);
+        MLUMPP_CHECK_OPT(avctx, ret, "Decode av_hwframe_get_buffer failed", AVERROR(EINVAL));
+        ret = ff_decode_frame_props(avctx, avframe);
+        MLUMPP_CHECK_OPT(avctx, ret, "Decode ff_decode_frame_props failed", AVERROR(EINVAL));
+    } else {
+        ret = ff_get_buffer(avctx, avframe, 0);
+        MLUMPP_CHECK_OPT(avctx, ret, "Decode ff_get_buffer failed", AVERROR(EINVAL));
+    }
+    for (int i = 0; i < cnframe->plane_num; ++i) {
+        factor = (i == 0) ? 1 : 2;
+        avframe->linesize[i] = cnframe->plane[i].stride;
+        if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+            if (ctx->mem_async) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2DAsync((void*)avframe->data[i],
+                        (void*)cnframe->plane[i].dev_addr,
+                        cnframe->plane[i].stride * cnframe->height / factor,
+                        ctx->mlu_queue, cnrtMemcpyDevToDev);
+                MLUMPP_CHECK(avctx, cnrt_ret, "Output frame D2DA failed!");
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)avframe->data[i],
+                        (void*)cnframe->plane[i].dev_addr,
+                        cnframe->plane[i].stride * cnframe->height / factor, cnrtMemcpyDevToDev);
+                MLUMPP_CHECK(avctx, cnrt_ret, "Output frame D2D failed!");
+            }
+        } else {
+            if (ctx->mem_async) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2HAsync((void*)avframe->data[i],
+                        (void*)cnframe->plane[i].dev_addr,
+                        cnframe->plane[i].stride*cnframe->height/factor,
+                        ctx->mlu_queue, cnrtMemcpyDevToHost);
+                MLUMPP_CHECK(avctx, cnrt_ret, "Output frame D2HA failed!");
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)avframe->data[i], (void*)cnframe->plane[i].dev_addr,
+                                cnframe->plane[i].stride*cnframe->height/factor, cnrtMemcpyDevToHost);
+                MLUMPP_CHECK(avctx, cnrt_ret, "Output frame D2H failed!");
+            }
+        }
+    }
+    if (ctx->mem_async) {
+        mlu_ctx->mluQueueSync(ctx->mlu_queue);
+    }
+
+    return 0;
+}
+
+static int cndec_output_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+
+    int ret = 0;
+    int64_t pts = -1;
+    int64_t dts = -1;
+    cncodecPicType_t pic_type;
+    DecEventInfoMsg_t frame_info;
+
+    if (!ctx->frame_queue) return AVERROR(EAGAIN);
+    ff_mutex_lock(&ctx->queue_mutex);
+    if (av_fifo_size(ctx->frame_queue) != 0) {
+        av_fifo_generic_read(ctx->frame_queue, &frame_info, sizeof(DecEventInfoMsg_t), NULL);
+    } else {
+        ff_mutex_unlock(&ctx->queue_mutex);
+        return AVERROR(EAGAIN);
+    }
+    ff_mutex_unlock(&ctx->queue_mutex);
+    if (CNCODEC_EVENT_EOS == frame_info.event_type) {
+        return AVERROR_EOF;
+    }
+    pts      = frame_info.event_output.frame.pts;
+    dts      = frame_info.event_output.frame.priv_data;
+    pic_type = frame_info.event_output.frame.pic_type;
+
+    ret = cndec_frame_copyout(avctx, frame, &frame_info.event_output.frame);
+    cncodecDecFrameUnref(ctx->codec_handle_, &frame_info.event_output.frame);
+    if (ret < 0) {
+        av_log(avctx, AV_LOG_ERROR, "cndec frame copyout failed\n");
+        return ret;
+    }
+
+    frame->pkt_pos      = -1;
+    frame->pkt_duration = 0;
+    frame->pkt_size     = -1;
+    frame->interlaced_frame = ctx->progressive ? 0 : 1;
+    frame->pts          = pts;
+    frame->pkt_dts      = dts;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+    frame->pkt_pts = frame->pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    frame->width  = avctx->width;
+    frame->height = avctx->height;
+    frame->pict_type = cncodec_get_frame_type(pic_type);
+    frame->key_frame = cncodec_get_keyframe_flag(pic_type);
+
+    return ret;
+}
+
+static int cndec_output_jpeg_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = -1;
+
+    while (!ctx->codec_abort_flag) {
+        ret = cndec_output_frame(avctx, frame);
+        if (ret == AVERROR(EAGAIN)) {
+            av_usleep(CN_TIMEOUT_UNIT);
+            continue;
+        }
+        if (ret == AVERROR_EOF) {
+            ctx->eos_received = 1;
+        }
+        return ret;
+    }
+    av_log(avctx, AV_LOG_ERROR, "Receive codec abort, return eof, [%lu]\n",
+        (long unsigned)pthread_self());
+
+    return AVERROR_EOF;
+}
+
+static int ff_cndec_receive_frame(AVCodecContext *avctx, AVFrame *frame)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int in_ret = -1;
+    int out_ret = -1;
+    AVPacket pkt = {0};
+    uint64_t cn_start = 0;
+    uint64_t cn_timeout = 0;
+    bool inbuf_valid = false;
+
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_receive_frame\n");
+        return AVERROR_BUG;
+    }
+    if (ctx->codec_abort_flag || !ctx->decoder_init_flag || !ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Decode got abort or not init or no handle, return AVERROR_BUG \n");
+        return AVERROR_BUG;
+    }
+    if (!ctx->affinity_set && mlu_device_affinity(ctx->hwdevice_ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device set affinity failed, func:%s, line:%d\n",
+            __func__, __LINE__);
+        exit(-1);
+    }
+    ctx->affinity_set = true;
+    if (ctx->eos_received) {
+        return AVERROR_EOF;
+    }
+    cn_start = cn_get_current_time();
+
+    while (!ctx->codec_abort_flag) {
+        inbuf_valid = cndec_input_buf_available(avctx);
+        if (!ctx->decoder_flushing && inbuf_valid) {
+            in_ret = ff_decode_get_packet(avctx, &pkt);
+            if (in_ret < 0 && in_ret != AVERROR_EOF) {
+                if (in_ret == AVERROR(EAGAIN))
+                    goto output_frame;
+                else
+                    return in_ret;
+            }
+            in_ret = cndec_send_packet(avctx, &pkt);
+            av_packet_unref(&pkt);
+            if (in_ret < 0 && in_ret != AVERROR_EOF) {
+                av_log(avctx, AV_LOG_ERROR, "Dec send packet failed, ret:%d\n",
+                    in_ret);
+                return in_ret;
+            }
+        }
+
+    output_frame:
+        if (ctx->codec_type == CNCODEC_JPEG) {
+            if (in_ret == AVERROR(EAGAIN)) return in_ret;
+            return cndec_output_jpeg_frame(avctx, frame);
+        }
+        out_ret = cndec_output_frame(avctx, frame);
+        if (out_ret == AVERROR(EAGAIN)) {
+            cn_timeout = cn_get_current_time() - cn_start;
+            if ((!inbuf_valid || ctx->decoder_flushing) &&
+                cn_timeout > CN_TIMEOUT_VALUE) {
+                av_log(avctx, AV_LOG_ERROR, "Dec output frame timeout\n");
+                return AVERROR_EXTERNAL;
+            }
+            if (in_ret == AVERROR(EAGAIN)) {
+                av_log(avctx, AV_LOG_DEBUG,
+                    "Dec got pkt and frame failed, return again\n");
+                return out_ret;
+            }
+            av_usleep(2 * CN_TIMEOUT_UNIT);
+            av_log(avctx, AV_LOG_DEBUG, "Dec frame empty, try again\n");
+        } else {
+            if (out_ret == AVERROR_EOF) {
+                ctx->eos_received = 1;
+            }
+            return out_ret;
+        }
+    }
+    av_log(avctx, AV_LOG_ERROR, "Dec abort, fatal error\n");
+
+    return AVERROR_BUG;
+}
+
+static av_cold int ff_cndec_decode_end(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    int ret = -1;
+    int semvalue = 0;
+    struct timespec ts;
+    if (NULL == avctx || NULL == avctx->priv_data || 0 == ctx->codec_handle_) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_decode_end \n");
+        return AVERROR_BUG;
+    }
+    // sem_wait(&ctx->eos_sema);
+    clock_gettime(CLOCK_REALTIME, &ts);
+    ts.tv_sec += 3;
+    if (-1 == sem_timedwait(&(ctx->eos_sema), &ts)) {
+        semvalue = -1;
+        sem_getvalue(&ctx->eos_sema, &semvalue);
+        av_log(avctx, AV_LOG_WARNING, "Decode waited eos timeout\n");
+    }
+
+    ret = cncodecDecDestroy(ctx->codec_handle_);
+    if (CNCODEC_SUCCESS != ret) {
+        print_cncodec_error(avctx, ret, "decoder destroy");
+    }
+    if (ctx->mem_async) {
+        ctx->mlu_ctx->mluQueueDestroy(ctx->mlu_queue);
+    }
+
+    sem_destroy(&ctx->eos_sema);
+    if (ctx->frame_queue) {
+        av_fifo_freep(&ctx->frame_queue);
+        ctx->frame_queue = NULL;
+    }
+    ff_mutex_destroy(&ctx->queue_mutex);
+    if (ctx->bsf) {
+        av_bsf_free(&ctx->bsf);
+        ctx->bsf = NULL;
+    }
+
+    ctx->decoder_init_flag = 0;
+    if (ctx->hw_frame_ref)  av_buffer_unref(&ctx->hw_frame_ref);
+    if (ctx->hw_device_ref) av_buffer_unref(&ctx->hw_device_ref);
+    if (ctx->hw_resize_frame_ref) av_buffer_unref(&ctx->hw_resize_frame_ref);
+
+    av_log(avctx, AV_LOG_DEBUG, "decode flushing flag:%d \n", ctx->decoder_flushing);
+    av_log(avctx, AV_LOG_DEBUG, "decode hw out pict count:%llu\n", ctx->total_outframe_count);
+    av_log(avctx, AV_LOG_DEBUG, "decode received pict count:%llu\n", ctx->total_frame_count);
+    av_log(avctx, AV_LOG_DEBUG, "decode feed data count:%llu\n", ctx->total_packet_count);
+    av_log(avctx, AV_LOG_DEBUG, "decoder close done, thread:%lu\n", (long unsigned)pthread_self());
+
+    return 0;
+}
+
+static av_cold int ff_cndec_decode_init(AVCodecContext *avctx)
+{
+    MLUMPPContext_t *ctx = (MLUMPPContext_t*)avctx->priv_data;
+    AVMLUDeviceContext *hwdevice_ctx;
+    AVHWFramesContext  *hwframe_ctx;
+    AVHWFramesContext  *resize_frame_ctx;
+
+    int ret = 0;
+    int probed_buf_size = 0;
+    char dev_idx[sizeof(int)];
+    const AVBitStreamFilter *bsf;
+    enum AVPixelFormat dec_pix_format = av_get_pix_fmt(ctx->output_pixfmt);
+    enum AVPixelFormat pix_fmts[3] = { AV_PIX_FMT_MLU, dec_pix_format, AV_PIX_FMT_NONE };
+
+    if (NULL == avctx || NULL == avctx->priv_data) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_cndec_decode_init func\n");
+        return AVERROR_BUG;
+    }
+
+    if (ctx->decoder_init_flag == 1) {
+        av_log(avctx, AV_LOG_ERROR, "Error, cndecode double init. \n");
+        return AVERROR_BUG;
+    }
+
+    cndec_version_info();
+    avctx->sw_pix_fmt = av_get_pix_fmt(ctx->output_pixfmt);
+    avctx->pix_fmt = ff_get_format(avctx, pix_fmts);
+    if (avctx->pix_fmt < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Error, ff_get_format failed: %d\n", avctx->pix_fmt);
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+
+    ctx->avctx = avctx;
+    ctx->coded_width  = avctx->codec->id == AV_CODEC_ID_MJPEG?
+                        FFALIGN(avctx->width,  JFRAME_STRIDE_ALIGN):
+                        FFALIGN(avctx->width,  ctx->stride_align);
+    ctx->coded_height = FFALIGN(avctx->height, VFRAME_HEIGHT_ALIGN);
+    if (ctx->resize_str && sscanf(ctx->resize_str, "%dx%d",
+                                &ctx->resize.width, &ctx->resize.height) != 2) {
+        av_log(avctx, AV_LOG_ERROR, "Invalid resize string\n");
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+    ctx->crop_str = NULL;
+    if (ctx->crop2_str) {
+        if (sscanf(ctx->crop2_str, "%dx%dx%dx%d",
+                &ctx->crop.x, &ctx->crop.y, &ctx->crop.w, &ctx->crop.h) != 4) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid crop string\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        } else {
+            int bottom = ctx->crop.y;
+            ctx->crop.y = ctx->crop.x;
+            ctx->crop.x = ctx->crop.w;
+            ctx->crop.w = avctx->width - (ctx->crop.w + ctx->crop.h);
+            ctx->crop.h = avctx->height- (ctx->crop.y + bottom);
+            ctx->crop_str = ctx->crop2_str;
+        }
+    } else if (ctx->crop1_str) {
+        if (sscanf(ctx->crop1_str, "%dx%dx%dx%d",
+                &ctx->crop.x, &ctx->crop.y, &ctx->crop.w, &ctx->crop.h) != 4) {
+            av_log(avctx, AV_LOG_ERROR, "Invalid crop string\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        ctx->crop_str = ctx->crop1_str;
+    }
+    if (avctx->hw_frames_ctx) {
+        av_buffer_unref(&ctx->hw_frame_ref);
+        ctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+        if (!ctx->hw_frame_ref) {
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+        if (!hwframe_ctx->pool || ctx->coded_width != hwframe_ctx->width) {
+            if (hwframe_ctx->pool) {
+                av_log(avctx, AV_LOG_WARNING, "hwframe w from [%d] change to [%d]\n",
+                    hwframe_ctx->width, ctx->coded_width);
+                av_buffer_pool_uninit(&hwframe_ctx->pool);
+            }
+            hwframe_ctx->format    = AV_PIX_FMT_MLU;
+            hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+            hwframe_ctx->width     = ctx->coded_width;
+            hwframe_ctx->height    = ctx->coded_height;
+            if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+                return AVERROR(ENAVAIL);
+            }
+        }
+        ctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+        if (!ctx->hw_device_ref) {
+            av_log(avctx, AV_LOG_ERROR, "A hardware frames or device context is "
+                "required for hardware accelerated decoding.\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+    } else {
+        if (avctx->hw_device_ctx) {
+            ctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+            if (!ctx->hw_device_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Error, ref hwdev failed\n");
+                ret = AVERROR(EINVAL);
+                goto error;
+            }
+        } else {
+            sprintf(dev_idx, "%d", ctx->device_id);
+            ret = av_hwdevice_ctx_create(&ctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, dev_idx,NULL,0);
+            if (ret < 0) {
+                av_log(avctx, AV_LOG_ERROR, "Hardware dev_ctx create failed, ret(%d).\n", ret);
+                goto error;
+            }
+        }
+        ctx->hw_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+        if (!ctx->hw_frame_ref) {
+            av_log(avctx, AV_LOG_ERROR, "Error, av_hwframe_ctx_alloc failed\n");
+            ret = AVERROR(EINVAL);
+            goto error;
+        }
+        hwframe_ctx = (AVHWFramesContext*)ctx->hw_frame_ref->data;
+    }
+
+    hwdevice_ctx = ((AVHWDeviceContext*)ctx->hw_device_ref->data)->hwctx;
+    ctx->hwdevice_ctx = hwdevice_ctx;
+    ctx->hwframes_ctx = hwframe_ctx;
+    ctx->mlu_ctx      = ctx->hwdevice_ctx->mlu_ctx;
+    ctx->device_id    = ctx->mlu_ctx->mlu_id;
+    if (cndec_params_checking(avctx)) {
+        return AVERROR(EINVAL);
+    }
+    if (ctx->mem_async) {
+        ctx->mlu_ctx->mluQueueCreate(&ctx->mlu_queue);
+    }
+    ctx->first_seq            = 1;
+    ctx->eos_received         = 0;
+    ctx->decoder_flushing     = 0;
+    ctx->codec_abort_flag     = 0;
+    ctx->total_frame_count    = 0;
+    ctx->total_packet_count   = 0;
+    ctx->total_outframe_count = 0;
+
+    sem_init(&(ctx->eos_sema), 0, 0);
+    ff_mutex_init(&ctx->queue_mutex, NULL);
+
+    switch (avctx->codec->id) {
+#if CONFIG_H264_MLUMPP_DECODER
+    case AV_CODEC_ID_H264:
+        ctx->codec_type = CNCODEC_H264;
+        break;
+#endif
+#if CONFIG_HEVC_MLUMPP_DECODER
+    case AV_CODEC_ID_HEVC:
+        ctx->codec_type = CNCODEC_HEVC;
+        break;
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+    case AV_CODEC_ID_MJPEG:
+        ctx->codec_type = CNCODEC_JPEG;
+        break;
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+    case AV_CODEC_ID_VP8:
+        ctx->codec_type = CNCODEC_VP8;
+        break;
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+    case AV_CODEC_ID_VP9:
+        ctx->codec_type = CNCODEC_VP9;
+        break;
+#endif
+#if CONFIG_AVS_MLUMPP_DECODER
+    case AV_CODEC_ID_AVS:
+    case AV_CODEC_ID_CAVS:
+        ctx->codec_type = CNCODEC_AVS;
+        break;
+#endif
+#if CONFIG_AVS2_MLUMPP_DECODER
+    case AV_CODEC_ID_AVS2:
+        ctx->codec_type = CNCODEC_AVS2;
+        break;
+#endif
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Invalid codec type, %d\n",avctx->codec->id);
+        return AVERROR_BUG;
+    }
+
+    ctx->bsf = NULL;
+    if (avctx->codec->id == AV_CODEC_ID_H264 ||
+        avctx->codec->id == AV_CODEC_ID_HEVC) {
+        if (avctx->codec->id == AV_CODEC_ID_H264)
+            bsf = av_bsf_get_by_name("h264_mp4toannexb");
+        else
+            bsf = av_bsf_get_by_name("hevc_mp4toannexb");
+        if (!bsf) {
+            ret = AVERROR_BSF_NOT_FOUND;
+            goto error;
+        }
+        if (ret = av_bsf_alloc(bsf, &ctx->bsf)) {
+            goto error;
+        }
+        if (((ret = avcodec_parameters_from_context(ctx->bsf->par_in, avctx)) < 0) ||
+            ((ret = av_bsf_init(ctx->bsf)) < 0)) {
+            av_bsf_free(&ctx->bsf);
+            goto error;
+        }
+    }
+    /*At this moment, if the demuxer does not set this value (avctx->field_order == UNKNOWN),
+    *   the input stream will be assumed as progressive one.
+    */
+    switch(avctx->field_order) {
+    case AV_FIELD_TT:
+    case AV_FIELD_BB:
+    case AV_FIELD_TB:
+    case AV_FIELD_BT:
+        ctx->progressive = 0;
+        av_log(avctx, AV_LOG_WARNING, "Stream field order interlaced\n");
+        break;
+    case AV_FIELD_PROGRESSIVE:
+    default:
+        ctx->progressive = 1;
+        break;
+    }
+
+    ctx->frame_queue = NULL;
+    ctx->max_width = FFALIGN(ctx->max_width, 64);
+    ctx->max_height = FFALIGN(ctx->max_height, 16);
+    probed_buf_size = (ctx->max_width > 0 && ctx->max_height > 0) ?
+        ctx->max_width * ctx->max_height * ctx->compress_scale :
+        ctx->coded_width * ctx->coded_height * ctx->compress_scale;
+
+    memset(&(ctx->create_info_), 0, sizeof(cncodecDecCreateInfo_t));
+    memset(&(ctx->codec_params_), 0, sizeof(cncodecDecParams_t));
+
+    ctx->create_info_.codec     = ctx->codec_type;
+    ctx->create_info_.device_id = ctx->mlu_ctx->mlu_id;
+    ctx->create_info_.send_mode = CNCODEC_DEC_SEND_MODE_FRAME;
+    ctx->create_info_.run_mode  = CNCODEC_RUN_MODE_ASYNC;
+#if CNCODEC_MAJOR_VERSION > 0
+    ctx->create_info_.backend   = ctx->image_dec_backend;
+#endif
+    ctx->create_info_.stream_buf_size = FFALIGN(probed_buf_size, 4096);
+    ctx->create_info_.user_context    = (void*)ctx;
+    ret = cncodecDecCreate(&ctx->codec_handle_, &cndec_event_callback, &ctx->create_info_);
+    if (CNCODEC_SUCCESS != ret) {
+        ret = print_cncodec_error(avctx, ret, "Failed to create decoder");
+        ctx->codec_handle_ = 0;
+        goto error;
+    }
+
+    ctx->async_queue_depth = ctx->output_buf_num;
+    ctx->frame_queue = av_fifo_alloc(ctx->async_queue_depth * sizeof(DecEventInfoMsg_t));
+    if (!ctx->frame_queue) {
+        av_log(avctx, AV_LOG_ERROR, "Failed to create jpeg frame queue \n");
+        ret = AVERROR(EINVAL);
+        goto error;
+    }
+    if (ctx->codec_type != CNCODEC_JPEG && ctx->codec_type != CNCODEC_AVS2 &&
+        ctx->codec_type != CNCODEC_AVS && avctx->extradata_size != 0) {
+        if (avctx->codec->id == AV_CODEC_ID_H264)
+            ret = cndec_h264_set_extradata(avctx);
+        else if (avctx->codec->id == AV_CODEC_ID_HEVC)
+            ret = cndec_hevc_set_extradata(avctx);
+        else
+            ret = cndec_common_set_extradata(avctx);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_WARNING, "Decoder set extradata failed\n");
+            // goto error;
+        }
+        if (ctx->seqhdr_data_size) {
+            cncodecStream_t input;
+            input.data_offset = 0;
+            input.mem_addr = (uint64_t)ctx->seqhdr_data;
+            input.data_len = ctx->seqhdr_data_size;
+            input.pts = -67;
+            input.mem_type = CNCODEC_MEM_TYPE_HOST;
+            input.alloc_len = ctx->seqhdr_data_size;
+            ret = cncodecDecSendStream(ctx->codec_handle_, &input, CN_TIMEOUT_VALUE);
+            MLUMPP_CHECK(avctx, ret, "Decoder send stream");
+        }
+        av_free(ctx->seqhdr_data);
+    }
+    if (CNCODEC_JPEG == ctx->codec_type) {
+        ctx->codec_params_.max_width      = FFALIGN(avctx->width,  JFRAME_STRIDE_ALIGN);
+        ctx->codec_params_.max_height     = FFALIGN(avctx->height, JFRAME_HEIGHT_ALIGN);
+        ctx->codec_params_.stride_align   = JFRAME_STRIDE_ALIGN; // ctx->stride_align;
+        ctx->codec_params_.output_buf_num = ctx->output_buf_num;
+        ctx->codec_params_.pixel_format   = cncodec_get_cn_pixfmt_by_av_pixfmt(avctx->sw_pix_fmt);
+        ctx->codec_params_.color_space    = ctx->color_space;
+        ctx->codec_params_.output_buf_source = CNCODEC_BUF_SOURCE_LIB;
+
+        if (!ctx->resize_str) {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 0;
+        } else {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 1;
+            if (ctx->resize.width == avctx->width / 2) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 1;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 1;
+            } else if (ctx->resize.width == avctx->width / 4) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 2;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 2;
+            } else if (ctx->resize.width == avctx->width / 8) {
+                ctx->codec_params_.pp_attr.scale.jpg_scale.width_factor = 3;
+                ctx->codec_params_.pp_attr.scale.jpg_scale.height_factor= 3;
+            }
+        }
+        if (!ctx->crop_str) {
+            ctx->codec_params_.pp_attr.scale.jpg_scale.enable = 0;
+        } else {
+            ctx->codec_params_.pp_attr.crop.enable = 1;
+            ctx->codec_params_.pp_attr.crop.x = ctx->crop.x;
+            ctx->codec_params_.pp_attr.crop.y = ctx->crop.y;
+            ctx->codec_params_.pp_attr.crop.width  = ctx->crop.w;
+            ctx->codec_params_.pp_attr.crop.height = ctx->crop.h;
+        }
+        ret = cncodecDecSetParams(ctx->codec_handle_, &ctx->codec_params_);
+        if (ret != CNCODEC_SUCCESS) {
+            ret = print_cncodec_error(avctx, ret, "Set jdec params failed");
+            goto error;
+        }
+        if (ctx->resize_str || ctx->crop_str) {
+            avctx->width  = ctx->resize.width ? ctx->resize.width : ctx->crop.w;
+            avctx->height = ctx->resize.height? ctx->resize.height: ctx->crop.h;
+            avctx->coded_width = FFALIGN(avctx->width, JFRAME_STRIDE_ALIGN);
+            avctx->coded_height= avctx->height;
+        } else {
+            avctx->coded_width = FFALIGN(avctx->width, JFRAME_STRIDE_ALIGN);
+            avctx->coded_height= avctx->height;
+        }
+        if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+            if (ctx->resize_str || ctx->crop_str) {
+                ctx->hw_resize_frame_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+                if (!ctx->hw_resize_frame_ref) {
+                    av_log(avctx, AV_LOG_ERROR, "Alloc resize hwframe failed\n");
+                    ret = AVERROR(EINVAL);
+                    goto error;
+                }
+                resize_frame_ctx = (AVHWFramesContext*)ctx->hw_resize_frame_ref->data;
+                resize_frame_ctx->format    = AV_PIX_FMT_MLU;
+                resize_frame_ctx->sw_format = avctx->sw_pix_fmt;
+                resize_frame_ctx->width     = FFALIGN(avctx->coded_width, JFRAME_STRIDE_ALIGN);
+                resize_frame_ctx->height    = FFALIGN(avctx->coded_height,JFRAME_HEIGHT_ALIGN);
+                if ((ret = av_hwframe_ctx_init(ctx->hw_resize_frame_ref)) < 0) {
+                    av_log(avctx, AV_LOG_ERROR, "Init resize hwframe: av_hwframe_ctx_init failed\n");
+                    return 0;
+                }
+            } else {
+                if (!hwframe_ctx->pool) {
+                    hwframe_ctx->format = AV_PIX_FMT_MLU;
+                    hwframe_ctx->sw_format = avctx->sw_pix_fmt;
+                    hwframe_ctx->width  = FFALIGN(avctx->coded_width, JFRAME_STRIDE_ALIGN);
+                    hwframe_ctx->height = FFALIGN(avctx->coded_height,JFRAME_HEIGHT_ALIGN);
+                    if ((ret = av_hwframe_ctx_init(ctx->hw_frame_ref)) < 0) {
+                        av_log(avctx, AV_LOG_ERROR, "Error, hwframe ctx init failed\n");
+                        return AVERROR(EINVAL);
+                    }
+                }
+            }
+        }
+    } else {
+        if (!ctx->resize_str && !ctx->crop_str) {
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        } else if (!ctx->resize_str && ctx->crop_str) {
+            avctx->width  = ctx->crop.w;
+            avctx->height = ctx->crop.h;
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        } else {
+            avctx->width  = ctx->resize.width;
+            avctx->height = ctx->resize.height;
+            avctx->coded_width  = FFALIGN(avctx->width, ctx->stride_align);
+            avctx->coded_height = avctx->height;
+        }
+    }
+    if (mlu_device_affinity(ctx->hwdevice_ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "MLU device set affinity failed, func:%s, line:%d\n",
+            __func__, __LINE__);
+        exit(-1);
+    }
+
+    ctx->affinity_set = false;
+    ctx->decoder_init_flag = 1;
+    avctx->pkt_timebase.num = 1;
+    avctx->pkt_timebase.den = 90000;
+    if (!avctx->pkt_timebase.num || !avctx->pkt_timebase.den) {
+        av_log(avctx, AV_LOG_WARNING,
+        "Invalid pkt_timebase, passing timestamps as-is.\n");
+    }
+    av_log(avctx, AV_LOG_DEBUG,
+        "Decoder init done, thread: %lu \n", (long unsigned)pthread_self());
+
+    return 0;
+
+error:
+    sem_post(&ctx->eos_sema);
+    ff_cndec_decode_end(avctx);
+    return ret;
+}
+
+static void ff_cndec_flush(AVCodecContext *avctx) {
+    ff_cndec_decode_end(avctx);
+    ff_cndec_decode_init(avctx);
+}
+
+static av_cold void ff_cndec_init_static(struct AVCodec *codec) {
+    mlu_init_static(codec);
+}
+
+#define OFFSET(x) offsetof(MLUMPPContext_t, x)
+#define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",      "use to choose the accelerator card",     OFFSET(device_id),         AV_OPT_TYPE_INT, {.i64 = 0 }, 0, INT_MAX, VD }, \
+    { "mlu",            "use to choose the accelerator card",     OFFSET(device_id),         AV_OPT_TYPE_INT, {.i64 = 0 }, 0, INT_MAX, VD }, \
+    { "output_buf_num", "number of output buffers for decoder",   OFFSET(output_buf_num),    AV_OPT_TYPE_INT, {.i64 = 2 }, 1, 18,  VD }, \
+    { "stride_align",   "stride align of output buf for decoder", OFFSET(stride_align),      AV_OPT_TYPE_INT, {.i64 = 1 }, 0, 128, VD }, \
+    { "max_width",      "max width of decoder buffer",            OFFSET(max_width),         AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 8192,VD }, \
+    { "max_height",     "max height of decoder buffer",           OFFSET(max_height),        AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 4320,VD }, \
+    { "output_pixfmt",  "output pix fmt of decoder",              OFFSET(output_pixfmt),     AV_OPT_TYPE_STRING, {.str = "nv12" },0, 0, VD }, \
+    { "output_order",   "output decode frame order",              OFFSET(output_order),      AV_OPT_TYPE_STRING, {.str = "display" },0, 0, VD }, \
+    { "mem_async",      "use async memory copy mode",             OFFSET(mem_async),         AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1,  VD }, \
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "crop",   "Crop (left)x(top)x(width)x(height)", OFFSET(crop1_str),  AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "crop2",  "Crop (top)x(bottom)x(left)x(right)", OFFSET(crop2_str),  AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "resize", "Resize (width)x(height)",            OFFSET(resize_str), AV_OPT_TYPE_STRING, { .str = NULL }, 0, 0, VD },
+    { "trace",  "Whether open trace switch or not",   OFFSET(trace_flag), AV_OPT_TYPE_INT,    { .i64 = 0    }, 0, 3, VD },
+    { "compress_scale", "Set the scale value of the stream_buf_size based on the image size", OFFSET(compress_scale), AV_OPT_TYPE_FLOAT, { .dbl = 1.5f }, 0.f, 4.f, VD },
+#if FF_MLU_VERSION >= 3300
+    { "backend",        "hardware backend for image decoder",    OFFSET(image_dec_backend), AV_OPT_TYPE_INT,  { .i64 = CNCODEC_BACKEND_DEFAULT_HW },
+                                                            CNCODEC_BACKEND_DEFAULT_HW, CNCODEC_BACKEND_VPU_HW, VD,  "backend" },
+    { "default",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_DEFAULT_HW },     0,  0,  VD,  "backend" },
+    { "jpu",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_JPU_HW },         0,  0,  VD,  "backend" },
+    { "vpu",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_VPU_HW },         0,  0,  VD,  "backend" },
+#else
+    { "backend",        "hardware backend for image decoder",    OFFSET(image_dec_backend), AV_OPT_TYPE_INT, {.i64 = 0 }, 0, 2,   VD },
+#endif
+    { "dec_colorspace", "decode color space", OFFSET(color_space), AV_OPT_TYPE_INT, { .i64 = CNCODEC_COLOR_SPACE_BT_709 }, CNCODEC_COLOR_SPACE_BT_601, CNCODEC_COLOR_SPACE_BT_2020_ER, VD, "dec_colorspace"},
+    { "bt601",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601 },    0,  0,  VD,  "dec_colorspace" },
+    { "bt709",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709 },    0,  0,  VD,  "dec_colorspace" },
+    { "bt2020",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020 },   0,  0,  VD,  "dec_colorspace" },
+    { "bt601er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601_ER }, 0,  0,  VD,  "dec_colorspace" },
+    { "bt709er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709_ER }, 0,  0,  VD,  "dec_colorspace" },
+    { "bt2020er",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020_ER },0,  0,  VD,  "dec_colorspace" },
+    { NULL }
+};
+
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX | \
+                           AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+
+#define MLUMPP_DEC_CODEC(x, X) \
+    static const AVClass x##_mlumpp_class = { \
+        .class_name = #x "_mludec", \
+        .item_name = av_default_item_name, \
+        .option = options, \
+        .version = LIBAVUTIL_VERSION_INT, \
+    }; \
+    AVCodec ff_##x##_mlumpp_decoder = { \
+        .name           = #x "_mludec", \
+        .long_name      = NULL_IF_CONFIG_SMALL("Cambricon MLUMPP " #X " decoder"), \
+        .type           = AVMEDIA_TYPE_VIDEO, \
+        .id             = AV_CODEC_ID_##X, \
+        .priv_data_size = sizeof(MLUMPPContext_t), \
+        .priv_class     = &x##_mlumpp_class, \
+        .init           = ff_cndec_decode_init, \
+        .close          = ff_cndec_decode_end, \
+        .receive_frame  = ff_cndec_receive_frame, \
+        .flush          = ff_cndec_flush,  \
+        .init_static_data = ff_cndec_init_static, \
+        .capabilities   = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_HARDWARE, \
+        .pix_fmts       = (const enum AVPixelFormat[]) { AV_PIX_FMT_MLU,        \
+                        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, AV_PIX_FMT_YUV420P,   \
+                        AV_PIX_FMT_P010, AV_PIX_FMT_GRAY8, AV_PIX_FMT_GRAY8A,   \
+                        AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB, AV_PIX_FMT_BGRA,      \
+                        AV_PIX_FMT_RGBA, AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,    \
+                        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR, AV_PIX_FMT_RGB0, AV_PIX_FMT_BGR0, \
+                        AV_PIX_FMT_NONE },                                      \
+        .hw_configs     = mlu_hw_configs, \
+        .wrapper_name   = "mludec",       \
+    };
+
+#if CONFIG_HEVC_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(hevc, HEVC)
+#endif
+#if CONFIG_H264_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(h264, H264)
+#endif
+#if CONFIG_MJPEG_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(mjpeg, MJPEG)
+#endif
+#if CONFIG_VP8_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp8, VP8)
+#endif
+#if CONFIG_VP9_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(vp9, VP9)
+#endif
+#if CONFIG_AVS_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(avs, CAVS)
+#endif
+#if CONFIG_AVS2_MLUMPP_DECODER
+MLUMPP_DEC_CODEC(avs2, AVS2)
+#endif
diff --git a/libavcodec/mlumpp_enc_h264.c b/libavcodec/mlumpp_enc_h264.c
new file mode 100644
index 0000000000..92fee93a31
--- /dev/null
+++ b/libavcodec/mlumpp_enc_h264.c
@@ -0,0 +1,219 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencH264EncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencH264EncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencH264EncContext *cnctx =(CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+// static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+// {
+//     CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+//     return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+// }
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+{
+    CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencH264EncContext *cnctx = (CNencH264EncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+static av_cold void mlumpp_init_static(struct AVCodec *codec)
+{
+    mlu_init_static(codec);
+}
+
+static const AVCodecDefault h264_defaults[] = {
+    { "b",                "2M" },
+    { "bf",               "0"  },
+    { "g",                "30" },
+    { "qmin",             "0"  },
+    { "qmax",             "51" },
+    { "qdiff",            "-1" },
+    { "qblur",            "-1" },
+    { "qcomp",            "-1" },
+    { "refs",             "0"  },
+    { NULL },
+};
+
+#define OFFSET(x) offsetof(CNencH264EncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",      "accelerator card index",   OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "mlu",            "accelerator card index",   OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "stride_align",   "pic stride_align. the number MUST be a power of 2", OFFSET(cnenc.stride_align), AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 128,VE },        \
+    { "input_buf_num",  "input buffer num. value 0 means AUTOmatic. Manual setting value MUST greater than frame_interval_p + 1",                           \
+                                                    OFFSET(cnenc.input_buf_num),  AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "stream_buf_size","stream buffer size. value 0 means AUTOmatic",                                                                                      \
+                                                    OFFSET(cnenc.stream_buf_size),AV_OPT_TYPE_INT, { .i64 = 0 },  0,  INT_MAX, VE },                        \
+    { "frame_interval_p","the number of B frames between two P frames", OFFSET(cnenc.frame_interval_p), AV_OPT_TYPE_INT, { .i64 = 1 }, 0,  INT_MAX, VE },   \
+    { "mem_async",       "use async memory copy mode", OFFSET(cnenc.mem_async),   AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1,  VE },                               \
+    { "max_width",       "max input frame width",   OFFSET(cnenc.max_width),      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },                             \
+    { "max_height",      "max input frame height",  OFFSET(cnenc.max_height),     AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },                             \
+    { "forced_idr",      "force keyframes as IDR frames.", OFFSET(cnenc.forced_idr),AV_OPT_TYPE_BOOL,{ .i64 = 0 }, 0, 1,  VE },                             \
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "preset",             "encode preset mode", OFFSET(cnenc.preset), AV_OPT_TYPE_INT,  { .i64 = CNCODEC_ENC_PRESET_FAST }, CNCODEC_ENC_PRESET_FAST, CNCODEC_ENC_PRESET_MAX, VE, "preset"},
+    { "fast",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_FAST },    0,  0,  VE,  "preset" },
+    { "medium",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_MEDIUM },  0,  0,  VE,  "preset" },
+    { "slow",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_SLOW },    0,  0,  VE,  "preset" },
+
+    { "rdo_level",          "encode rdo level", OFFSET(cnenc.rdo_level), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 4, VE, "rdo_level"},
+
+    { "colorspace",         "encode color space", OFFSET(cnenc.color_space), AV_OPT_TYPE_INT, { .i64 = CNCODEC_COLOR_SPACE_BT_709 }, CNCODEC_COLOR_SPACE_BT_601, CNCODEC_COLOR_SPACE_BT_2020_ER, VE, "colorspace"},
+    { "bt601",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601 },    0,  0,  VE,  "colorspace" },
+    { "bt709",              "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709 },    0,  0,  VE,  "colorspace" },
+    { "bt2020",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020 },   0,  0,  VE,  "colorspace" },
+    { "bt601er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601_ER }, 0,  0,  VE,  "colorspace" },
+    { "bt709er",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709_ER }, 0,  0,  VE,  "colorspace" },
+    { "bt2020er",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020_ER }, 0,  0,  VE,  "colorspace" },
+
+    { "stream_type",        "encode output stream type.", OFFSET(cnenc.stream_type), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BYTE_STREAM }, CNCODEC_ENC_BYTE_STREAM, CNCODEC_ENC_STREAM_TYPE_MAX, VE, "stream_type"},
+    { "byte_stream",        "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BYTE_STREAM }, 0,  0,  VE,  "stream_type" },
+    { "nalu_stream",        "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_NALU_STREAM }, 0,  0,  VE,  "stream_type" },
+
+    { "rc",                 "encode output stream type.", OFFSET(cnenc.rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_RATE_CTRL_VBR }, CNCODEC_ENC_RATE_CTRL_CBR, CNCODEC_ENC_RATE_CTRL_MODE_MAX, VE, "rc"},
+    { "cbr",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CBR },           0,  0,  VE,  "rc" },
+    { "vbr",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_VBR },           0,  0,  VE,  "rc" },
+    { "cvbr",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CVBR },          0,  0,  VE,  "rc" },
+    { "crf",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CRF },           0,  0,  VE,  "rc" },
+    { "fixedqp",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_FIXEDQP },       0,  0,  VE,  "rc" },
+    { "mode_max",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_MODE_MAX },      0,  0,  VE,  "rc" },
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+    { "block_size",         "encode block size.", OFFSET(cnenc.block_size), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 }, CNCODEC_ENC_BLOCK_UNIT_64x64, CNCODEC_ENC_BLOCK_UNIT_MAX, VE, "block_size"},
+    { "64",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 },       0,  0, VE,   "block_size" },
+    { "32",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_32x32 },       0,  0, VE,   "block_size" },
+    { "16",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_16x16 },       0,  0, VE,   "block_size" },
+    { "block_max",          "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_MAX   },       0,  0, VE,   "block_size" },
+
+    { "ctb_rc",             "encode CTB RC mode.", OFFSET(cnenc.ctb_rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_CTB_RC_DISABLED }, CNCODEC_ENC_CTB_RC_DISABLED, CNCODEC_ENC_CTB_RC_MAX, VE, "ctb_rc"},
+    { "disable",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_DISABLED },              0,  0, VE,  "ctb_rc" },
+    { "sub",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_SUBJECTIVE_QUALITY },    0,  0, VE,  "ctb_rc" },
+    { "obj",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_OBJECTIVE_QUALITY  },    0,  0, VE,  "ctb_rc" },
+    { "both",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_BOTH   },                0,  0, VE,  "ctb_rc" },
+    { "ctb_rc_max",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_MAX    },                0,  0, VE,  "ctb_rc" },
+
+    { "target_quality",     "target quality, only works in rc mode crf", OFFSET(cnenc.target_quality), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 51, VE, "target_quality"},
+    { "lookahead",          "lookahead depth, value range [0] and [4 ,40], lower than 4 will be set as 0.", OFFSET(cnenc.lookahead_depth), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 40, VE, "lookahead_depth"},
+    { "ctb_row",            "ctb row qp step", OFFSET(cnenc.ctb_row_qp_step), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 64, VE, "ctb_row_qp_step"},
+    { "rc_qp_delta_range",  "specified the max delta qp value", OFFSET(cnenc.rc_qp_delta_range), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 15, VE, "rc_qp_delta_range"},
+    { "base_ctb",           "specifies the rc base ctb complexity in ctb rc", OFFSET(cnenc.rc_base_ctb_comp), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 30, VE, "ctb_row_qp_step"},
+#endif
+    { "rc_bufsize",         "vbv bufsize.", OFFSET(cnenc.rc_bufsize), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE, "bufsize"},
+
+    { "init_qpI",           "the QP for I frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_i), AV_OPT_TYPE_INT,      { .i64 = 30 },    0,  51, VE },
+    { "init_qpB",           "the QP for B frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_b), AV_OPT_TYPE_INT,      { .i64 = 32 },    0,  51, VE },
+    { "init_qpP",           "the QP for P frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_p), AV_OPT_TYPE_INT,      { .i64 = 32 },    0,  51, VE },
+    { "qp",                 "the initial QP value",                         OFFSET(cnenc.init_qp),    AV_OPT_TYPE_INT,      { .i64 = 27 },    -1, 51, VE },
+    { "rc_windows",         "the windows of rc to ensure bitrate",          OFFSET(cnenc.rc_windows), AV_OPT_TYPE_INT,      { .i64 = 100},    0,  400,VE },
+
+    { "profile",            "the encode profile. value range 0 to 3", OFFSET(cnenc.profile), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_PROFILE_H264_MAIN }, CNCODEC_ENC_PROFILE_H264_BASELINE, CNCODEC_ENC_PROFILE_H264_HIGH_10, VE, "profile"},
+    { "baseline",           "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_BASELINE },   0,  0,  VE,  "profile" },
+    { "main",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_MAIN },       0,  0,  VE,  "profile" },
+    { "high",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_HIGH },       0,  0,  VE,  "profile" },
+    { "high10",             "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_H264_HIGH_10 },    0,  0,  VE,  "profile" },
+
+    { "level",              "the encode level. value range 0 to 19", OFFSET(cnenc.level), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_LEVEL_H264_51 }, CNCODEC_ENC_LEVEL_H264_1, CNCODEC_ENC_LEVEL_H264_62, VE, "level"},
+    { "auto",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_13 },           0,  0,  VE,  "level" },
+    { "1",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1 },            0,  0,  VE,  "level" },
+    { "1.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1 },            0,  0,  VE,  "level" },
+    { "1b",                 "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1B },           0,  0,  VE,  "level" },
+    { "1.0b",               "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_1B },           0,  0,  VE,  "level" },
+    { "1.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_11 },           0,  0,  VE,  "level" },
+    { "1.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_12 },           0,  0,  VE,  "level" },
+    { "1.3",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_13 },           0,  0,  VE,  "level" },
+    { "2",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_2 },            0,  0,  VE,  "level" },
+    { "2.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_2 },            0,  0,  VE,  "level" },
+    { "2.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_21 },           0,  0,  VE,  "level" },
+    { "2.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_22 },           0,  0,  VE,  "level" },
+    { "3",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_3 },            0,  0,  VE,  "level" },
+    { "3.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_3 },            0,  0,  VE,  "level" },
+    { "3.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_31 },           0,  0,  VE,  "level" },
+    { "3.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_32 },           0,  0,  VE,  "level" },
+    { "4",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_4 },            0,  0,  VE,  "level" },
+    { "4.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_4 },            0,  0,  VE,  "level" },
+    { "4.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_41 },           0,  0,  VE,  "level" },
+    { "4.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_42 },           0,  0,  VE,  "level" },
+    { "5",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_5 },            0,  0,  VE,  "level" },
+    { "5.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_5 },            0,  0,  VE,  "level" },
+    { "5.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_51 },           0,  0,  VE,  "level" },
+    { "5.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_52 },           0,  0,  VE,  "level" },
+    { "6",                  "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_6 },            0,  0,  VE,  "level" },
+    { "6.0",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_6 },            0,  0,  VE,  "level" },
+    { "6.1",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_61 },           0,  0,  VE,  "level" },
+    { "6.2",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_H264_62 },           0,  0,  VE,  "level" },
+    { NULL },
+};
+static const AVClass class = {
+    .class_name = "h264_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX
+                         | AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_h264_mlumpp_encoder = {
+    .name             = "h264_mluenc",
+    .long_name        = NULL_IF_CONFIG_SMALL("H.264 ENCODER(Cambricon Video acceleration)"),
+    .type             = AVMEDIA_TYPE_VIDEO,
+    .id               = AV_CODEC_ID_H264,
+    .init             = mlumpp_enc_init,
+    .receive_packet   = mlumpp_enc_receive_packet,
+    .close            = mlumpp_enc_close,
+    .init_static_data = mlumpp_init_static,
+    .priv_data_size   = sizeof(CNencH264EncContext),
+    .priv_class       = &class,
+    .defaults         = h264_defaults,
+    .capabilities     = AV_CODEC_CAP_DELAY,
+    .caps_internal    = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts         = (const enum AVPixelFormat[]) {
+                        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, AV_PIX_FMT_YUV420P,
+                        AV_PIX_FMT_P010, AV_PIX_FMT_YUYV422, AV_PIX_FMT_UYVY422,
+                        AV_PIX_FMT_ARGB, AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+                        AV_PIX_FMT_ABGR, AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+                        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR, AV_PIX_FMT_RGB0, AV_PIX_FMT_BGR0,
+                        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE},
+    .wrapper_name     = "mluenc",
+    .hw_configs       = mlu_hw_configs,
+};
diff --git a/libavcodec/mlumpp_enc_hevc.c b/libavcodec/mlumpp_enc_hevc.c
new file mode 100644
index 0000000000..6676a84205
--- /dev/null
+++ b/libavcodec/mlumpp_enc_hevc.c
@@ -0,0 +1,230 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencHevcEncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencHevcEncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+
+// static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+// {
+//     CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+//     return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+// }
+
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt){
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencHevcEncContext *cnctx = (CNencHevcEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+
+static av_cold void mlumpp_init_static(struct AVCodec *codec)
+{
+    mlu_init_static(codec);
+}
+
+static const AVCodecDefault hevc_defaults[] = {
+    { "b",                "2M" },
+    { "bf",               "0"  },
+    { "g",                "30" },
+    { "qmin",             "0"  },
+    { "qmax",             "51" },
+    { "qdiff",            "-1" },
+    { "qblur",            "-1" },
+    { "qcomp",            "-1" },
+    { "refs",             "0"  },
+#if FF_API_CODER_TYPE
+    { "coder",            "-1" },
+#endif
+    { NULL },
+};
+
+#define OFFSET(x) offsetof(CNencHevcEncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+#define MLU3XX_COMMON_OPTS \
+    { "device_id",       "accelerator card index", OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "mlu",             "accelerator card index", OFFSET(cnenc.device_id),      AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "stride_align",    "pic stride_align. the number MUST be a power of 2", OFFSET(cnenc.stride_align), AV_OPT_TYPE_INT, { .i64 = 1 }, 1,  128, VE },  \
+    { "input_buf_num",   "input buffer num. value 0 means AUTOmatic(2pass proposed). Manual setting value MUST greater than frame_interval_p + 1.",      \
+                                                   OFFSET(cnenc.input_buf_num),  AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "stream_buf_size", "stream buffer size. value 0 means AUTOmatic",                                                                                  \
+                                                   OFFSET(cnenc.stream_buf_size),AV_OPT_TYPE_INT, { .i64 = 0 },  0, INT_MAX, VE },                       \
+    { "frame_interval_p","the number of B frames between two P frames", OFFSET(cnenc.frame_interval_p), AV_OPT_TYPE_INT, { .i64 = 1 }, 0,  INT_MAX, VE },\
+    { "mem_async",       "use async memory copy mode", OFFSET(cnenc.mem_async), AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1,  VE },                              \
+    { "max_width",       "max input frame width",   OFFSET(cnenc.max_width),    AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },                            \
+    { "max_height",      "max input frame height",  OFFSET(cnenc.max_height),   AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },                            \
+    { "forced_idr",      "force keyframes as IDR frames.", OFFSET(cnenc.forced_idr),AV_OPT_TYPE_BOOL,{ .i64 = 0 }, 0, 1,VE },                            \
+
+static const AVOption options[] = {
+    MLU3XX_COMMON_OPTS
+    { "preset",             "encode preset mode", OFFSET(cnenc.preset), AV_OPT_TYPE_INT,    { .i64 = CNCODEC_ENC_PRESET_FAST }, CNCODEC_ENC_PRESET_FAST, CNCODEC_ENC_PRESET_MAX, VE, "preset"},
+    { "fast",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_FAST },            0,  0, VE,  "preset" },
+    { "medium",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_MEDIUM },          0,  0, VE,  "preset" },
+    { "slow",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PRESET_SLOW },            0,  0, VE,  "preset" },
+
+    { "rdo_level",          "encode rdo level", OFFSET(cnenc.rdo_level), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 4, VE, "rdo_level"},
+
+    { "colorspace",         "encode colorspace.", OFFSET(cnenc.color_space), AV_OPT_TYPE_INT,{ .i64 = CNCODEC_COLOR_SPACE_BT_709 }, CNCODEC_COLOR_SPACE_BT_601, CNCODEC_COLOR_SPACE_BT_2020_ER, VE, "colorspace"},
+    { "bt601",              "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601 },         0,  0, VE,  "colorspace" },
+    { "bt709",              "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709 },         0,  0, VE,  "colorspace" },
+    { "bt2020",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020 },        0,  0, VE,  "colorspace" },
+    { "bt601er",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_601_ER },      0,  0, VE,  "colorspace" },
+    { "bt709er",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_709_ER },      0,  0, VE,  "colorspace" },
+    { "bt2020er",           "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_COLOR_SPACE_BT_2020_ER },     0,  0, VE,  "colorspace" },
+
+    { "stream_type",        "encode output stream type.", OFFSET(cnenc.stream_type), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BYTE_STREAM }, CNCODEC_ENC_BYTE_STREAM, CNCODEC_ENC_STREAM_TYPE_MAX, VE, "stream_type"},
+    { "byte_stream",        "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BYTE_STREAM },            0,  0, VE,  "stream_type" },
+    { "nalu_stream",        "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_NALU_STREAM },            0,  0, VE,  "stream_type" },
+
+    { "rc",                 "encode output stream type.", OFFSET(cnenc.rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_RATE_CTRL_VBR }, CNCODEC_ENC_RATE_CTRL_CBR, CNCODEC_ENC_RATE_CTRL_MODE_MAX, VE, "rc"},
+    { "cbr",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CBR },          0,  0, VE,  "rc" },
+    { "vbr",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_VBR },          0,  0, VE,  "rc" },
+    { "cvbr",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CVBR },         0,  0, VE,  "rc" },
+    { "crf",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_CRF },          0,  0, VE,  "rc" },
+    { "fixedqp",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_FIXEDQP },      0,  0, VE,  "rc" },
+    { "mode_max",           "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_RATE_CTRL_MODE_MAX },     0,  0, VE,  "rc" },
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+    { "block_size",         "encode block size.", OFFSET(cnenc.block_size), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 }, CNCODEC_ENC_BLOCK_UNIT_64x64, CNCODEC_ENC_BLOCK_UNIT_MAX, VE, "block_size"},
+    { "64",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_64x64 },       0,  0, VE,   "block_size" },
+    { "32",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_32x32 },       0,  0, VE,   "block_size" },
+    { "16",                 "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_16x16 },       0,  0, VE,   "block_size" },
+    { "8",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_8x8   },       0,  0, VE,   "block_size" },
+    { "block_max",          "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_BLOCK_UNIT_MAX   },       0,  0, VE,   "block_size" },
+
+    { "ctb_rc",             "encode CTB RC mode.", OFFSET(cnenc.ctb_rc_mode), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_CTB_RC_DISABLED }, CNCODEC_ENC_CTB_RC_DISABLED, CNCODEC_ENC_CTB_RC_MAX, VE, "ctb_rc"},
+    { "disable",            "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_DISABLED },              0,  0, VE,  "ctb_rc" },
+    { "sub",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_SUBJECTIVE_QUALITY },    0,  0, VE,  "ctb_rc" },
+    { "obj",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_OBJECTIVE_QUALITY  },    0,  0, VE,  "ctb_rc" },
+    { "both",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_BOTH   },                0,  0, VE,  "ctb_rc" },
+    { "ctb_rc_max",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_CTB_RC_MAX    },                0,  0, VE,  "ctb_rc" },
+
+    { "target_quality",     "target quality, only works in rc mode crf", OFFSET(cnenc.target_quality), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 51, VE, "target_quality"},
+    { "lookahead",          "lookahead depth, value range [0] and [4 ,40], lower than 4 will be set as 0.", OFFSET(cnenc.lookahead_depth), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 40, VE, "lookahead_depth"},
+    { "ctb_row",            "ctb row qp step, only works in obj and both ctb rc mode", OFFSET(cnenc.ctb_row_qp_step), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 64, VE, "ctb_row_qp_step"},
+    { "rc_qp_delta_range",  "specified the max delta qp value", OFFSET(cnenc.rc_qp_delta_range), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 15, VE, "rc_qp_delta_range"},
+    { "base_ctb",           "specifies the rc base ctb complexity in ctb rc, only works in sub and obj ctb rc mode", OFFSET(cnenc.rc_base_ctb_comp), AV_OPT_TYPE_INT,  { .i64 = 0 }, 0, 30, VE, "ctb_row_qp_step"},
+#endif
+    { "rc_bufsize",         "vbv bufsize.", OFFSET(cnenc.rc_bufsize), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE, "bufsize"},
+
+    { "init_qpI",           "set the QP for I frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_i),     AV_OPT_TYPE_INT, { .i64 = 30 },  0, 51, VE },
+    { "init_qpB",           "set the QP for B frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_b),     AV_OPT_TYPE_INT, { .i64 = 32 },  0, 51, VE },
+    { "init_qpP",           "set the QP for P frame while rc mode is fixedQP",  OFFSET(cnenc.const_qp_p),     AV_OPT_TYPE_INT, { .i64 = 30 },  0, 51, VE },
+    { "qp",                 "set the initial QP value",                         OFFSET(cnenc.init_qp),        AV_OPT_TYPE_INT, { .i64 = 27 },  0, 51, VE },
+    { "rc_windows",         "set the windows of rc to ensure bitrate",          OFFSET(cnenc.rc_windows),     AV_OPT_TYPE_INT, { .i64 = 60 },  0, INT_MAX, VE },
+    { "enable_sao",         "hevc encode params for enable sao",                OFFSET(cnenc.enable_sao),     AV_OPT_TYPE_INT, { .i64 = 1  },  0, 1,  VE },
+
+    { "profile",            "set the encoder profile. Effective value range 4 to 7", OFFSET(cnenc.profile), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN }, CNCODEC_ENC_PROFILE_HEVC_MAIN, CNCODEC_ENC_PROFILE_MAX, VE, "profile"},
+    { "main",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN },       0,  0, VE,  "profile" },
+    { "main_still",         "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN_STILL }, 0,  0, VE,  "profile" },
+    { "prof_max",           "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_MAX},              0,  0, VE,  "profile" },
+    { "main10",             "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_PROFILE_HEVC_MAIN_10 },    0,  0, VE,  "profile" },
+
+    { "tier",               "set the HEVC encoder tier. Effective value range 0 to 2", OFFSET(cnenc.tier), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_TIER_HEVC_MAIN }, CNCODEC_ENC_TIER_HEVC_MAIN, CNCODEC_ENC_TIER_HEVC_MAX, VE, "tier"},
+    { "main",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_MAIN },          0,  0, VE,  "tier" },
+#if CNCODEC_MAJOR_VERSION < 1
+    { "high",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_HIGHT },         0,  0, VE,  "tier" },
+#else
+    { "high",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_TIER_HEVC_HIGH },         0,  0, VE,  "tier" },
+#endif
+
+    { "level",              "set the encoder level. Effective value range 20 to 33", OFFSET(cnenc.level), AV_OPT_TYPE_INT, { .i64 = CNCODEC_ENC_LEVEL_HEVC_51 }, CNCODEC_ENC_LEVEL_HEVC_1, CNCODEC_ENC_LEVEL_MAX, VE, "level"},
+    { "auto",               "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "1",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_1 },            0,  0,  VE, "level" },
+    { "1.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_1 },            0,  0,  VE, "level" },
+    { "2",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_2 },            0,  0,  VE, "level" },
+    { "2.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_2 },            0,  0,  VE, "level" },
+    { "2.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_21 },           0,  0,  VE, "level" },
+    { "3",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_3 },            0,  0,  VE, "level" },
+    { "3.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_3 },            0,  0,  VE, "level" },
+    { "3.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_31 },           0,  0,  VE, "level" },
+    { "4",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_4 },            0,  0,  VE, "level" },
+    { "4.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_4 },            0,  0,  VE, "level" },
+    { "4.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_41 },           0,  0,  VE, "level" },
+    { "5",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "5.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_5 },            0,  0,  VE, "level" },
+    { "5.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_51 },           0,  0,  VE, "level" },
+    { "5.2",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_52 },           0,  0,  VE, "level" },
+    { "6",                  "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_6 },            0,  0,  VE, "level" },
+    { "6.0",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_6 },            0,  0,  VE, "level" },
+    { "6.1",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_61 },           0,  0,  VE, "level" },
+    { "6.2",                "",     0,     AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_ENC_LEVEL_HEVC_62 },           0,  0,  VE, "level" },
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "hevc_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX
+                         | AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_hevc_mlumpp_encoder = {
+    .name = "hevc_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("HEVC ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_HEVC,
+    .init = mlumpp_enc_init,
+    // .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    /*.encode2 = mlumpp_enc_frame,*/
+    .close = mlumpp_enc_close,
+    .init_static_data = mlumpp_init_static,
+    .priv_data_size = sizeof(CNencHevcEncContext),
+    .priv_class = &class,
+    .defaults = hevc_defaults,
+    .capabilities = AV_CODEC_CAP_DELAY,
+    .caps_internal = FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]) {AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+                AV_PIX_FMT_YUV420P, AV_PIX_FMT_P010, AV_PIX_FMT_YUYV422,
+                AV_PIX_FMT_UYVY422, AV_PIX_FMT_ARGB, AV_PIX_FMT_BGRA,
+                AV_PIX_FMT_RGBA,    AV_PIX_FMT_ABGR,
+                AV_PIX_FMT_RGB24,   AV_PIX_FMT_BGR24,
+                AV_PIX_FMT_0RGB,    AV_PIX_FMT_0BGR, AV_PIX_FMT_RGB0, AV_PIX_FMT_BGR0,
+                AV_PIX_FMT_MLU, AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
diff --git a/libavcodec/mlumpp_enc_jpeg.c b/libavcodec/mlumpp_enc_jpeg.c
new file mode 100644
index 0000000000..9a60b6ecf9
--- /dev/null
+++ b/libavcodec/mlumpp_enc_jpeg.c
@@ -0,0 +1,125 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#include "mlumpp_vid_enc.h"
+
+typedef struct _CNencJpegEncContext {
+    AVClass *class;
+    MLUMPPEncContext_t cnenc;
+} CNencJpegEncContext;
+
+static av_cold int mlumpp_enc_init(AVCodecContext *avctx)
+{
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_init(avctx, &cnctx->cnenc);
+}
+
+// static int mlumpp_enc_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+// {
+//     CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+//     return ff_mlumpp_enc_send_frame(avctx, &cnctx->cnenc, frame);
+// }
+
+static int mlumpp_enc_receive_packet(AVCodecContext *avctx, AVPacket *pkt){
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_receive_packet(avctx, &cnctx->cnenc, pkt);
+}
+
+static av_cold int mlumpp_enc_close(AVCodecContext *avctx)
+{
+    CNencJpegEncContext *cnctx = (CNencJpegEncContext*)avctx->priv_data;
+    return ff_mlumpp_enc_close(avctx, &cnctx->cnenc);
+}
+
+static av_cold void mlumpp_init_static(struct AVCodec *codec)
+{
+    mlu_init_static(codec);
+}
+
+#define OFFSET(x) offsetof(CNencJpegEncContext, x)
+#ifndef VE
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+#endif
+
+static const AVOption options[] = {
+    { "device_id",       "accelerator card index",      OFFSET(cnenc.device_id),       AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },
+    { "mlu",             "accelerator card index",      OFFSET(cnenc.device_id),       AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },
+    { "stride_align",    "pic stride_align. the number MUST be a power of 2",
+                                                        OFFSET(cnenc.stride_align),    AV_OPT_TYPE_INT, { .i64 = 1 }, 1, 128,     VE },
+    { "input_buf_num",   "input buffer num. value 0 means decided AUTOmatic",
+                                                        OFFSET(cnenc.input_buf_num),   AV_OPT_TYPE_INT, { .i64 = 2 }, 0, INT_MAX, VE },
+    { "stream_buf_size", "stream buffer size. value 0 means decided AUTOmatic",
+                                                        OFFSET(cnenc.stream_buf_size), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, VE },
+    { "quality",         "jpeg encoder picure quality", OFFSET(cnenc.quality),         AV_OPT_TYPE_INT, { .i64 = 80}, 1, INT_MAX, VE },
+    { "mem_async",       "use async memory copy mode",  OFFSET(cnenc.mem_async),       AV_OPT_TYPE_BOOL, {.i64 = 0 }, 0, 1,  VE },
+    { "max_width",       "max input frame width",       OFFSET(cnenc.max_width),       AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },
+    { "max_height",      "max input frame height",      OFFSET(cnenc.max_height),      AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 8192, VE },
+#if FF_MLU_VERSION >= 3300
+    { "backend",         "encode preset mode",          OFFSET(cnenc.image_enc_backend), AV_OPT_TYPE_INT,  { .i64 = CNCODEC_BACKEND_DEFAULT_HW },
+                                                            CNCODEC_BACKEND_DEFAULT_HW, CNCODEC_BACKEND_VPU_HW, VE,  "backend" },
+    { "default",            "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_DEFAULT_HW },     0,  0,  VE,  "backend" },
+    { "jpu",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_JPU_HW },         0,  0,  VE,  "backend" },
+    { "vpu",                "",     0,   AV_OPT_TYPE_CONST,  { .i64 = CNCODEC_BACKEND_VPU_HW },         0,  0,  VE,  "backend" },
+#endif
+    { NULL },
+};
+
+static const AVClass class = {
+    .class_name = "mjpeg_mluenc",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+static const AVCodecHWConfigInternal *mlu_hw_configs[] = {
+    &(const AVCodecHWConfigInternal) {
+        .public= {
+            .pix_fmt     = AV_PIX_FMT_MLU,
+            .methods     = AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX | AV_CODEC_HW_CONFIG_METHOD_HW_FRAMES_CTX
+                         | AV_CODEC_HW_CONFIG_METHOD_INTERNAL,
+            .device_type = AV_HWDEVICE_TYPE_MLU
+        },
+        .hwaccel = NULL,
+    },
+    NULL
+};
+AVCodec ff_mjpeg_mlumpp_encoder = {
+    .name = "mjpeg_mluenc",
+    .long_name = NULL_IF_CONFIG_SMALL("Jpeg ENCODER(Cambricon Video acceleration)"),
+    .type = AVMEDIA_TYPE_VIDEO,
+    .id = AV_CODEC_ID_MJPEG,
+    .init = mlumpp_enc_init,
+    // .send_frame = mlumpp_enc_send_frame,
+    .receive_packet = mlumpp_enc_receive_packet,
+    .close = mlumpp_enc_close,
+    .init_static_data = mlumpp_init_static,
+    .priv_data_size = sizeof(CNencJpegEncContext),
+    .priv_class = &class,
+    .capabilities = AV_CODEC_CAP_FRAME_THREADS | AV_CODEC_CAP_INTRA_ONLY,
+    .caps_internal = FF_CODEC_CAP_INIT_THREADSAFE | FF_CODEC_CAP_INIT_CLEANUP,
+    .pix_fmts = (const enum AVPixelFormat[]) {AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+                AV_PIX_FMT_YUV420P, AV_PIX_FMT_YUYV422,
+                AV_PIX_FMT_UYVY422, AV_PIX_FMT_ARGB, AV_PIX_FMT_BGRA,
+                AV_PIX_FMT_RGBA,    AV_PIX_FMT_ABGR,
+                AV_PIX_FMT_RGB24,   AV_PIX_FMT_BGR24,
+                AV_PIX_FMT_0RGB,    AV_PIX_FMT_0BGR, AV_PIX_FMT_RGB0, AV_PIX_FMT_BGR0,
+                AV_PIX_FMT_MLU,     AV_PIX_FMT_NONE},
+    .wrapper_name = "mluenc",
+    .hw_configs   = mlu_hw_configs,
+};
\ No newline at end of file
diff --git a/libavcodec/mlumpp_vid_enc.c b/libavcodec/mlumpp_vid_enc.c
new file mode 100644
index 0000000000..cf2a490f9e
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.c
@@ -0,0 +1,1166 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+// #include "config.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/avassert.h"
+#include "libavutil/mem.h"
+#include "libavutil/pixdesc.h"
+#include "encode.h"
+#include "internal.h"
+#include "packet_internal.h"
+
+#include "mlumpp_vid_enc.h"
+
+#define CN_JFRAME_ALIGN_H 16
+#define CN_JFRAME_ALIGN_W 64
+#define CN_VFRAME_ALIGN_W 1
+
+static int cnenc_params_checking(MLUMPPEncContext_t *ctx) {
+    AVCodecContext *avctx = ctx->avctx;
+    cncodecType_t codec_type;
+    cncodecEncCaps_t enc_caps = {0};
+    enum AVPixelFormat in_pixfmt;
+    int ret = 0, s_power = 0, align = 0;
+    codec_type = cncodec_get_cn_name_by_av_name(avctx->codec_id);
+    ret = cncodecEncGetCaps(codec_type, ctx->device_id, &enc_caps);
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Cnenc get caps failed, unsupport encode type:%s, ret(%d)\n",
+            avctx->codec->name, ret);
+        return -1;
+    }
+    if (!enc_caps.supported) {
+        av_log(avctx, AV_LOG_ERROR, "MLU unsupport encode type: %s\n",
+            avctx->codec->name);
+        return -1;
+    }
+    in_pixfmt = avctx->sw_pix_fmt >= 0 ? avctx->sw_pix_fmt : avctx->pix_fmt;
+    ret = cnenc_check_input_pixfmt(enc_caps.input_pixel_format_mask,
+          cncodec_get_cn_pixfmt_by_av_pixfmt(in_pixfmt));
+    if (ret != 0) {
+        av_log(avctx, AV_LOG_ERROR, "%s unsupport input pixfmt(%s)\n",
+            avctx->codec->name, av_get_pix_fmt_name(in_pixfmt));
+        return -1;
+    }
+    if (avctx->width < enc_caps.min_width || avctx->width > enc_caps.max_width ||
+        avctx->height< enc_caps.min_height|| avctx->height> enc_caps.max_height){
+        av_log(avctx, AV_LOG_ERROR,
+            "%s support resolution:%dx%d~%dx%d, but input:%dx%d\n", avctx->codec->name,
+            enc_caps.min_width, enc_caps.min_height, enc_caps.max_width,
+            enc_caps.max_height, avctx->width, avctx->height);
+        return -1;
+    }
+    align = ctx->stride_align;
+    if (align & (align - 1)) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Enc parames error, stride align must be a power of 2, now is %d\n",
+            ctx->stride_align);
+        return -1;
+    }
+    s_power = 0;
+    while (align > 1) {
+        align >>= 1;
+        s_power++;
+    }
+    av_log(avctx, AV_LOG_DEBUG, "stride align is the %d power of 2.\n", s_power);
+
+    return 0;
+}
+
+static inline unsigned int cnenc_fifo_elem_size(void)
+{
+    return sizeof(EventInfo_t);
+}
+
+static inline unsigned int cnenc_fifo_size(const AVFifoBuffer *fifo)
+{
+    return av_fifo_size(fifo) / cnenc_fifo_elem_size();
+}
+
+static int cnenc_is_fifo_empty(MLUMPPEncContext_t *cnctx)
+{
+    int is_fifo_empty = 0;
+    ff_mutex_lock(&cnctx->queue_mutex);
+    is_fifo_empty = (cnenc_fifo_size(cnctx->frame_queue) == 0);
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    return is_fifo_empty;
+}
+
+static inline void cnenc_timestamp_queue_push(
+    AVFifoBuffer* queue, int64_t timestamp) {
+    av_fifo_generic_write(queue, &timestamp, sizeof(timestamp), NULL);
+    return;
+}
+
+static inline int64_t cnenc_timestamp_queue_pop(AVFifoBuffer* queue) {
+    int64_t timestamp = AV_NOPTS_VALUE;
+    if (av_fifo_size(queue) > 0) {
+        av_fifo_generic_read(queue, &timestamp, sizeof(timestamp), NULL);
+    }
+    return timestamp;
+}
+
+static int cnenc_set_packet_timestamp(MLUMPPEncContext_t *cnctx,
+    EventInfo_t *info, AVPacket *pkt) {
+    int64_t ts0, ts1, tsbase;
+    AVCodecContext *avctx = cnctx->avctx;
+    pkt->pts = info->stream.pts;
+    if (avctx->max_b_frames > 0 && !cnctx->first_pts_out
+        && cnctx->initial_pts[1] != AV_NOPTS_VALUE) {
+        ts0 = cnctx->initial_pts[0];
+        ts1 = cnctx->initial_pts[1];
+        if ((ts0 < 0 && ts1 > INT64_MAX + ts0) || (ts0 > 0 && ts1 < INT64_MIN + ts0))
+            return AVERROR(ERANGE);
+        tsbase = ts1 - ts0;
+        if ((tsbase < 0 && ts0 > INT64_MAX + tsbase) || (tsbase > 0 && ts0 < INT64_MIN + tsbase))
+            return AVERROR(ERANGE);
+        pkt->dts = ts0 - tsbase;
+        cnctx->first_pts_out = 1;
+        return 0;
+    }
+    pkt->dts = cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+    cnctx->first_pts_out = 1;
+    return 0;
+}
+
+static int cnenc_get_extradata(MLUMPPEncContext_t *cnctx,
+                               cncodecStream_t *stream) {
+    int ret = 0;
+    int out_size = 0;
+    AVCodecContext *avctx = cnctx->avctx;
+    MluContext *mlu_ctx = cnctx->mlu_ctx;
+
+    out_size = stream->data_len;
+    avctx->extradata_size = stream->data_len;
+    avctx->extradata = av_mallocz(out_size + AV_INPUT_BUFFER_PADDING_SIZE);
+    if (!avctx->extradata) {
+        return AVERROR(ENOMEM);
+    }
+    if (cnctx->mem_async) {
+        ret = mlu_ctx->mluMemcpyD2HAsync(avctx->extradata,
+                (void*)(stream->mem_addr + stream->data_offset), stream->data_len,
+                cnctx->mlu_queue, CNRT_MEM_TRANS_DIR_DEV2HOST);
+        mlu_ctx->mluQueueSync(cnctx->mlu_queue);
+    } else {
+        ret = mlu_ctx->mluMemcpyD2H(avctx->extradata, (void*)(stream->mem_addr + stream->data_offset),
+                stream->data_len, CNRT_MEM_TRANS_DIR_DEV2HOST);
+    }
+    if (CNRT_RET_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR,
+            "Cnenc get extradata error, func:%s, line:%d\n", __func__, __LINE__);
+        return AVERROR(EINVAL);
+    }
+    return 0;
+}
+
+static int cnenc_process_new_frame_event(cncodecEventType_t evt_type, void *user_data, void *info)
+{
+    EventInfo_t msg;
+    cnrtRet_t cnrt_ret;
+    int ret = 0, extra_offset = 0;
+    MLUMPPEncContext_t *cnctx = (MLUMPPEncContext_t *)user_data;
+    cncodecStream_t *stream = ((cncodecStream_t*)info);
+    MluContext *mlu_ctx = cnctx->mlu_ctx;
+    msg.event_type  = evt_type;
+    memcpy(&msg.stream, stream, sizeof(cncodecStream_t));
+
+    if (NULL == (void*)(stream->mem_addr + stream->data_offset) || stream->data_len <= 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "new_frame event invalid buffer address or data len\n");
+        return -1;
+    }
+    if ((CNCODEC_NALU_TYPE_I == stream->stream_type || CNCODEC_NALU_TYPE_IDR == stream->stream_type)
+        && cnctx->first_iframe && !cnctx->forced_idr) {
+        extra_offset = cnctx->avctx->extradata_size;
+    }
+    msg.buf_size = stream->data_len + extra_offset;
+    msg.buf = av_mallocz(msg.buf_size);
+    if (NULL == msg.buf) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "failed to allocte cpu buffer for stream data\n");
+        return -1;
+    }
+    if (extra_offset && cnctx->first_iframe) {
+        cnctx->first_iframe = false;
+        memcpy((void*)msg.buf, cnctx->avctx->extradata, extra_offset);
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "enc insert header before first Iframe\n");
+    }
+    ff_mutex_lock(&cnctx->queue_mutex);
+    if (cnctx->mem_async) {
+        cnrt_ret = mlu_ctx->mluMemcpyD2HAsync((void*)(msg.buf + extra_offset),
+                (void*)(stream->mem_addr + stream->data_offset), stream->data_len,
+                cnctx->mlu_queue, CNRT_MEM_TRANS_DIR_DEV2HOST);
+        mlu_ctx->mluQueueSync(cnctx->mlu_queue);
+    } else {
+        cnrt_ret = mlu_ctx->mluMemcpyD2H((void*)(msg.buf + extra_offset),
+                (void*)(stream->mem_addr + stream->data_offset), stream->data_len,
+                CNRT_MEM_TRANS_DIR_DEV2HOST);
+    }
+    if (0 != cnrt_ret) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "enc d2h failed, ret(%u), func:%s, line:%d\n",
+            cnrt_ret, __func__, __LINE__);
+        cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+        ret = -1;
+    }
+    if (0 == ret) {
+        av_fifo_generic_write(cnctx->frame_queue, &msg, sizeof(EventInfo_t), NULL);
+    }
+    ff_mutex_unlock(&cnctx->queue_mutex);
+
+    return ret;
+}
+
+static int cnenc_event_cb(cncodecEventType_t eventType, void *pUserData, void *cbInfo)
+{
+    EventInfo_t msg;
+    cncodecStream_t *stream;
+    MLUMPPEncContext_t *cnctx = (MLUMPPEncContext_t *)pUserData;
+    msg.event_type = eventType;
+    if (!cnctx->handle) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Callback func can't find cnctx handle!\n");
+        sem_post(&cnctx->eos_sema);
+        return -1;
+    }
+    if (!cnctx->affinity_set_c && mlu_device_affinity(cnctx->hw_device_ctx) < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "MLU device set affinity failed, func:%s, line:%d\n",
+            __func__, __LINE__);
+        exit(-1);
+    }
+
+    switch (eventType) {
+    case CNCODEC_EVENT_NEW_FRAME:
+        stream = ((cncodecStream_t*)cbInfo);
+        if (stream->stream_type == CNCODEC_NALU_TYPE_EOS) {
+            break;
+        }
+        if (!cnctx->extradata_ready && cnctx->avctx->codec_id != AV_CODEC_ID_MJPEG &&
+            (stream->stream_type == CNCODEC_H264_NALU_TYPE_SPS_PPS ||
+             stream->stream_type == CNCODEC_HEVC_NALU_TYPE_VPS_SPS_PPS)) {
+            cnctx->affinity_set_c = true;
+            if (cnenc_get_extradata(cnctx, (cncodecStream_t *)cbInfo)) {
+                return -1;
+            }
+            cnctx->extradata_ready = true;
+            cnctx->first_iframe    = true;
+            sem_post(&(cnctx->header_sema));
+            break;
+        }
+        if (cnenc_process_new_frame_event(eventType, pUserData, cbInfo)) {
+            return -1;
+        }
+        break;
+    case CNCODEC_EVENT_EOS:
+        msg.stream.stream_type = CNCODEC_NALU_TYPE_EOS;
+        msg.stream.data_len = 0;
+        msg.stream.mem_addr = msg.stream.data_offset = msg.stream.alloc_len = 0;
+        ff_mutex_lock(&cnctx->queue_mutex);
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "eos event, write eos frame into queue\n");
+        av_fifo_generic_write(cnctx->frame_queue, &msg, sizeof(EventInfo_t), NULL);
+        if (!cnctx->eos_post_flag) {
+            cnctx->eos_post_flag = 1;
+        }
+        ff_mutex_unlock(&cnctx->queue_mutex);
+        sem_post(&cnctx->eos_sema);
+        break;
+    case CNCODEC_EVENT_OUT_OF_MEMORY:
+    case CNCODEC_EVENT_STREAM_NOT_SUPPORTED:
+    default:
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Enc got error eventType:%d, abort\n", eventType);
+        if (!cnctx->codec_abort_flag) {
+            sem_post(&cnctx->eos_sema);
+            cnctx->codec_abort_flag = 1;
+        }
+        break;
+    }
+
+    return 0;
+}
+
+static int cnenc_memcpy_block(MLUMPPEncContext_t *cnctx,
+    void *dst, void *src, size_t data_size) {
+    MluContext *mlu_ctx = NULL;
+    cnrtRet_t cnrt_ret;
+
+    mlu_ctx = cnctx->mlu_ctx;
+    if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        if (cnctx->mem_async) {
+            cnrt_ret = mlu_ctx->mluMemcpyD2DAsync(dst, src, data_size, cnctx->mlu_queue,
+                    CNRT_MEM_TRANS_DIR_DEV2DEV);
+            MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy D2DA");
+        } else {
+            cnrt_ret = mlu_ctx->mluMemcpyD2D(dst, src, data_size, CNRT_MEM_TRANS_DIR_DEV2DEV);
+            MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy D2D");
+        }
+    } else {
+        if (cnctx->mem_async) {
+            cnrt_ret = mlu_ctx->mluMemcpyH2DAsync(dst, src, data_size, cnctx->mlu_queue,
+                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy H2DA");
+        } else {
+            cnrt_ret = mlu_ctx->mluMemcpyH2D(dst, src, data_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy H2D");
+        }
+    }
+    return 0;
+}
+
+static int cnenc_memcpy_by_line(MLUMPPEncContext_t *cnctx, void *dst, void *src,
+    size_t data_size, int cnframe_stride, int avlinesize, int width) {
+    cnrtRet_t cnrt_ret;
+    int linecount, line_index;
+    uint8_t *dst_ptr = NULL;
+    uint8_t *src_ptr = NULL;
+    uint8_t *line_space = NULL;
+    MluContext *mlu_ctx = NULL;
+
+    mlu_ctx = cnctx->mlu_ctx;
+    linecount = data_size / avlinesize;
+
+    line_space = (uint8_t*)malloc(cnframe_stride * linecount);
+    if (NULL == line_space) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "input buf memcpy malloc failed!\n");
+        return AVERROR(EINVAL);
+    }
+    memset(line_space, 0, cnframe_stride * linecount);
+
+    if (cnctx->avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        for (line_index = 0; line_index < linecount; ++line_index) {
+            dst_ptr = (uint8_t*)(dst) + cnframe_stride * line_index;
+            src_ptr = (uint8_t*)(src) + avlinesize * line_index;
+            if (cnctx->mem_async) {
+                cnrt_ret = mlu_ctx->mluMemcpyD2DAsync((void*)dst_ptr, (void*)src_ptr,
+                        width, cnctx->mlu_queue, CNRT_MEM_TRANS_DIR_DEV2DEV);
+            } else {
+                cnrt_ret = mlu_ctx->mluMemcpyD2D((void*)dst_ptr, (void*)src_ptr,
+                        width, CNRT_MEM_TRANS_DIR_DEV2DEV);
+            }
+            if (0 != cnrt_ret) {
+                free(line_space);
+                MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy D2D");
+            }
+        }
+    } else {
+        for (line_index = 0; line_index < linecount; ++line_index) {
+            src_ptr = (uint8_t*)(src) + avlinesize * line_index;
+            memcpy(line_space + cnframe_stride * line_index, src_ptr, width);
+        }
+        if (cnctx->mem_async) {
+            cnrt_ret = mlu_ctx->mluMemcpyH2DAsync(dst, (void*)line_space, cnframe_stride * linecount,
+                    cnctx->mlu_queue, CNRT_MEM_TRANS_DIR_HOST2DEV);
+        } else {
+            cnrt_ret = mlu_ctx->mluMemcpyH2D(dst, (void*)line_space, cnframe_stride * linecount,
+                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+        }
+        if (0 != cnrt_ret) {
+            free(line_space);
+            MLUMPP_CHECK(cnctx->avctx, cnrt_ret, "input buf memcpy H2D");
+        }
+    }
+    if (cnctx->mem_async) {
+        mlu_ctx->mluQueueSync(cnctx->mlu_queue);
+    }
+    free(line_space);
+    return 0;
+}
+
+static int cnenc_build_input_buffer(MLUMPPEncContext_t *cnctx,
+    cncodecFrame_t *tempInput, const AVFrame *frame)
+{
+    int ret = -1;
+    cncodecPixelFormat_t pix_fmt;
+    int plane_sum;
+    int plane_i;
+    int cnframe_stride;
+    int avlinesize;
+    float w_depth;
+    float h_depth;
+
+    pix_fmt = cnctx->enc_attr.pixel_format;
+    plane_sum = cncodec_get_plane_num(pix_fmt);
+    ret = cncodecEncWaitAvailInputBuf(cnctx->handle, tempInput, CN_TIMEOUT_VALUE);
+    MLUMPP_CHECK(cnctx->avctx, ret, "wait avail input buf");
+    for (plane_i = 0; plane_i < plane_sum; ++plane_i) {
+        if (!tempInput->plane[plane_i].dev_addr) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Enc input buffer dst address is NULL\n");
+            return AVERROR(EINVAL);
+        }
+        if (NULL == frame->data[plane_i]) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Enc input data src address is NULL\n");
+            return AVERROR(EINVAL);
+        }
+    }
+    for (plane_i = 0; plane_i < plane_sum; ++plane_i) {
+        cnframe_stride = tempInput->plane[plane_i].stride;
+        avlinesize = frame->linesize[plane_i];
+        if (cncodec_get_plane_depth(pix_fmt, plane_i, &w_depth, &h_depth)) {
+            av_log(cnctx->avctx, AV_LOG_ERROR, "Unsupported pix format!\n");
+        }
+        if (cnframe_stride == avlinesize) {
+            ret = cnenc_memcpy_block(cnctx, (void *)tempInput->plane[plane_i].dev_addr,
+                    (void *)frame->data[plane_i], avlinesize * frame->height * h_depth);
+        } else {
+            av_log(cnctx->avctx, AV_LOG_WARNING,
+                "Warning: data is not aligned, dst stride:%d, src stride:%d\n",
+                cnframe_stride, avlinesize);
+            ret = cnenc_memcpy_by_line(cnctx, (void *)tempInput->plane[plane_i].dev_addr,
+                (void *)frame->data[plane_i], avlinesize * frame->height * h_depth,
+                cnframe_stride, avlinesize, frame->width * w_depth);
+        }
+        if (ret)
+            break;
+    }
+    if (cnctx->mem_async) {
+        cnctx->mlu_ctx->mluQueueSync(cnctx->mlu_queue);
+    }
+
+    return ret;
+}
+
+static int cnenc_output_packet(MLUMPPEncContext_t *cnctx, AVPacket *pkt, int *got_packet)
+{
+    int ret = 0;
+    EventInfo_t info;
+    enum AVPictureType pict_type = AV_PICTURE_TYPE_NONE;
+    if (cnenc_is_fifo_empty(cnctx)) {
+        *got_packet = 0;
+        return AVERROR(EAGAIN);
+    }
+    ff_mutex_lock(&cnctx->queue_mutex);
+    av_fifo_generic_read(cnctx->frame_queue, &info, sizeof(EventInfo_t), NULL);
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    if (CNCODEC_EVENT_EOS == info.event_type) {
+        memset(&info, 0, sizeof(info));
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "output eos frame\n");
+        return AVERROR_EOF;
+    }
+
+    ret = av_packet_from_data(pkt, info.buf, info.buf_size);
+    if (ret < 0) {
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Failed to allocate pkt memory\n");
+        *got_packet = 0;
+        cnenc_timestamp_queue_pop(cnctx->timestamp_queue);
+        return AVERROR(EINVAL);
+    }
+
+    *got_packet = 1;
+    switch (info.stream.stream_type) {
+    case CNCODEC_NALU_TYPE_IDR:
+    case CNCODEC_NALU_TYPE_I:
+        pkt->flags |= AV_PKT_FLAG_KEY;
+        pict_type = AV_PICTURE_TYPE_I;
+        break;
+    case CNCODEC_NALU_TYPE_P:
+        pict_type = AV_PICTURE_TYPE_P;
+        break;
+    case CNCODEC_NALU_TYPE_B:
+        pict_type = AV_PICTURE_TYPE_B;
+        break;
+    case CNCODEC_HEVC_NALU_TYPE_VPS_SPS_PPS:
+    case CNCODEC_H264_NALU_TYPE_SPS_PPS:
+        pkt->pts = 0;
+        pkt->dts = -1;
+        av_log(cnctx->avctx, AV_LOG_DEBUG, "enc get output pkt sps/pps, type:%d\n",
+            info.stream.stream_type);
+        break;
+    case CNCODEC_NALU_TYPE_EOS:
+        pkt->pts = cnctx->top_pts + 1;
+        pkt->dts = cnctx->top_dts + 1;
+        break;
+    case CNCODEC_NALU_TYPE_UNKNOWN:
+    default:
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Error picture type encountered, type:%d\n",
+            info.stream.stream_type);
+        break;
+    }
+#if FF_API_CODED_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    cnctx->avctx->coded_frame->pict_type = pict_type;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    if (pict_type == AV_PICTURE_TYPE_I || pict_type == AV_PICTURE_TYPE_P ||
+        pict_type == AV_PICTURE_TYPE_B) {
+        ret = cnenc_set_packet_timestamp(cnctx, &info, pkt);
+        if (ret != 0) {
+            av_log(cnctx->avctx, AV_LOG_ERROR,
+                "Set timestamp failed! Please check encoder params!\n");
+            return ret;
+        }
+        cnctx->top_pts = pkt->pts;
+        cnctx->top_dts = pkt->dts;
+    }
+
+    return 0;
+}
+
+static int cnenc_reconfig_encoder(MLUMPPEncContext_t *cnctx, const AVFrame *frame) {
+    AVCodecContext *avctx = cnctx->avctx;
+    cncodecEncParam_t enc_params;
+    cncodecEncReconfigFlag_t enc_reconfig;
+    bool need_reconfig  = false;
+    bool bitrate_change = false;
+    int ret;
+    enc_params = cnctx->enc_attr;
+
+    if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        return 0;
+    }
+    if (avctx->width > cnctx->max_width || avctx->height > cnctx->max_height ||
+        frame->width > cnctx->max_width || frame->height > cnctx->max_height) {
+        av_log(avctx, AV_LOG_ERROR, "frame size exceeds maximum size[%d,%d]\n",
+            cnctx->max_width, cnctx->max_height);
+        exit(-1);
+    }
+    if (avctx->width != enc_params.pic_width || avctx->height != enc_params.pic_height ||
+        frame->width != enc_params.pic_width || frame->height != enc_params.pic_height) {
+        av_log(avctx, AV_LOG_WARNING,
+            "frame size change from [%d, %d] to avctx[%d, %d], frame[%d, %d]\n",
+            enc_params.pic_width, enc_params.pic_height,
+            avctx->width, avctx->height, frame->width, frame->height);
+        if (avctx->width != frame->width || avctx->height != frame->height) {
+            av_log(avctx, AV_LOG_ERROR, "frame size not equal to avctx size\n");
+            exit(-1);
+        }
+        enc_params.pic_width = avctx->width;
+        enc_params.pic_height= avctx->height;
+        need_reconfig = true;
+    }
+    if ((avctx->framerate.den > 0 && avctx->framerate.num > 0) &&
+        (avctx->framerate.den != enc_params.frame_rate_den ||
+        avctx->framerate.num != enc_params.frame_rate_num)) {
+        av_log(avctx, AV_LOG_WARNING, "framerate change from [%d, %d] to [%d, %d]\n",
+            enc_params.frame_rate_den, enc_params.frame_rate_num,
+            avctx->framerate.den, avctx->framerate.num);
+        enc_params.frame_rate_den = avctx->framerate.den;
+        enc_params.frame_rate_num = avctx->framerate.num;
+        need_reconfig = true;
+    }
+    if (cnctx->rc_mode != CNCODEC_ENC_RATE_CTRL_CRF &&
+        cnctx->rc_mode != CNCODEC_ENC_RATE_CTRL_FIXEDQP) {
+        if (avctx->bit_rate > 0 &&
+            avctx->bit_rate != enc_params.coding_attr.rc_attr.target_bitrate) {
+            av_log(avctx, AV_LOG_WARNING, "bitrate change from %d to %ld\n",
+                enc_params.coding_attr.rc_attr.target_bitrate, avctx->bit_rate);
+            enc_params.coding_attr.rc_attr.target_bitrate = avctx->bit_rate;
+            need_reconfig = true;
+            bitrate_change = true;
+        }
+        if (avctx->rc_buffer_size > 0 &&
+            avctx->rc_buffer_size != enc_params.coding_attr.rc_attr.vbv_buffer_size) {
+            av_log(avctx, AV_LOG_WARNING, "rc_buf_size change from %d to %d\n",
+                enc_params.coding_attr.rc_attr.vbv_buffer_size, avctx->rc_buffer_size);
+            enc_params.coding_attr.rc_attr.vbv_buffer_size = avctx->rc_buffer_size;
+            need_reconfig = true;
+        } else {
+            if (bitrate_change && cnctx->rc_mode == CNCODEC_ENC_RATE_CTRL_CBR) {
+                enc_params.coding_attr.rc_attr.vbv_buffer_size = avctx->bit_rate * 2;
+                avctx->rc_buffer_size = avctx->bit_rate * 2;
+            }
+        }
+    }
+
+    if (need_reconfig) {
+        cnctx->enc_attr = enc_params;
+        cnctx->extradata_ready = false;
+        enc_reconfig.reset_encoder = 1;
+        ret = cncodecEncSetParams(cnctx->handle, &enc_params, &enc_reconfig);
+        if (ret != CNCODEC_SUCCESS) {
+            av_log(avctx, AV_LOG_ERROR, "failed to reconfigure cnencoder, ret:%d\n", ret);
+        }
+    }
+    return need_reconfig;
+}
+
+int ff_mlumpp_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame)
+{
+    cncodecFrame_t input_frame;
+    cncodecEncPicAttr_t frame_attr;
+    int ret = -1;
+    memset(&frame_attr, 0, sizeof(frame_attr));
+    if (NULL == avctx || NULL == cnctx || !cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in func: ff_mlumpp_enc_send_frame\n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_FATAL,
+            "encoder got abort flag before send frame, return AVERROR_EXTERNAL");
+        return AVERROR_EXTERNAL;
+    }
+    if (!cnctx->handle) {
+        av_log(avctx, AV_LOG_WARNING, "Enc handle is NULL, guess couldn't create encode\n");
+        return AVERROR(EINVAL);
+    }
+    if (!cnctx->affinity_set_r && mlu_device_affinity(cnctx->hw_device_ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR,
+            "MLU device set affinity failed, func:%s, line:%d\n", __func__, __LINE__);
+        exit(-1);
+    }
+    cnctx->affinity_set_r = true;
+    if (frame && frame->buf[0] && !cnctx->encoder_flushing) {
+        av_log(avctx, AV_LOG_DEBUG, "Send frame size: %ux%u, pts:%ld, frame type:%d\n",
+            frame->width, frame->height, frame->pts, frame->pict_type);
+        // cnenc_reconfig_encoder(cnctx, frame);
+        if (cnenc_reconfig_encoder(cnctx, frame)) {
+            frame_attr.vid_pic_attr.force_idr = 1;
+        } else {
+            frame_attr.vid_pic_attr.force_idr =
+                (cnctx->forced_idr > 0 && frame->pict_type == AV_PICTURE_TYPE_I) ? 1 : 0;
+        }
+        memset(&input_frame, 0, sizeof(input_frame));
+        input_frame.width = frame->width;
+        input_frame.height = frame->height;
+        input_frame.pixel_format = cnctx->enc_attr.pixel_format;
+        input_frame.color_space  = cnctx->enc_attr.color_space;
+        input_frame.pts = frame->pts;
+        // main_still only support 1 frame encode
+        if (cnctx->frame_send_sum >=1 && CNCODEC_ENC_PROFILE_HEVC_MAIN_STILL == cnctx->profile) {
+            av_log(avctx, AV_LOG_ERROR,
+                "HEVC main_still mode can only support encoding 1 frame! \n");
+            MLUMPP_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Send EOS");
+            cnctx->encoder_flushing = 1;
+            return 0;
+        }
+        ret = cnenc_build_input_buffer(cnctx, &input_frame, frame);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_WARNING,
+                "Get cnencode build std buffer failed, ret(%d)\n", ret);
+            return AVERROR(EAGAIN);
+        }
+        if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+            frame_attr.jpg_pic_attr.jpeg_param.quality = cnctx->quality;
+        }
+        // else {
+        //     frame_attr.vid_pic_attr.force_idr =
+        //         (cnctx->forced_idr > 0 && frame->pict_type == AV_PICTURE_TYPE_I) ? 1 : 0;
+        // }
+        ret = cncodecEncSendFrame(cnctx->handle, &input_frame, &frame_attr, CN_TIMEOUT_VALUE);
+        MLUMPP_CHECK(cnctx->avctx, ret, "Enc send frame failed");
+        cnenc_timestamp_queue_push(cnctx->timestamp_queue, frame->pts);
+        if (cnctx->initial_pts[0] == AV_NOPTS_VALUE) {
+            cnctx->initial_pts[0] = frame->pts;
+        } else if (cnctx->initial_pts[1] == AV_NOPTS_VALUE) {
+            cnctx->initial_pts[1] = frame->pts;
+        }
+        cnctx->frame_send_sum++;
+        return 0;
+    } else {
+        av_log(avctx, AV_LOG_DEBUG, "Send null data(eos) to encoder\n");
+        MLUMPP_CHECK(cnctx->avctx, cncodecEncSetEos(cnctx->handle), "Send EOS");
+
+        cnctx->encoder_flushing = 1;
+        return avctx->codec_id == AV_CODEC_ID_MJPEG ? AVERROR_EOF : 0;
+    }
+    av_log(avctx, AV_LOG_WARNING, "Both valid frame and eos were sent, skip send functions\n");
+
+    return AVERROR_EOF;
+}
+
+int ff_mlumpp_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt)
+{
+    int ret = -1;
+    int got_packet = 0;
+    int waittime;
+    bool jpeg_send_eof = false;
+    AVFrame *frame = cnctx->frame;
+
+    if (NULL == avctx || NULL == cnctx || !cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_receive_packet \n");
+        return AVERROR_EXTERNAL;
+    }
+    if (cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_FATAL,
+            "Encode got abort before receiving packet, return error\n");
+        return AVERROR_EXTERNAL;
+    }
+    if (!frame->buf[0]) {
+        ret = ff_encode_get_frame(avctx, frame);
+        if (ret < 0 && ret != AVERROR_EOF) {
+            return ret;
+        } else if (ret == AVERROR_EOF) {
+            frame = NULL;
+        }
+    }
+    ret = ff_mlumpp_enc_send_frame(avctx, cnctx, frame);
+    if (ret < 0 && AVERROR_EOF != ret && AVERROR(EAGAIN) != ret) {
+        return ret;
+    } else {
+        av_frame_unref(frame);
+        if (AVERROR_EOF == ret) jpeg_send_eof = true;
+    }
+
+    if (avctx->codec_id == AV_CODEC_ID_MJPEG) {
+        waittime = CN_TIMEOUT_VALUE;
+        while (waittime > 0) {
+            ret = cnenc_output_packet(cnctx, pkt, &got_packet);
+            if (!ret) {
+                cnctx->pkt_recv_sum += 1;
+                return ret;
+            } else if (ret == AVERROR(EAGAIN)) {
+                if (cnctx->pkt_recv_sum == cnctx->frame_send_sum && !jpeg_send_eof) {
+                    return ret;
+                }
+            } else {
+                return ret;
+            }
+            av_usleep(100);
+            waittime -= 1;
+        }
+        av_log(cnctx->avctx, AV_LOG_ERROR, "Receive packet timeout, return eof\n");
+        return AVERROR_EOF;
+    }
+
+    if (!cnctx->encoder_flushing) {
+        av_log(avctx, AV_LOG_DEBUG, "Ready to output packet.\n");
+        return cnenc_output_packet(cnctx, pkt, &got_packet);
+    } else {
+        waittime = CN_TIMEOUT_VALUE;
+        while (waittime > 0) {
+            ret = cnenc_output_packet(cnctx, pkt, &got_packet);
+            if (ret == AVERROR(EAGAIN)) {
+                av_log(avctx, AV_LOG_DEBUG, "Wait packet from queue\n");
+                if (waittime <= 0 && !cnctx->eos_post_flag) {
+                    av_log(avctx, AV_LOG_WARNING, "Wait packet from queue timeout\n");
+                    cnctx->codec_abort_flag = 1;
+                    return AVERROR_EOF;
+                }
+                if (cnctx->eos_post_flag && cnenc_is_fifo_empty(cnctx)) {
+                    av_log(avctx, AV_LOG_WARNING, "EOS in queue LOST, Unkonwn Error!!!\n");
+                    cnctx->codec_abort_flag = 1;
+                    return AVERROR_EOF;
+                }
+                av_usleep(10);
+                waittime-=1;
+                continue;
+            }
+            return ret;
+        }
+    }
+    av_log(avctx, AV_LOG_ERROR, "[%lu] Receive frame timeout, abort!!!\n", (long unsigned)pthread_self());
+    return ret;
+}
+
+static int probe_buf_num(int lookahead_depth, int frame_interval_p, int rdo_level) {
+    int extra_num = 0;
+    int frame_num = 0;
+    frame_num = frame_interval_p < 2 ? 1 : frame_interval_p;
+    if (lookahead_depth) {
+        frame_num = lookahead_depth + 8 + (8 >> 2);
+        extra_num = 8;
+        if (rdo_level > 1) {
+            extra_num = (extra_num >> 1);
+        }
+        if (lookahead_depth <= 20) {
+            extra_num = (extra_num >> 1);
+        }
+        frame_num += extra_num;
+    } else {
+        frame_num = frame_interval_p + 2;
+    }
+    return frame_num;
+}
+
+av_cold int ff_mlumpp_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    AVMLUDeviceContext *device_hwctx;
+    AVHWFramesContext *hwframe_ctx;
+    int ret = -1;
+    int min_input_buf_num   = 0;
+    int probe_input_buf_num = 0;
+    int pixel_depth         = 0;
+    char mlu[sizeof(int)];
+
+    if (NULL == avctx || NULL == cnctx || cnctx->encoder_init_flag) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_init\n");
+        return AVERROR_BUG;
+    }
+    cnctx->avctx = avctx;
+    if (AV_CODEC_ID_MJPEG == avctx->codec->id && 64 != cnctx->stride_align) {
+        cnctx->stride_align = CN_JFRAME_ALIGN_W;
+    }
+
+    memset(&cnctx->enc_attr, 0, sizeof(cnctx->enc_attr));
+    if (!cnctx->max_width || !cnctx->max_height) {
+        cnctx->max_width  = avctx->codec->id == AV_CODEC_ID_MJPEG ?
+            FFALIGN(avctx->coded_width, CN_JFRAME_ALIGN_W) :
+            FFALIGN(avctx->coded_width, cnctx->stride_align);
+        cnctx->max_height = avctx->codec->id == AV_CODEC_ID_MJPEG ?
+            FFALIGN(avctx->coded_height, CN_JFRAME_ALIGN_H) : avctx->coded_height;
+    }
+
+    cnctx->enc_attr.pic_width   = avctx->width;
+    cnctx->enc_attr.pic_height  = avctx->height;
+    cnctx->enc_attr.max_width   = cnctx->max_width;
+    cnctx->enc_attr.max_height  = cnctx->max_height;
+    cnctx->enc_attr.color_space = cnctx->color_space;
+    cnctx->enc_attr.input_stride_align = cnctx->stride_align;
+    cnctx->enc_attr.input_buf_source   = CNCODEC_BUF_SOURCE_LIB;
+
+    if (avctx->codec_id != AV_CODEC_ID_MJPEG) {
+        if (cnctx->frame_interval_p > 1) {
+            avctx->max_b_frames = cnctx->frame_interval_p - 1;
+        } else if (cnctx->frame_interval_p == 0) {
+            avctx->max_b_frames = 0;
+        } else {
+            if(avctx->max_b_frames > 0) {
+                cnctx->frame_interval_p = avctx->max_b_frames + 1;
+            }
+        }
+        if (avctx->gop_size > 0) {
+            cnctx->idr_period = avctx->gop_size;
+        } else if (avctx->gop_size == 0) {
+            cnctx->frame_interval_p = 0;
+            cnctx->idr_period = 1;
+        } else {
+            cnctx->idr_period = 0;
+        }
+    }
+
+    min_input_buf_num = cnctx->frame_interval_p >= 0 ? cnctx->frame_interval_p + 2 : 3;
+    if(cnctx->input_buf_num != 0) {
+        probe_input_buf_num = probe_buf_num(cnctx->lookahead_depth,
+                                            cnctx->frame_interval_p,
+                                            cnctx->rdo_level);
+        if (cnctx->input_buf_num < probe_input_buf_num) {
+            av_log(avctx, AV_LOG_ERROR,
+            "input buf num[%d] too small, clould set a larger value or 0(auto) for 2Pass mode.\n",
+            cnctx->input_buf_num);
+            return AVERROR(EINVAL);
+        }
+    }
+    cnctx->enc_attr.input_buf_num = cnctx->input_buf_num;
+
+    sprintf(mlu, "%d", cnctx->device_id);
+    if (avctx->pix_fmt == AV_PIX_FMT_MLU) {
+        if (avctx->hw_frames_ctx) {
+            av_buffer_unref(&cnctx->hw_frame_ref);
+            cnctx->hw_frame_ref = av_buffer_ref(avctx->hw_frames_ctx);
+            if (!cnctx->hw_frame_ref) {
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            cnctx->hw_device_ref = av_buffer_ref(hwframe_ctx->device_ref);
+            if (!cnctx->hw_device_ref) {
+                return AVERROR(EINVAL);
+            }
+            device_hwctx         = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx  = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+        } else {
+            if (avctx->hw_device_ctx) {
+                cnctx->hw_device_ref = av_buffer_ref(avctx->hw_device_ctx);
+                if (!cnctx->hw_device_ref) {
+                    return AVERROR(EINVAL);
+                }
+            } else {
+                ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU,
+                        mlu, NULL, 0);
+                if (ret < 0) {
+                    return AVERROR(EINVAL);
+                }
+            }
+            cnctx->hw_frame_ref = av_hwframe_ctx_alloc(cnctx->hw_device_ref);
+            if (!cnctx->hw_frame_ref) {
+                av_log(avctx, AV_LOG_ERROR, "Failed in av_hwframe_ctx_alloc\n");
+                return AVERROR(EINVAL);
+            }
+
+            hwframe_ctx          = (AVHWFramesContext*)cnctx->hw_frame_ref->data;
+            device_hwctx         = hwframe_ctx->device_ctx->hwctx;
+            cnctx->hw_frame_ctx  = hwframe_ctx;
+            cnctx->hw_device_ctx = device_hwctx;
+            cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+        }
+        cnctx->in_sw_pixfmt = avctx->sw_pix_fmt;
+    } else {
+        av_buffer_unref(&cnctx->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&cnctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "Failed in av_hwdevice_ctx_create\n");
+            return AVERROR(EINVAL);
+        }
+        cnctx->hw_device_ctx = ((AVHWDeviceContext*)cnctx->hw_device_ref->data)->hwctx;
+        cnctx->mlu_ctx       = cnctx->hw_device_ctx->mlu_ctx;
+        cnctx->in_sw_pixfmt  = avctx->pix_fmt;
+    }
+    cnctx->device_id = cnctx->mlu_ctx->mlu_id;
+    if (cnenc_params_checking(cnctx)) {
+        return AVERROR(EINVAL);
+    }
+    cnctx->affinity_set_r = false;
+    cnctx->affinity_set_c = false;
+    if (mlu_device_affinity(cnctx->hw_device_ctx) < 0) {
+        av_log(avctx, AV_LOG_ERROR, "Cndec set affinity failed, func:%s, line:%d\n",
+            __func__, __LINE__);
+        exit(-1);
+    }
+
+    cnctx->enc_attr.user_context    = cnctx;
+    cnctx->enc_attr.run_mode        = CNCODEC_RUN_MODE_ASYNC;
+    cnctx->enc_attr.device_id       = cnctx->mlu_ctx->mlu_id;
+    cnctx->enc_attr.stream_buf_size = 0;
+    cnctx->enc_attr.pixel_format    = cncodec_get_cn_pixfmt_by_av_pixfmt(cnctx->in_sw_pixfmt);
+    pixel_depth = cnctx->enc_attr.pixel_format
+                  == CNCODEC_PIX_FMT_P010 ? PIXEL_DEPTH_10 : PIXEL_DEPTH_8;
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+    cnctx->enc_attr.coding_attr.rdo_level     = cnctx->rdo_level;
+#elif CNCODEC_MINOR_VERSION >= 7 || CNCODEC_MAJOR_VERSION >=1
+    cnctx->enc_attr.rdo_level       = cnctx->rdo_level;
+#endif
+
+    if (CNENC_MIN_FPS > avctx->framerate.num / avctx->framerate.den ||
+        CNENC_MAX_FPS < avctx->framerate.num / avctx->framerate.den) {
+        cnctx->enc_attr.frame_rate_den  = 1;
+        cnctx->enc_attr.frame_rate_num  = 25;
+        av_log(avctx, AV_LOG_WARNING,
+            "framerate is (den:%d,num:%d),out of range(3,120), rectified default params\n",
+            avctx->framerate.den, avctx->framerate.num);
+    } else {
+        cnctx->enc_attr.frame_rate_den  = avctx->framerate.den;
+        cnctx->enc_attr.frame_rate_num  = avctx->framerate.num;
+    }
+    cnctx->enc_attr.coding_attr.stream_type        = cnctx->stream_type;
+    cnctx->enc_attr.coding_attr.frame_interval_p   = cnctx->frame_interval_p;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_mode    = cnctx->rc_mode;
+    cnctx->enc_attr.coding_attr.rc_attr.initial_qp = cnctx->init_qp;
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+    if (cnctx->block_size >= 3 && cnctx->ctb_rc_mode != 0) {
+        av_log(avctx, AV_LOG_ERROR, "ctb rc mode do not support block size value 3!\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->enc_attr.coding_attr.rc_attr.ctb_rc_mode = cnctx->ctb_rc_mode;
+    cnctx->lookahead_depth = cnctx->lookahead_depth < 4 ? 0 : cnctx->lookahead_depth;
+    cnctx->enc_attr.coding_attr.rc_attr.block_size     = cnctx->block_size;
+    cnctx->enc_attr.coding_attr.rc_attr.ctb_row_qp_step = cnctx->ctb_row_qp_step;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_qp_delta_range = cnctx->rc_qp_delta_range;
+    cnctx->enc_attr.coding_attr.rc_attr.rc_base_ctb_complexity = cnctx->rc_base_ctb_comp;
+#endif
+
+    switch (cnctx->rc_mode) {
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+    case CNCODEC_ENC_RATE_CTRL_CRF:
+        cnctx->enc_attr.coding_attr.rc_attr.target_quality  = cnctx->target_quality;
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+        if (cnctx->lookahead_depth < 4) {
+            av_log(avctx, AV_LOG_ERROR,
+                "CRF RC mode lookahead value should not less than 4!\n");
+            return AVERROR(EINVAL);
+        }
+        break;
+#endif
+    case CNCODEC_ENC_RATE_CTRL_CBR:
+        if (cnctx->rc_bufsize > 0) {
+            avctx->rc_buffer_size = cnctx->rc_bufsize;
+            cnctx->enc_attr.coding_attr.rc_attr.vbv_buffer_size = avctx->rc_buffer_size;
+        } else {
+            avctx->rc_buffer_size = avctx->bit_rate * 2;
+            cnctx->enc_attr.coding_attr.rc_attr.vbv_buffer_size = avctx->bit_rate * 2;
+        }
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_VBR:
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_CVBR:
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.target_bitrate  = avctx->bit_rate;
+        cnctx->enc_attr.coding_attr.rc_attr.rc_windows      = cnctx->rc_windows;
+        cnctx->enc_attr.coding_attr.rc_attr.min_qp     = avctx->qmin;
+        cnctx->enc_attr.coding_attr.rc_attr.max_qp     = avctx->qmax;
+        break;
+    case CNCODEC_ENC_RATE_CTRL_FIXEDQP:
+#if CNCODEC_MINOR_VERSION >= 8 || CNCODEC_MAJOR_VERSION >=1
+        if (cnctx->lookahead_depth != 0) {
+            av_log(avctx, AV_LOG_WARNING,
+                "fixed qp mode only support lookahead depth value 0!\n");
+            return AVERROR(EINVAL);
+        }
+        cnctx->enc_attr.coding_attr.rc_attr.lookahead_depth = cnctx->lookahead_depth;
+#endif
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_i = cnctx->const_qp_i;
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_b = cnctx->const_qp_b;
+        cnctx->enc_attr.coding_attr.rc_attr.const_qp_p = cnctx->const_qp_p;
+        break;
+    default:
+        av_log(avctx, AV_LOG_WARNING,
+            "Unknown rc mode, only support crf/cbr/vbr/cvbr/fixedqp\n");
+        return AVERROR(EINVAL);
+    }
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_HEVC:
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_HEVC;
+        cnctx->enc_attr.coding_attr.profile          = cnctx->profile;
+        cnctx->enc_attr.coding_attr.level            = cnctx->level;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.tier = cnctx->tier;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.idr_period = cnctx->idr_period;
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.enable_sao = cnctx->enable_sao;
+#if CNCODEC_VERSION >= 1500
+        if (CN_370 < cncoedc_get_mlu_type(get_mlu_device_name(cnctx->mlu_ctx))) {
+            cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.pixel_depth_minus8 = pixel_depth;
+        }
+#endif
+        cnctx->enc_attr.coding_attr.codec_attr.hevc_attr.enable_repeat_sps_pps =
+            (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;
+        break;
+    case AV_CODEC_ID_H264:
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_H264;
+        cnctx->enc_attr.coding_attr.profile          = cnctx->profile;
+        cnctx->enc_attr.coding_attr.level            = cnctx->level;
+        cnctx->enc_attr.coding_attr.codec_attr.h264_attr.idr_period = cnctx->idr_period;
+#if CNCODEC_VERSION >= 1500
+        if (CN_370 < cncoedc_get_mlu_type(get_mlu_device_name(cnctx->mlu_ctx))) {
+            cnctx->enc_attr.coding_attr.codec_attr.h264_attr.pixel_depth_minus8 = pixel_depth;
+        }
+#endif
+        cnctx->enc_attr.coding_attr.codec_attr.h264_attr.enable_repeat_sps_pps =
+            (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) ? 0 : 1;
+        break;
+    case AV_CODEC_ID_MJPEG:
+        // memset(&cnctx->enc_attr.coding_attr, 0, sizeof(cnctx->enc_attr.coding_attr));
+        cnctx->enc_attr.frame_rate_den = 0;
+        cnctx->enc_attr.frame_rate_num = 0;
+        cnctx->enc_attr.coding_attr.codec_attr.codec = CNCODEC_JPEG;
+        if (cnctx->input_buf_num != 1 && cnctx->input_buf_num != 2) {
+            av_log(avctx, AV_LOG_ERROR,
+                "Jpeg encode only support set input buf num 1 and 2 at present\n");
+            return AVERROR(EINVAL);
+        }
+        // FIX-ME:v3 Jpeg encoder not supported set input_buf_num 0 at present.
+        cnctx->enc_attr.input_buf_num = cnctx->input_buf_num;
+#if FF_MLU_VERSION >= 3300
+        cnctx->enc_attr.coding_attr.backend = cnctx->image_enc_backend;
+#endif
+        break;
+    default:
+        av_log(avctx, AV_LOG_ERROR, "Unknown codec type, ret(%d)\n", avctx->codec_id);
+        return AVERROR(EINVAL);
+    }
+
+    cnctx->eos_post_flag    = 0;
+    cnctx->codec_abort_flag = 0;
+    sem_init(&(cnctx->eos_sema), 0, 0);
+    sem_init(&(cnctx->header_sema), 0, 0);
+    ff_mutex_init(&cnctx->queue_mutex, NULL);
+    cnctx->async_queue_depth = min_input_buf_num * 2;
+    cnctx->frame_queue = av_fifo_alloc(cnctx->async_queue_depth * cnenc_fifo_elem_size());
+    if (!cnctx->frame_queue) {
+        sem_post(&(cnctx->eos_sema));
+        av_log(avctx, AV_LOG_FATAL, "Failed to alloc memory for async fifo\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->timestamp_queue = av_fifo_alloc(TIMESTAMP_QUEUE_SIZE * sizeof(int64_t));
+    if (!cnctx->timestamp_queue) {
+        sem_post(&(cnctx->eos_sema));
+        av_log(avctx, AV_LOG_FATAL, "Failed to alloc memory for timestamp fifo\n");
+        return AVERROR(EINVAL);
+    }
+    cnctx->initial_pts[0] = AV_NOPTS_VALUE;
+    cnctx->initial_pts[1] = AV_NOPTS_VALUE;
+    cnctx->first_pts_out = 0;
+    cnctx->top_pts = 0;
+    cnctx->top_dts = 0;
+    cnctx->extradata_ready = false;
+
+    MLUMPP_CHECK(avctx, cncodecEncCreate(&cnctx->handle, cnenc_event_cb,
+                &cnctx->enc_attr), "Create encoder");
+    av_log(avctx, AV_LOG_DEBUG, "enc init func: encoder created \n");
+
+    if (cnctx->mem_async) {
+        cnctx->mlu_ctx->mluQueueCreate(&cnctx->mlu_queue);
+    }
+    cnctx->encoder_init_flag = 1;
+    if (avctx->codec_id != AV_CODEC_ID_MJPEG) {
+        sem_wait(&(cnctx->header_sema));
+    }
+    cnctx->frame = av_frame_alloc();
+    if (!cnctx->frame) {
+        return AVERROR(ENOMEM);
+    }
+
+    cnctx->frame_send_sum = 0;
+    cnctx->first_iframe = true;
+    av_log(avctx, AV_LOG_DEBUG, "enc init func: encoder init done \n");
+
+    return 0;
+}
+
+int ff_mlumpp_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx)
+{
+    int ret = -1;
+    int semvalue = -1;
+    struct timespec ts;
+    if (NULL == avctx || NULL == cnctx || !cnctx->handle) {
+        av_log(avctx, AV_LOG_ERROR, "Early error in ff_mlumpp_enc_close\n");
+        return AVERROR(EINVAL);
+    }
+    if (!cnctx->eos_post_flag && !cnctx->codec_abort_flag) {
+        av_log(avctx, AV_LOG_DEBUG, "Haven't got EOS, waiting\n");
+        clock_gettime(CLOCK_REALTIME, &ts);
+        ts.tv_sec += 3;
+        if(-1 == sem_timedwait(&(cnctx->eos_sema), &ts)) {
+            sem_getvalue(&cnctx->eos_sema, &semvalue);
+            av_log(avctx, AV_LOG_WARNING, "Encode waited eos timeout\n");
+        }
+    }
+
+    av_frame_free(&cnctx->frame);
+    ff_mutex_lock(&cnctx->queue_mutex);
+    av_fifo_free(cnctx->frame_queue);
+    cnctx->frame_queue = NULL;
+    av_fifo_free(cnctx->timestamp_queue);
+    cnctx->timestamp_queue = NULL;
+    cnctx->initial_pts[0] = AV_NOPTS_VALUE;
+    cnctx->initial_pts[1] = AV_NOPTS_VALUE;
+    ff_mutex_unlock(&cnctx->queue_mutex);
+    ff_mutex_destroy(&cnctx->queue_mutex);
+    if (cnctx->mem_async) {
+        cnctx->mlu_ctx->mluQueueDestroy(cnctx->mlu_queue);
+    }
+
+    ret = cncodecEncDestroy(cnctx->handle);
+    cnctx->handle = 0;
+    if (CNCODEC_SUCCESS != ret) {
+        av_log(avctx, AV_LOG_ERROR,
+            "CNtoolkit Error: destroy encoder failed, func:%s, line:%d, ret(%d)\n",
+            __func__, __LINE__, ret);
+    }
+    sem_destroy(&(cnctx->eos_sema));
+    sem_destroy(&(cnctx->header_sema));
+    if (cnctx->hw_frame_ref) {
+        av_buffer_unref(&cnctx->hw_frame_ref);
+    }
+    if (cnctx->hw_device_ref) {
+        av_buffer_unref(&cnctx->hw_device_ref);
+    }
+    cnctx->encoder_init_flag = 0;
+    av_log(avctx, AV_LOG_DEBUG, "Cnenc closed, thread:%lu\n", (long unsigned)pthread_self());
+
+    return 0;
+}
diff --git a/libavcodec/mlumpp_vid_enc.h b/libavcodec/mlumpp_vid_enc.h
new file mode 100644
index 0000000000..c3fb2248f8
--- /dev/null
+++ b/libavcodec/mlumpp_vid_enc.h
@@ -0,0 +1,130 @@
+/******************************************************************************
+ * Cambricon MLU Media Process Platform(MLU MPP) SDK
+ * Copyright (C) [2019] by Cambricon, Inc. All rights reserved
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ *******************************************************************************/
+#ifndef AVCODEC_MLUMPP_VID_ENC_H
+#define AVCODEC_MLUMPP_VID_ENC_H
+#include <stdint.h>
+#include <unistd.h>
+#include <time.h>
+#include <semaphore.h>
+#include <stdatomic.h>
+#include <fcntl.h>
+#include <sys/time.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+
+#include "cncodec_v3_enc.h"
+#include "mlumpp_codec.h"
+
+typedef struct EventInfoMsg {
+    cncodecEventType_t event_type;
+    cncodecStream_t    stream;
+    uint8_t*           buf;
+    uint32_t           buf_size;
+    uint64_t           priv;
+} EventInfo_t;
+
+enum cnencPixelDepth {
+    PIXEL_DEPTH_8  = 0,
+    PIXEL_DEPTH_10 = 2,
+};
+
+typedef struct MLUMPPEncContext {
+    cncodecHandle_t                 handle;
+    cncodecEncParam_t               enc_attr;
+    AVCodecContext                  *avctx;
+    int                             device_id;
+    int                             color_space;
+    int                             stride_align;
+    int                             input_buf_num;
+    int                             stream_buf_size;
+    int                             encoder_flushing;
+    int                             codec_abort_flag;
+    int                             async_queue_depth;
+    volatile int                    eos_post_flag;
+    volatile int                    encoder_init_flag;
+    volatile int                    frame_send_sum;
+    volatile int                    pkt_recv_sum;
+
+    int                             tier;
+    int                             level;
+    int                             profile;
+    int                             quality;
+    int                             rc_mode;
+    int                             rc_bufsize;
+    int                             rc_windows;
+    int                             init_qp;
+    int                             const_qp_i;
+    int                             const_qp_b;
+    int                             const_qp_p;
+    int                             ctb_row_qp_step;
+    int                             rc_qp_delta_range;
+    int                             rc_base_ctb_comp;
+    int                             ctb_rc_mode;
+    int                             block_size;
+    int                             lookahead_depth;
+    int                             target_quality;
+    int                             preset;
+    int                             rdo_level;
+    int                             gop_size;
+    int                             stream_type;
+    int                             target_bitrate;
+    int                             frame_interval_p;
+    int                             idr_period;
+    int                             enable_sao;
+    int                             max_width;
+    int                             max_height;
+    int                             forced_idr;
+    sem_t                           eos_sema;
+    sem_t                           header_sema;
+    int64_t                         initial_pts[2];
+    int                             first_pts_out;
+    int64_t                         top_pts;
+    int64_t                         top_dts;
+    AVFifoBuffer                    *frame_queue;
+    AVFifoBuffer                    *timestamp_queue;
+    AVMutex                         queue_mutex;
+    bool                            mem_async;
+    bool                            affinity_set_r;
+    bool                            affinity_set_c;
+    bool                            first_iframe;
+    bool                            extradata_ready;
+    cnrtQueue_t                     mlu_queue;
+
+    AVFrame                         *frame;
+    AVBufferRef                     *hw_frame_ref;
+    AVBufferRef                     *hw_device_ref;
+
+    MluContext                      *mlu_ctx;
+    AVMLUDeviceContext              *hw_device_ctx;
+    AVHWFramesContext               *hw_frame_ctx;
+    enum AVPixelFormat              in_sw_pixfmt;
+    cncodecJpegBackend_t            image_enc_backend;
+
+} MLUMPPEncContext_t;
+
+// main functions
+int ff_mlumpp_enc_init(AVCodecContext *avctx, MLUMPPEncContext_t* cnctx);
+int ff_mlumpp_enc_send_frame(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, const AVFrame *frame);
+int ff_mlumpp_enc_receive_packet(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx, AVPacket *pkt);
+int ff_mlumpp_enc_close(AVCodecContext *avctx, MLUMPPEncContext_t *cnctx);
+
+#endif /* AVCODEC_MLUMPP_VID_ENC_H */
\ No newline at end of file
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index b2c254ea67..cf4bd392e0 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -220,6 +220,9 @@ OBJS-$(CONFIG_CROP_FILTER)                   += vf_crop.o
 OBJS-$(CONFIG_CROPDETECT_FILTER)             += vf_cropdetect.o
 OBJS-$(CONFIG_CUE_FILTER)                    += f_cue.o
 OBJS-$(CONFIG_CURVES_FILTER)                 += vf_curves.o
+OBJS-$(CONFIG_CVT_RGBX2RGBX_MLU_FILTER)      += vf_cvt_rgbx2rgbx_mlu.o
+OBJS-$(CONFIG_CVT_YUV2RGBX_MLU_FILTER)       += vf_cvt_yuv2rgbx_mlu.o
+OBJS-$(CONFIG_CVT_RGBX2YUV_MLU_FILTER)       += vf_cvt_rgbx2yuv_mlu.o
 OBJS-$(CONFIG_DATASCOPE_FILTER)              += vf_datascope.o
 OBJS-$(CONFIG_DBLUR_FILTER)                  += vf_dblur.o
 OBJS-$(CONFIG_DCTDNOIZ_FILTER)               += vf_dctdnoiz.o
@@ -295,9 +298,11 @@ OBJS-$(CONFIG_HQX_FILTER)                    += vf_hqx.o
 OBJS-$(CONFIG_HSTACK_FILTER)                 += vf_stack.o framesync.o
 OBJS-$(CONFIG_HUE_FILTER)                    += vf_hue.o
 OBJS-$(CONFIG_HWDOWNLOAD_FILTER)             += vf_hwdownload.o
+OBJS-$(CONFIG_HWDOWNLOAD_MLU_FILTER)         += vf_hwdownload_mlu.o
 OBJS-$(CONFIG_HWMAP_FILTER)                  += vf_hwmap.o
 OBJS-$(CONFIG_HWUPLOAD_CUDA_FILTER)          += vf_hwupload_cuda.o
 OBJS-$(CONFIG_HWUPLOAD_FILTER)               += vf_hwupload.o
+OBJS-$(CONFIG_HWUPLOAD_MLU_FILTER)           += vf_hwupload_mlu.o
 OBJS-$(CONFIG_HYSTERESIS_FILTER)             += vf_hysteresis.o framesync.o
 OBJS-$(CONFIG_IDENTITY_FILTER)               += vf_identity.o
 OBJS-$(CONFIG_IDET_FILTER)                   += vf_idet.o
@@ -353,6 +358,7 @@ OBJS-$(CONFIG_OVERLAY_OPENCL_FILTER)         += vf_overlay_opencl.o opencl.o \
                                                 opencl/overlay.o framesync.o
 OBJS-$(CONFIG_OVERLAY_QSV_FILTER)            += vf_overlay_qsv.o framesync.o
 OBJS-$(CONFIG_OVERLAY_VULKAN_FILTER)         += vf_overlay_vulkan.o vulkan.o
+OBJS-$(CONFIG_OVERLAY_MLU_FILTER)            += vf_overlay_mlu.o framesync.o
 OBJS-$(CONFIG_OWDENOISE_FILTER)              += vf_owdenoise.o
 OBJS-$(CONFIG_PAD_FILTER)                    += vf_pad.o
 OBJS-$(CONFIG_PAD_OPENCL_FILTER)             += vf_pad_opencl.o opencl.o opencl/pad.o
@@ -390,6 +396,7 @@ OBJS-$(CONFIG_ROBERTS_FILTER)                += vf_convolution.o
 OBJS-$(CONFIG_ROBERTS_OPENCL_FILTER)         += vf_convolution_opencl.o opencl.o \
                                                 opencl/convolution.o
 OBJS-$(CONFIG_ROTATE_FILTER)                 += vf_rotate.o
+OBJS-$(CONFIG_ROTATE_MLU_FILTER)             += vf_rotate_mlu.o
 OBJS-$(CONFIG_SAB_FILTER)                    += vf_sab.o
 OBJS-$(CONFIG_SCALE_FILTER)                  += vf_scale.o scale_eval.o
 OBJS-$(CONFIG_SCALE_CUDA_FILTER)             += vf_scale_cuda.o scale_eval.o \
@@ -399,6 +406,9 @@ OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale_eval.o vaapi_vpp.o
 OBJS-$(CONFIG_SCALE_VULKAN_FILTER)           += vf_scale_vulkan.o vulkan.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
+OBJS-$(CONFIG_SCALE_CVT_YUV2RGBX_MLU_FILTER) += vf_scale_cvt_yuv2rgbx_mlu.o
+OBJS-$(CONFIG_SCALE_YUV2YUV_MLU_FILTER)      += vf_scale_yuv2yuv_mlu.o
+OBJS-$(CONFIG_SCALE_RGBX2RGBX_MLU_FILTER)    += vf_scale_rgbx2rgbx_mlu.o
 OBJS-$(CONFIG_SCDET_FILTER)                  += vf_scdet.o
 OBJS-$(CONFIG_SCROLL_FILTER)                 += vf_scroll.o
 OBJS-$(CONFIG_SELECT_FILTER)                 += f_select.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 0872c6e0f2..105d8318dc 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -207,6 +207,9 @@ extern AVFilter ff_vf_crop;
 extern AVFilter ff_vf_cropdetect;
 extern AVFilter ff_vf_cue;
 extern AVFilter ff_vf_curves;
+extern AVFilter ff_vf_cvt_rgbx2rgbx_mlu;
+extern AVFilter ff_vf_cvt_yuv2rgbx_mlu;
+extern AVFilter ff_vf_cvt_rgbx2yuv_mlu;
 extern AVFilter ff_vf_datascope;
 extern AVFilter ff_vf_dblur;
 extern AVFilter ff_vf_dctdnoiz;
@@ -279,9 +282,11 @@ extern AVFilter ff_vf_hqx;
 extern AVFilter ff_vf_hstack;
 extern AVFilter ff_vf_hue;
 extern AVFilter ff_vf_hwdownload;
+extern AVFilter ff_vf_hwdownload_mlu;
 extern AVFilter ff_vf_hwmap;
 extern AVFilter ff_vf_hwupload;
 extern AVFilter ff_vf_hwupload_cuda;
+extern AVFilter ff_vf_hwupload_mlu;
 extern AVFilter ff_vf_hysteresis;
 extern AVFilter ff_vf_identity;
 extern AVFilter ff_vf_idet;
@@ -337,6 +342,7 @@ extern AVFilter ff_vf_overlay_opencl;
 extern AVFilter ff_vf_overlay_qsv;
 extern AVFilter ff_vf_overlay_vulkan;
 extern AVFilter ff_vf_overlay_cuda;
+extern AVFilter ff_vf_overlay_mlu;
 extern AVFilter ff_vf_owdenoise;
 extern AVFilter ff_vf_pad;
 extern AVFilter ff_vf_pad_opencl;
@@ -372,6 +378,7 @@ extern AVFilter ff_vf_rgbashift;
 extern AVFilter ff_vf_roberts;
 extern AVFilter ff_vf_roberts_opencl;
 extern AVFilter ff_vf_rotate;
+extern AVFilter ff_vf_rotate_mlu;
 extern AVFilter ff_vf_sab;
 extern AVFilter ff_vf_scale;
 extern AVFilter ff_vf_scale_cuda;
@@ -380,6 +387,9 @@ extern AVFilter ff_vf_scale_qsv;
 extern AVFilter ff_vf_scale_vaapi;
 extern AVFilter ff_vf_scale_vulkan;
 extern AVFilter ff_vf_scale2ref;
+extern AVFilter ff_vf_scale_cvt_yuv2rgbx_mlu;
+extern AVFilter ff_vf_scale_yuv2yuv_mlu;
+extern AVFilter ff_vf_scale_rgbx2rgbx_mlu;
 extern AVFilter ff_vf_scdet;
 extern AVFilter ff_vf_scroll;
 extern AVFilter ff_vf_select;
diff --git a/libavfilter/mlu_filter_common.h b/libavfilter/mlu_filter_common.h
new file mode 100644
index 0000000000..47fb051a5f
--- /dev/null
+++ b/libavfilter/mlu_filter_common.h
@@ -0,0 +1,146 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#ifndef AVFILTER_MLU_FILTER_COMMON_H
+#define AVFILTER_MLU_FILTER_COMMON_H
+#include <stdio.h>
+#include <string.h>
+#include "libavutil/pixfmt.h"
+#include "libavutil/log.h"
+#include "libavutil/pixdesc.h"
+
+#define MLUFILTER_CHECK(avctx, ret)                                         \
+    if (ret != 0) {                                                         \
+        av_log(avctx, AV_LOG_ERROR, "mlufilter failed, func:%s, line:%d\n", \
+            __func__, __LINE__);                                            \
+        ret = AVERROR(EINVAL);                                              \
+        goto fail;                                                          \
+    }
+#define MLUFILTER_CHECK_OPT(avctx, ret, err_msg, new_ret) {                 \
+    int t_ret = ret;                                                        \
+    if (t_ret != 0) {                                                       \
+        av_log(avctx, AV_LOG_ERROR, "%s, ret(%d), func%s, line:%d\n",       \
+            err_msg, t_ret, __func__, __LINE__);                            \
+        return new_ret;                                                     \
+    }                                                                       \
+}
+
+#define CHECK_RGBX(rgbx) (!strcmp(rgbx, "rgb0") ? "rgba" :                 \
+                         (!strcmp(rgbx, "0rgb") ? "argb" :                 \
+                         (!strcmp(rgbx, "bgr0") ? "bgra" :                 \
+                         (!strcmp(rgbx, "0bgr") ? "abgr" : rgbx))))
+
+static int get_stride_scale_by_pixfmt(enum AVPixelFormat pixfmt) {
+    int scale = 1;
+    switch (pixfmt) {
+    case AV_PIX_FMT_NV12:
+    case AV_PIX_FMT_NV21:
+        scale = 1; break;
+    case AV_PIX_FMT_BGR24:
+    case AV_PIX_FMT_RGB24:
+        scale = 3; break;
+    case AV_PIX_FMT_ABGR:
+    case AV_PIX_FMT_ARGB:
+    case AV_PIX_FMT_BGRA:
+    case AV_PIX_FMT_RGBA:
+    case AV_PIX_FMT_0BGR:
+    case AV_PIX_FMT_0RGB:
+    case AV_PIX_FMT_BGR0:
+    case AV_PIX_FMT_RGB0:
+        scale = 4; break;
+    default:
+        av_log(NULL, AV_LOG_WARNING,
+            "unsupported pixfmt %s\n, set stride scale as 1", av_get_pix_fmt_name(pixfmt));
+        break;
+    }
+    return scale;
+}
+
+static int get_pixfmt_plane_size(size_t sizes[4], enum AVPixelFormat pix_fmt, int width, int height)
+{
+    int i, has_plane[4] = {0};
+    int linesizes[4] = {0};
+    int ret;
+
+    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);
+    memset(sizes, 0, sizeof(sizes[0]) * 4);
+
+    ret = av_image_fill_linesizes(linesizes, pix_fmt, width);
+    if (ret < 0)
+        return ret;
+    if (!desc || desc->flags & AV_PIX_FMT_FLAG_HWACCEL)
+        return AVERROR(EINVAL);
+
+    if (linesizes[0] > SIZE_MAX / height)
+        return AVERROR(EINVAL);
+    sizes[0] = linesizes[0] * (size_t)height;
+
+    if (desc->flags & AV_PIX_FMT_FLAG_PAL) {
+        sizes[1] = 256 * 4;
+        return 0;
+    }
+
+    for (i = 0; i < 4; i++) {
+        has_plane[desc->comp[i].plane] = 1;
+    }
+
+    for (i = 1; i < 4 && has_plane[i]; i++) {
+        int h, s = (i == 1 || i == 2) ? desc->log2_chroma_h : 0;
+        h = (height + (1 << s) - 1) >> s;
+        if (linesizes[i] > SIZE_MAX / h)
+            return AVERROR(EINVAL);
+        sizes[i] = (size_t)h * linesizes[i];
+    }
+
+    return 0;
+}
+
+#if CONFIG_MLUAFFINITY
+#ifndef mluDevCheckErrors
+#define __mluDevCheckErrors(ctx, err, file, line)                                    \
+    do {                                                                             \
+        mluDevRet_t _err = (err);                                                    \
+        if (0 != _err) {                                                             \
+            fprintf(stderr, "mluDevCheckErrors(%d): %s, from file <%s>, line %i.\n", \
+                _err, ctx->mluDevGetErrorString(_err), (char*)file, line);           \
+            exit(1);                                                                 \
+        }                                                                            \
+    } while (0)
+#define mluDevCheckErrors(ctx, err) __mluDevCheckErrors(ctx, (err), __FILE__, __LINE__)
+#endif
+#endif
+
+static inline int mlu_device_affinity(AVMLUDeviceContext *dev_ctx) {
+#if CONFIG_MLUAFFINITY
+    MluContext *mlu_ctx = dev_ctx->mlu_ctx;
+    int dev_hdl;
+    MLUFILTER_CHECK_OPT(NULL, mlu_ctx->mluSetDevice(mlu_ctx->mlu_id),
+        "mluSetDevice failed", AVERROR(EINVAL));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevGetDeviceHandleByIndex(mlu_ctx->mlu_id, &dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevClearCurrentThreadAffinity(mlu_ctx->dev_version, dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevSetCurrentThreadAffinity(mlu_ctx->dev_version, dev_hdl));
+#endif
+
+    return 0;
+}
+
+#endif
diff --git a/libavfilter/vf_cvt_rgbx2rgbx_mlu.c b/libavfilter/vf_cvt_rgbx2rgbx_mlu.c
new file mode 100644
index 0000000000..0dcb0e7aa5
--- /dev/null
+++ b/libavfilter/vf_cvt_rgbx2rgbx_mlu.c
@@ -0,0 +1,413 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+ */
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixfmt.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCvtRgbx2RgbxContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format;
+
+    char *mlu;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    void *input_mlu_rgbx;
+    void *output_mlu_rgbx;
+    int input_mlu_rgbx_size;
+    int output_mlu_rgbx_size;
+    bool affinity_set;
+
+    void *op_handle;
+} MluCvtRgbx2RgbxContext;
+
+static int mlurgbx2rgbx_query_formats(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+        AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    out_pixfmt = av_get_pix_fmt(s->enter_out_fmt);
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbx2rgbx_init(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    s->input_mlu_rgbx  = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle       = NULL;
+    s->affinity_set    = false;
+
+    return 0;
+}
+
+static av_cold void mlurgbx2rgbx_uninit(AVFilterContext *ctx)
+{
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        mlu_ctx->mluCvtRgbx2RgbxDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbx2rgbx_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCvtRgbx2RgbxContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char mlu[sizeof(int)];
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+        outlink->format = av_get_pix_fmt(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->output_mlu_rgbx_size = outlink->w * outlink->h * get_stride_scale_by_pixfmt(s->out_fmt);
+    s->input_mlu_rgbx_size  = inlink->w * inlink->h * get_stride_scale_by_pixfmt(s->in_fmt);
+
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluCvtRgbx2RgbxInit(&s->op_handle, inlink->w, inlink->h,
+                                CHECK_RGBX(s->pic_pixfmt), CHECK_RGBX(s->enter_out_fmt), s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_rgbx),
+                                       sizeof(char) * s->input_mlu_rgbx_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx),
+                                       sizeof(char) * s->output_mlu_rgbx_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbx2rgbx_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx      = link->dst;
+    MluCvtRgbx2RgbxContext *s = ctx->priv;
+    AVFilterLink *outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx       = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+    out->linesize[1] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                                        s->input_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        ret = mlu_ctx->mluCvtRgbx2RgbxExec(s->op_handle, s->input_mlu_rgbx,
+                                            s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2rgbx with mlu\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                                        s->output_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCvtRgbx2RgbxContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixfmt", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS },
+    { "n",     "device index",  OFFSET(mlu),        AV_OPT_TYPE_STRING, {.str = "in"}, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbx2rgbx_class = {
+    .class_name = "mlurgbx2rgbx",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbx2rgbx_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbx2rgbx_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbx2rgbx_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbx2rgbx_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_rgbx2rgbx_mlu = {
+    .name      = "cvt_rgbx2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert rgbx to rgbx"),
+
+    .init          = mlurgbx2rgbx_init,
+    .uninit        = mlurgbx2rgbx_uninit,
+    .query_formats = mlurgbx2rgbx_query_formats,
+
+    .priv_size = sizeof(MluCvtRgbx2RgbxContext),
+    .priv_class = &mlurgbx2rgbx_class,
+
+    .inputs    = mlurgbx2rgbx_inputs,
+    .outputs   = mlurgbx2rgbx_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_cvt_rgbx2yuv_mlu.c b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
new file mode 100644
index 0000000000..109594fb1e
--- /dev/null
+++ b/libavfilter/vf_cvt_rgbx2yuv_mlu.c
@@ -0,0 +1,429 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTRGBX2YUVContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format;
+    char *mlu;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    void *input_mlu_rgbx;
+    void *output_mlu_y;
+    void *output_mlu_uv;
+
+    int output_mlu_y_size;
+    int output_mlu_uv_size;
+    int input_mlu_rgbx_size;
+    bool affinity_set;
+
+    void *op_handle;
+} MluCVTRGBX2YUVContext;
+
+static int mlurgbx2yuv_query_formats(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+        AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    out_pixfmt = av_get_pix_fmt(s->enter_out_fmt);
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbx2yuv_init(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    s->input_mlu_rgbx = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+    s->op_handle = NULL;
+    s->affinity_set = false;
+
+    return 0;
+}
+
+static av_cold void mlurgbx2yuv_uninit(AVFilterContext *ctx)
+{
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        mlu_ctx->mluCvtRgbx2YuvDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbx2yuv_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTRGBX2YUVContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char mlu[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+        outlink->format = av_get_pix_fmt(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->output_mlu_y_size   = outlink->w * outlink->h;
+    s->output_mlu_uv_size  = outlink->w * outlink->h / 2;
+    s->input_mlu_rgbx_size = inlink->w * inlink->h * get_stride_scale_by_pixfmt(s->in_fmt);
+
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluCvtRgbx2YuvInit(&s->op_handle, inlink->w, inlink->h,
+                                    CHECK_RGBX(s->pic_pixfmt), s->enter_out_fmt, s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_rgbx_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), sizeof(char) * s->output_mlu_y_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), sizeof(char) * s->output_mlu_uv_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbx2yuv_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx     = link->dst;
+    MluCVTRGBX2YUVContext *s = ctx->priv;
+    AVFilterLink *outlink    = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+    out->linesize[1] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_y = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                             s->input_mlu_rgbx_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        ret = mlu_ctx->mluCvtRgbx2YuvExec(s->op_handle, s->input_mlu_rgbx,
+                                           s->output_mlu_y, s->output_mlu_uv);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2yuv with mlu\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->output_mlu_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->output_mlu_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTRGBX2YUVContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixfmt", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, { .str = "of" }, .flags = FLAGS },
+    { "n",     "device index",  OFFSET(mlu),        AV_OPT_TYPE_STRING, { .str = "0" },  .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mlurgbx2yuv_class = {
+    .class_name = "mlurgbx2yuv",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbx2yuv_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbx2yuv_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbx2yuv_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbx2yuv_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_rgbx2yuv_mlu = {
+    .name      = "cvt_rgbx2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mlurgbx2yuv_init,
+    .uninit        = mlurgbx2yuv_uninit,
+    .query_formats = mlurgbx2yuv_query_formats,
+
+    .priv_size = sizeof(MluCVTRGBX2YUVContext),
+    .priv_class = &mlurgbx2yuv_class,
+
+    .inputs    = mlurgbx2yuv_inputs,
+    .outputs   = mlurgbx2yuv_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_cvt_yuv2rgbx_mlu.c b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
new file mode 100644
index 0000000000..ef80e1dea5
--- /dev/null
+++ b/libavfilter/vf_cvt_yuv2rgbx_mlu.c
@@ -0,0 +1,425 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluCVTYUV2RGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+
+    MluContext         *mlu_ctx;
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format;
+
+    char *mlu;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    int  in_y_size;
+    int  in_uv_size;
+    int  out_mlu_size;
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_rgbx;
+    bool affinity_set;
+
+    void *op_handle;
+} MluCVTYUV2RGBXContext;
+
+static int mluyuv2rgbx_query_formats(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+   int ret;
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    out_pixfmt = av_get_pix_fmt(s->enter_out_fmt);
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluyuv2rgbx_init(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle = NULL;
+    s->affinity_set = false;
+
+    return 0;
+}
+
+static av_cold void mluyuv2rgbx_uninit(AVFilterContext *ctx)
+{
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        mlu_ctx->mluCvtYuv2RgbxDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluyuv2rgbx_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluCVTYUV2RGBXContext *s  = ctx->priv;
+
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char mlu[sizeof(int)];
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    s->inlink_pixfmt = inlink->format;
+    s->in_y_size    = inlink->w * inlink->h;
+    s->in_uv_size   = inlink->w * inlink->h / 2;
+    s->out_mlu_size = outlink->w * outlink->h *
+                    get_stride_scale_by_pixfmt(av_get_pix_fmt(s->enter_out_fmt));
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+        outlink->format = av_get_pix_fmt(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluCvtYuv2RgbxInit(&s->op_handle, inlink->w, inlink->h, s->pic_pixfmt,
+                                    CHECK_RGBX(s->enter_out_fmt), s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), sizeof(char) * s->in_y_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), sizeof(char) * s->in_uv_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->out_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluyuv2rgbx_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext*ctx      = link->dst;
+    MluCVTYUV2RGBXContext *s = ctx->priv;
+    AVFilterLink*outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y = in->data[0];
+            s->input_mlu_uv = in->data[1];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                                  s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                                  s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        ret = mlu_ctx->mluCvtYuv2RgbxExec(s->op_handle, s->input_mlu_y,
+                                        s->input_mlu_uv, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2rgbx filter with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->out_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluCVTYUV2RGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "o_fmt", "output pixel format", OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, { .str = "of" },.flags = FLAGS },
+    { "n",     "device index",        OFFSET(mlu),        AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { NULL },
+};
+
+static const AVClass mluyuv2rgbx_class = {
+    .class_name = "mluyuv2rgbx",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluyuv2rgbx_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluyuv2rgbx_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluyuv2rgbx_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluyuv2rgbx_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_cvt_yuv2rgbx_mlu = {
+    .name      = "cvt_yuv2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated convert yuv to rgbx"),
+
+    .init          = mluyuv2rgbx_init,
+    .uninit        = mluyuv2rgbx_uninit,
+    .query_formats = mluyuv2rgbx_query_formats,
+
+    .priv_size = sizeof(MluCVTYUV2RGBXContext),
+    .priv_class = &mluyuv2rgbx_class,
+
+    .inputs    = mluyuv2rgbx_inputs,
+    .outputs   = mluyuv2rgbx_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwdownload_mlu.c b/libavfilter/vf_hwdownload_mlu.c
new file mode 100644
index 0000000000..a649524c97
--- /dev/null
+++ b/libavfilter/vf_hwdownload_mlu.c
@@ -0,0 +1,215 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/log.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MLUDownloadContext {
+    const AVClass *class;
+    int mlu;
+
+    AVBufferRef   *hwframes_ref;
+    AVHWFramesContext *hwframes;
+} MLUDownloadContext;
+
+static int hwdownload_query_formats(AVFilterContext *avctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_RGB24,  AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR,   AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA,   AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_0RGB,   AV_PIX_FMT_0BGR,
+        AV_PIX_FMT_BGR0,   AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_NV12,   AV_PIX_FMT_NV21,
+        AV_PIX_FMT_YUV420P,AV_PIX_FMT_P010,
+        AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &avctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &avctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+    return 0;
+}
+
+static int hwdownload_config_input(AVFilterLink *inlink)
+{
+    AVFilterContext *avctx = inlink->dst;
+    MLUDownloadContext *ctx = avctx->priv;
+
+    if (!inlink->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "The input must have a hardware frame reference.\n");
+        return AVERROR(EINVAL);
+    }
+    av_buffer_unref(&ctx->hwframes_ref);
+    ctx->hwframes_ref = av_buffer_ref(inlink->hw_frames_ctx);
+    if (!ctx->hwframes_ref)
+        return AVERROR(ENOMEM);
+
+    ctx->hwframes = (AVHWFramesContext*)ctx->hwframes_ref->data;
+
+    return 0;
+}
+
+static int hwdownload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *avctx  = outlink->src;
+    AVFilterLink *inlink    = avctx->inputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+
+    int err;
+    enum AVPixelFormat *formats;
+
+    if (!ctx->hwframes_ref)
+        return AVERROR(EINVAL);
+
+    err = av_hwframe_transfer_get_formats(ctx->hwframes_ref,
+                                          AV_HWFRAME_TRANSFER_DIRECTION_FROM,
+                                          &formats, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Hwframe transfer get formats failed \n");
+        return err;
+    }
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    outlink->format = formats[0];
+
+    av_freep(&formats);
+    return 0;
+}
+
+static int hwdownload_filter_frame(AVFilterLink *link, AVFrame *input)
+{
+    AVFilterContext *avctx  = link->dst;
+    AVFilterLink  *outlink  = avctx->outputs[0];
+    MLUDownloadContext *ctx = avctx->priv;
+
+    int err;
+    AVFrame *output = NULL;
+    if (!ctx->hwframes_ref || !input->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+    if ((void*)ctx->hwframes != input->hw_frames_ctx->data) {
+        av_log(ctx, AV_LOG_ERROR, "Input frame is not the in the configured hwframe context.\n");
+        err = AVERROR(EINVAL);
+        goto fail;
+    }
+
+    output = ff_get_video_buffer(outlink, ctx->hwframes->width,
+                                 ctx->hwframes->height);
+    if (!output) {
+        err = AVERROR(ENOMEM);
+        goto fail;
+    }
+    output->width  = outlink->w;
+    output->height = outlink->h;
+    for (int i = 0; i < FF_ARRAY_ELEMS(input->data) && input->data[i]; i++) {
+        output->linesize[i] = input->linesize[i];
+    }
+
+    err = av_hwframe_transfer_data(output, input, 0);
+    if (err < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Failed to download frame: %d.\n", err);
+        goto fail;
+    }
+
+    err = av_frame_copy_props(output, input);
+    if (err < 0) {
+        goto fail;
+    }
+
+    av_frame_free(&input);
+    return ff_filter_frame(avctx->outputs[0], output);
+
+fail:
+    av_frame_free(&input);
+    av_frame_free(&output);
+    return err;
+}
+
+static av_cold void hwdownload_uninit(AVFilterContext *avctx)
+{
+    MLUDownloadContext *ctx = avctx->priv;
+    av_buffer_unref(&ctx->hwframes_ref);
+}
+
+static const AVClass hwdownload_class = {
+    .class_name = "hwdownload_mlu",
+    .item_name  = av_default_item_name,
+    .option     = NULL,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad hwdownload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_input,
+        .filter_frame = hwdownload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad hwdownload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = hwdownload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwdownload_mlu = {
+    .name          = "hwdownload_mlu",
+    .description   = NULL_IF_CONFIG_SMALL("Download a hardware frame to a normal frame"),
+    .uninit        = hwdownload_uninit,
+    .query_formats = hwdownload_query_formats,
+    .priv_size     = sizeof(MLUDownloadContext),
+    .priv_class    = &hwdownload_class,
+    .inputs        = hwdownload_inputs,
+    .outputs       = hwdownload_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_hwupload_mlu.c b/libavfilter/vf_hwupload_mlu.c
new file mode 100644
index 0000000000..978606a934
--- /dev/null
+++ b/libavfilter/vf_hwupload_mlu.c
@@ -0,0 +1,198 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/buffer.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/log.h"
+#include "libavutil/opt.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+
+typedef struct MluUploadContext {
+    const AVClass *class;
+    int mlu;
+
+    AVBufferRef *hwdevice;
+    AVBufferRef *hwframe;
+} MluUploadContext;
+
+static av_cold int mlu_upload_init(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+    char buf[64] = { 0 };
+    snprintf(buf, sizeof(buf), "%d", s->mlu);
+
+    return av_hwdevice_ctx_create(&s->hwdevice, AV_HWDEVICE_TYPE_MLU, buf, NULL, 0);
+}
+
+static av_cold void mlu_upload_uninit(AVFilterContext *ctx)
+{
+    MluUploadContext *s = ctx->priv;
+
+    av_buffer_unref(&s->hwframe);
+    av_buffer_unref(&s->hwdevice);
+}
+
+static int mlu_upload_query_formats(AVFilterContext *ctx)
+{
+    int ret;
+    AVFilterFormats *in_fmts;
+    AVFilterFormats *out_fmts;
+    static const enum AVPixelFormat input_pix_fmts[] = {
+        AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB,
+        AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+        AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_P010, AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat output_pix_fmts[] = {
+        AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+    };
+
+    in_fmts  = ff_make_format_list(input_pix_fmts);
+    ret = ff_formats_ref(in_fmts, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    out_fmts = ff_make_format_list(output_pix_fmts);
+    ret = ff_formats_ref(out_fmts, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int mlu_upload_config_output(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluUploadContext *s = ctx->priv;
+
+    int ret;
+    AVHWFramesContext *hwframe_ctx;
+
+    av_buffer_unref(&s->hwframe);
+    s->hwframe = av_hwframe_ctx_alloc(s->hwdevice);
+    if (!s->hwframe)
+        return AVERROR(ENOMEM);
+
+    hwframe_ctx            = (AVHWFramesContext*)s->hwframe->data;
+    hwframe_ctx->format    = AV_PIX_FMT_MLU;
+    hwframe_ctx->sw_format = inlink->format;
+    hwframe_ctx->width     = inlink->w;
+    hwframe_ctx->height    = inlink->h;
+
+    ret = av_hwframe_ctx_init(s->hwframe);
+    if (ret < 0)
+        return ret;
+
+    outlink->hw_frames_ctx = av_buffer_ref(s->hwframe);
+    if (!outlink->hw_frames_ctx)
+        return AVERROR(ENOMEM);
+
+    return 0;
+}
+
+static int mlu_upload_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext   *ctx = link->dst;
+    AVFilterLink  *outlink = ctx->outputs[0];
+
+    AVFrame *out = NULL;
+    int ret;
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    for (int i = 0; i < FF_ARRAY_ELEMS(in->data) && in->data[i]; i++) {
+        out->linesize[i] = in->linesize[i];
+    }
+
+    ret = av_hwframe_transfer_data(out, in, 0);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "Error transferring data to the MLU\n");
+        goto fail;
+    }
+
+    ret = av_frame_copy_props(out, in);
+    if (ret < 0)
+        goto fail;
+
+    av_frame_free(&in);
+
+    return ff_filter_frame(ctx->outputs[0], out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluUploadContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption mlu_upload_options[] = {
+    { "device", "use to choose the accelerator card", OFFSET(mlu), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+    { NULL },
+};
+
+AVFILTER_DEFINE_CLASS(mlu_upload);
+
+static const AVFilterPad mlu_upload_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlu_upload_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlu_upload_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlu_upload_config_output,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_hwupload_mlu = {
+    .name        = "hwupload_mlu",
+    .description = NULL_IF_CONFIG_SMALL("Upload a system memory frame to a mlu device."),
+
+    .init      = mlu_upload_init,
+    .uninit    = mlu_upload_uninit,
+
+    .query_formats = mlu_upload_query_formats,
+
+    .priv_size  = sizeof(MluUploadContext),
+    .priv_class = &mlu_upload_class,
+
+    .inputs    = mlu_upload_inputs,
+    .outputs   = mlu_upload_outputs,
+
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_overlay_mlu.c b/libavfilter/vf_overlay_mlu.c
new file mode 100644
index 0000000000..4fb357423c
--- /dev/null
+++ b/libavfilter/vf_overlay_mlu.c
@@ -0,0 +1,702 @@
+/*
+ * Copyright (c) 2024, CAMBRICON CORPORATION. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright no5tice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/opt.h"
+#include "libavutil/log.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/eval.h"
+
+#include "avfilter.h"
+#include "filters.h"
+#include "framesync.h"
+#include "internal.h"
+#include "mlu_filter_common.h"
+#include "time.h"
+
+#define MAIN 0
+#define OVERLAY 1
+#define MAX_PLANE_NUM 4
+#define CNFILTER_FRAME_ALIGNMENT 1
+
+enum var_name
+{
+    VAR_MAIN_W,    VAR_MW,
+    VAR_MAIN_H,    VAR_MH,
+    VAR_OVERLAY_W, VAR_OW,
+    VAR_OVERLAY_H, VAR_OH,
+    VAR_X, VAR_Y,  VAR_N, VAR_T,
+    VAR_VARS_NB
+};
+
+enum EvaluateMode
+{
+    EVAL_MODE_INIT,
+    EVAL_MODE_FRAME,
+    EVAL_MODE_NB
+};
+
+static const char *const var_names[] = {
+    "main_w", "W",    // width  of the main video
+    "main_h", "H",    // height of the main video
+    "overlay_w", "w", // width  of the overlay video
+    "overlay_h", "h", // height of the overlay video
+    "x", "y",
+    "n", // number of frame
+    "t", // timestamp expressed in seconds
+    NULL
+};
+
+typedef struct OverlayMluContext
+{
+    const AVClass      *class;
+    enum AVPixelFormat in_format_overlay;
+    enum AVPixelFormat in_format_main;
+    enum AVPixelFormat inlink_main_pixfmt;
+    enum AVPixelFormat inlink_overlay_pixfmt;
+
+    AVMLUDeviceContext *hwctx;
+    FFFrameSync fs;
+
+    int eval_mode;
+    int x_position, y_position, mlu;
+    double var_values[VAR_VARS_NB];
+    char *x_expr, *y_expr;
+    AVExpr *x_pexpr, *y_pexpr;
+
+    AVBufferRef *hw_device_ref;
+    AVBufferRef *main_hwframe_ref;
+    MluContext *mlu_ctx;
+
+    int stride_align;
+    double overlay_alpha;
+    bool have_alpha_planar;
+
+    size_t main_plane_size[4], overlay_plane_size[4];
+    void* main_mlu_ptr[4],  *overlay_mlu_ptr[4], *output_mlu_ptr[4];
+    bool affinity_set;
+
+    void *op_handle;
+} OverlayMluContext;
+
+static const enum AVPixelFormat supported_main_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, /* AV_PIX_FMT_YUV420P,*/
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA, AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0, AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+};
+
+static const enum AVPixelFormat supported_overlay_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, AV_PIX_FMT_YUV420P,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA, AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0, AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+};
+
+static const enum AVPixelFormat supported_output_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, /*AV_PIX_FMT_YUV420P,*/
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA, AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0, AV_PIX_FMT_MLU, AV_PIX_FMT_NONE,
+};
+
+static int mlu_overlay_query_formats(AVFilterContext *ctx)
+{
+    AVFilterFormats *main_formats    = NULL;
+    AVFilterFormats *overlay_formats = NULL;
+    AVFilterFormats *output_formats  = NULL;
+    int ret;
+
+    if (!(main_formats = ff_make_format_list(supported_main_formats))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+    ret = ff_formats_ref(main_formats, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0) {
+        return ret;
+    }
+    if (!(overlay_formats = ff_make_format_list(supported_overlay_formats))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+    ret = ff_formats_ref(overlay_formats, &ctx->inputs[1]->outcfg.formats);
+    if (ret < 0) {
+        return ret;
+    }
+    if (!(output_formats = ff_make_format_list(supported_output_formats))) {
+        ret = AVERROR(ENOMEM);
+        goto fail;
+    }
+    ret = ff_formats_ref(output_formats, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0) {
+        return ret;
+    }
+
+    return 0;
+fail:
+    if (main_formats)
+        av_freep(&main_formats->formats);
+    av_freep(&main_formats);
+    if (overlay_formats)
+        av_freep(&overlay_formats->formats);
+    av_freep(&overlay_formats);
+    if (output_formats)
+        av_freep(&output_formats->formats);
+    av_freep(&output_formats);
+    return ret;
+}
+
+static int format_is_supported(const enum AVPixelFormat formats[], enum AVPixelFormat fmt)
+{
+    for (int i = 0; formats[i] != AV_PIX_FMT_NONE; i++)
+        if (formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static inline int normalize_xy(double d, int chroma_sub)
+{
+    if (isnan(d))
+        return INT_MAX;
+    return (int)d & ~((1 << chroma_sub) - 1);
+}
+
+static void eval_expr(AVFilterContext *avctx)
+{
+    OverlayMluContext *ctx = avctx->priv;
+
+    ctx->var_values[VAR_X] = av_expr_eval(ctx->x_pexpr, ctx->var_values, NULL);
+    ctx->var_values[VAR_Y] = av_expr_eval(ctx->y_pexpr, ctx->var_values, NULL);
+    /* necessary if x is expressed from y  */
+    ctx->var_values[VAR_X] = av_expr_eval(ctx->x_pexpr, ctx->var_values, NULL);
+
+    ctx->x_position = normalize_xy(ctx->var_values[VAR_X], 1);
+
+    /* the mlu pixel format is using hwaccel, normalizing y is unnecessary */
+    ctx->y_position = ctx->var_values[VAR_Y];
+}
+
+static int set_expr(AVExpr **pexpr, const char *expr, const char *option, void *log_ctx)
+{
+    int ret;
+    AVExpr *old = NULL;
+
+    if (*pexpr) {
+        old = *pexpr;
+    }
+    ret = av_expr_parse(pexpr, expr, var_names, NULL, NULL, NULL, NULL, 0, log_ctx);
+    if (ret < 0) {
+        av_log(log_ctx, AV_LOG_ERROR, "Error when evaluating the expression '%s' for %s\n",
+                expr, option);
+        *pexpr = old;
+        return ret;
+    }
+
+    av_expr_free(old);
+    return 0;
+}
+
+static int have_alpha_planar(AVFilterLink *link)
+{
+    enum AVPixelFormat pix_fmt = link->format;
+    const AVPixFmtDescriptor *desc;
+    AVHWFramesContext *hwframe_ctx;
+
+    if (link->format == AV_PIX_FMT_MLU) {
+        hwframe_ctx = (AVHWFramesContext *)link->hw_frames_ctx->data;
+        pix_fmt = hwframe_ctx->sw_format;
+    }
+
+    desc = av_pix_fmt_desc_get(pix_fmt);
+    if (!desc)
+        return 0;
+
+    return !!(desc->flags & AV_PIX_FMT_FLAG_ALPHA);
+}
+
+static int config_input_main(AVFilterLink *inlink)
+{
+    // AVFilterContext *avctx = inlink->dst;
+    // OverlayMluContext *ctx = inlink->dst->priv;
+
+    return 0;
+}
+
+static int config_input_overlay(AVFilterLink *inlink)
+{
+    AVFilterContext *avctx = inlink->dst;
+    OverlayMluContext *ctx = inlink->dst->priv;
+    int ret;
+
+    av_log(ctx, AV_LOG_DEBUG, "Input[%d] is of %s.\n", FF_INLINK_IDX(inlink),
+           av_get_pix_fmt_name(inlink->format));
+
+    /* Finish the configuration by evaluating the expressions now when both inputs are configured */
+    ctx->var_values[VAR_MAIN_W] = ctx->var_values[VAR_MW] = avctx->inputs[MAIN]->w;
+    ctx->var_values[VAR_MAIN_H] = ctx->var_values[VAR_MH] = avctx->inputs[MAIN]->h;
+    ctx->var_values[VAR_OVERLAY_W] = ctx->var_values[VAR_OW] = avctx->inputs[OVERLAY]->w;
+    ctx->var_values[VAR_OVERLAY_H] = ctx->var_values[VAR_OH] = avctx->inputs[OVERLAY]->h;
+    ctx->var_values[VAR_X] = NAN;
+    ctx->var_values[VAR_Y] = NAN;
+    ctx->var_values[VAR_N] = 0;
+    ctx->var_values[VAR_T] = NAN;
+
+    if ((ret = set_expr(&ctx->x_pexpr, ctx->x_expr, "x", avctx)) < 0 ||
+        (ret = set_expr(&ctx->y_pexpr, ctx->y_expr, "y", avctx)) < 0)
+        return ret;
+
+    if (ctx->eval_mode == EVAL_MODE_INIT) {
+        eval_expr(avctx);
+        av_log(avctx, AV_LOG_VERBOSE, "x:%f xi:%d y:%f yi:%d\n",
+                ctx->var_values[VAR_X], ctx->x_position, ctx->var_values[VAR_Y], ctx->y_position);
+    }
+
+    return 0;
+}
+
+static int config_output(AVFilterLink *outlink)
+{
+    AVHWFramesContext *main_hwframes_ctx    = NULL;
+    AVHWFramesContext *overlay_hwframes_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx    = NULL;
+    char dev_idx[sizeof(int)];
+    const char *alpha_fmt;
+    int ret;
+
+    AVFilterContext *avctx = outlink->src;
+    AVFilterLink *inlink_main = avctx->inputs[0];
+    AVFilterLink *inlink_overlay = avctx->inputs[1];
+    OverlayMluContext *ctx = avctx->priv;
+
+    ctx->inlink_overlay_pixfmt = inlink_overlay->format;
+    ctx->inlink_main_pixfmt    = inlink_main->format;
+    ctx->fs.time_base          = inlink_main->time_base;
+    ctx->have_alpha_planar = have_alpha_planar(inlink_main) || have_alpha_planar(inlink_overlay);
+
+    outlink->w = inlink_main->w;
+    outlink->h = inlink_main->h;
+    outlink->format = inlink_main->format;
+    av_log(ctx, AV_LOG_DEBUG, "pixfmt main:%s, overlay:%s, blend:%s\n",
+            av_get_pix_fmt_name(inlink_main->format), av_get_pix_fmt_name(inlink_overlay->format),
+            av_get_pix_fmt_name(outlink->format));
+    if (inlink_overlay->format == AV_PIX_FMT_MLU && inlink_overlay->hw_frames_ctx) {
+        overlay_hwframes_ctx = (AVHWFramesContext*)inlink_overlay->hw_frames_ctx->data;
+        if (!overlay_hwframes_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "no hwcontext provided on overlay input\n");
+            return AVERROR(EINVAL);
+        }
+        ctx->in_format_overlay = overlay_hwframes_ctx->sw_format;
+    } else {
+        ctx->in_format_overlay = inlink_overlay->format;
+    }
+    if (!format_is_supported(supported_overlay_formats, ctx->in_format_overlay)) {
+        av_log(ctx, AV_LOG_ERROR, "unsupported overlay input format:%s\n",
+            av_get_pix_fmt_name(ctx->in_format_overlay));
+        return AVERROR(ENOSYS);
+    }
+    if (inlink_main->format == AV_PIX_FMT_MLU && inlink_main->hw_frames_ctx) {
+        main_hwframes_ctx = (AVHWFramesContext*)inlink_main->hw_frames_ctx->data;
+        ctx->hwctx = main_hwframes_ctx->device_ctx->hwctx;
+
+        ctx->stride_align = CNFILTER_FRAME_ALIGNMENT;
+        if (!inlink_main->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "input must have a hwframe reference\n");
+            return AVERROR(EINVAL);
+        }
+        ctx->hw_device_ref   = av_buffer_ref(main_hwframes_ctx->device_ref);
+        ctx->in_format_main  = main_hwframes_ctx->sw_format;
+
+        av_buffer_unref(&ctx->main_hwframe_ref);
+        ctx->main_hwframe_ref = av_hwframe_ctx_alloc(ctx->hw_device_ref);
+        if (!ctx->main_hwframe_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(EINVAL);
+            goto fail;
+        }
+        // for output hwframe creating.
+        out_hw_frames_ctx = (AVHWFramesContext*)ctx->main_hwframe_ref->data;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format    = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = ctx->in_format_main; // for in pixfmt == out pixfmt
+            out_hw_frames_ctx->width     = FFALIGN(outlink->w, ctx->stride_align);
+            out_hw_frames_ctx->height    = outlink->h;
+            if ((ret = av_hwframe_ctx_init(ctx->main_hwframe_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(ctx->main_hwframe_ref);
+        if (!outlink->hw_frames_ctx) {
+            return AVERROR(EINVAL);
+        }
+    } else {
+        sprintf(dev_idx, "%d", ctx->mlu);
+        ctx->in_format_main = inlink_main->format;
+
+        av_buffer_unref(&ctx->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&ctx->hw_device_ref, AV_HWDEVICE_TYPE_MLU, dev_idx, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        ctx->hwctx = ((AVHWDeviceContext*)ctx->hw_device_ref->data)->hwctx;
+        ctx->stride_align = 1;
+    }
+    if (!format_is_supported(supported_main_formats, ctx->in_format_main)) {
+        av_log(ctx, AV_LOG_ERROR, "unsupported main input format: %s\n",
+            av_get_pix_fmt_name(ctx->in_format_main));
+        return AVERROR(ENOSYS);
+    }
+
+    ret = get_pixfmt_plane_size(ctx->main_plane_size,
+            ctx->in_format_main, inlink_main->w, inlink_main->h);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "main input get plane size failed, ret:%d\n", ret);
+        return ret;
+    }
+    ret = get_pixfmt_plane_size(ctx->overlay_plane_size,
+            ctx->in_format_overlay, inlink_overlay->w, inlink_overlay->h);
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "overlay input get plane size failed, ret:%d\n", ret);
+        return ret;
+    }
+
+    ctx->mlu_ctx = ctx->hwctx->mlu_ctx;
+    if (mlu_device_affinity(ctx->hwctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    if (!ctx->op_handle) {
+        // mlu overlay init
+        alpha_fmt = ctx->have_alpha_planar ? "rgba" : "rgb24";
+        ctx->mlu_ctx->mluOverlayInit(&ctx->op_handle, inlink_main->w, inlink_main->h,
+                CHECK_RGBX(av_get_pix_fmt_name(ctx->in_format_main)),
+                CHECK_RGBX(av_get_pix_fmt_name(ctx->in_format_overlay)), CHECK_RGBX(alpha_fmt));
+
+        if (inlink_overlay->format != AV_PIX_FMT_MLU) {
+            for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                if (0 != ctx->overlay_plane_size[i]) {
+                    ret = ctx->mlu_ctx->mluMemAlloc(
+                            (void **)(&ctx->overlay_mlu_ptr[i]), ctx->overlay_plane_size[i]);
+                    MLUFILTER_CHECK(ctx, ret);
+                }
+            }
+        }
+        if (inlink_main->format != AV_PIX_FMT_MLU) {
+            for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                if (0 != ctx->main_plane_size[i]) {
+                    ret = ctx->mlu_ctx->mluMemAlloc(
+                            (void**)(&ctx->main_mlu_ptr[i]), ctx->main_plane_size[i]);
+                    MLUFILTER_CHECK(ctx, ret);
+                    ret = ctx->mlu_ctx->mluMemAlloc(
+                            (void**)(&ctx->output_mlu_ptr[i]), ctx->main_plane_size[i]);
+                    MLUFILTER_CHECK(ctx, ret);
+                }
+            }
+        }
+    }
+
+    outlink->time_base = inlink_main->time_base;
+    if (inlink_main->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational) {outlink->h * inlink_main->w,
+            outlink->w * inlink_main->h}, inlink_main->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink_main->sample_aspect_ratio;
+    }
+
+    // init dual input
+    ret = ff_framesync_init_dualinput(&ctx->fs, avctx);
+    if (ret < 0) {
+        return ret;
+    }
+
+    return ff_framesync_configure(&ctx->fs);
+
+fail:
+    if (ctx->main_hwframe_ref)
+        av_buffer_unref(&ctx->main_hwframe_ref);
+    if (ctx->hw_device_ref)
+        av_buffer_unref(&ctx->hw_device_ref);
+    return ret;
+}
+
+static int overlay_mlu_blend(FFFrameSync *fs)
+{
+    AVFilterContext *avctx = fs->parent;
+    OverlayMluContext *ctx = avctx->priv;
+    AVFilterLink *outlink  = avctx->outputs[0];
+    AVFilterLink *inlink_main    = avctx->inputs[0];
+    AVFilterLink *inlink_overlay = avctx->inputs[1];
+    MluContext *mlu_ctx          = ctx->hwctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *output, *input_main, *input_overlay;
+
+    if (!ctx->affinity_set && mlu_device_affinity(ctx->hwctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    ctx->affinity_set = true;
+    ret = ff_framesync_dualinput_get(fs, &input_main, &input_overlay);
+    if (ret < 0) {
+        return ret;
+    }
+    if (!input_main) {
+        if (input_overlay) av_frame_free(&input_overlay);
+        return AVERROR_BUG;
+    }
+    if (!input_overlay) {
+        return ff_filter_frame(outlink, input_main);
+    }
+    ret = av_frame_make_writable(input_main);
+    if (ret < 0) {
+        av_frame_free(&input_main);
+        return ret;
+    }
+    if (ctx->eval_mode == EVAL_MODE_FRAME) {
+        ctx->var_values[VAR_N] = inlink_main->frame_count_out;
+        ctx->var_values[VAR_T] = input_main->pts == AV_NOPTS_VALUE ?
+            NAN : input_main->pts * av_q2d(inlink_main->time_base);
+        ctx->var_values[VAR_OVERLAY_W] = ctx->var_values[VAR_OW] = input_overlay->width;
+        ctx->var_values[VAR_OVERLAY_H] = ctx->var_values[VAR_OH] = input_overlay->height;
+        ctx->var_values[VAR_MAIN_W   ] = ctx->var_values[VAR_MW] = input_main->width;
+        ctx->var_values[VAR_MAIN_H   ] = ctx->var_values[VAR_MH] = input_main->height;
+
+        eval_expr(avctx);
+
+        av_log(avctx, AV_LOG_DEBUG, "n:%f t:%f x:%f xi:%d y:%f yi:%d\n",
+               ctx->var_values[VAR_N], ctx->var_values[VAR_T],
+               ctx->var_values[VAR_X], ctx->x_position,
+               ctx->var_values[VAR_Y], ctx->y_position);
+    }
+
+    output = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!output) {
+        ret = AVERROR(EINVAL);
+        av_log(avctx, AV_LOG_WARNING, "ff_get_video_buffer failed\n");
+        goto fail;
+    }
+    av_frame_copy_props(output, input_main);
+
+    if (ctx->op_handle) {
+        if (inlink_main->format == AV_PIX_FMT_MLU) {
+            for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                if (0 != ctx->main_plane_size[i]) {
+                    ctx->main_mlu_ptr[i]  = input_main->data[i];
+                    ctx->output_mlu_ptr[i]= output->data[i];
+                }
+            }
+            if (inlink_overlay->format == AV_PIX_FMT_MLU) {
+                for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                    if (0 != ctx->overlay_plane_size[i]) {
+                        ctx->overlay_mlu_ptr[i] = input_overlay->data[i];
+                    }
+                }
+            } else {
+                for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                    if (0 != ctx->overlay_plane_size[i]) {
+                        ret = mlu_ctx->mluMemcpyH2D((void*)ctx->overlay_mlu_ptr[i],
+                                (void*)input_overlay->data[i], ctx->overlay_plane_size[i],
+                                CNRT_MEM_TRANS_DIR_HOST2DEV);
+                        MLUFILTER_CHECK(avctx, ret);
+                    }
+                }
+            }
+        } else {
+            for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                if (0 != ctx->main_plane_size[i]) {
+                    ret = mlu_ctx->mluMemcpyH2D((void *)ctx->main_mlu_ptr[i],
+                            (void *)input_main->data[i], ctx->main_plane_size[i],
+                    CNRT_MEM_TRANS_DIR_HOST2DEV);
+                }
+            }
+            if (inlink_overlay->format == AV_PIX_FMT_MLU) {
+                for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                    if (0 != ctx->overlay_plane_size[i]) {
+                        ctx->overlay_mlu_ptr[i] = input_overlay->data[i];
+                    }
+                }
+            } else {
+                for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                    if (0 != ctx->overlay_plane_size[i]) {
+                        ret = mlu_ctx->mluMemcpyH2D((void *)ctx->overlay_mlu_ptr[i],
+                                (void *)input_overlay->data[i], ctx->overlay_plane_size[i],
+                        CNRT_MEM_TRANS_DIR_HOST2DEV);
+                    }
+                }
+            }
+        }
+        ret = mlu_ctx->mluOverlayExec(ctx->op_handle,
+                ctx->output_mlu_ptr, ctx->main_mlu_ptr, ctx->overlay_mlu_ptr,
+                input_overlay->width, input_overlay->height,
+                ctx->x_position, ctx->y_position,
+                input_overlay->width, input_overlay->height,
+                ctx->overlay_alpha, 1 - ctx->overlay_alpha, 0);
+        if (ret < 0) {
+            av_log(avctx, AV_LOG_ERROR, "overlay_mlu exec failed, ret:%d\n", ret);
+            goto fail;
+        }
+        if (inlink_main->format != AV_PIX_FMT_MLU) {
+            for (int i = 0; i < MAX_PLANE_NUM; i++) {
+                if (0 != ctx->main_plane_size[i]) {
+                    ret = mlu_ctx->mluMemcpyD2H((void *)output->data[i],
+                            (void *)ctx->output_mlu_ptr[i], ctx->main_plane_size[i],
+                            CNRT_MEM_TRANS_DIR_DEV2HOST);
+                    MLUFILTER_CHECK(avctx, ret);
+                }
+            }
+        }
+    }
+
+    av_reduce(&output->sample_aspect_ratio.num, &output->sample_aspect_ratio.den,
+            (int64_t)input_main->sample_aspect_ratio.num * outlink->h * inlink_main->w,
+            (int64_t)input_main->sample_aspect_ratio.den * outlink->w * inlink_main->h, INT_MAX);
+    av_frame_free(&input_main);
+
+    return ff_filter_frame(outlink, output);
+
+fail:
+    av_frame_free(&input_main);
+    av_frame_free(&output);
+
+    return ret;
+}
+
+static av_cold int overlay_mlu_init(AVFilterContext *avctx)
+{
+    OverlayMluContext *ctx = avctx->priv;
+    ctx->fs.on_event  = &overlay_mlu_blend;
+    ctx->op_handle    = NULL;
+    ctx->affinity_set = false;
+
+    return 0;
+}
+
+static av_cold void overlay_mlu_uninit(AVFilterContext *avctx)
+{
+    OverlayMluContext *ctx = avctx->priv;
+    MluContext *mlu_ctx = NULL;
+
+    ff_framesync_uninit(&ctx->fs);
+    av_expr_free(ctx->x_pexpr); ctx->x_pexpr = NULL;
+    av_expr_free(ctx->y_pexpr); ctx->y_pexpr = NULL;
+    if (!ctx->hwctx) return;
+
+    mlu_ctx = ctx->hwctx->mlu_ctx;
+    if (ctx->op_handle) {
+        mlu_ctx->mluOverlayDestroy(ctx->op_handle);
+        ctx->op_handle = NULL;
+    }
+    if (ctx->inlink_overlay_pixfmt != AV_PIX_FMT_MLU) {
+        for (int i = 0; i < MAX_PLANE_NUM; i++) {
+            if (0 != ctx->overlay_plane_size[i]) {
+                mlu_ctx->mluMemFree(ctx->overlay_mlu_ptr[i]);
+                ctx->overlay_mlu_ptr[i] = NULL;
+            }
+        }
+    }
+    if (ctx->inlink_main_pixfmt != AV_PIX_FMT_MLU) {
+        for (int i = 0; i < MAX_PLANE_NUM; i++) {
+            if (0 != ctx->main_plane_size[i]) {
+                mlu_ctx->mluMemFree(ctx->main_mlu_ptr[i]);
+                mlu_ctx->mluMemFree(ctx->output_mlu_ptr[i]);
+                ctx->main_mlu_ptr[i] = NULL;
+                ctx->output_mlu_ptr[i] = NULL;
+            }
+        }
+    }
+    if (ctx->main_hwframe_ref) {
+        av_buffer_unref(&ctx->main_hwframe_ref);
+    }
+    if (ctx->hw_device_ref) {
+        av_buffer_unref(&ctx->hw_device_ref);
+    }
+}
+
+static int overlay_mlu_activate(AVFilterContext *avctx)
+{
+    OverlayMluContext *ctx = avctx->priv;
+    return ff_framesync_activate(&ctx->fs);
+}
+
+#define OFFSET(x) offsetof(OverlayMluContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+
+static const AVOption overlay_mlu_options[] = {
+    {"x", "set the x expression of overlay", OFFSET(x_expr), AV_OPT_TYPE_STRING, {.str = "0"}, 0, 0, FLAGS},
+    {"y", "set the y expression of overlay", OFFSET(y_expr), AV_OPT_TYPE_STRING, {.str = "0"}, 0, 0, FLAGS},
+    {"n", "mlu device index",                OFFSET(mlu), AV_OPT_TYPE_INT,       {.str = 0  }, 0, 255,.flags = FLAGS },
+    {"alpha", "overlay global alpha", OFFSET(overlay_alpha), AV_OPT_TYPE_DOUBLE, {.dbl = 0.5}, 0, 1,  .flags = FLAGS},
+    {"eof_action", "Action to take when encountering EOF from secondary input ",
+        OFFSET(fs.opt_eof_action), AV_OPT_TYPE_INT, {.i64 = EOF_ACTION_REPEAT}, EOF_ACTION_REPEAT, EOF_ACTION_PASS, .flags = FLAGS, .unit = "eof_action"},
+        {"repeat", "Repeat the previous frame.", 0, AV_OPT_TYPE_CONST, {.i64 = EOF_ACTION_REPEAT},.flags = FLAGS, .unit = "eof_action"},
+        {"endall", "End both streams.",          0, AV_OPT_TYPE_CONST, {.i64 = EOF_ACTION_ENDALL},.flags = FLAGS, .unit = "eof_action"},
+        {"pass", "Pass through the main input.", 0, AV_OPT_TYPE_CONST, {.i64 = EOF_ACTION_PASS},  .flags = FLAGS, .unit = "eof_action"},
+    {"eval", "specify when to evaluate expressions", OFFSET(eval_mode), AV_OPT_TYPE_INT, {.i64 = EVAL_MODE_FRAME}, 0, EVAL_MODE_NB - 1, FLAGS, .unit = "eval"},
+        {"init", "eval expressions once during initialization", 0, AV_OPT_TYPE_CONST, {.i64 = EVAL_MODE_INIT}, .flags = FLAGS, .unit = "eval"},
+        {"frame", "eval expressions per-frame",                 0, AV_OPT_TYPE_CONST, {.i64 = EVAL_MODE_FRAME},.flags = FLAGS, .unit = "eval"},
+    {"shortest", "force termination when the shortest input terminates", OFFSET(fs.opt_shortest),   AV_OPT_TYPE_BOOL, {.i64 = 0}, 0, 1, FLAGS},
+    {"repeatlast", "repeat overlay of the last overlay frame",           OFFSET(fs.opt_repeatlast), AV_OPT_TYPE_BOOL, {.i64 = 1}, 0, 1, FLAGS},
+    {NULL},
+};
+
+FRAMESYNC_DEFINE_CLASS(overlay_mlu, OverlayMluContext, fs);
+
+static const AVFilterPad overlay_mlu_inputs[] = {
+    {
+        .name = "main",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .config_props  = config_input_main,
+    },
+    {
+        .name = "overlay",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_input_overlay,
+    },
+    { NULL }
+};
+
+static const AVFilterPad overlay_mlu_outputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_output,
+    },
+    { NULL }
+};
+
+const AVFilter ff_vf_overlay_mlu = {
+    .name           = "overlay_mlu",
+    .description    = NULL_IF_CONFIG_SMALL("MLU accelerated overlay filter"),
+    .priv_size      = sizeof(OverlayMluContext),
+    .priv_class     = &overlay_mlu_class,
+    .query_formats  = mlu_overlay_query_formats,
+    .preinit        = overlay_mlu_framesync_preinit,
+    .init           = overlay_mlu_init,
+    .uninit         = overlay_mlu_uninit,
+    .activate       = overlay_mlu_activate,
+    .inputs         = overlay_mlu_inputs,
+    .outputs        = overlay_mlu_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_rotate_mlu.c b/libavfilter/vf_rotate_mlu.c
new file mode 100644
index 0000000000..3f8a574f96
--- /dev/null
+++ b/libavfilter/vf_rotate_mlu.c
@@ -0,0 +1,326 @@
+/*
+ * Copyright (c) 2024, CAMBRICON CORPORATION. All rights reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright no5tice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+ * DEALINGS IN THE SOFTWARE.
+ */
+
+/**
+ * @file
+ * rotation mlu filter
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/eval.h"
+#include "libavutil/opt.h"
+#include "libavutil/intreadwrite.h"
+#include "libavutil/parseutils.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/common.h"
+#include "libavutil/internal.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/log.h"
+
+#include "mlu_filter_common.h"
+#include "filters.h"
+#include "time.h"
+#include <float.h>
+
+#define MAX_PLANE_NUM 4
+#define CNFILTER_FRAME_ALIGNMENT 1
+
+typedef struct RotMluContext {
+    const AVClass *class;
+
+    AVMLUDeviceContext *hw_device_ctx;
+    AVHWFramesContext  *hw_frame_ctx;
+    AVBufferRef *hw_device_ref;
+    AVBufferRef *hw_frame_ref;
+    MluContext *mlu_ctx;
+
+    int mlu;
+    int passthrough;
+    double angle;
+    enum AVPixelFormat pic_pixfmt;
+    enum AVPixelFormat inlink_pixfmt;
+
+    uint8_t fillcolor[4];
+    char *fillcolor_str;
+    char *fillmode_str;
+
+    void *input_mlu;
+    void *output_mlu;
+    int input_mlu_size;
+    int output_mlu_size;
+
+    bool affinity_set;
+    void *op_handle;
+} RotMluContext;
+
+static av_cold int rotate_mlu_init(AVFilterContext *ctx)
+{
+    RotMluContext *rot = ctx->priv;
+
+    if (!strcmp(rot->fillcolor_str, "none")) {
+        rot->fillcolor_str = "white";
+    }
+    if (av_parse_color(rot->fillcolor, rot->fillcolor_str, -1, ctx) < 0) {
+        av_log(ctx, AV_LOG_ERROR, "parse color failed!!!\n");
+        return AVERROR(EINVAL);
+    }
+
+    rot->input_mlu = NULL;
+    rot->output_mlu= NULL;
+    rot->op_handle = NULL;
+    rot->affinity_set = false;
+
+    return 0;
+}
+
+static av_cold void rotate_mlu_uninit(AVFilterContext *ctx)
+{
+    RotMluContext *rot = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+
+    if (!rot->hw_device_ctx)
+        return;
+    mlu_ctx = rot->hw_device_ctx->mlu_ctx;
+    if (rot->op_handle) {
+        mlu_ctx->mluRotateDestroy(rot->op_handle);
+    }
+    if (rot->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (rot->input_mlu)
+            mlu_ctx->mluMemFree(rot->input_mlu);
+        if (rot->output_mlu)
+            mlu_ctx->mluMemFree(rot->output_mlu);
+    }
+    if (rot->hw_frame_ref) {
+        av_buffer_unref(&rot->hw_frame_ref);
+    }
+    if (rot->hw_device_ref) {
+        av_buffer_unref(&rot->hw_device_ref);
+    }
+}
+
+static int query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_0RGB, AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_0BGR, AV_PIX_FMT_BGR0,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    AVFilterFormats *fmts_list = ff_make_format_list(pix_fmts);
+    if (!fmts_list)
+        return AVERROR(ENOMEM);
+    return ff_set_common_formats(ctx, fmts_list);
+}
+
+static int rotate_mlu_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    RotMluContext *rot = ctx->priv;
+    AVFilterLink *inlink = ctx->inputs[0];
+    const AVPixFmtDescriptor *pixdesc = av_pix_fmt_desc_get(inlink->format);
+
+    int ret;
+    char mlu[sizeof(int)];
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    rot->inlink_pixfmt = inlink->format;
+
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        rot->hw_frame_ctx  = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        rot->hw_device_ctx = (AVMLUDeviceContext *)rot->hw_frame_ctx->device_ctx->hwctx;
+        rot->hw_frame_ref  = av_buffer_ref(inlink->hw_frames_ctx);
+        rot->hw_device_ref = av_buffer_ref(rot->hw_frame_ctx->device_ref);
+
+        rot->pic_pixfmt = rot->hw_frame_ctx->sw_format;
+        outlink->format = inlink->format;
+        outlink->hw_frames_ctx = av_buffer_ref(inlink->hw_frames_ctx);
+    } else {
+        sprintf(mlu, "%d", rot->mlu);
+        rot->pic_pixfmt = inlink->format;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&rot->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&rot->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        rot->hw_device_ctx = ((AVHWDeviceContext*)rot->hw_device_ref->data)->hwctx;
+    }
+
+    rot->input_mlu_size = av_image_get_buffer_size(rot->pic_pixfmt, inlink->w,  inlink->h,  1);
+    rot->output_mlu_size= av_image_get_buffer_size(rot->pic_pixfmt, outlink->w, outlink->h, 1);
+
+    rot->mlu_ctx = rot->hw_device_ctx->mlu_ctx;
+    if (mlu_device_affinity(rot->hw_device_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+
+    if (!rot->op_handle) {
+        rot->mlu_ctx->mluRotateInit(&rot->op_handle, inlink->w, inlink->h, (rot->angle*180.0/M_PI),
+                CHECK_RGBX(av_get_pix_fmt_name(rot->pic_pixfmt)), rot->fillmode_str, rot->fillcolor);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = rot->mlu_ctx->mluMemAlloc((void **)(&rot->input_mlu), rot->input_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = rot->mlu_ctx->mluMemAlloc((void **)(&rot->output_mlu), rot->output_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q(
+            (AVRational){outlink->h*inlink->w, outlink->w*inlink->h}, inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!rot->hw_frame_ref)
+        av_buffer_unref(&rot->hw_frame_ref);
+    if (!rot->hw_device_ref)
+        av_buffer_unref(&rot->hw_device_ref);
+    return ret;
+}
+
+static int filter_frame(AVFilterLink *inlink, AVFrame *in)
+{
+    AVFilterContext *ctx  = inlink->dst;
+    AVFilterLink *outlink = ctx->outputs[0];
+    RotMluContext *rot    = ctx->priv;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (inlink->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!rot->affinity_set && mlu_device_affinity(rot->hw_device_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    rot->affinity_set = true;
+
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        av_frame_free(&in);
+        return AVERROR(ENOMEM);
+    }
+    if (rot->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    // ret = av_image_fill_linesizes(out->linesize, rot->pic_pixfmt, out->width);
+
+    if (rot->op_handle) {
+        if (inlink->format == AV_PIX_FMT_MLU) {
+            rot->input_mlu  = in->data[0];
+            rot->output_mlu = out->data[0];
+        } else {
+            ret = rot->mlu_ctx->mluMemcpyH2D((void *)rot->input_mlu, (void *)in->data[0],
+                    rot->input_mlu_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        ret = rot->mlu_ctx->mluRotateExec(rot->op_handle, rot->input_mlu, rot->output_mlu);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rotate image with mlu\n");
+            goto fail;
+        }
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = rot->mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)rot->output_mlu,
+                    rot->output_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+            (int64_t)in->sample_aspect_ratio.num * outlink->h * inlink->w,
+            (int64_t)in->sample_aspect_ratio.den * outlink->w * inlink->h, INT_MAX);
+    av_frame_free(&in);
+
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(RotMluContext, x)
+#define FLAGS AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM
+
+static const AVOption rotate_mlu_options[] = {
+    { "n",         "set device imdex",          OFFSET(mlu),   AV_OPT_TYPE_INT64,  {.i64=0},   0, INT_MAX,  .flags=FLAGS },
+    { "angle",     "set angle (in radians)",    OFFSET(angle), AV_OPT_TYPE_DOUBLE, {.dbl=0.0}, -M_PI, M_PI, .flags=FLAGS },
+    { "a",         "set angle (in radians)",    OFFSET(angle), AV_OPT_TYPE_DOUBLE, {.dbl=0.0}, -M_PI, M_PI, .flags=FLAGS },
+    { "fillcolor", "set background fill color", OFFSET(fillcolor_str), AV_OPT_TYPE_STRING, {.str="black"},    0, 0, .flags=FLAGS },
+    { "c",         "set background fill color", OFFSET(fillcolor_str), AV_OPT_TYPE_STRING, {.str="black"},    0, 0, .flags=FLAGS },
+    { "fillmode",  "set background fill mode",  OFFSET(fillmode_str),  AV_OPT_TYPE_STRING, {.str="constant"}, 0, 0, .flags=FLAGS, .unit = "fillmode"},
+        { "constant",  "", 0, AV_OPT_TYPE_CONST, {.str="constant"}, .flags=FLAGS, .unit = "fillmode"},
+        { "replicate", "", 0, AV_OPT_TYPE_CONST, {.str="replicate"},.flags=FLAGS, .unit = "fillmode"},
+    { "m",         "set background fill mode",  OFFSET(fillmode_str), AV_OPT_TYPE_STRING, {.str="constant"},  0, 0, .flags=FLAGS, .unit = "m"},
+        { "constant",  "", 0, AV_OPT_TYPE_CONST, {.str="constant"}, .flags=FLAGS, .unit = "m"},
+        { "replicate", "", 0, AV_OPT_TYPE_CONST, {.str="replicate"},.flags=FLAGS, .unit = "m"},
+
+    { NULL }
+};
+
+AVFILTER_DEFINE_CLASS(rotate_mlu);
+
+static const AVFilterPad rotate_mlu_inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad rotate_mlu_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = rotate_mlu_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_rotate_mlu = {
+    .name          = "rotate_mlu",
+    .description   = NULL_IF_CONFIG_SMALL("MLU accelerated Rotate the input image."),
+    .priv_size     = sizeof(RotMluContext),
+    .priv_class    = &rotate_mlu_class,
+    .init          = rotate_mlu_init,
+    .uninit        = rotate_mlu_uninit,
+    .query_formats = query_formats,
+    .inputs        = rotate_mlu_inputs,
+    .outputs       = rotate_mlu_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c b/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
new file mode 100644
index 0000000000..bcda02fb17
--- /dev/null
+++ b/libavfilter/vf_scale_cvt_yuv2rgbx_mlu.c
@@ -0,0 +1,431 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale_eval.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21, AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA, AV_PIX_FMT_ABGR,  AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR, AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluScaleCvtYUV2RGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat  inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format;
+
+    char *w_expr;
+    char *h_expr;
+    char *mlu;
+    char *depth;
+    char *enter_out_fmt;
+    const char *pic_pixfmt;
+
+    int  in_y_size;
+    int  in_uv_size;
+    int  out_mlu_size;
+    void *input_mlu_y;
+    void *input_mlu_uv;
+    void *output_mlu_rgbx;
+    bool affinity_set;
+
+    void *op_handle;
+} MluScaleCvtYUV2RGBXContext;
+
+static int mluscale_cvt_query_formats(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    enum AVPixelFormat out_pixfmt;
+    AVFilterFormats *pixel_formats;
+
+    int ret;
+    static const enum AVPixelFormat in_pix_fmts[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    static const enum AVPixelFormat out_pix_fmts[] = {
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    out_pixfmt = av_get_pix_fmt(s->enter_out_fmt);
+    pixel_formats = ff_make_format_list(in_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    if (out_pixfmt == AV_PIX_FMT_NONE)
+        return ff_set_common_formats(ctx, pixel_formats);
+
+    ret = ff_formats_ref(pixel_formats, &ctx->inputs[0]->outcfg.formats);
+    if (ret < 0)
+        return ret;
+
+    pixel_formats = NULL;
+    pixel_formats = ff_make_format_list(out_pix_fmts);
+    if (!pixel_formats)
+        return AVERROR(ENOMEM);
+    ret = ff_add_format(&pixel_formats, out_pixfmt);
+    if (ret < 0)
+        return ret;
+    ret = ff_formats_ref(pixel_formats, &ctx->outputs[0]->incfg.formats);
+    if (ret < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluscale_cvt_init(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    s->input_mlu_y     = NULL;
+    s->input_mlu_uv    = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle       = NULL;
+    s->affinity_set    = false;
+
+    return 0;
+}
+
+static av_cold void mluscale_cvt_uninit(AVFilterContext *ctx)
+{
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        mlu_ctx->mluScaleCvtYuv2RgbxDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluscale_cvt_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluScaleCvtYUV2RGBXContext *s  = ctx->priv;
+
+    int w, h;
+    MluContext *mlu_ctx = NULL;
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    int ret;
+    char mlu[sizeof(int)];
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr,
+                                        inlink, outlink, &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    s->in_y_size    = inlink->w * inlink->h;
+    s->in_uv_size   = inlink->w * inlink->h / 2;
+    s->out_mlu_size = outlink->w * outlink->h *
+                    get_stride_scale_by_pixfmt(av_get_pix_fmt(s->enter_out_fmt));
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = av_get_pix_fmt(s->enter_out_fmt);
+        outlink->format = av_get_pix_fmt(s->enter_out_fmt);
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluScaleCvtYuv2RgbxInit(&s->op_handle,
+                                       inlink->w, inlink->h,
+                                       outlink->w, outlink->h,
+                                       s->pic_pixfmt, CHECK_RGBX(s->enter_out_fmt),
+                                       s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), sizeof(char) * s->in_y_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), sizeof(char) * s->in_uv_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->out_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h*inlink->w,
+                                                             outlink->w*inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluscale_cvt_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext*ctx      = link->dst;
+    MluScaleCvtYUV2RGBXContext *s = ctx->priv;
+    AVFilterLink*outlink     = ctx->outputs[0];
+    MluContext *mlu_ctx      = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y = in->data[0];
+            s->input_mlu_uv = in->data[1];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                                  s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                                  s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        ret = mlu_ctx->mluScaleCvtYuv2RgbxExec(s->op_handle, s->input_mlu_y,
+                                             s->input_mlu_uv, s->output_mlu_rgbx);
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2rgbx filter with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->out_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleCvtYUV2RGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "Output video width",  OFFSET(w_expr), AV_OPT_TYPE_STRING, {.str = "iw"}, .flags = FLAGS },
+    { "h", "Output video height", OFFSET(h_expr), AV_OPT_TYPE_STRING, {.str = "ih"}, .flags = FLAGS },
+    { "o_fmt", "output pixfmt",   OFFSET(enter_out_fmt), AV_OPT_TYPE_STRING, {.str = "of"}, .flags = FLAGS},
+    { "n",     "device index",    OFFSET(mlu),    AV_OPT_TYPE_STRING, {.str = "0"}, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mluscale_cvt_class = {
+    .class_name = "mluscale_cvt",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluscale_cvt_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluscale_cvt_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluscale_cvt_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluscale_cvt_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_cvt_yuv2rgbx_mlu = {
+    .name      = "scale_cvt_yuv2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated resize and convert yuv to rgbx"),
+
+    .init          = mluscale_cvt_init,
+    .uninit        = mluscale_cvt_uninit,
+    .query_formats = mluscale_cvt_query_formats,
+
+    .priv_size = sizeof(MluScaleCvtYUV2RGBXContext),
+    .priv_class = &mluscale_cvt_class,
+
+    .inputs    = mluscale_cvt_inputs,
+    .outputs   = mluscale_cvt_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_rgbx2rgbx_mlu.c b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
new file mode 100644
index 0000000000..68baa80ba1
--- /dev/null
+++ b/libavfilter/vf_scale_rgbx2rgbx_mlu.c
@@ -0,0 +1,421 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale_eval.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+    AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_MLU,
+};
+
+typedef struct MluScaleRGBXContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[3], planes_out[3];
+
+    AVFrame            *out_hw_frame;
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int passthrough;
+    enum AVPixelFormat format;
+
+    char *w_expr;
+    char *h_expr;
+    char *mlu;
+    char *depth;
+    const char *pic_pixfmt;
+
+    bool is_crop;
+    int crop_x, crop_y, crop_w, crop_h;
+    int dst_crop_x, dst_crop_y, dst_crop_w, dst_crop_h;
+
+    int  input_mlu_size;
+    int  output_mlu_size;
+    void *input_mlu_rgbx;
+    void *output_mlu_rgbx;
+    bool affinity_set;
+
+    void *op_handle;
+} MluScaleRGBXContext;
+
+static int mlurgbxscale_query_formats(AVFilterContext *ctx)
+{
+    static const enum AVPixelFormat pix_fmts[] = {
+        AV_PIX_FMT_ARGB, AV_PIX_FMT_RGBA,
+        AV_PIX_FMT_ABGR, AV_PIX_FMT_BGRA,
+        AV_PIX_FMT_RGB24,AV_PIX_FMT_BGR24,
+        AV_PIX_FMT_0RGB, AV_PIX_FMT_0BGR,
+        AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+
+    int ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->inputs[0]->outcfg.formats)) < 0)
+        return ret;
+    if ((ret = ff_formats_ref(ff_make_format_list(pix_fmts),
+                              &ctx->outputs[0]->incfg.formats)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mlurgbxscale_init(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+    s->is_crop         = false;
+    s->input_mlu_rgbx  = NULL;
+    s->output_mlu_rgbx = NULL;
+    s->op_handle       = NULL;
+    s->affinity_set    = false;
+
+    return 0;
+}
+
+static av_cold void mlurgbxscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleRGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+
+    if (s->op_handle) {
+        mlu_ctx->mluScaleRgbxDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->input_mlu_rgbx);
+        if (s->output_mlu_rgbx)
+            mlu_ctx->mluMemFree(s->output_mlu_rgbx);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mlurgbxscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx   = outlink->src;
+    AVFilterLink *inlink   = ctx->inputs[0];
+    MluScaleRGBXContext *s = ctx->priv;
+    MluContext *mlu_ctx    = NULL;
+
+    int w, h, ret;
+    char mlu[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx  = NULL;
+
+    if (s->crop_x != 0 || s->crop_y != 0) {
+        s->is_crop = true;
+        s->crop_w = atoi(s->w_expr);
+        s->crop_h = atoi(s->h_expr);
+        s->dst_crop_x = 0;
+        s->dst_crop_y = 0;
+        s->dst_crop_w = s->crop_w;
+        s->dst_crop_h = s->crop_h;
+    }
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr, inlink, outlink, &w, &h)) < 0)
+        goto fail;
+
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big.\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "the input must have a hwframe reference. \n");
+            return AVERROR(EINVAL);
+        }
+
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(ENOMEM);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width  = FFALIGN(outlink->w, 1);
+            out_hw_frames_ctx->height = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx)
+            return AVERROR(ENOMEM);
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref, AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+    }
+
+    s->input_mlu_size  = inlink->w * inlink->h * get_stride_scale_by_pixfmt(s->in_fmt);
+    s->output_mlu_size = outlink->w * outlink->h * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluScaleRgbxInit(&s->op_handle, inlink->w, inlink->h, outlink->w, outlink->h,
+                                CHECK_RGBX(s->pic_pixfmt), s->depth);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = cnrtMalloc((void **)(&s->input_mlu_rgbx), sizeof(char) * s->input_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = cnrtMalloc((void **)(&s->output_mlu_rgbx), sizeof(char) * s->output_mlu_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational){outlink->h * inlink->w,
+                                                             outlink->w * inlink->h},
+                                                inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mlurgbxscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx   = link->dst;
+    MluScaleRGBXContext *s = ctx->priv;
+    AVFilterLink *outlink  = ctx->outputs[0];
+    MluContext *mlu_ctx    = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_rgbx = in->data[0];
+            s->output_mlu_rgbx = out->data[0];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_rgbx, (void *)in->data[0],
+                              s->input_mlu_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        if (!s->is_crop) {
+            ret = mlu_ctx->mluScaleRgbxExec(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx);
+            // ret = mlu_ctx->mluScaleRgbxExecPad(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx);
+        } else {
+            ret = mlu_ctx->mluScaleRgbxExecCrop(s->op_handle, s->input_mlu_rgbx, s->output_mlu_rgbx,
+                        s->crop_x, s->crop_y, s->crop_w, s->crop_h,
+                        s->dst_crop_x, s->dst_crop_y, s->dst_crop_w, s->dst_crop_h);
+        }
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to rgbx2rgbx scale with mluop \n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_rgbx,
+                            s->output_mlu_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleRGBXContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "out width",   OFFSET(w_expr), AV_OPT_TYPE_STRING, { .str = "iw" }, .flags = FLAGS },
+    { "h", "out height",  OFFSET(h_expr), AV_OPT_TYPE_STRING, { .str = "ih" }, .flags = FLAGS },
+    { "n", "device index",OFFSET(mlu), AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { "x", "crop x",      OFFSET(crop_x), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { "y", "crop y",      OFFSET(crop_y), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mlurgbxscale_class = {
+    .class_name = "mlurgbxscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mlurgbxscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mlurgbxscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mlurgbxscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mlurgbxscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_rgbx2rgbx_mlu = {
+    .name      = "scale_rgbx2rgbx_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer for rgbx only support 8U"),
+
+    .init          = mlurgbxscale_init,
+    .uninit        = mlurgbxscale_uninit,
+    .query_formats = mlurgbxscale_query_formats,
+
+    .priv_size = sizeof(MluScaleRGBXContext),
+    .priv_class = &mlurgbxscale_class,
+
+    .inputs    = mlurgbxscale_inputs,
+    .outputs   = mlurgbxscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavfilter/vf_scale_yuv2yuv_mlu.c b/libavfilter/vf_scale_yuv2yuv_mlu.c
new file mode 100644
index 0000000000..50a7b89e5a
--- /dev/null
+++ b/libavfilter/vf_scale_yuv2yuv_mlu.c
@@ -0,0 +1,436 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include "libavutil/avstring.h"
+#include "libavutil/common.h"
+#include "libavutil/hwcontext.h"
+#include "libavutil/hwcontext_mlu.h"
+#include "libavutil/internal.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "scale_eval.h"
+#include "video.h"
+#include "mlu_filter_common.h"
+
+#define CNFILTER_FRAME_ALIGNMENT 1
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+};
+
+typedef struct MluScaleContext {
+    const AVClass *class;
+    enum AVPixelFormat in_fmt;
+    enum AVPixelFormat out_fmt;
+
+    struct {
+        int width;
+        int height;
+    } planes_in[4], planes_out[4];
+
+    AVBufferRef        *hw_device_ref;
+    AVBufferRef        *in_hw_frame_ref;
+    AVBufferRef        *out_hw_frame_ref;
+    MluContext         *mlu_ctx;
+    AVMLUDeviceContext *hw_dev_ctx;
+    AVHWFramesContext  *in_hw_frame_ctx;
+    AVHWFramesContext  *out_hw_frame_ctx;
+    enum AVPixelFormat inlink_pixfmt;
+
+    int stride_align;
+    int passthrough;
+    enum AVPixelFormat format;
+
+    char *w_expr;
+    char *h_expr;
+    char *mlu;
+    char *depth;
+    const char *pic_pixfmt;
+
+    bool is_crop;
+    int crop_x, crop_y, crop_w, crop_h;
+    int dst_crop_x, dst_crop_y, dst_crop_w, dst_crop_h;
+
+    int  in_y_size, in_uv_size, out_y_size, out_uv_size;
+    void *input_mlu_y, *input_mlu_uv, *output_mlu_y, *output_mlu_uv;
+    bool affinity_set;
+
+    void *op_handle;
+} MluScaleContext;
+
+static int mluscale_query_formats(AVFilterContext *ctx)
+{
+    int ret;
+    static const enum AVPixelFormat pixel_formats[] = {
+        AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+        AV_PIX_FMT_MLU,  AV_PIX_FMT_NONE,
+    };
+    AVFilterFormats *pix_fmts = ff_make_format_list(pixel_formats);
+
+    if ((ret = ff_set_common_formats(ctx, pix_fmts)) < 0)
+        return ret;
+
+    return 0;
+}
+
+static int format_is_supported(enum AVPixelFormat fmt)
+{
+    int i;
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        if (supported_formats[i] == fmt)
+            return 1;
+    return 0;
+}
+
+static av_cold int mluscale_init(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+    s->format = AV_PIX_FMT_NONE;
+    s->is_crop = false;
+    s->input_mlu_y = NULL;
+    s->input_mlu_uv = NULL;
+    s->output_mlu_y = NULL;
+    s->output_mlu_uv = NULL;
+    s->op_handle = NULL;
+    s->affinity_set = false;
+    return 0;
+}
+
+static av_cold void mluscale_uninit(AVFilterContext *ctx)
+{
+    MluScaleContext *s = ctx->priv;
+    MluContext *mlu_ctx = NULL;
+    if (!s->hw_dev_ctx) return;
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    if (s->op_handle) {
+        mlu_ctx->mluScaleYuvDestroy(s->op_handle);
+    }
+    if (s->inlink_pixfmt != AV_PIX_FMT_MLU) {
+        if (s->input_mlu_y)
+            mlu_ctx->mluMemFree(s->input_mlu_y);
+        if (s->input_mlu_uv)
+            mlu_ctx->mluMemFree(s->input_mlu_uv);
+        if (s->output_mlu_y)
+            mlu_ctx->mluMemFree(s->output_mlu_y);
+        if (s->output_mlu_uv)
+            mlu_ctx->mluMemFree(s->output_mlu_uv);
+    }
+    if (s->in_hw_frame_ref) {
+        av_buffer_unref(&s->in_hw_frame_ref);
+    }
+    if (s->out_hw_frame_ref) {
+        av_buffer_unref(&s->out_hw_frame_ref);
+    }
+    if (s->hw_device_ref) {
+        av_buffer_unref(&s->hw_device_ref);
+    }
+}
+
+static av_cold int mluscale_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    AVFilterLink *inlink = ctx->inputs[0];
+    MluScaleContext *s   = ctx->priv;
+    MluContext *mlu_ctx  = NULL;
+
+    int w, h, ret;
+    char mlu[sizeof(int)];
+    AVMLUDeviceContext *hw_device_ctx    = NULL;
+    AVHWFramesContext *in_hw_frames_ctx  = NULL;
+    AVHWFramesContext *out_hw_frames_ctx = NULL;
+
+    if (s->crop_x != 0 || s->crop_y != 0) {
+        s->is_crop = true;
+        s->crop_w = atoi(s->w_expr);
+        s->crop_h = atoi(s->h_expr);
+        s->dst_crop_x = 0;
+        s->dst_crop_y = 0;
+        s->dst_crop_w = s->crop_w;
+        s->dst_crop_h = s->crop_h;
+    }
+
+    if ((ret = ff_scale_eval_dimensions(s, s->w_expr, s->h_expr,
+                                        inlink, outlink,  &w, &h)) < 0)
+        goto fail;
+    if (((int64_t)h * inlink->w) > INT_MAX  || ((int64_t)w * inlink->h) > INT_MAX)
+        av_log(ctx, AV_LOG_ERROR, "Rescaled value for width or height is too big\n");
+
+    outlink->w = w;
+    outlink->h = h;
+    s->inlink_pixfmt = inlink->format;
+    sprintf(mlu, "%d", atoi(s->mlu));
+    if (inlink->format == AV_PIX_FMT_MLU && inlink->hw_frames_ctx) {
+        in_hw_frames_ctx = (AVHWFramesContext*)inlink->hw_frames_ctx->data;
+        hw_device_ctx = in_hw_frames_ctx->device_ctx->hwctx;
+
+        s->stride_align = CNFILTER_FRAME_ALIGNMENT;
+        if (!inlink->hw_frames_ctx) {
+            av_log(ctx, AV_LOG_ERROR, "Input must have a hwframe reference\n");
+            return AVERROR(EINVAL);
+        }
+        s->in_hw_frame_ref = av_buffer_ref(inlink->hw_frames_ctx);
+        s->hw_device_ref = av_buffer_ref(in_hw_frames_ctx->device_ref);
+
+        s->hw_dev_ctx = hw_device_ctx;
+        s->in_hw_frame_ctx = in_hw_frames_ctx;
+        s->in_fmt  = in_hw_frames_ctx->sw_format;
+        s->out_fmt = in_hw_frames_ctx->sw_format;
+
+        outlink->format = inlink->format;
+        av_buffer_unref(&s->out_hw_frame_ref);
+        s->out_hw_frame_ref = av_hwframe_ctx_alloc(s->hw_device_ref);
+        if (!s->out_hw_frame_ref) {
+            av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_alloc failed \n");
+            ret = AVERROR(EINVAL);
+            goto fail;
+        }
+        out_hw_frames_ctx = (AVHWFramesContext*)s->out_hw_frame_ref->data;
+        s->out_hw_frame_ctx = out_hw_frames_ctx;
+        if (!out_hw_frames_ctx->pool) {
+            out_hw_frames_ctx->format    = AV_PIX_FMT_MLU;
+            out_hw_frames_ctx->sw_format = s->out_fmt;
+            out_hw_frames_ctx->width     = FFALIGN(outlink->w, s->stride_align);
+            out_hw_frames_ctx->height    = outlink->h;
+            if ((ret = av_hwframe_ctx_init(s->out_hw_frame_ref)) < 0) {
+                av_log(ctx, AV_LOG_ERROR, "av_hwframe_ctx_init failed \n");
+                return 0;
+            }
+        }
+        outlink->hw_frames_ctx = av_buffer_ref(s->out_hw_frame_ref);
+        if (!outlink->hw_frames_ctx) {
+            return AVERROR(EINVAL);
+        }
+    } else {
+        s->in_fmt  = inlink->format;
+        s->out_fmt = s->in_fmt;
+        outlink->format = inlink->format;
+
+        av_buffer_unref(&s->hw_device_ref);
+        ret = av_hwdevice_ctx_create(&s->hw_device_ref,
+                                    AV_HWDEVICE_TYPE_MLU, mlu, NULL, 0);
+        if (ret < 0) {
+            goto fail;
+        }
+        s->hw_dev_ctx = ((AVHWDeviceContext*)s->hw_device_ref->data)->hwctx;
+        s->stride_align = 1;
+    }
+
+    s->in_y_size   = FFALIGN(inlink->w,  s->stride_align) * inlink->h;
+    s->in_uv_size  = FFALIGN(inlink->w,  s->stride_align) * inlink->h / 2;
+    s->out_y_size  = FFALIGN(outlink->w, s->stride_align) * outlink->h;
+    s->out_uv_size = FFALIGN(outlink->w, s->stride_align) * outlink->h / 2;
+
+    if (!format_is_supported(s->in_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported input format: %s\n",
+               av_get_pix_fmt_name(s->in_fmt));
+        return AVERROR(ENOSYS);
+    }
+    if (!format_is_supported(s->out_fmt)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported output format: %s\n",
+               av_get_pix_fmt_name(s->out_fmt));
+        return AVERROR(ENOSYS);
+    }
+
+    mlu_ctx = s->hw_dev_ctx->mlu_ctx;
+    s->mlu_ctx = mlu_ctx;
+    if (mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    if (!s->op_handle) {
+        char depth_[3] = "8U";
+        s->depth = depth_;
+
+        s->pic_pixfmt = av_get_pix_fmt_name(s->in_fmt);
+        mlu_ctx->mluScaleYuvInit(&s->op_handle,
+                            FFALIGN(inlink->w, s->stride_align), inlink->h,
+                            FFALIGN(outlink->w, s->stride_align), outlink->h,
+                            s->depth, s->pic_pixfmt);
+        if (inlink->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_y), s->in_y_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->input_mlu_uv), s->in_uv_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_y), s->out_y_size);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemAlloc((void **)(&s->output_mlu_uv), s->out_uv_size);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+
+    outlink->time_base = inlink->time_base;
+    if (inlink->sample_aspect_ratio.num) {
+        outlink->sample_aspect_ratio = av_mul_q((AVRational) {
+                                        outlink->h*inlink->w,
+                                        outlink->w*inlink->h},
+                                        inlink->sample_aspect_ratio);
+    } else {
+        outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    }
+
+    return 0;
+
+fail:
+    if (!s->in_hw_frame_ref)
+        av_buffer_unref(&s->in_hw_frame_ref);
+    if (!s->out_hw_frame_ref)
+        av_buffer_unref(&s->out_hw_frame_ref);
+    if (!s->hw_device_ref)
+        av_buffer_unref(&s->hw_device_ref);
+    return ret;
+}
+
+static int mluscale_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext  *ctx = link->dst;
+    MluScaleContext    *s = ctx->priv;
+    AVFilterLink *outlink = ctx->outputs[0];
+    MluContext *mlu_ctx   = s->hw_dev_ctx->mlu_ctx;
+
+    int ret = 0;
+    AVFrame *out = NULL;
+    if (link->format == AV_PIX_FMT_MLU && !in->hw_frames_ctx) {
+        av_log(ctx, AV_LOG_ERROR, "Input frames must have hardware context.\n");
+        goto fail;
+    }
+    if (!s->affinity_set && mlu_device_affinity(s->hw_dev_ctx) < 0) {
+        return AVERROR(ENODEV);
+    }
+    s->affinity_set = true;
+    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+    if (!out) {
+        ret = AVERROR(EINVAL);
+        goto fail;
+    }
+    if (s->passthrough) {
+        av_frame_free(&out);
+        return ff_filter_frame(outlink, in);
+    }
+
+    av_frame_copy_props(out, in);
+    out->width  = outlink->w;
+    out->height = outlink->h;
+    out->linesize[0] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+    out->linesize[1] = out->width * get_stride_scale_by_pixfmt(s->out_fmt);
+
+    if (s->op_handle) {
+        if (link->format == AV_PIX_FMT_MLU) {
+            s->input_mlu_y   = in->data[0];
+            s->input_mlu_uv  = in->data[1];
+            s->output_mlu_y  = out->data[0];
+            s->output_mlu_uv = out->data[1];
+        } else {
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_y, (void *)in->data[0],
+                            s->in_y_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyH2D((void *)s->input_mlu_uv, (void *)in->data[1],
+                            s->in_uv_size, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+        if (!s->is_crop) {
+            ret = mlu_ctx->mluScaleYuvExec(s->op_handle, s->input_mlu_y,
+            // ret = s->mluScaleYuvExecPad(s->op_handle, s->input_mlu_y,
+                        s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv);
+        } else {
+            ret = mlu_ctx->mluScaleYuvExecCrop(s->op_handle, s->input_mlu_y,
+                        s->input_mlu_uv, s->output_mlu_y, s->output_mlu_uv,
+                        s->crop_x, s->crop_y, s->crop_w, s->crop_h, s->dst_crop_x,
+                        s->dst_crop_y, s->dst_crop_w, s->dst_crop_h);
+        }
+        if (ret < 0) {
+            av_log(ctx, AV_LOG_ERROR, "Failed to yuv2yuv scale with mluop\n");
+            goto fail;
+        }
+        if (link->format != AV_PIX_FMT_MLU) {
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[0], (void *)s->output_mlu_y,
+                            s->out_y_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+            ret = mlu_ctx->mluMemcpyD2H((void *)out->data[1], (void *)s->output_mlu_uv,
+                            s->out_uv_size, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            MLUFILTER_CHECK(ctx, ret);
+        }
+    }
+    av_reduce(&out->sample_aspect_ratio.num, &out->sample_aspect_ratio.den,
+              (int64_t)in->sample_aspect_ratio.num * outlink->h * link->w,
+              (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
+              INT_MAX);
+
+    av_frame_free(&in);
+    return ff_filter_frame(outlink, out);
+fail:
+    av_frame_free(&in);
+    av_frame_free(&out);
+    return ret;
+}
+
+#define OFFSET(x) offsetof(MluScaleContext, x)
+#define FLAGS (AV_OPT_FLAG_FILTERING_PARAM|AV_OPT_FLAG_VIDEO_PARAM)
+static const AVOption options[] = {
+    { "w", "out width (crop w)", OFFSET(w_expr), AV_OPT_TYPE_STRING, { .str = "iw" }, .flags = FLAGS },
+    { "h", "out height(crop h)", OFFSET(h_expr), AV_OPT_TYPE_STRING, { .str = "ih" }, .flags = FLAGS },
+    { "n", "device index",       OFFSET(mlu), AV_OPT_TYPE_STRING, { .str = "0" }, .flags = FLAGS },
+    { "x", "crop x",        OFFSET(crop_x), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { "y", "crop y",        OFFSET(crop_y), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, .flags = FLAGS},
+    { NULL },
+};
+
+static const AVClass mluscale_class = {
+    .class_name = "mluscale",
+    .item_name  = av_default_item_name,
+    .option     = options,
+    .version    = LIBAVUTIL_VERSION_INT,
+};
+
+static const AVFilterPad mluscale_inputs[] = {
+    {
+        .name        = "default",
+        .type        = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = mluscale_filter_frame,
+    },
+    { NULL }
+};
+
+static const AVFilterPad mluscale_outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = mluscale_config_props,
+    },
+    { NULL }
+};
+
+AVFilter ff_vf_scale_yuv2yuv_mlu = {
+    .name      = "scale_yuv2yuv_mlu",
+    .description = NULL_IF_CONFIG_SMALL("MLU accelerated video resizer"),
+
+    .init          = mluscale_init,
+    .uninit        = mluscale_uninit,
+    .query_formats = mluscale_query_formats,
+
+    .priv_size = sizeof(MluScaleContext),
+    .priv_class = &mluscale_class,
+
+    .inputs    = mluscale_inputs,
+    .outputs   = mluscale_outputs,
+    .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+};
diff --git a/libavutil/Makefile b/libavutil/Makefile
index 27bafe9e12..90fd2d59f4 100644
--- a/libavutil/Makefile
+++ b/libavutil/Makefile
@@ -46,6 +46,7 @@ HEADERS = adler32.h                                                     \
           hwcontext_videotoolbox.h                                      \
           hwcontext_vdpau.h                                             \
           hwcontext_vulkan.h                                            \
+		  hwcontext_mlu.h                                               \
           imgutils.h                                                    \
           intfloat.h                                                    \
           intreadwrite.h                                                \
@@ -186,6 +187,7 @@ OBJS-$(CONFIG_VAAPI)                    += hwcontext_vaapi.o
 OBJS-$(CONFIG_VIDEOTOOLBOX)             += hwcontext_videotoolbox.o
 OBJS-$(CONFIG_VDPAU)                    += hwcontext_vdpau.o
 OBJS-$(CONFIG_VULKAN)                   += hwcontext_vulkan.o
+OBJS-$(CONFIG_MLU)                      += hwcontext_mlu.o
 
 OBJS += $(COMPAT_OBJS:%=../compat/%)
 
@@ -203,6 +205,7 @@ SKIPHEADERS-$(CONFIG_VAAPI)            += hwcontext_vaapi.h
 SKIPHEADERS-$(CONFIG_VIDEOTOOLBOX)     += hwcontext_videotoolbox.h
 SKIPHEADERS-$(CONFIG_VDPAU)            += hwcontext_vdpau.h
 SKIPHEADERS-$(CONFIG_VULKAN)           += hwcontext_vulkan.h
+SKIPHEADERS-$(CONFIG_MLU)              += hwcontext_mlu.h
 
 TESTPROGS = adler32                                                     \
             aes                                                         \
diff --git a/libavutil/hwcontext.c b/libavutil/hwcontext.c
index d13d0f7c9b..92ae8f46a2 100644
--- a/libavutil/hwcontext.c
+++ b/libavutil/hwcontext.c
@@ -62,6 +62,10 @@ static const HWContextType * const hw_table[] = {
 #if CONFIG_VULKAN
     &ff_hwcontext_type_vulkan,
 #endif
+#if CONFIG_MLU
+    &ff_hwcontext_type_mlu,
+#endif
+
     NULL,
 };
 
@@ -77,6 +81,7 @@ static const char *const hw_type_names[] = {
     [AV_HWDEVICE_TYPE_VIDEOTOOLBOX] = "videotoolbox",
     [AV_HWDEVICE_TYPE_MEDIACODEC] = "mediacodec",
     [AV_HWDEVICE_TYPE_VULKAN] = "vulkan",
+    [AV_HWDEVICE_TYPE_MLU]   = "mlu",
 };
 
 enum AVHWDeviceType av_hwdevice_find_type_by_name(const char *name)
diff --git a/libavutil/hwcontext.h b/libavutil/hwcontext.h
index 04d19d89c2..a6c5057e4f 100644
--- a/libavutil/hwcontext.h
+++ b/libavutil/hwcontext.h
@@ -37,6 +37,7 @@ enum AVHWDeviceType {
     AV_HWDEVICE_TYPE_OPENCL,
     AV_HWDEVICE_TYPE_MEDIACODEC,
     AV_HWDEVICE_TYPE_VULKAN,
+    AV_HWDEVICE_TYPE_MLU,
 };
 
 typedef struct AVHWDeviceInternal AVHWDeviceInternal;
diff --git a/libavutil/hwcontext_internal.h b/libavutil/hwcontext_internal.h
index e6266494ac..de6bf2a769 100644
--- a/libavutil/hwcontext_internal.h
+++ b/libavutil/hwcontext_internal.h
@@ -174,5 +174,6 @@ extern const HWContextType ff_hwcontext_type_vdpau;
 extern const HWContextType ff_hwcontext_type_videotoolbox;
 extern const HWContextType ff_hwcontext_type_mediacodec;
 extern const HWContextType ff_hwcontext_type_vulkan;
+extern const HWContextType ff_hwcontext_type_mlu;
 
 #endif /* AVUTIL_HWCONTEXT_INTERNAL_H */
diff --git a/libavutil/hwcontext_mlu.c b/libavutil/hwcontext_mlu.c
new file mode 100644
index 0000000000..3644a390ca
--- /dev/null
+++ b/libavutil/hwcontext_mlu.c
@@ -0,0 +1,436 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#include <dlfcn.h>
+#include "buffer.h"
+#include "common.h"
+#include "hwcontext.h"
+#include "hwcontext_internal.h"
+#include "hwcontext_mlu.h"
+#include "mem.h"
+#include "pixdesc.h"
+#include "pixfmt.h"
+#include "imgutils.h"
+#include "hwcontext_mlu_internal.h"
+
+#define MLU_FRAME_ALIGNMENT 1
+#define CN_CHECK(avctx, ret, msg) {                    \
+    int t_ret = ret;                                   \
+    if (t_ret != 0) {                                  \
+        av_log(avctx, AV_LOG_ERROR, "MluError:%s, ret:%d, func:%s, line:%d\n", \
+            msg, t_ret, __func__, __LINE__);           \
+        goto error;                                    \
+    }                                                  \
+}
+
+#if CONFIG_MLUAFFINITY
+#include <cndev.h>
+#define CNDEV_LIBNAME  "libcndev.so"
+#define MLUDEV_VERSION CNDEV_VERSION_6
+#ifndef mluDevCheckErrors
+#define __mluDevCheckErrors(ctx, err, file, line)                                    \
+    do {                                                                             \
+        mluDevRet_t _err = (err);                                                    \
+        if (0 != _err) {                                                             \
+            fprintf(stderr, "mluDevCheckErrors(%d): %s, from file <%s>, line %i.\n", \
+                _err, ctx->mluDevGetErrorString(_err), (char*)file, line);           \
+            exit(1);                                                                 \
+        }                                                                            \
+    } while (0)
+#define mluDevCheckErrors(ctx, err) __mluDevCheckErrors(ctx, (err), __FILE__, __LINE__)
+#endif
+#endif
+
+typedef struct MLUFramesContext {
+    int shift_width, shift_height;
+} MLUFramesContext_t;
+
+static const enum AVPixelFormat supported_formats[] = {
+    AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+    AV_PIX_FMT_ABGR, AV_PIX_FMT_ARGB,
+    AV_PIX_FMT_BGRA, AV_PIX_FMT_RGBA,
+    AV_PIX_FMT_0BGR, AV_PIX_FMT_0RGB,
+    AV_PIX_FMT_BGR0, AV_PIX_FMT_RGB0,
+    AV_PIX_FMT_NV12, AV_PIX_FMT_NV21,
+    AV_PIX_FMT_P010, AV_PIX_FMT_YUV420P,
+};
+
+static int mlu_frames_get_constraints(AVHWDeviceContext *ctx, const void *hwconfig,
+                                       AVHWFramesConstraints *constraints)
+{
+    int i;
+
+    constraints->valid_sw_formats = av_malloc_array(FF_ARRAY_ELEMS(supported_formats) + 1,
+                                                    sizeof(*constraints->valid_sw_formats));
+    if (!constraints->valid_sw_formats)
+        return AVERROR(ENOMEM);
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++)
+        constraints->valid_sw_formats[i] = supported_formats[i];
+    constraints->valid_sw_formats[FF_ARRAY_ELEMS(supported_formats)] = AV_PIX_FMT_NONE;
+
+    constraints->valid_hw_formats = av_malloc_array(2, sizeof(*constraints->valid_hw_formats));
+    if (!constraints->valid_hw_formats)
+        return AVERROR(ENOMEM);
+
+    constraints->valid_hw_formats[0] = AV_PIX_FMT_MLU;
+    constraints->valid_hw_formats[1] = AV_PIX_FMT_NONE;
+
+    return 0;
+}
+
+static void mlu_buffer_free(void *opaque, uint8_t *data)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    mlu_ctx->mluMemFree(data);
+}
+
+static AVBufferRef *mlu_pool_alloc(void *opaque, int size)
+{
+    AVHWFramesContext        *ctx = opaque;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext     *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    AVBufferRef *ret = NULL;
+    void* data = NULL;
+
+    cnrtRet_t cnrt_ret;
+    cnrt_ret = mlu_ctx->mluMemAlloc((void **)(&data), size);
+    if (cnrt_ret != cnrtSuccess) {
+        av_log(ctx, AV_LOG_ERROR, "cnrtMalloc failed: dev addr %p, size %d \n", data, size);
+        return NULL;
+    }
+    ret = av_buffer_create((uint8_t*)data, size, mlu_buffer_free, ctx, 0);
+    if (!ret) {
+        mlu_ctx->mluMemFree(data);
+    }
+    return ret;
+}
+
+static int mlu_frames_init(AVHWFramesContext *ctx)
+{
+    MLUFramesContext_t *priv = ctx->internal->priv;
+    int i;
+
+    for (i = 0; i < FF_ARRAY_ELEMS(supported_formats); i++) {
+        if (ctx->sw_format == supported_formats[i])
+            break;
+    }
+    if (i == FF_ARRAY_ELEMS(supported_formats)) {
+        av_log(ctx, AV_LOG_ERROR, "Pixel format '%s' is not supported\n",
+               av_get_pix_fmt_name(ctx->sw_format));
+        return AVERROR(ENOSYS);
+    }
+
+    av_pix_fmt_get_chroma_sub_sample(ctx->sw_format, &priv->shift_width, &priv->shift_height);
+
+    if (!ctx->pool) {
+        int size = av_image_get_buffer_size(ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+        if (size < 0)
+            return size;
+
+        ctx->internal->pool_internal = av_buffer_pool_init2(size, ctx, mlu_pool_alloc, NULL);
+        if (!ctx->internal->pool_internal)
+            return AVERROR(ENOMEM);
+    }
+
+    return 0;
+}
+
+static int mlu_get_buffer(AVHWFramesContext *ctx, AVFrame *frame)
+{
+    int res;
+
+    frame->buf[0] = av_buffer_pool_get(ctx->pool);
+    if (!frame->buf[0])
+        return AVERROR(ENOMEM);
+
+    res = av_image_fill_arrays(frame->data, frame->linesize, frame->buf[0]->data,
+                               ctx->sw_format, ctx->width, ctx->height, MLU_FRAME_ALIGNMENT);
+    if (res < 0)
+        return res;
+
+    frame->format = AV_PIX_FMT_MLU;
+    frame->width  = ctx->width;
+    frame->height = ctx->height;
+
+    return 0;
+}
+
+static int mlu_transfer_get_formats(AVHWFramesContext *ctx,
+                                     enum AVHWFrameTransferDirection dir,
+                                     enum AVPixelFormat **formats)
+{
+    enum AVPixelFormat *fmts;
+
+    fmts = av_malloc_array(2, sizeof(*fmts));
+    if (!fmts)
+        return AVERROR(ENOMEM);
+
+    fmts[0] = ctx->sw_format;
+    fmts[1] = AV_PIX_FMT_NONE;
+
+    *formats = fmts;
+
+    return 0;
+}
+
+static int mlu_transfer_data(AVHWFramesContext *ctx, AVFrame *dst,
+                                   const AVFrame *src)
+{
+    // MLUFramesContext_t        *priv = ctx->internal->priv;
+    AVHWDeviceContext *device_ctx = ctx->device_ctx;
+    AVMLUDeviceContext    *hwctx = device_ctx->hwctx;
+    MluContext           *mlu_ctx = hwctx->mlu_ctx;
+
+    int i;
+    size_t nBytes;
+    cnrtRet_t cnrt_ret;
+    for (i = 0; i < FF_ARRAY_ELEMS(src->data) && src->data[i]; i++) {
+        // nBytes = src->linesize[i] * src->height * (i ? 1.0 / 2 : 1);
+        nBytes = FFMIN(src->linesize[i], dst->linesize[i]) * src->height * (i ? 1.0 / 2 : 1);
+        if (src->hw_frames_ctx && dst->hw_frames_ctx) {
+            cnrt_ret = mlu_ctx->mluMemcpyD2D(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_DEV2DEV);
+            if (cnrt_ret != CNRT_RET_SUCCESS) {
+                av_log(ctx, AV_LOG_ERROR, "d2d: dev %p -> dev %p, size %lu \n", src->data[i], dst->data[i], nBytes);
+                av_log(ctx, AV_LOG_ERROR, "mluMemcpyD2D error occur, func: %s, line: %d\n", __func__, __LINE__);
+                return -1;
+            }
+        } else if (src->hw_frames_ctx) {
+            cnrt_ret = mlu_ctx->mluMemcpyD2H(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_DEV2HOST);
+            if (cnrt_ret != cnrtSuccess) {
+                av_log(ctx, AV_LOG_ERROR, "d2h: dev %p -> host %p size %lu \n", src->data[i], dst->data[i], nBytes);
+                av_log(ctx, AV_LOG_ERROR, " mluMemcpyD2H error occur, fuc: %s, line:%d\n", __func__, __LINE__);
+                return -1;
+            }
+        } else if (dst->hw_frames_ctx) {
+            cnrt_ret = mlu_ctx->mluMemcpyH2D(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_HOST2DEV);
+            if (cnrt_ret != CNRT_RET_SUCCESS) {
+                av_log(ctx, AV_LOG_ERROR, "h2d: host %p -> dev %p, size %lu \n", src->data[i], dst->data[i], nBytes);
+                av_log(ctx, AV_LOG_ERROR, "mluMemcpyH2D error occur, func: %s, line: %d\n", __func__, __LINE__);
+                return -1;
+            }
+        } else {
+            cnrt_ret = mlu_ctx->mluMemcpyH2H(dst->data[i], src->data[i], nBytes, CNRT_MEM_TRANS_DIR_HOST2HOST);
+            if (cnrt_ret != CNRT_RET_SUCCESS) {
+                av_log(ctx, AV_LOG_ERROR, "h2h: host %p -> host %p, size %lu \n", src->data[i], dst->data[i], nBytes);
+                av_log(ctx, AV_LOG_ERROR, "mluMemcpyH2H error occur, func: %s, line: %d\n", __func__, __LINE__);
+                return -1;
+            }
+        }
+    }
+
+    return 0;
+}
+
+static void mlu_device_uninit(AVHWDeviceContext *device_ctx)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+#if CONFIG_MLUAFFINITY
+    hwctx->mlu_ctx->mluDevRelease();
+#endif
+    if (hwctx->cnrt_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->cnrt_lib);
+        hwctx->cnrt_lib = NULL;
+    }
+    if (hwctx->cndev_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->cndev_lib);
+        hwctx->cndev_lib = NULL;
+    }
+    if (hwctx->mluop_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->mluop_lib);
+        hwctx->mluop_lib = NULL;
+    }
+    if (hwctx->mlu_ctx) {
+        av_freep(&hwctx->mlu_ctx);
+        hwctx->mlu_ctx = NULL;
+    }
+}
+
+static int mlu_device_init(AVHWDeviceContext *ctx)
+{
+    AVMLUDeviceContext *hwctx = ctx->hwctx;
+    if (!hwctx->mlu_ctx) {
+        hwctx->mlu_ctx = av_mallocz(sizeof(*hwctx->mlu_ctx));
+        if (!hwctx->mlu_ctx)
+            return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static int mlu_load_functions(AVMLUDeviceContext *hwctx, void *ctx) {
+    MluContext *mlu_ctx = hwctx->mlu_ctx;
+
+#if CONFIG_MLU
+    MLU_LOAD_LIBRARY(hwctx->cnrt_lib, CNRT_LIBNAME);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluGetDevice, mluGetDevice_t, "cnrtGetDevice", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluSetDevice, mluSetDevice_t, "cnrtSetDevice", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluGetDeviceProp, mluGetDeviceProp_t, "cnrtGetDeviceProperties", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluGetDeviceCount,mluGetDeviceCount_t, "cnrtGetDeviceCount", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemAlloc, mluMemAlloc_t, "cnrtMalloc", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemFree, mluMemFree_t, "cnrtFree", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyH2D, mluMemcpyH2D_t, "cnrtMemcpy", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyD2H, mluMemcpyD2H_t, "cnrtMemcpy", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyD2D, mluMemcpyD2D_t, "cnrtMemcpy", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyH2H, mluMemcpyH2H_t, "cnrtMemcpy", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyH2DAsync, mluMemcpyH2DAsync_t, "cnrtMemcpyAsync", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyD2HAsync, mluMemcpyD2HAsync_t, "cnrtMemcpyAsync", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyD2DAsync, mluMemcpyD2DAsync_t, "cnrtMemcpyAsync", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluMemcpyH2HAsync, mluMemcpyH2HAsync_t, "cnrtMemcpyAsync", hwctx->cnrt_lib);
+
+    MLU_LOAD_SYMBOL(mlu_ctx->mluQueueSync, mluQueueSync_t, "cnrtQueueSync", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluQueueCreate, mluQueueCreate_t, "cnrtQueueCreate", hwctx->cnrt_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluQueueDestroy, mluQueueDestroy_t, "cnrtQueueDestroy", hwctx->cnrt_lib);
+#endif
+#if CONFIG_MLUFILTER
+    MLU_LOAD_LIBRARY(hwctx->mluop_lib, MLUOP_LIBNAME);
+    MLU_LOAD_SYMBOL_OPT(mlu_ctx->mluOpGetVersion, mluOpGetVersion_t, "mluOpGetVersion", hwctx->mluop_lib);
+    mlu_ctx->mluOpGetVersion = (mluOpGetVersion_t*)FFCN_SYM_FUNC(hwctx->mluop_lib, "mluOpGetVersion");
+    if (mlu_ctx->mluOpGetVersion) {
+        FFCN_DEBUG_LOG(NULL, "Mluop Version:%d\n", mlu_ctx->mluOpGetVersion());
+    }
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2RgbxInit, mluCvtRgbx2RgbxInit_t, "mluOpConvertRgbx2RgbxInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2RgbxExec, mluCvtRgbx2RgbxExec_t, "mluOpConvertRgbx2RgbxExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2RgbxDestroy, mluCvtRgbx2RgbxDestroy_t, "mluOpConvertRgbx2RgbxDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2YuvInit, mluCvtRgbx2YuvInit_t, "mluOpConvertRgbx2YuvInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2YuvExec, mluCvtRgbx2YuvExec_t, "mluOpConvertRgbx2YuvExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtRgbx2YuvDestroy, mluCvtRgbx2YuvDestroy_t, "mluOpConvertRgbx2YuvDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtYuv2RgbxInit, mluCvtYuv2RgbxInit_t, "mluOpConvertYuv2RgbxInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtYuv2RgbxExec, mluCvtYuv2RgbxExec_t, "mluOpConvertYuv2RgbxExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluCvtYuv2RgbxDestroy, mluCvtYuv2RgbxDestroy_t, "mluOpConvertYuv2RgbxDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleCvtYuv2RgbxInit, mluScaleCvtYuv2RgbxInit_t, "mluOpResizeCvtInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleCvtYuv2RgbxExec, mluScaleCvtYuv2RgbxExec_t, "mluOpResizeCvtExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleCvtYuv2RgbxDestroy, mluScaleCvtYuv2RgbxDestroy_t, "mluOpResizeCvtDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleRgbxInit, mluScaleRgbxInit_t, "mluOpResizeRgbxInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleRgbxExec, mluScaleRgbxExec_t, "mluOpResizeRgbxExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleRgbxExecPad, mluScaleRgbxExecPad_t, "mluOpResizeRgbxExecPad", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleRgbxExecCrop, mluScaleRgbxExecCrop_t, "mluOpResizeRgbxExecRoi", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleRgbxDestroy, mluScaleRgbxDestroy_t, "mluOpResizeRgbxDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleYuvInit, mluScaleYuvInit_t, "mluOpResizeYuvInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleYuvExec, mluScaleYuvExec_t, "mluOpResizeYuvExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleYuvExecPad, mluScaleYuvExecPad_t, "mluOpResizeYuvExecPad", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleYuvExecCrop, mluScaleYuvExecCrop_t, "mluOpResizeYuvExecRoi", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluScaleYuvDestroy, mluScaleYuvDestroy_t, "mluOpResizeYuvDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluOverlayInit, mluOverlayInit_t, "mluOpOverlayInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluOverlayExec, mluOverlayExec_t, "mluOpOverlayExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluOverlayDestroy, mluOverlayDestroy_t, "mluOpOverlayDestroy", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluRotateInit, mluRotateInit_t, "mluOpRotateInit", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluRotateExec, mluRotateExec_t, "mluOpRotateExec", hwctx->mluop_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluRotateDestroy, mluRotateDestroy_t, "mluOpRotateDestroy", hwctx->mluop_lib);
+#endif
+#if CONFIG_MLUAFFINITY
+    MLU_LOAD_LIBRARY(hwctx->cndev_lib, CNDEV_LIBNAME);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevGetErrorString, mluDevGetErrorString_t, "cndevGetErrorString", hwctx->cndev_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevInit, mluDevInit_t, "cndevInit", hwctx->cndev_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevRelease, mluDevRelease_t, "cndevRelease", hwctx->cndev_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevGetDeviceHandleByIndex, mluDevGetDeviceHandleByIndex_t, "cndevGetDeviceHandleByIndex", hwctx->cndev_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevClearCurrentThreadAffinity, mluDevClearCurrentThreadAffinity_t, "cndevClearCurrentThreadAffinity", hwctx->cndev_lib);
+    MLU_LOAD_SYMBOL(mlu_ctx->mluDevSetCurrentThreadAffinity, mluDevSetCurrentThreadAffinity_t, "cndevSetCurrentThreadAffinity", hwctx->cndev_lib);
+#endif
+
+    return 0;
+
+error:
+    if (hwctx->cnrt_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->cnrt_lib);
+        hwctx->cnrt_lib = NULL;
+    }
+    if (hwctx->cndev_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->cndev_lib);
+        hwctx->cndev_lib = NULL;
+    }
+    if (hwctx->mluop_lib) {
+        MLU_UNLOAD_LIBRARY(hwctx->mluop_lib);
+        hwctx->mluop_lib = NULL;
+    }
+    mlu_ctx = NULL;
+    return AVERROR_EXTERNAL;
+}
+
+static int mlu_device_create(AVHWDeviceContext *device_ctx,
+                              const char *device,
+                              AVDictionary *opts, int flags)
+{
+    AVMLUDeviceContext *hwctx = device_ctx->hwctx;
+    MluContext *mlu_ctx = NULL;
+
+    int mlu = 0;
+    int dev_hdl    = 0;
+    unsigned int dev_num = 0;
+    if (device) mlu = strtol(device, NULL, 0);
+    CN_CHECK(device_ctx, mlu_device_init(device_ctx), "mlu_device_init failed");
+    CN_CHECK(device_ctx, mlu_load_functions(hwctx, device_ctx), "mlu_load_functions failed");
+
+    mlu_ctx = hwctx->mlu_ctx;
+    mlu_ctx->mlu_id = mlu;
+#if CONFIG_MLUAFFINITY
+    mlu_ctx->dev_version = MLUDEV_VERSION;
+    mlu_ctx->mluDevInit(0);
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevGetDeviceHandleByIndex(mlu_ctx->mlu_id, &dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevClearCurrentThreadAffinity(MLUDEV_VERSION, dev_hdl));
+    mluDevCheckErrors(mlu_ctx, mlu_ctx->mluDevSetCurrentThreadAffinity(MLUDEV_VERSION, dev_hdl));
+#endif
+    CN_CHECK(device_ctx, mlu_ctx->mluGetDeviceCount(&dev_num), "mluGetDeviceCount failed");
+    if (dev_num == 0) {
+        av_log(device_ctx, AV_LOG_ERROR, "Can't find MLU card, or dev count is 0 \n");
+        goto error;
+    }
+    av_log(device_ctx, AV_LOG_DEBUG, "Got mlu count num:%d\n", dev_num);
+
+    CN_CHECK(device_ctx, mlu_ctx->mluSetDevice(mlu), "mluSetDevice failed");
+    CN_CHECK(device_ctx, mlu_ctx->mluGetDevice(&dev_hdl), "mluGetDevice failed");
+    CN_CHECK(device_ctx, mlu_ctx->mluGetDeviceProp(&mlu_ctx->dev_prop, dev_hdl), "mluGetDeviceProp failed");
+    av_log(device_ctx, AV_LOG_DEBUG, "dev id:%d, dev name:%s\n", dev_hdl, mlu_ctx->dev_prop.name);
+
+    return 0;
+
+error:
+    mlu_device_uninit(device_ctx);
+    return AVERROR_UNKNOWN;
+}
+
+#undef CN_CHECK
+
+const HWContextType ff_hwcontext_type_mlu = {
+    .type                 = AV_HWDEVICE_TYPE_MLU,
+    .name                 = "MLU",
+
+    .device_hwctx_size    = sizeof(AVMLUDeviceContext),
+    .frames_priv_size     = sizeof(MLUFramesContext_t),
+
+    .device_create        = mlu_device_create,
+    .device_init          = mlu_device_init,
+    .device_uninit        = mlu_device_uninit,
+    .frames_get_constraints = mlu_frames_get_constraints,
+    .frames_init          = mlu_frames_init,
+    .frames_get_buffer    = mlu_get_buffer,
+    .transfer_get_formats = mlu_transfer_get_formats,
+    .transfer_data_to     = mlu_transfer_data,
+    .transfer_data_from   = mlu_transfer_data,
+
+    .pix_fmts             = (const enum AVPixelFormat[]){ AV_PIX_FMT_MLU, AV_PIX_FMT_NONE },
+};
diff --git a/libavutil/hwcontext_mlu.h b/libavutil/hwcontext_mlu.h
new file mode 100644
index 0000000000..8abb8b5e60
--- /dev/null
+++ b/libavutil/hwcontext_mlu.h
@@ -0,0 +1,170 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+*/
+
+#ifndef AVUTIL_HWCONTEXT_MLU_H
+#define AVUTIL_HWCONTEXT_MLU_H
+
+#include <cnrt.h>
+#include "pixfmt.h"
+
+#define MLUAPI
+typedef int mluDevRet_t;
+typedef int mluRet_t;
+
+#if CONFIG_MLU
+typedef mluRet_t MLUAPI mluGetDevice_t(int*);
+typedef mluRet_t MLUAPI mluSetDevice_t(int);
+typedef mluRet_t MLUAPI mluGetDeviceProp_t(cnrtDeviceProp_t *, int);
+typedef mluRet_t MLUAPI mluGetDeviceCount_t(int *);
+typedef mluRet_t MLUAPI mluMemFree_t(void *);
+typedef mluRet_t MLUAPI mluMemAlloc_t(void **, size_t);
+typedef mluRet_t MLUAPI mluMemcpyH2D_t(void *, void *, size_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyD2H_t(void *, void *, size_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyD2D_t(void *, void *, size_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyH2H_t(void *, void *, size_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyH2DAsync_t(void *, void *, size_t, cnrtQueue_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyD2HAsync_t(void *, void *, size_t, cnrtQueue_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyD2DAsync_t(void *, void *, size_t, cnrtQueue_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluMemcpyH2HAsync_t(void *, void *, size_t, cnrtQueue_t, cnrtMemTransDir_t);
+typedef mluRet_t MLUAPI mluQueueCreate_t(cnrtQueue_t *);
+typedef mluRet_t MLUAPI mluQueueSync_t(cnrtQueue_t);
+typedef mluRet_t MLUAPI mluQueueDestroy_t(cnrtQueue_t);
+#endif
+#if CONFIG_MLUFILTER
+typedef int MLUAPI mluOpGetVersion_t(void);
+typedef int MLUAPI mluCvtRgbx2RgbxInit_t(void**, int, int, const char*, const char*, const char*);
+typedef int MLUAPI mluCvtRgbx2RgbxExec_t(void*, void*, void*);
+typedef int MLUAPI mluCvtRgbx2RgbxDestroy_t(void*);
+typedef int MLUAPI mluCvtRgbx2YuvInit_t(void**, int, int, const char*, const char*, const char*);
+typedef int MLUAPI mluCvtRgbx2YuvExec_t(void*, void*, void*, void*);
+typedef int MLUAPI mluCvtRgbx2YuvDestroy_t(void*);
+typedef int MLUAPI mluCvtYuv2RgbxInit_t(void**, int, int, const char*, const char*, const char*);
+typedef int MLUAPI mluCvtYuv2RgbxExec_t(void*, void*, void*, void*);
+typedef int MLUAPI mluCvtYuv2RgbxDestroy_t(void*);
+typedef int MLUAPI mluScaleCvtYuv2RgbxInit_t(void**, int, int, int, int, const char*, const char*, const char*);
+typedef int MLUAPI mluScaleCvtYuv2RgbxExec_t(void*, void*, void*, void*);
+typedef int MLUAPI mluScaleCvtYuv2RgbxDestroy_t(void*);
+typedef int MLUAPI mluScaleRgbxInit_t(void**, int, int, int, int, const char*, const char*);
+typedef int MLUAPI mluScaleRgbxExec_t(void*, void*, void*);
+typedef int MLUAPI mluScaleRgbxExecPad_t(void*, void*, void*);
+typedef int MLUAPI mluScaleRgbxExecCrop_t(void*, void*, void*, int, int, int, int, int, int, int, int);
+typedef int MLUAPI mluScaleRgbxDestroy_t(void*);
+typedef int MLUAPI mluScaleYuvInit_t(void**, int, int, int, int, const char*, const char*);
+typedef int MLUAPI mluScaleYuvExec_t(void*, void*, void*, void*, void*);
+typedef int MLUAPI mluScaleYuvExecPad_t(void*, void*, void*, void*, void*);
+typedef int MLUAPI mluScaleYuvExecCrop_t(void*, void*, void*, void*, void*, int, int, int, int, int, int, int, int);
+typedef int MLUAPI mluScaleYuvDestroy_t(void*);
+typedef int MLUAPI mluOverlayInit_t(void**, uint32_t, uint32_t, const char *, const char *, const char *);
+typedef int MLUAPI mluOverlayExec_t(void*, void*, void*, void*, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, uint32_t, float, float, float);
+typedef int MLUAPI mluOverlayDestroy_t(void*);
+typedef int MLUAPI mluRotateInit_t(void**, uint32_t, uint32_t, double, const char *, const char *, const uint8_t *);
+typedef int MLUAPI mluRotateExec_t(void*, void*, void*);
+typedef int MLUAPI mluRotateDestroy_t(void*);
+#endif
+#if CONFIG_MLUAFFINITY
+typedef const char* MLUAPI mluDevGetErrorString_t(mluDevRet_t errorId);
+typedef mluDevRet_t MLUAPI mluDevInit_t(int);
+typedef mluDevRet_t MLUAPI mluDevRelease_t();
+typedef mluDevRet_t MLUAPI mluDevGetDeviceHandleByIndex_t(int index, int *handle);
+typedef mluDevRet_t MLUAPI mluDevClearCurrentThreadAffinity_t(int version, int device);
+typedef mluDevRet_t MLUAPI mluDevSetCurrentThreadAffinity_t(int version, int device);
+#endif
+typedef struct MluContext {
+    int mlu_id;
+#if CONFIG_MLU
+    cnrtDeviceProp_t      dev_prop;
+    mluGetDevice_t       *mluGetDevice;
+    mluGetDeviceProp_t   *mluGetDeviceProp;
+    mluGetDeviceCount_t  *mluGetDeviceCount;
+    mluSetDevice_t       *mluSetDevice;
+    mluMemFree_t         *mluMemFree;
+    mluMemAlloc_t        *mluMemAlloc;
+    mluMemcpyH2D_t       *mluMemcpyH2D;
+    mluMemcpyD2H_t       *mluMemcpyD2H;
+    mluMemcpyD2D_t       *mluMemcpyD2D;
+    mluMemcpyH2H_t       *mluMemcpyH2H;
+    mluMemcpyH2DAsync_t  *mluMemcpyH2DAsync;
+    mluMemcpyD2HAsync_t  *mluMemcpyD2HAsync;
+    mluMemcpyD2DAsync_t  *mluMemcpyD2DAsync;
+    mluMemcpyH2HAsync_t  *mluMemcpyH2HAsync;
+    mluQueueSync_t       *mluQueueSync;
+    mluQueueCreate_t     *mluQueueCreate;
+    mluQueueDestroy_t    *mluQueueDestroy;
+#endif
+#if CONFIG_MLUFILTER
+    mluOpGetVersion_t            *mluOpGetVersion;
+    mluCvtRgbx2RgbxInit_t        *mluCvtRgbx2RgbxInit;
+    mluCvtRgbx2RgbxExec_t        *mluCvtRgbx2RgbxExec;
+    mluCvtRgbx2RgbxDestroy_t     *mluCvtRgbx2RgbxDestroy;
+    mluCvtRgbx2YuvInit_t         *mluCvtRgbx2YuvInit;
+    mluCvtRgbx2YuvExec_t         *mluCvtRgbx2YuvExec;
+    mluCvtRgbx2YuvDestroy_t      *mluCvtRgbx2YuvDestroy;
+    mluCvtYuv2RgbxInit_t         *mluCvtYuv2RgbxInit;
+    mluCvtYuv2RgbxExec_t         *mluCvtYuv2RgbxExec;
+    mluCvtYuv2RgbxDestroy_t      *mluCvtYuv2RgbxDestroy;
+    mluScaleCvtYuv2RgbxInit_t    *mluScaleCvtYuv2RgbxInit;
+    mluScaleCvtYuv2RgbxExec_t    *mluScaleCvtYuv2RgbxExec;
+    mluScaleCvtYuv2RgbxDestroy_t *mluScaleCvtYuv2RgbxDestroy;
+    mluScaleRgbxInit_t           *mluScaleRgbxInit;
+    mluScaleRgbxExec_t           *mluScaleRgbxExec;
+    mluScaleRgbxExecPad_t        *mluScaleRgbxExecPad;
+    mluScaleRgbxExecCrop_t       *mluScaleRgbxExecCrop;
+    mluScaleRgbxDestroy_t        *mluScaleRgbxDestroy;
+    mluScaleYuvInit_t            *mluScaleYuvInit;
+    mluScaleYuvExec_t            *mluScaleYuvExec;
+    mluScaleYuvExecPad_t         *mluScaleYuvExecPad;
+    mluScaleYuvExecCrop_t        *mluScaleYuvExecCrop;
+    mluScaleYuvDestroy_t         *mluScaleYuvDestroy;
+    mluOverlayInit_t             *mluOverlayInit;
+    mluOverlayExec_t             *mluOverlayExec;
+    mluOverlayDestroy_t          *mluOverlayDestroy;
+    mluRotateInit_t              *mluRotateInit;
+    mluRotateExec_t              *mluRotateExec;
+    mluRotateDestroy_t           *mluRotateDestroy;
+#endif
+#if CONFIG_MLUAFFINITY
+    int dev_version;
+    mluDevGetErrorString_t             *mluDevGetErrorString;
+    mluDevInit_t                       *mluDevInit;
+    mluDevRelease_t                    *mluDevRelease;
+    mluDevGetDeviceHandleByIndex_t     *mluDevGetDeviceHandleByIndex;
+    mluDevClearCurrentThreadAffinity_t *mluDevClearCurrentThreadAffinity;
+    mluDevSetCurrentThreadAffinity_t   *mluDevSetCurrentThreadAffinity;
+#endif
+} MluContext;
+
+/**
+ * @file
+ * This struct is allocated as AVHWDeviceContext.hwctx
+ */
+typedef struct AVMLUDeviceContext {
+    void *cnrt_lib;
+    void *cndev_lib;
+    void *mluop_lib;
+    MluContext *mlu_ctx;
+} AVMLUDeviceContext;
+
+/**
+ * AVHWFramesContext.hwctx is currently not used
+ */
+
+#endif /* AVUTIL_HWCONTEXT_MLU_H */
diff --git a/libavutil/hwcontext_mlu_internal.h b/libavutil/hwcontext_mlu_internal.h
new file mode 100644
index 0000000000..4865e89602
--- /dev/null
+++ b/libavutil/hwcontext_mlu_internal.h
@@ -0,0 +1,86 @@
+/*
+* Copyright (c) 2020, CAMBRICON CORPORATION. All rights reserved.
+*
+* Permission is hereby granted, free of charge, to any person obtaining a
+* copy of this software and associated documentation files (the "Software"),
+* to deal in the Software without restriction, including without limitation
+* the rights to use, copy, modify, merge, publish, distribute, sublicense,
+* and/or sell copies of the Software, and to permit persons to whom the
+* Software is furnished to do so, subject to the following conditions:
+*
+* The above copyright no5tice and this permission notice shall be included in
+* all copies or substantial portions of the Software.
+*
+* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+* IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+* FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+* THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+* LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+* FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
+* DEALINGS IN THE SOFTWARE.
+ */
+
+#ifndef AVUTIL_MLU_DL_LOADER_H
+#define AVUTIL_MLU_DL_LOADER_H
+
+#include <stdlib.h>
+#include <cnrt.h>
+#include "log.h"
+
+#define FFCN_LIB_HANDLE void*
+
+#define CNRT_LIBNAME  "libcnrt.so"
+#define MLUOP_LIBNAME "libcncv.so"
+
+#if !defined(FFCN_LOAD_FUNC) || !defined(FFCN_SYM_FUNC)
+#  include <dlfcn.h>
+#  define FFCN_LOAD_FUNC(path)    dlopen((path), RTLD_LAZY)
+#  define FFCN_SYM_FUNC(lib, sym) dlsym((lib), (sym))
+#  define FFCN_FREE_FUNC(lib)     dlclose(lib)
+# endif
+
+#if !defined(FFCN_ERROR_LOG) || !defined(FFCN_INFO_LOG)
+# include <stdio.h>
+# define FFCN_INFO_LOG(ctx, msg, ...)    \
+            av_log(ctx, AV_LOG_INFO, (msg), __VA_ARGS__)
+# define FFCN_ERROR_LOG(ctx, msg, ...)   \
+            av_log(ctx, AV_LOG_ERROR, (msg), __VA_ARGS__)
+# define FFCN_DEBUG_LOG(ctx, msg, ...)   \
+            av_log(ctx, AV_LOG_DEBUG, (msg), __VA_ARGS__)
+# define FFCN_WARNING_LOG(ctx, msg, ...) \
+            av_log(ctx, AV_LOG_WARNING, (msg), __VA_ARGS__)
+#endif
+
+#define MLU_LOAD_LIBRARY(lib, path)                                 \
+    do {                                                            \
+        if (!(lib = FFCN_LOAD_FUNC(path))) {                        \
+            FFCN_ERROR_LOG(NULL, "Cannot load %s\n", path);         \
+            goto error;                                             \
+        }                                                           \
+        FFCN_DEBUG_LOG(NULL, "Loaded lib:%s, ptr:%p\n", path, lib); \
+    } while (0)
+
+#define MLU_UNLOAD_LIBRARY(lib)                                     \
+    do {                                                            \
+        FFCN_FREE_FUNC(lib);                                        \
+        FFCN_DEBUG_LOG(NULL, "Unloaded lib:%p\n", lib);             \
+    } while (0)
+
+#define MLU_LOAD_SYMBOL(fun, tp, symbol, lib)                       \
+    do {                                                            \
+        if (!(fun = (tp*)FFCN_SYM_FUNC(lib, symbol))) {             \
+            FFCN_ERROR_LOG(NULL, "Cannot load %s\n", symbol);       \
+            goto error;                                             \
+        }                                                           \
+        FFCN_DEBUG_LOG(NULL, "Loaded sym: %s\n", symbol);           \
+    } while (0)
+
+#define MLU_LOAD_SYMBOL_OPT(fun, tp, symbol, lib)                   \
+    do {                                                            \
+        if (!(fun = (tp*)FFCN_SYM_FUNC(lib, symbol))) {             \
+            FFCN_ERROR_LOG(NULL, "Cannot load optional %s\n", symbol);\
+        } else {                                                    \
+            FFCN_DEBUG_LOG(NULL, "Loaded sym: %s\n", symbol);       \
+        }                                                           \
+    } while (0)
+#endif
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index 18c7a0efc8..d41a34ec27 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -2395,6 +2395,11 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         .name = "vulkan",
         .flags = AV_PIX_FMT_FLAG_HWACCEL,
     },
+    [AV_PIX_FMT_MLU] = {
+        .name = "mlu",
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
+
 };
 #if FF_API_PLUS1_MINUS1
 FF_ENABLE_DEPRECATION_WARNINGS
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 46ef211add..a99ff80568 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -360,6 +360,13 @@ enum AVPixelFormat {
 
     AV_PIX_FMT_X2RGB10LE, ///< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), little-endian, X=unused/undefined
     AV_PIX_FMT_X2RGB10BE, ///< packed RGB 10:10:10, 30bpp, (msb)2X 10R 10G 10B(lsb), big-endian, X=unused/undefined
+
+    /**
+     * HW acceleration through MLU. data[i] contain mlu deviceptr pointers
+     * exactly as for system memory frames.
+     */
+    AV_PIX_FMT_MLU,
+
     AV_PIX_FMT_NB         ///< number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
 };
 
-- 
2.25.1

